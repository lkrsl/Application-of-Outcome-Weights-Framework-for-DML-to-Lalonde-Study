---
title: "Replication and Extension of Imbens & Xu (2024) Tutorial - LaLonde-Dehejia-Wahba (LDW) Data" 
output: html_document
date: "2025-05-08"
---

# LaLonde-Dehejia-Wahba (LDW) Data
LaLonde (1986) evaluated the effect of the National Supported Work Demonstration (NSW) program on both female and male participants. While the female participants were drawn from the Aid to Families with Dependent Children (AFDC) program, the male participants were drawn from three other groups: former drug addicts, ex-criminal offenders, and high-school dropouts. LaLonde relied on two main data sources:
(1) CPS-SSA-1, based on Westat’s Matched Current Population Survey–Social Security Administration File for individuals under 55 matching specific criteria;
(2) PSID-1, based on Panel Study of Income Dynamics for household heads under 55 from specific years who were not retired in 1975, adjusted for factors like employment status and poverty level, resulting in four additional comparison groups;

Dehejia and Wahba (1999) constructed a subset of LaLonde's original data, retaining 62% of observations and restricting the focus to male participants based on their 1974 earnings. As the dataset was formed entirely on pretreatment information like employment records or month of assignment, treatment allocation was effectively independent of all pretreatment variables. Thus they concluded that this subset, known as the LaLonde-Dehejia-Wahba (LDW) data, constitutes a valid experimental sample.

The analysis in section 2 and 3 builds on the LDW data and considers in total three samples: 
(1) LDW-Experimental, consisting of 185 treated individuals and 280 controls from the experimental data;
(2) LDW-CPS1, which pairs the same treated sample with 15,992 controls from CPS-SSA-1;
(3) LDW-PSID1, featuring the same treated sample with 2,490 controls from PSID-1; 
In section 4, the analysis applies the same set of statistical tools to analyze a fourth sample as an additional demonstration:
(4) Lalonde male samples (1986).

This section covers Model B, which, similar to Model A, uses 1978 earnings (`re78`) as the outcome variable but adjusts for a slightly different set of covariates: age, education, race indicators (black, hispanic), marital status, lack of a high school degree, 1975 earnings (`re75`), and unemployment status in 1974 and 1975 (`u74`, `u75`), explicitly excluding 1974 earnings (`re74`) to test the model’s robustness. The model is specified via a logistic regression formula based on these covariates. To enhance covariate balance and overlap between treated and control groups, the same comprehensive suite of methods is employed as in Model A, organized into five categories. From these approaches, the top 5 methods are selected based on absolute standardized mean differences and effective sample size, and their resulting datasets are used to estimate the Average Treatment Effect on the Treated (ATT). This estimation process also incorporates the Augmented Inverse Probability Weighting (AIPW) estimator from the `OutcomeWeights` R package. As with Model A, placebo analyses using 1975 earnings as an outcome and sensitivity analyses are performed to assess bias and the robustness of the causal inference assumptions. 

# Set up
## Source functions and load data
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("/Users/laurakreisel/Workspace/uni/semester04/thesis/lalonde/code/replication/tutorial/functions.R")
```

```{r}
# load data
load("/Users/laurakreisel/Workspace/uni/semester04/thesis/lalonde/code/replication/data/lalonde.RData")
```

## Inspect data
```{r}
#| code-fold: show
# collect datasets in a list
data <- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid)

# inspect each datasets summary statistics
summary_stats <- inspect_data(data)
print(summary_stats)

# display first 5 rows of each dataset
lapply(data, head, 5)
```

## Load and preprocess data (LaLonde-Dehejia-Wahba (LDW))
```{r}
#| code-fold: show
# assigns 1 to the experimental controls
ldw_co$treat <- 1

# merge experimental data with CPS1 data
ldw_cps_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 obs)
  ldw_cps    # CPS1 data (16177 obs)
)

# merge experimental data with PSID1 data
ldw_psid_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 obs)
  ldw_psid   # PSID1 data (2675 obs)
)

datasets <- list(ldw_cps_plus  = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus)

# inspect each dataset
summary_stats_plus <- inspect_data(datasets)
print(summary_stats_plus)

# display first 5 rows of each dataset
lapply(datasets, head, 5)
```

# Model B
```{r}
#| code-fold: show
# define variables
Y <- "re78" 
treat <- "treat" 
covar <- c("age", "education", "black", "hispanic", "married", 
           "nodegree", "re75", "u74", "u75") #re74 excluded
```

## Assessing overlap 

To identify the average causal effect under unconfoundedness (that ensures that the treatment assignment is independent of the potential outcomes), it must be ensured that one can estimate the average effect at every value for the covariates. Thus, overlaps between the treated and control units (meaning that for every combination of covariates, there are both treated and control units in the dataset) are required. The `assess_overlap()` function of Imbens & Xu (2024) is used to assess the overlaps in the propensity scores and use histograms to visualize results.

In a properly balanced experimental design, the distributions of the treatment group (red) and the control group (gray) would show considerable overlap.
```{r, class.source = "fold-show", fig.cap='FIGURE1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1.',out.width='100%', fig.asp=0.5}
#| code-fold: show
# assess overlap
ldw.ps <- assess_overlap(data = ldw, treat = treat, cov = covar)
ldw_cps.ps <- assess_overlap(data = ldw_cps, treat = treat, cov = covar) 
ldw_psid.ps <- assess_overlap(data = ldw_psid, treat = treat, cov = covar) 
```

As anticipated, the LDW-Experimental data exhibit an almost perfect overlap. In contrast, the observational datasets LDW-CPS1 and LDW-PSID1 display weak overlap. In particular, many treated units have propensity scores outside the range of the controls, while a large share of control units are concentrated at very low log-odds.

Next, we examine the overlap of the expanded datasets. 
```{r, class.source = "fold-show", fig.cap='FIGURE2. SubfigureA:LDW-CPS1-PLUS. SubfigureD:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
#| code-fold: show
# assess overlap
ldw_cps_plus.ps <- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) 
ldw_psid_plus.ps <- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) 
```

In the subsequent analysis that is focused on improving covariate balance and overlap, only the two datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS are used. The LDW-Experimental data is excluded from these steps, as randomization already ensures adequate covariate balance and good overlap.

Next we set up a model formula that is used in the following analysis.
```{r}
#| code-fold: show
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

## Improving covariate balance
### Matching 
#### Distance Matching
##### 1:1 Nearest neighbor matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform nearest neighbor matching with k=1, logistic propensity score and replacement
m.out.cps_plus.nearest <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", replace = TRUE)
m.out.psid_plus.nearest <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", replace = TRUE)
```

##### k:1 matching (k=2)
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
k<-2
# perform nearest neighbor matching with k=2, logistic propensity score and replacement
m.out.cps_plus.k2 <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid_plus.k2 <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### k:1 matching (k=3)
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
k<-3
# perform nearest neighbor matching with k=3, logistic propensity score and replacement
m.out.cps_plus.k3 <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid_plus.k3 <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### Caliper matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform nearest neighbor matching with a caliper of 0.1 on the propensity score logit
m.out.cps_plus.caliper <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
m.out.psid_plus.caliper <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
```

##### Common support restriction matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform nearest neighbor matching with exclusion of units outside common support
m.out.cps_plus.cs <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
m.out.psid_plus.cs <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
```

##### Mahalanobis distance matching (mahvars) 
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform nearest neighbor matching using mahalanobis distance on selected covariates
m.out.cps_plus.mahvars <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re74 + re75, replace = FALSE)
m.out.psid_plus.mahvars <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re74 + re75, replace = FALSE)
```

##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.cps_plus.optimal_pair <- matchit(model, data = ldw_cps_plus, method = "optimal", distance = "logit")
m.out.psid_plus.optimal_pair <- matchit(model, data = ldw_psid_plus, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform optimal full matching allowing sets with varying ratios of treated to controls, minimizing a global distance criterion
m.out.cps_plus.optimal_full <- matchit(model, data = ldw_cps_plus, method = "full", distance = "logit")
m.out.psid_plus.optimal_full <- matchit(model, data = ldw_psid_plus, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform generalized full matching using fast approximation, producing matched sets with flexible treated/control ratios 
m.out.cps_plus.general_full <- matchit(model, data = ldw_cps_plus, method = "quick", distance = "logit")
m.out.psid_plus.general_full <- matchit(model, data = ldw_psid_plus, method = "quick", distance = "logit")
```

##### Genetic matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# perform genetic matching
m.out.cps_plus.genetic <- matchit(model, data = ldw_cps_plus, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
m.out.psid_plus.genetic <- matchit(model, data = ldw_psid_plus, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
```

#### Stratum matching
##### Exact matching (exact)
Strata = unique covariate profiles (raw covariates)
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# match units exactly by raw covariate profiles 
m.out.cps_plus.exact <- matchit(model, data = ldw_cps_plus, method = "exact")
m.out.psid_plus.exact <- matchit(model, data = ldw_psid_plus, method = "exact")
```

##### Coarsened matching (cem)
Strata = coarsened versions of covariates
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# match units exactly within coarse strata 
m.out.cps_plus.cem <- matchit(model, data = ldw_cps_plus, method = "cem")
m.out.psid_plus.cem <- matchit(model, data = ldw_psid_plus, method = "cem")
```

##### Subclassification 
Strata = bins of the propensity score
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# partition sample into fixed number of bins based on propensity score 
m.out.cps_plus.subcl <- matchit(model, data = ldw_cps_plus, method = "subclass", subclass = 5)
m.out.psid_plus.subcl <- matchit(model, data = ldw_psid_plus, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# select largest balanced subsample meeting covariate balance tolerances
m.out.cps_plus.card <- matchit(model, data = ldw_cps_plus, method = "cardinality", tols = 0.1, ratio = 1)
m.out.psid_plus.card <- matchit(model, data = ldw_psid_plus, method = "cardinality", tols = 0.1, ratio = 1)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# matching by directly optimizing balance profile measures across covariates
m.out.cps_plus.profile <- matchit_profile(ldw_cps_plus, treat, covar)
m.out.psid_plus.profile <- matchit_profile(ldw_psid_plus, treat, covar)
```

### Weighting
#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute weights as inverse of estimated propensity scores 
w.out.cps_plus.ipw <- weightit(model, data = ldw_cps_plus, method = "ps", estimand = "ATT")
w.out.psid_plus.ipw <- weightit(model, data = ldw_psid_plus, method = "ps", estimand = "ATT")

ldw_cps_plus$ipw_weight <- w.out.cps_plus.ipw$weights
ldw_psid_plus$ipw_weight <- w.out.psid_plus.ipw$weights
```

#### Standardized mortality ratio (SMR) treated weights
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# calculate weights for ATT by assigning weight = 1 to treated units and weights proportional to odds of treatment for control
ldw_cps_plus$smr_weight <- create_smr_weights(ldw_cps_plus, model, "ATT")
ldw_psid_plus$smr_weight <- create_smr_weights(ldw_psid_plus, model, "ATT")
```

#### Matching weights
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# derive optimal matching weights intending to minimize covariate imbalance while targeting ATT
w.out.cps_plus.opt <- weightit(model, data = ldw_cps_plus, method = "optweight", estimand = "ATT")
w.out.psid_plus.opt <- weightit(model, data = ldw_psid_plus, method = "optweight", estimand = "ATT")

ldw_cps_plus$opt_weight <- w.out.cps_plus.opt$weights
ldw_psid_plus$opt_weight <- w.out.psid_plus.opt$weights
```

#### Overlap weights
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# calculate overlap weights emphasizing units with propensity scores near 0.5
ldw_cps_plus$overlap_weight <- create_overlap_weights(ldw_cps_plus, model)
ldw_psid_plus$overlap_weight <- create_overlap_weights(ldw_psid_plus, model)
```

#### Entropy weights
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute entropy balancing weights 
w.out.cps_plus.ebal <- weightit(model, data = ldw_cps_plus, method = "ebal", estimand = "ATT")
w.out.psid_plus.ebal <- weightit(model, data = ldw_psid_plus, method = "ebal", estimand = "ATT")

ldw_cps_plus$ebal_weight <- w.out.cps_plus.ebal$weights
ldw_psid_plus$ebal_weight <- w.out.psid_plus.ebal$weights
```

### Truncation
```{r}
#| code-fold: show
# list of weight columns to apply truncation 
weight_columns <- c("ipw_weight", "smr_weight", "smr_ate_weight", "opt_weight", "overlap_weight","ebal_weight")
```

#### Fixed maximum value truncation
```{r}
#| code-fold: show
# truncate weights by imposing a maximum threshold of 10
ldw_cps_plus.fixed <- ldw_cps_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps_plus.fixed)) {
    ldw_cps_plus.fixed <- truncate_weights_fixed(ldw_cps_plus.fixed, weight_col = wcol, max_weight = 10)
  }
}

ldw_psid_plus.fixed <- ldw_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid_plus.fixed)) {
    ldw_psid_plus.fixed <- truncate_weights_fixed(ldw_psid_plus.fixed, weight_col = wcol, max_weight = 10)
  }
}
```

#### At percentile truncation
```{r}
#| code-fold: show
# truncate weights such that values above the 99th percentile are capped
ldw_cps_plus.percent <- ldw_cps_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps_plus.percent)) {
    ldw_cps_plus.percent <- truncate_weights_percentile(ldw_cps_plus.percent, weight_col = wcol, percentile = 0.99)
  }
}

ldw_psid_plus.percent <- ldw_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid_plus.percent)) {
    ldw_psid_plus.percent <- truncate_weights_percentile(ldw_psid_plus.percent, weight_col = wcol, percentile = 0.99)
  }
}
```

#### Adaptive weight truncation

We inspect the variance of the estimated weights. If variance is zero, adaptive weight truncation is not meaningful. 
```{r}
#| code-fold: sh
# inspect variance of weights 
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps_plus)) {
    check_weights(ldw_cps_plus, wcol)
  } else {
    cat("Column", wcol, "not found in ldw_cps.plus\n")
  }
}
```

Regarding these results we only apply this method to `ipw, smr, smr_ate` and `ebal` alike in model A. 
```{r}
#| code-fold: show
# list weights that are valid 
weight_columns_at <- c("ipw_weight", "smr_weight", "smr_ate_weight", "overlap_weight", "ebal_weight")
```

```{r}
#| code-fold: show
# truncate adaptively at mean + 3 standard deviations 
ldw_cps_plus.adapt <- ldw_cps_plus
for (wcol in weight_columns_at) {
  if (wcol %in% names(ldw_cps_plus.adapt)) {
    ldw_cps_plus.adapt <- truncate_weights_adaptive(ldw_cps_plus.adapt, weight_col = wcol, c = 3)
  }
}

ldw_psid_plus.adapt <- ldw_psid_plus
for (wcol in weight_columns_at) {
  if (wcol %in% names(ldw_psid_plus.adapt)) {
    ldw_psid_plus.adapt <- truncate_weights_adaptive(ldw_psid_plus.adapt, weight_col = wcol, c = 3)
  }
}
```

## Improving overlap
### Trimming 
#### Propensity score threshold trimming (similar to tutorial of Imbens & Xu (2024))
```{r}
#| code-fold: show
# apply trimming with thresholds 0.9 and 0.8 for CPS and PSID respectively
ldw_cps_trim <- ps_trim(ldw_cps_plus.ps, threshold = 0.9)
ldw_psid_trim <- ps_trim(ldw_psid_plus.ps, threshold = 0.8)

# exclude experimental controls, subset trimmed data appropriately
ldw_cps.trim_match <- subset(ldw_cps_trim, sample %in% c(1,3) & ps_assoverlap)
ldw_psid.trim_match <- subset(ldw_psid_trim, sample %in% c(1,4) & ps_assoverlap)

# re-estimate propensity scores on trimmed data & perform 1:1 matching (e.g. with GRF or matchit)
ldw_cps.trim_match <- psmatch(data = ldw_cps.trim_match, Y = "re78", treat = "treat", cov = covar)
ldw_psid.trim_match <- psmatch(data = ldw_psid.trim_match, Y = "re78", treat = "treat", cov = covar)
```

#### Common range trimming
```{r}
#| code-fold: show
# trim observations outside the common support region of propensity scores
ldw_cps_plus.common   <- common_range_trim(ldw_cps_plus.ps)
ldw_psid_plus.common  <- common_range_trim(ldw_psid_plus.ps)
```

#### Propensity score trimming (Crump)
```{r}
#| code-fold: show
# trim observations with propensity scores outside [0.1, 0.9] interval
ldw_cps_plus.crump  <- crump_trim(ldw_cps_plus.ps, lower = 0.1, upper = 0.9)
ldw_psid_plus.crump <- crump_trim(ldw_psid_plus.ps, lower = 0.1, upper = 0.9)
```

#### Stuermer trimming
```{r}
#| code-fold: show
# trim observations based on propensity score quantiles separately for treated and control
ldw_cps_plus.stuermer  <- stuermer_trim(ldw_cps_plus.ps)
ldw_psid_plus.stuermer <- stuermer_trim(ldw_psid_plus.ps)
```

#### Walker trimming
```{r}
#| code-fold: show
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
ldw_cps_plus.walker   <- walker_trim(ldw_cps_plus.ps)
ldw_psid_plus.walker  <- walker_trim(ldw_psid_plus.ps)
```

## Improving both, covariate balance and overlap 
### Combination of methods
```{r}
#| code-fold: show
# list trimming methods
trim_names <- c("ps_threshold", "common_range", "stuermer", "walker", "crump")
trimmed_cps  <- list(ps_threshold = ldw_cps_trim, common_range = ldw_cps_plus.common, stuermer = ldw_cps_plus.stuermer, walker = ldw_cps_plus.walker, crump = ldw_cps_plus.crump)
trimmed_psid <- list(ps_threshold = ldw_psid_trim, common_range = ldw_psid_plus.common, stuermer = ldw_psid_plus.stuermer, walker = ldw_psid_plus.walker, crump = ldw_psid_plus.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r}
ipw_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "ipw_weight")),
  trim_names
)
ipw_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "ipw_weight")),
  trim_names
)
```

#### SMR treated weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r}
#| code-fold: show
smr_treat_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "smr_weight")),
  trim_names
)
smr_treat_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "smr_weight")),
  trim_names
)
```

#### Overlap weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r}
#| code-fold: show
ov_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "overlap_weight")),
  trim_names
)
ov_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "overlap_weight")),
  trim_names
)
```

#### Entropy weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r}
#| code-fold: show
entropy_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "ebal_weight")),
  trim_names
)
entropy_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "ebal_weight")),
  trim_names
)
```

## Reassessing methods
### Matching
Methods
```{r}
#| code-fold: show
# list all matching methods
methods.cps_plus <- list(
  nn = m.out.cps_plus.nearest,
  k2 = m.out.cps_plus.k2,
  k3 = m.out.cps_plus.k3,
  caliper = m.out.cps_plus.caliper,
  cS = m.out.cps_plus.cs,
  mahvars = m.out.cps_plus.mahvars,
  optimal_pair = m.out.cps_plus.optimal_pair,
  optimal_full = m.out.cps_plus.optimal_full,
  gen_full = m.out.cps_plus.general_full,
  genetic = m.out.cps_plus.genetic,
  exact = m.out.cps_plus.exact,
  cem = m.out.cps_plus.cem,
  card = m.out.cps_plus.card,
  profile = m.out.cps_plus.profile,
  subcl = m.out.cps_plus.subcl
)

methods.psid_plus <- list(
  nn = m.out.psid_plus.nearest,
  k2 = m.out.psid_plus.k2,
  k3 = m.out.psid_plus.k3,
  caliper = m.out.psid_plus.caliper,
  cs = m.out.psid_plus.cs,
  mahvars = m.out.psid_plus.mahvars,
  optimal_pair = m.out.psid_plus.optimal_pair,
  optimal_full = m.out.psid_plus.optimal_full,
  gen_full = m.out.psid_plus.general_full,
  genetic = m.out.psid_plus.genetic,
  exact = m.out.psid_plus.exact,
  cem = m.out.psid_plus.cem,
  card = m.out.psid_plus.card,
  profile = m.out.psid_plus.profile,
  subcl = m.out.psid_plus.subcl
)
```

```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# calculate balance statistics 
bal.cps_plus <- cobalt::bal.tab(model, data = ldw_cps_plus, un = TRUE, weights = methods.cps_plus, s.d.denom = "treated")
bal.psid_plus <- cobalt::bal.tab(model, data = ldw_psid_plus, un = TRUE, weights = methods.psid_plus, s.d.denom = "treated")
```

#### SMD
```{r}
#| code-fold: show
# compute absolute standardized mean differences (SMD)
smd_matchit.cps_plus <- compute_abs_smd_matchit(methods.cps_plus)
smd_matchit.psid_plus <- compute_abs_smd_matchit(methods.psid_plus)
```

#### Effective Sample Sizes 
```{r}
#| code-fold: show
# compute effective sample sizes (ESS)
ess_matchit.cps_plus <- compute_ess_matchit(bal.cps_plus)
ess_matchit.psid_plus <- compute_ess_matchit(bal.psid_plus)
```

#### Visuals
```{r, class.source = "fold-show", fig.cap='FIGURE3.'}
#| code-fold: show
# visualize covariate balance 
plot_matchit(methods.cps_plus, "LDW-CPS1-PLUS")
plot_matchit(methods.psid_plus, "LDW-PSID1-PLUS")
```

For all matching methods, the love plots of model B closely resemble those of model A, with nearly identical patterns in the absolute SMDs for all shared covariates, except for the absent covariate `re74`. Minor differences of the values between model A and B may result from changes to the matching specification and sample composition. 

### Weighting
Methods
```{r}
#| code-fold: show
# list all weights
weight.cps_plus <- list(
  ipw = ldw_cps_plus$ipw_weight,
  smr_tr = ldw_cps_plus$smr_weight,
  mw = ldw_cps_plus$opt_weight,
  ow = ldw_cps_plus$overlap_weight,
  ew = ldw_cps_plus$ebal_weight
)

weight.psid_plus <- list(
  ipw = ldw_psid_plus$ipw_weight,
  smr_tr = ldw_psid_plus$smr_weight,
  ow = ldw_psid_plus$overlap_weight,
  ew = ldw_psid_plus$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute SMD 
smd_weight.cps_plus <- compute_abs_smd_weight(ldw_cps_plus, "treat", covar, weight_columns)
smd_weight.psid_plus <- compute_abs_smd_weight(ldw_psid_plus, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute ESS
ess_weight.cps_plus <- compute_ess_weight(ldw_cps_plus, "treat", covar, weight_columns)
ess_weight.psid_plus <- compute_ess_weight(ldw_psid_plus, "treat", covar, weight_columns)
```

#### Visuals
```{r, class.source = "fold-show", fig.cap='FIGURE4.'}
#| code-fold: show
# visualize covariate balance
plot_weighting_methods(ldw_cps_plus, "treat", covar, weight.cps_plus, "LDW-CPS1-PLUS") 
plot_weighting_methods(ldw_psid_plus, "treat", covar, weight.psid_plus, "LDW-PSID1-PLUS")
```

### Truncation
Methods
```{r}
# list truncation methods
#| code-fold: show
trunc.cps_plus <- list(
  fix_max_value_trunc.cps_plus = ldw_cps_plus.fixed,
  at_perc_trunc.cps_plus = ldw_cps_plus.percent,
  adap_weight_trunc.cps_plus = ldw_cps_plus.adapt
)

trunc.psid_plus <- list(
  fix_max_value_trunc.psid_plus = ldw_psid_plus.fixed,
  at_perc_trunc.psid_plus = ldw_psid_plus.percent,
  adap_weight_trunc.psid_plus = ldw_psid_plus.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute SMD
smd_trunc.cps_plus <- compute_abs_smd_trunc(trunc.cps_plus, "treat", covar, weight_columns)
smd_trunc.psid_plus <- compute_abs_smd_trunc(trunc.psid_plus, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute ESS
ess_trunc.cps_plus <- compute_ess_trunc(trunc.cps_plus, "treat", covar, weight_columns)
ess_trunc.psid_plus <- compute_ess_trunc(trunc.psid_plus, "treat", covar, weight_columns)
```

#### Visuals
```{r, class.source = "fold-show", fig.cap='FIGURE5.'}
#| code-fold: show
# visualize covariate balance
plot_truncation_methods(trunc.cps_plus, "treat", covar, weight_columns, "LDW-CPS1-PLUS")
plot_truncation_methods(trunc.psid_plus, "treat", covar, weight_columns, "LDW-PSID1-PLUS")
```

For weighting and truncation methods, the love plots of model B display similarly close resemblance to those from model A, again showing almost identical patterns in the absolute SMDs across shared covariates, with `re74` omitted. Minor differences in values may be attributed to changes in model specification and sample composition.

### Trimming
Methods
```{r}
#| code-fold: show
# list trimming objects
trim.cps_plus <- list(
  original = ldw_cps_plus,  
  ps_threshold = ldw_cps.trim_match,  
  common_range = ldw_cps_plus.common,      
  crump = ldw_cps_plus.crump,      
  stuermer = ldw_cps_plus.stuermer,     
  walker = ldw_cps_plus.walker    
)

trim.psid_plus <- list(
  original = ldw_psid_plus,
  ps_threshold = ldw_psid.trim_match, 
  common_range = ldw_psid_plus.common,
  crump = ldw_psid_plus.crump,
  stuermer = ldw_psid_plus.stuermer,
  walker = ldw_psid_plus.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute SMD
smd_trim.cps_plus <- compute_abs_smd_trim(trim.cps_plus, "treat", covar)
smd_trim.psid_plus <- compute_abs_smd_trim(trim.psid_plus, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# compute ESS
ess_trim.cps_plus <- compute_ess_trim(trim.cps_plus, "treat", covar)
ess_trim.psid_plus <- compute_ess_trim(trim.psid_plus, "treat", covar)
```

#### Visuals
```{r, class.source = "fold-show", fig.cap='FIGURE6.'}
#| code-fold: show
# visualize overlap
plot_trim(trim.cps_plus, treat, covar)
plot_trim(trim.psid_plus, treat, covar)
```

```{r, class.source = "fold-show", fig.cap='FIGURE7.'}
#| code-fold: show
# visualize covariate balance
love.plot(ldw_cps, ldw_cps.trim_match, treat, covar = covar, title = "LDW-CPS1-PLUS - propensity threshold trimming")
love.plot(ldw_cps_plus, ldw_cps_plus.common, treat, covar, title = "LDW-CPS1-PLUS - common range trimming")
love.plot(ldw_cps_plus, ldw_cps_plus.common, treat, covar, title = "LDW-CPS1-PLUS - common range trimming")
love.plot(ldw_cps_plus, ldw_cps_plus.crump,  treat, covar, title = "LDW-CPS1-PLUS - crump trimming") 
love.plot(ldw_cps_plus, ldw_cps_plus.stuermer, treat, covar, title = "LDW-CPS1-PLUS - stuermer trimming")
love.plot(ldw_cps_plus, ldw_cps_plus.walker,  treat, covar, title = "LDW-CPS1-PLUS - walker trimming")

love.plot(ldw_psid, ldw_psid.trim_match, treat, covar = covar, title = "LDW-PSID1-PLUS - propensity threshold trimming")
love.plot(ldw_psid_plus, ldw_psid_plus.common, treat, covar, title = "LDW-PSID1-PLUS - common range trimming")
love.plot(ldw_psid_plus, ldw_psid_plus.common, treat, covar, title = "LDW-PSID1-PLUS - common range trimming")
love.plot(ldw_psid_plus, ldw_psid_plus.crump, treat, covar, title = "LDW-PSID1-PLUS - crump trimming")
love.plot(ldw_psid_plus, ldw_psid_plus.stuermer, treat, covar, title = "LDW-PSID1-PLUS - stuermer trimming")
love.plot(ldw_psid_plus, ldw_psid_plus.walker,  treat, covar, title = "LDW-PSID1-PLUS - walker trimming")
```

Across all trimming methods, the overlap plots for model B closely resemble those patterns observed in model A, with comparable distributions of propensity score log odds for treated and control groups. Minor differences in these distributions may result from the exclusion of the covariate `re74` in model B, which leads to an altered propensity score model and some changes in sample composition. The same holds true for the love plots, which exhibit nearly identical patterns in the absolute standardized mean differences (SMDs) across shared covariates, with only minor deviations due to the modified covariate set and resulting model specification.

### Combined methods
```{r}
# list all combined method results
comb_meth.cps_plus <- list(
  ipw = ipw_comb.cps_plus,
  smr_treated = smr_treat_comb.cps_plus,
  overlap = ov_comb.cps_plus,
  matching = matching_comb.cps_plus,
  entropy = entropy_comb.cps_plus
)

comb_meth.psid_plus <- list(
  ipw = ipw_comb.psid_plus,
  smr_treated = smr_treat_comb.psid_plus,
  overlap = ov_comb.psid_plus,
  matching = matching_comb.psid_plus,
  entropy = entropy_comb.psid_plus
)

all_comb_meth <- list(
  CPS  = comb_meth.cps_plus,
  PSID = comb_meth.psid_plus  
)
```

#### SMD
```{r}
# compute SMD
smd_all_comb_meth <- compute_smd_all_datasets(all_comb_meth, "treat", covar)
```

#### ESS
```{r}
# compute ESS 
ess_all_comb_meth <- compute_ess_all_datasets(all_comb_meth, "treat", covar)
```

#### Visuals
```{r, class.source = "fold-show", fig.cap='FIGURE8.'}
# visualize overlap
plot_comb_overlap_all_interactive(all_comb_meth, "treat", covar)
```

```{r, class.source = "fold-show", fig.cap='FIGURE9.'}
# visualize covariate balance
plot_comb_love_plots(all_comb_meth, "treat", covar)
```

Across all combined methods, the overlap plots for model B display similar patterns to those found in model A, with treated and control groups showing highly comparable distributions of propensity score log odds across the various trimming and weighting strategies. Likewise, the corresponding love plots reveal nearly identical patterns of absolute standardized mean differences (SMDs) for shared covariates in both models. 

These results underscore that omitting a single covariate—such as `re74` in model B—has a consistent and observable impact on the performance of each covariate balance and overlap improvement method, subtly influencing the resulting sample composition and the extent of covariate balance and overlap achieved.

```{r, message=FALSE, warning=FALSE}
# combine all results
all_cps_plus <- combine_results("cps_plus")
all_psid_plus <- combine_results("psid_plus")

# print all results
print(all_cps_plus)
print(all_psid_plus)

# save results 
save_csv(all_cps_plus, "CPS1_PLUS_all_results_model_b")
save_csv(all_psid_plus, "PSID1_PLUS_all_results_model_b")
```

### Getting top methods and datasets
Assess all methods and create score
- smd_score rescales Mean_Abs_SMD to a 0-1 range where lower Mean_Abs_SMD leads to a higher score
- ess_score measures sample size effectiveness by combining effective sample sizes (Control + Treated) and normalizing between 0 and 1
```{r}
ranked_cps_plus  <- assess_methods(all_cps_plus)
ranked_psid_plus <- assess_methods(all_psid_plus)
```

Rank the results and get only the top 5
```{r}
top5_methods.cps_plus <- get_top_methods(ranked_cps_plus, top_n = 5)
top5_methods.psid_plus <- get_top_methods(ranked_psid_plus, top_n = 5)

# save results 
save_csv(top5_methods.cps_plus, "CPS1_PLUS_top5_methods_model_b")
save_csv(top5_methods.psid_plus, "PSID1_PLUS_top5_methods_model_b")
```

After excluding `re74`, a partially overlapping but distinct set of top-performing methods was identified for model B, confirming that the choice of covariates directly influences which approaches achieve the best covariate balance and overlap—while methods such as mahvars, optimal_pair, and profile remain robust across both specifications, others like gen_full, optimal_full, and card varied in their ranking, illustrating the sensitivity of combined method performance to covariate selection.

```{r}
# create combined lists of all methods
all_methods.cps_plus <- c(methods.cps_plus, trim.cps_plus, trunc.cps_plus, weight.cps_plus, comb_meth.cps_plus)
all_methods.psid_plus <- c(methods.psid_plus, trim.psid_plus, trunc.psid_plus, weight.psid_plus, comb_meth.psid_plus)

# create the datasets from combined lists for your top 5 methods:
top5_datasets.cps_plus <- create_top5_datasets(all_methods.cps_plus, top5_methods.cps_plus)
top5_datasets.psid_plus <- create_top5_datasets(all_methods.psid_plus, top5_methods.psid_plus)

# save them in .RData files
save_top5_individual_files(all_methods.cps_plus, top5_methods.cps_plus, prefix = "model_b_cps")
save_top5_individual_files(all_methods.psid_plus, top5_methods.psid_plus, prefix = "model_b_psid")
```

## Estimate the ATT

Next we process with the estimation of the ATT using both the LDW-Experimental dataset and the newly constructed top 5 samples for each observational dataset that had highest score results. 
```{r, message=FALSE, warning=FALSE}
out1 <- estimate_all(ldw, "re78", "treat", covar)
out2 <- estimate_all(ldw_cps, "re78", "treat", covar)
out3 <- estimate_all(ldw_psid, "re78", "treat", covar)
```

```{r, message=FALSE, warning=FALSE}
out.cps_plus <- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, "re78", "treat", covar))
out.psid_plus <- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, "re78", "treat", covar))
```

```{r}
out4 <- out.cps_plus[[1]]
out5 <- out.cps_plus[[2]]
out6 <- out.cps_plus[[3]]
out7 <- out.cps_plus[[4]]
out8 <- out.cps_plus[[5]]

out9 <- out.psid_plus[[1]]
out10 <- out.psid_plus[[2]]
out11 <- out.psid_plus[[3]]
out12 <- out.psid_plus[[4]]
out13 <- out.psid_plus[[5]]
```

```{r}
# build plot titles 
base_titles <- c("(1) LDW-Experimental", "(2) LDW-CPS1", "(3) LDW-PSID1")
top5_titles.cps_plus <- paste0("(", 4:(3 + length(top5_methods.cps_plus)), ") Top CPS1: ", top5_methods.cps_plus)
top5_titles.psid_plus <- paste0("(", (4 + length(top5_methods.cps_plus)):(3 + length(top5_methods.cps_plus) + length(top5_methods.psid_plus)), ") Top PSID1: ", top5_methods.psid_plus)
plot_titles <- c(base_titles, top5_titles.cps_plus, top5_titles.psid_plus)

# combine all results
all_outs <- list(out1, out2, out3, out4, out5, out6, out7, out8, out9, out10, out11, out12, out13)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 10. ATT Estimates Model B Given Unconfoundedness using LDW Samples"}
# plot results
band <- out1[1, 3:4]
est  <- out1[1, 1]
plot_att_panels(all_outs, base_titles, top5_methods.cps_plus, top5_methods.psid_plus, band, est)

# save results
save_att_panels(all_outs, base_titles, top5_methods.cps_plus, top5_methods.psid_plus, band, est, "model_b")
```

```{r, warning=FALSE}
# Prepare all results in the order shown in the plots
all_summaries <- lapply(all_outs, summarize_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- plot_titles
att_summary
```

The above figures show the ATT estimates and their 95% confidence intervals for thirteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1 and the top-ranked for CPS1-PLUS and PSID1-PLUS after application of advanced covariate balancing and overlap improvement techniques.

Figure (1) presents the benchmark from the experimental sample (LDW-Experimental). Figures (2) and (3) show results for the  observational samples, LDW-CPS1 and LDW-PSID1, respectively. Figures (4-8) display ATT estimates for samples derived from top-ranked methods applied to CPS1-PLUS, while figures (9) to (13) display estimates for samples derived from top-ranked methods of PSID1-PLUS.

Across the CPS1-PLUS samples (figures 4–8), alike in model A, all estimators yield positive ATT estimates that tightly cluster around the experimental benchmark (red dashed line).

In PSID1-PLUS samples (figures 9–13), unlike in model A, all estimators similarly produce positive ATT estimates close to the experimental benchmark, with the exception of `difference-in-means` applied to the `gen_full` and `optimal_full` samples, which yield large negative estimates. The PSID1-PLUS samples further exhibit somewhat higher mean standard errors and substantially greater variability in effect estimates than CPS1-PLUS samples.

Notably, the negative ATT estimates observed in PSID1-PLUS may be attributed to the specific method used to establish the sample rather than the model specification, since method-wise comparison between CPS1-PLUS and PSID1-PLUS across models (model A and model B) shows nearly identical ATT results.

The ATT results are presented in the table below:
```{r class.source = 'fold-hide'}
#| code-fold: show
# get result matrix
result_mat <- create_matrix_results(all_outs, plot_titles)
knitr::kable(result_mat, booktabs = TRUE, caption = "Model B ATT Estimates and SEs for All Samples and Estimators")
```

::: callout-tip
The first value in each cell represents the point estimate from the respective estimator and method, specifically the estimated ATT. The number in brackets directly following it is the standard error (SE) associated with that estimate, indicating the uncertainty or variability around the point estimate.
:::

Column 1 reports the estimates from the LDW-Experimental sample, column 2 corresponds to LDW-CPS1, and column 3 to LDW-PSID1, while columns 4 through 13 present the estimates obtained from samples derived using the top-ranked methods applied to the CPS1-PLUS and PSID1-PLUS datasets, each evaluated across several estimators. 

The LDW-CPS1 dataset produces estimates closely aligned with the experimental benchmark, whereas the LDW-PSID1 dataset exhibits greater variability in the estimates. The top-ranked samples yield diverse results. 

xx

```{r}
# save results 
save_csv(result_mat, "LDW_att_estimates_model_b")
```

::: callout-tip
Improved overlap and covariate balance generally leads to estimates closer to the experimental benchmark, but often at the cost of increased standard errors due to reduced effective sample size. This highlights the importance of balancing bias reduction with precision, and the need to carefully select methods that optimize this trade-off for robust causal inference.
:::

## Alternative Estimands: CATT and QTET
### Conditional Average Treatment Effect on the Treated (CATT)

Analyzing causal estimates for alternative estimands such as heterogeneous treatment effects and quantile treatment effects may provide valuable insight into the validity of the unconfoundedness assumption.

The Conditional Average Treatment Effect on the Treated (CATT) specifically allows investigation of how treatment effects differ across covariate-defined subpopulations. In the following, we estimate the CATT using causal forests through the Augmented Inverse Probability Weighting Generalized Random Forest (AIPW-GRF) method for multiple datasets: the LDW-Experimental, LDW-CPS1, and LDW-PSID1 samples, as well as top-ranked samples derived from the CPS1-PLUS and PSID1-PLUS datasets. Estimation is implemented via the `catt()`-function from Imbens and Xu (2024).
```{r, warning=FALSE}
#| code-fold: show
catt.ldw <- catt(ldw, Y, treat, covar)
catt.cps <- catt(ldw_cps, Y, treat, covar)
catt.psid <- catt(ldw_psid, Y, treat, covar)
catt.cps.trim <- catt(ldw_trim_cps, Y, treat, covar)
catt.psid.trim <- catt(ldw_trim_psid, Y, treat, covar)
```

```{r, warning=FALSE}
#| code-fold: show
catt.top5_cps_plus <- lapply(top5_datasets.cps_plus, function(d) catt(d, Y, treat, covar))
catt.top5_psid_plus <- lapply(top5_datasets.psid_plus, function(d) catt(d, Y, treat, covar))
```

Then, we employ a modified version of the `plot_catt()` function from Imbens & Xu (2024) to visualize the results. In the subsequent figures, we plot the estimated CATTs from all samples at the covariate values of each treated unit against their corresponding experimental benchmarks. Gray dots represent pairs of CATT estimates at covariate values of treated units, while the red crosses indicate pairs of estimated ATTs.
```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 11. CATT Estimates Model B using LDW Data"}
#| code-fold: show
# combine all catt objects  
all_catt <- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim), catt.top5_cps_plus, catt.top5_psid_plus)

# plot results
plot_catt_panels(all_catt, plot_titles)

# save results
save_catt_panels(all_catt, plot_titles, prefix = "model_b")
```

Although the AIPW estimator can produce ATT estimates closely aligned with the experimental benchmark using LDW data, its performance for revealing the true CATT is considerably worse. 

```{r, warning=FALSE}
#| code-fold: show
for (i in seq_along(all_catt)) {
  catt_vec <- all_catt[[i]]$catt
  min_val <- min(catt_vec, na.rm = TRUE)
  max_val <- max(catt_vec, na.rm = TRUE)
  cat(sprintf("Method: %s\nMin CATT: %.2f\nMax CATT: %.2f\n\n", plot_titles[i], min_val, max_val))
}
```

xx

### Quantile Treatment Effect on the Treated (QTET)

QTET provides a robust way to analyze treatment effect heterogeneity while being less impacted by outliers compared to average treatment effect measures. The QTET estimates are obtained using the propensity score re-weighting method introduced by Firpo (2007). Implementation leverages the function `qte()` from Imbens and Xu (2024), while visualization employs a modified version of their function `plot_qte()`.
```{r, message=FALSE, warning=FALSE}
#| code-fold: show
qte.ldw <- est_qte(Y, treat, covar, data = ldw, cores = 4)
```

```{r, message=FALSE, warning=FALSE}
#| code-fold: show
#qte.ldw_cps <- est_qte(Y, treat, covar, data = ldw_cps)
#qte.ldw_psid <- est_qte(Y, treat, covar, data = ldw_psid)
#qte.ldw_cps.trim <- est_qte(Y, treat, covar, data = ldw_cps_trim)
#qte.ldw_psid.trim <- est_qte(Y, treat, covar, data = ldw_psid_trim) 
```

```{r, warning=FALSE}
#| code-fold: show
#qte.top5_cps_plus  <- lapply(top5_datasets.cps_plus,  function(d) est_qte(Y, treat, covar, data = d))
#qte.top5_psid_plus <- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, warning=FALSE}
#| code-fold: show
#qte.ldw0 <- est_qte(Y, treat, NULL, data = ldw)
#qte.ldw.cps0 <- est_qte(Y, treat, NULL, data = ldw_cps)
#qte.ldw.psid0 <- est_qte(Y, treat, NULL, data = ldw_psid)
#qte.ldw_cps.trim0 <- est_qte(Y, treat, NULL, data = ldw_cps_trim)
#qte.ldw_psid.trim0 <- est_qte(Y, treat, NULL, data = ldw_psid_trim)
#qte.top5_cps_plus0  <- lapply(top5_datasets.cps_plus,  function(d) est_qte(Y, treat, NULL, data = d))
#qte.top5_psid_plus0 <- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 12. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental"}
#| code-fold: show
# combine all qte objects in order 
#all_qtet <- c(list(qte.ldw, qte.ldw_cps, qte.ldw_psid), qte.top5.cps, qte.top5.psid)

# plot results
#plot_qtet_panels(all_qtet, plot_titles, experimental_qte = qte.ldw, plots_per_page = 4, ylim = c(-25000, 15000))
```

## Validation through Placebo Analyses

To further evaluate the credibility of the unconfoundedness assumption, a placebo analysis is performed by designating 1975 earnings (re75) as the outcome variable and omitting both re75 and u75 from the list of adjustment covariates. The analysis utilizes all previously considered datasets, excluding re75 and u75 from the model. Using these new samples, the ATT is then recomputed with the function `estimate_all`, conditioning only on the remaining set of covariates.
```{r, warning=FALSE}
#| code-fold: show
# define variables
Y_pl <- "re75"
treat <- "treat"
covar_pl <- c("age", "education", "black", "hispanic", "married", "nodegree", "re74", "u74")
```

```{r, warning=FALSE}
#| code-fold: show
# estimate placebo ATT on original and observational datasets
out1_pl <- estimate_all(ldw, Y_pl, "treat", covar_pl)
out2_pl <- estimate_all(ldw_cps, Y_pl, "treat", covar_pl)
out3_pl <- estimate_all(ldw_psid, Y_pl, "treat", covar_pl)
```

```{r, message=FALSE, warning=FALSE}
#| code-fold: show
# estimate placebo ATT on top ranked datasets
out_cps_pl <- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, Y_pl, "treat", covar_pl))
out_psid_pl <- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, Y_pl, "treat", covar_pl))
out4_pl <- out_cps_pl[[1]]
out5_pl <- out_cps_pl[[2]]
out6_pl <- out_cps_pl[[3]]
out7_pl <- out_cps_pl[[4]]
out8_pl <- out_cps_pl[[5]]
out9_pl <- out_psid_pl[[1]]
out10_pl <- out_psid_pl[[2]]
out11_pl <- out_psid_pl[[3]]
out12_pl <- out_psid_pl[[4]]
out13_pl <- out_psid_pl[[5]]
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 13. Placebo Test Model B: '75 Earnings as the Outcome"}
#| code-fold: show
# collect all placebo results 
all_outs_pl <- list(out1_pl, out2_pl, out3_pl, out4_pl, out5_pl, out6_pl, out7_pl, out8_pl, out9_pl, out10_pl, out11_pl, out12_pl, out13_pl)

# plot placebo results
band_pl <- out1_pl[1, 3:4]
est_pl  <- out1_pl[1, 1]
ylim_pl <- c(-12000, 2000)
plot_att_panels(all_outs_pl, base_titles, top5_methods.cps_plus, top5_methods.psid_plus, band_pl, est_pl, ylim_pl)

# save results
save_att_panels(all_outs, base_titles, top5_methods.cps_plus, top5_methods.psid_plus, band, est, "model_b_placebo")
```

The *Placebo* ATT results are presented in the table below:
```{r class.source = 'fold-hide'}
#| code-fold: show
all_outs_pl <- list(
  out1_pl, out2_pl, out3_pl,
  out4_pl, out5_pl, out6_pl, out7_pl, out8_pl,
  out9_pl, out10_pl, out11_pl, out12_pl, out13_pl
)

result_mat_pl <- create_matrix_results(all_outs_pl, plot_titles)
knitr::kable(result_mat_pl, booktabs = TRUE, caption = "Model B Placebo ATT Estimates and SEs for All Samples and Estimators")
```

The placebo analysis for model B closely parallels the findings from model A. The experimental benchmark (first row and first column) for 1975 earnings remains near zero and statistically insignificant, and all estimators applied to the observational CPS1 (2) and PSID1 datasets (3) again yield large, negative ATT estimates.

The top-ranked samples for both CPS1-PLUS and PSID1-PLUS generally produce ATT estimates that deviate further from the experimental benchmark compared to model A, with the exception of `profile` matching (13) sample (compare first row of placebo analysis tables of model A and model B). Similar patterns can be observed across all estimators for each of the observational samples.

Across all estimators and observational top-ranked samples (5–13), with the exception of the exact matching sample (4), the placebo analysis consistently demonstrates alike in model A substantial bias and deviation from the true effect, underscoring the inherent limitations of confounding adjustment using observational data.  

```{r}
#| code-fold: show
# save results 
save_csv(result_mat, "LDW_att_estimates_model_b")
```

## Sensitivity Analyses

Now we also conduct a sensitivity analyses using the LDW data, and depict the results in contour plots below using the `sens_ana`-function of Imbens & Xu (2024).
```{r, warning=FALSE}
#| code-fold: show
Y <- "re78"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "re74", "re75", "u74", "u75")
bm <- c("re75") 
```

```{r, warning=FALSE}
#| code-fold: show
# check for valid datasets 
datasets_sens <- c(list(ldw, ldw_cps, ldw_psid), top5_datasets.cps_plus, top5_datasets.psid_plus)
filtered_datasets_sens <- check_filter_datasets(datasets_sens, Y, treat, covar, bm)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 14. Sensitivity Analyses Model B"}
#| code-fold: show
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = plot_titles[idx])
}
```

```{r}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, "model_b")
```

xx

::: callout-tip
The analyses suggest that some samples maintain stable treatment effect estimates despite increasing confounder strength, while others show greater sensitivity. This highlights the importance of assessing robustness across different samples (respectively methods used to derive specific samples) to account for potential unobserved bias.
:::

# Summary


