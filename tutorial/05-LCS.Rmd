# LaLonde-Calónico-Smith (LCS) Data 

This section (5) examines the LaLonde female samples reconstructed by @calonico_smith_2017, referred to as the LaLonde-Calónico-Smith (LCS) sample (loaded as `lcs` below, similar to @imbens2024). 

For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only present and explain the LCS–specific results.

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lcs.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Load and preprocess data 
```{r, message=FALSE, warning=FALSE}
# expc = 0: experimental treated; 
# expc = 1: experimental control; 
# expc = 2: psid control;

lcs_psid$expc <- 0 
lcs_psid[lcs_psid$treat==0, ]$expc <- 2 
lcs_tr <- lcs[lcs$treat==1, ]
lcs_co <- lcs[lcs$treat==0, ]
lcs_co$treat <- 1
lcs_co$expc <- 1
lcs_psid_plus <- rbind.data.frame(lcs_psid, lcs_co)
```

### Inspect data
```{r, message=FALSE, warning=FALSE}
# collect datasets in a list
data <- list(lcs = lcs, lcs_psid = lcs_psid, lcs_psid_plus = lcs_psid_plus)

# inspect key metrics of each dataset
summary_stats <- inspect_data(data)
knitr::kable(summary_stats, caption = "Summary Statistics")
```

```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re79"
treat <- "treat"
# redefine covariates: removing "nchildren75" to be used as placebo outcome
covar <- c("age", "educ", "nodegree", "married", "black", "hisp", 
           "re75", "u75")
```

<div class="callout-note">
In the following analysis, only PSID1 data is used as the original LaLonde study and its reconstruction by Calónico and Smith (2017) designate PSID1 as the appropriate nonexperimental control group for women, providing a comparable observational dataset that aligns with the experimental sample’s characteristics.
</div>

### Assessing overlap and covariate balance
#### Overlap
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1.',out.width='100%', fig.asp=0.5}
# assess overlap
lcs.ps <- assess_overlap(data = lcs, treat = treat, cov = covar, xlim = c(-1.5, 1.5), breaks = 40)
lcs_psid.ps <- assess_overlap(data = lcs_psid, treat = treat, cov = covar, xlim = c(-11, 7), breaks = 40)
```

As anticipated, the LCS-Experimental data exhibit an almost perfect overlap. In contrast, the observational dataset LCS-PSID1 displays weak overlap. 
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED2. SubfigureC:LCS-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
# assess overlap
lcs_psid_plus.ps <- assess_overlap(data = lcs_psid_plus, treat = treat, cov = covar, xlim = c(-15, 5))
```

With the expanded dataset LCS-PSID1, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater spread of log-odds densities across both samples.

```{r, message=FALSE, warning=FALSE}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

#### Covariate balance
```{r, message=FALSE, warning=FALSE}
love.plot(lcs, lcs_psid, treat, covar = covar, title = "LCS-PSID1")
love.plot(lcs, lcs_psid_plus, treat, covar = covar, title = "LCS-PSID1-PLUS")
```

<div class="callout-note">
Due to computational constraints, we use a reduced set of matching methods, consistent with previous sections.
</div>

## Improving primarily covariate balance
### Matching 
#### Distance Matching
##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.psid.optimal_pair <- matchit(model, data = lcs_psid, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
m.out.psid.optimal_full <- matchit(model, data = lcs_psid, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios 
m.out.psid.general_full <- matchit(model, data = lcs_psid, method = "quick", distance = "logit")
```

#### Stratum matching
##### Coarsened matching (cem)
Strata = coarsened versions of covariates
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
m.out.psid.cem <- matchit(model, data = lcs_psid, method = "cem")
```

##### Subclassification 
Strata = bins of the propensity score
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
m.out.psid.subcl <- matchit(model, data = lcs_psid, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units
m.out.psid.card <- matchit(model, data = lcs_psid, method = "cardinality", tols = 0.1, ratio = 1)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
# select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact
m.out.psid.profile <- matchit(model, data = lcs_psid, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs")
```

### Weighting
#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores with a parametric generalized linear model and converts them into weights
w.out.ipw <- WeightIt::weightit(model, data = lcs_psid, estimand = "ATT", method = "glm")
lcs_psid$ipw_weight <- w.out.ipw$weights
```

#### Stable balancing weights 
```{r, message=FALSE, warning=FALSE}
# estimates weights by solving a quadratic programming problem 
w.out.opt <- optweight::optweight(model, data = lcs_psid, estimand = "ATT")
lcs_psid$opt_weight <- w.out.opt$weights
```

#### Covariate balance propensity score weights
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores using generalized method of moments and then converts them into weights
w.out.cbps <- WeightIt::weightit(model, data = lcs_psid, estimand = "ATT", method = "cbps")
lcs_psid$cbps_weight <- w.out.cbps$weights
```

#### Entropy balancing weights
```{r, message=FALSE, warning=FALSE}
# estimates weights by minimizing the negative entropy of the weights subject to exact moment balancing constraints
w.out.ebal <- WeightIt::weightit(model, data = lcs_psid, estimand = "ATT", method = "ebal")
lcs_psid$ebal_weight <- w.out.ebal$weights
```

## Improving primarily overlap
### Truncation
```{r, message=FALSE, warning=FALSE}
# list of weight columns to apply truncation 
weight_columns <- c("ipw_weight", "opt_weight", "cbps_weight", "ebal_weight")
```

#### Fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum threshold
lcs_psid.fixed <- lcs_psid
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid.fixed)) {
    lcs_psid.fixed <- truncate_weights_fixed(lcs_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
lcs_psid.percent <- lcs_psid
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid.percent)) {
    lcs_psid.percent <- truncate_weights_percentile(lcs_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}
```

#### Adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
psid_results <- list()

for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid)) {
    psid_results[[wcol]] <- check_weights(lcs_psid, wcol)
  } else {
    warning(paste("Column", wcol, "not found in LCS-PSID1"))
  }
}

var_psid_table <- bind_rows(psid_results)
knitr::kable(var_psid_table, caption = "Variance of Weights")
```

Regarding these results we can apply adaptive weight truncation to all considered weights.
```{r, message=FALSE, warning=FALSE}
# truncate adaptively at mean + 3 standard deviations 
lcs_psid.adapt <- lcs_psid
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid.adapt)) {
    lcs_psid.adapt <- truncate_weights_adaptive(lcs_psid.adapt, weight_col = wcol, c = 3)
  }
}
```
 
### Trimming 
#### Propensity score threshold trimming and nn matching
(Similar to tutorial of @imbens2024)
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
lcs_psid_plus.trim <- ps_trim(lcs_psid_plus.ps, threshold = 0.9)

# exclude experimental controls, subset trimmed data appropriately
lcs_psid_plus.trim.match <- subset(lcs_psid_plus.trim, expc %in% c(0,2) & ps_assoverlap)

# re-estimate propensity scores on trimmed data and perform 1:1 matching
lcs_psid_plus.trim.match <- psmatch(data = lcs_psid_plus.trim.match, Y = "re79", treat = "treat", cov = covar)

# trim experimental data and re-assign treat variable for controls in sample 3 or 4 (non-treated group)
#lcs_trim_psid <- subset(lcs_psid_trim, expc %in% c(0, 1))
#lcs_trim_psid$treat[lcs_trim_psid$expc == 1] <- 0
```

#### Propensity score threshold trimming 
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
lcs_psid.trim <- ps_trim(lcs_psid.ps, threshold = 0.9)

# re-estimate propensity scores on trimmed data 
lcs_psid.trim <- ps_estimate(data = lcs_psid.trim, Y = "re79", treat = "treat", cov = covar)
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
lcs_psid.common  <- common_range_trim(lcs_psid.ps)

# re-estimate propensity scores on trimmed data 
lcs_psid.common <- ps_estimate(data = lcs_psid.common, Y = "re79", treat = "treat", cov = covar)
```

#### Crump trimming 
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
lcs_psid.crump <- crump_trim(lcs_psid.ps, lower = 0.1, upper = 0.9)

# re-estimate propensity scores on trimmed data 
lcs_psid.crump <- ps_estimate(data = lcs_psid.crump, Y = "re79", treat = "treat", cov = covar)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
lcs_psid.stuermer <- stuermer_trim(lcs_psid.ps)

# re-estimate propensity scores on trimmed data 
lcs_psid.stuermer <- ps_estimate(data = lcs_psid.stuermer, Y = "re79", treat = "treat", cov = covar)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
lcs_psid.walker  <- walker_trim(lcs_psid.ps)

# re-estimate propensity scores on trimmed data 
lcs_psid.walker <- ps_estimate(data = lcs_psid.walker, Y = "re79", treat = "treat", cov = covar)
```

## Integrated methods
```{r, message=FALSE, warning=FALSE}
# list trimming objects
all_trim.psid  <- list(ps_threshold = lcs_psid.trim, 
                     common_range = lcs_psid.common, 
                     stuermer = lcs_psid.stuermer, 
                     walker = lcs_psid.walker, 
                     crump = lcs_psid.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply inverse probability weighting (IPW) with trimming and attach IPW weights
ipw_comb.psid <- trim_attach_weights(all_trim.psid, model, "ipw_weight")
```

#### Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply stable balancing with trimming and attach stable balance weights
opt_comb.psid <- trim_attach_weights(all_trim.psid, model, "opt_weight")
```

#### Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply propensity score weighting with trimming and attach propensity score weights
cbps_comb.psid <- trim_attach_weights(all_trim.psid, model, "cbps_weight")
```

#### Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
ebal_comb.psid <- trim_attach_weights(all_trim.psid, model, "ebal_weight")
```

## Reassessing methods
### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching objects
all_match.psid <- list(
  optimal_pair = m.out.psid.optimal_pair,
  optimal_full = m.out.psid.optimal_full,
  gen_full = m.out.psid.general_full,
  cem = m.out.psid.cem,
  card = m.out.psid.card,
  profile = m.out.psid.profile,
  subcl = m.out.psid.subcl
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_matchit.psid <- compute_abs_smd_matchit(all_match.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# calculate balance statistics 
bal.psid <- cobalt::bal.tab(model, data = lcs_psid, un = TRUE, weights = all_match.psid, s.d.denom = "treated")
```

```{r, message=FALSE, warning=FALSE}
# compute effective sample sizes (ESS)
ess_matchit.psid <- compute_ess_matchit(bal.psid)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED3.'}
# visualize covariate balance 
plot_matching_balance(all_match.psid, title = "LCS-PSID1")
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
all_weight.psid <- list(
  ipw_weight = lcs_psid$ipw_weight,
  opt_weight = lcs_psid$opt_weight,
  cbps_weight = lcs_psid$cbps_weight,
  ebal_weight = lcs_psid$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_weight.psid <- compute_abs_smd_weight(lcs_psid, treat, covar, all_weight.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_weight.psid <- compute_ess_weight(lcs_psid, treat, covar, all_weight.psid)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED4.'}
# visualize covariate balance
plot_weighting_balance(lcs_psid, treat, covar, all_weight.psid, "LCS-PSID1")
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
all_trunc.psid <- list(
  fix_max_value = lcs_psid.fixed,
  at_perc = lcs_psid.percent,
  adap_weight = lcs_psid.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trunc.psid <- compute_abs_smd_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trunc.psid <- compute_ess_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED5.'}
# visualize covariate balance
plot_trunc_balance(all_trunc.psid, "treat", covar, weight_columns, "LCS-PSID1")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming object plus original
all_trim.psid <- list(
  original = lcs_psid,
  ps_threshold = lcs_psid.trim,
  common_range = lcs_psid.common,
  crump = lcs_psid.crump,
  stuermer = lcs_psid.stuermer,
  walker = lcs_psid.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trim.psid <- compute_abs_smd_trim(all_trim.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trim.psid <- compute_ess_trim(all_trim.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED6.'}
# visualize overlap
plot_trim_overlap(all_trim.psid, treat, covar, prefix = "LDW-PSID1")
```

## Integrated methods
```{r, message=FALSE, warning=FALSE}
# list all combined results
comb.psid <- list(
  ipw = ipw_comb.psid,
  opt = opt_comb.psid,
  cbps = cbps_comb.psid,
  ebal = ebal_comb.psid
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_all_comb_meth.psid <- compute_abs_smd_comb(comb.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.psid <- compute_ess_comb(comb.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED8.'}
# visualize overlap
plot_comb_overlap(comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix_psid = "LCS-PSID1")
```

```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED9.'} 
# visualize covariate balance
plot_comb_balance(comb_meth_psid = comb.psid, treat = "treat", covar = covar, orig_psid = lcs_psid, prefix_psid = "LCS-PSID1")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_comb_hist(comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix = "lcs", prefix_psid = "lcs_psid1")
save_comb_loveplots(comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix = "lcs", prefix_psid = "lcs_psid1")
```

## Identifying best methods
```{r, message=FALSE, warning=FALSE}
# combine all results
all_psid <- combine_results("psid") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_psid, "ldw_psid1_all_results")
```

```{r, message=FALSE, warning=FALSE}
# assess and rank methods
ranked_psid <- assess_methods(all_psid)
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods
top5_methods.psid <- get_top_methods(ranked_psid, top_n = 5)

# print results
top5_methods_df.psid <- ranked_psid %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.psid, caption = "Top 5 Methods", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.psid, "PSID1_top5_methods_lcs")
```

The table shows that CPS1 and PSID1 share the same top five methods, with the exception of one differing method and a variation in their ordering for PSID1.
```{r}
dataset_list_psid <- list(
  "All" = lcs_psid,
  "original" = lcs_psid,
  "card" = m.out.psid.card,
  "optimal_full" = m.out.psid.optimal_full,
  "optimal_pair" = m.out.psid.optimal_pair,
  "gen_full" = m.out.psid.general_full,
  "subcl" = m.out.psid.subcl,
  "profile" = m.out.psid.profile,
  "ipw_weight" = lcs_psid$ipw_weight, 
  "opt_weight" = lcs_psid$opt_weight,
  "cbps_weight" = lcs_psid$cbps_weight,
  "ebal_weight" = lcs_psid$ebal_weight,
  "fix_max_value_ipw_weight" = lcs_psid.fixed$ipw_weight,
  "fix_max_value_opt_weight" = lcs_psid.fixed$opt_weight,
  "fix_max_value_cbps_weight" = lcs_psid.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = lcs_psid.fixed$ebal_weight,
  "at_perc_ipw_weight" = lcs_psid.percent$ipw_weight,
  "at_perc_opt_weight" = lcs_psid.percent$opt_weight,
  "at_perc_cbps_weight" = lcs_psid.percent$cbps_weight,
  "at_perc_ebal_weight" = lcs_psid.percent$ebal_weight,
  "adap_weight_ipw_weight" = lcs_psid.adapt$ipw_weight,
  "adap_weight_opt_weight" = lcs_psid.adapt$opt_weight,
  "adap_weight_cbps_weight" = lcs_psid.adapt$cbps_weight,
  "adap_weight_ebal_weight" = lcs_psid.adapt$ebal_weight,
  "ps_threshold" = lcs_psid.trim,
  "common_range" = lcs_psid.common,
  "stuermer" = lcs_psid.stuermer,
  "walker" = lcs_psid.walker,
  "crump" = lcs_psid.crump,
  "ipw_common_range" = ipw_comb.psid[[1]],
  "ipw_crump"= ipw_comb.psid[[2]],
  "ipw_ps_threshold"= ipw_comb.psid[[3]],
  "ipw_stuermer"= ipw_comb.psid[[4]],
  "ipw_walker" = ipw_comb.psid[[5]],
  "opt_common_range" = opt_comb.psid[[1]],
  "opt_crump" = opt_comb.psid[[2]],
  "opt_ps_threshold" = opt_comb.psid[[3]],
  "opt_stuermer" = opt_comb.psid[[4]],
  "opt_walker" = opt_comb.psid[[5]],
  "cbps_common_range" = cbps_comb.psid[[1]],
  "cbps_crump" = cbps_comb.psid[[2]],
  "cbps_ps_threshold"  = cbps_comb.psid[[3]],
  "cbps_stuermer" = cbps_comb.psid[[4]],
  "cbps_walker"= cbps_comb.psid[[5]],
  "ebal_common_range" = ebal_comb.psid[[1]],
  "ebal_crump" = ebal_comb.psid[[2]],
  "ebal_ps_threshold" = ebal_comb.psid[[3]],
  "ebal_stuermer" = ebal_comb.psid[[4]],
  "ebal_walker" = ebal_comb.psid[[5]])
```

```{r, message=FALSE, warning=FALSE}
# create the datasets from combined lists for your top 5 methods:
top5_datasets.psid <- create_top5_datasets(dataset_list_psid, top5_methods.psid)
```

```{r, message=FALSE, warning=FALSE}
# save them into .RData files
save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = "lcs_psid1")
```

## Estimating
### Average treatment effect on the treated (ATT)
```{r, message=FALSE, warning=FALSE}
# get estimates
out1 <- estimate_all(lcs, "re79", "treat", covar)
out2 <- estimate_all(lcs_psid, "re79", "treat", covar)
out3 <- estimate_all(lcs_psid.trim, "re79", "treat", covar)  
out4 <- estimate_all(lcs_psid_plus.trim, "re79", "treat", covar) # similar to Imbens & Xu (2024)

out.psid <- lapply(top5_datasets.psid, function(d) estimate_all(d, "re79", "treat", covar))
out5 <- out.psid[[1]]
out6 <- out.psid[[2]]
out7 <- out.psid[[3]]
out8 <- out.psid[[4]]
out9 <- out.psid[[5]]
```

```{r, message=FALSE, warning=FALSE}
# build plot titles 
base_titles <- c("(A) LCS-Experimental", "(B) LCS-PSID1" , "(C) Trimmed LCS-PSID1", "(D) Trimmed LCS-PSID1-PLUS")
top_start <- 5 # E is 5th letter
num_psid <- length(top5_methods.psid)
top_letters_psid <- LETTERS[top_start:(top_start + num_psid - 1)]
top5_titles.psid <- paste0("(", top_letters_psid, ") Top PSID1: ", top5_methods.psid)
plot_titles <- c(base_titles, top5_titles.psid)

# combine all results
all_outs <- c(list(out1, out2, out3, out4), out.psid)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED10. ATT Estimates Given Unconfoundedness using LCS Samples"}
# plot results
band <- out1[1, 3:4]
est  <- out1[1, 1]
plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs, plot_titles, band, est, "lcs")
```

The above figures show the ATT estimates and their 95% confidence intervals for eight samples: LCS-Experimental, LCS-PSID1, a trimmed version of the LCS-PSID1 sample (analogous to @imbens2024) and a series of top-ranked subsamples of LCS-PSID1 based on various matching, weighting, truncation and trimming criteria.

Figure (A) presents the benchmark from the experimental sample (LCS-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) shows results for the observational sample LCS-PSID1 and figure (C) for its trimmed version, replicating the tutorial results of Imbens & Xu (2024). Figures (D) through (H) display results for PSID1-based subsamples. 

Across the LCS-PSID1 dataset and its top-ranked subsamples, all estimators yield ATT estimates that largely cluster around the experimental benchmark except `Diff-in-Means`, which tends to produce estimates that deviate more noticeably from the benchmark.
```{r, warning=FALSE, message=FALSE}
# prepare all results in the order shown in the plots
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- plot_titles
knitr::kable(att_summary, caption = "ATT Summary Statistics", booktabs = TRUE)
```

```{r, warning=FALSE, message=FALSE}
# get result matrix
result_mat <- create_matrix_results(all_outs, plot_titles)
knitr::kable(result_mat, booktabs = TRUE, caption = "ATT Estimates and SEs") %>% kable_styling(full_width = TRUE) 
```

The tabulated results confirm visual patterns: Column (A) reports the estimates for the LCS-Experimental sample, column (B) for the LCS-PSID1 sample, and column (C) for its trimmed version. Columns (D)-(H) show results of the top-ranked subsample of LCS-PSID1.

For all PSID1-based samples, the ATT estimates remain overly positive. However, the estimates obtained with the `Diff-in-Means` estimator are consistently negative. Likewise, for the sample constructed with the `card` method, the estimates remain negative across all estimators. 
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "LCS_att_estimates")
```

### Conditional average treatment effect on the treated (CATT)
```{r, warning=FALSE, message=FALSE}
catt.lcs <- catt(lcs, Y, treat, covar)
catt.psid <- catt(lcs_psid, Y, treat, covar)
catt.psid.trim <- catt(lcs_psid.trim, Y, treat, covar)
catt.psid_plus.trim <- catt(lcs_psid_plus.trim, Y, treat, covar) # similar to Imbens & Xu (2024)
```

```{r, warning=FALSE, message=FALSE}
catt.top5_psid <- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar))
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED11. CATT Estimates using LCS Data"}
# combine all catt objects 
all_catt <- c(list(catt.lcs, catt.psid, catt.psid.trim, catt.psid_plus.trim), catt.top5_psid)

# plot results
par(mfrow = c(2,2))
par(cex.main = 0.8)
plot_catt_panels(all_catt, plot_titles)
```

```{r, warning=FALSE, message=FALSE}
all_catt_eval <- eval_catt(all_catt, plot_titles)
knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

With LCS-PSID1, CATT estimates span from $-3,357.48 to $2,404.33, contrasting with the CATT estimated from experimental data which ranges from $-359.43 to $2,719.14, with a mean CATT estimate of $863.51. 

In contract, across the LCS-PSID1-based subsamples, the ranges of CATT estimates are relatively similar. Importantly, the mean CATT estimates remain positive in all cases, except for `card` subsample, that produces a mean CATT estimate of $-415.71.
```{r, message=FALSE, warning=FALSE}
# save results
save_catt_panels(all_catt, plot_titles, prefix = "lcs")
```

### Quantile treatment effect on the treated (QTET)
```{r, message=FALSE, warning=FALSE}
qte.lcs <- est_qte(Y, treat, covar, data = lcs, cores = 4)
```

```{r, message=FALSE, warning=FALSE}
qte.lcs_psid <- est_qte(Y, treat, covar, data = lcs_psid)
qte.lcs_psid_plus <- est_qte(Y, treat, covar, data = lcs_psid_plus)
qte.lcs_psid.trim <- est_qte(Y, treat, covar, data = lcs_psid.trim) 
qte.lcs_psid_plus.trim <- est_qte(Y, treat, covar, data = lcs_psid_plus.trim) # similar to Imbens & Xu (2024)
```

```{r, message=FALSE, warning=FALSE}
qte.top5_psid <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.lcs0 <- est_qte(Y, treat, NULL, data = lcs)
qte.lcs_psid0 <- est_qte(Y, treat, NULL, data = lcs_psid)
qte.lcs_psid.trim0 <- est_qte(Y, treat, NULL, data = lcs_psid.trim)
qte.lcs_psid_plus.trim0 <- est_qte(Y, treat, NULL, data = lcs_psid_plus.trim)
qte.top5_psid0 <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED12. QTET Estimates Model A using LCS Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.8)

# PSID1
plot_qte(qte.lcs_psid, qte.lcs_psid0, qte.lcs, main = "(B) LCS-PSID1", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1 trimmed
plot_qte(qte.lcs_psid.trim, qte.lcs_psid.trim0, qte.lcs_psid, main = "(C) LCS-PSID1 (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1-PLUS trimmed 
plot_qte(qte.lcs_psid_plus.trim, qte.lcs_psid_plus.trim0, qte.lcs_psid_plus, main = "(D) LCS-PSID1-PLUS (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n") # similar to Imbens & Xu (2024)

# PSID1 top methods
plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.lcs_psid, plot_titles, main_start = 5, ylim = c(-25000, 15000))
```

These figures present QTET estimates obtained from LCS-Experimental sample and several observational samples. The QTETs estimated from both the original and trimmed LCS-PSID1 samples (B and C), as well as from the top-ranked subsamples (E through H), align comparatively close with the true QTET. However, the QTETs from subsample (F) exhibit a stronger bias, suggesting greater estimation uncertainty.
```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED13. QTET Estimates using LCS Data: Experimental vs. Nonexperimental"}
plots_lcs <- list(
  list(mod = qte.lcs_psid, mod0 = qte.lcs_psid0, bm = qte.lcs, main = "(B) LCS PSID1"),
  list(mod = qte.lcs_psid.trim, mod0 = qte.lcs_psid.trim0, bm = qte.lcs_psid, main = "(D) LCS PSID1 (Trimmed)"),
  list(mod = qte.lcs_psid_plus.trim, mod0 = qte.lcs_psid_plus.trim0, bm = qte.lcs_psid_plus, main = "(C) LCS PSID1-PLUS (Trimmed)") # similar to Imbens & Xu (2024)
)

save_qtet(plots_lcs, prefix = "lcs", ylim = c(-25000, 15000))
save_qte_top(qte.top5_psid, qte.top5_psid0, qte.lcs_psid, plot_titles, main_start = 5, ylim = c(-25000, 15000), prefix = "lcs_top")
```

### Assessing outcome weights (OW)
```{r, warning=FALSE, message=FALSE}
# list all datasets
all_datasets <- c(list(lcs, lcs_psid, lcs_psid.trim, lcs_psid_plus.trim), top5_datasets.psid)
```

```{r, warning=FALSE, message=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r,  message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED14. Outcome Weights using LCS Data"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# plot outcome weights distribution
plot_ow(ow_att, plot_titles) 
```

```{r, warning=FALSE, message=FALSE}
# evaluate results
res_ow <- eval_ow(ow_att, all_datasets, plot_titles, treat, "AIPW-ATT")
knitr::kable(res_ow, caption = "Outcome Weights for Treated and Untreated", booktabs = TRUE) 
```

Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero.
```{r, message=FALSE, warning=FALSE}
# save results
save_ow(ow_att, plot_titles, prefix = "lcs")
```

## Validation through placebo analyses
```{r, warning=FALSE, message=FALSE}
# define variables
Y_pl <- "nchildren75"
treat <- "treat"
covar_pl <- c("age", "educ", "nodegree", "married", "black", "hisp", "re75", "u75")
```

```{r, warning=FALSE, message=FALSE}
# estimate placebo ATT on original and observational datasets
out1_pl <- estimate_all(lcs, Y_pl, "treat", covar_pl)
out2_pl <- estimate_all(lcs_psid, Y_pl, "treat", covar_pl)
```

```{r, warning=FALSE, message=FALSE}
# estimate placebo ATT on trimmed datasets 
out3_pl <- estimate_all(lcs_psid.trim, Y_pl, "treat", covar_pl)
out4_pl <- estimate_all(lcs_psid_plus.trim, Y_pl, "treat", covar_pl) # similar to Imbens & Xu (2024)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on top ranked datasets
out.psid_pl <- lapply(top5_datasets.psid, function(d) estimate_all(d, Y_pl, "treat", covar_pl))
out5_pl <- out.psid_pl[[1]]
out6_pl <- out.psid_pl[[2]]
out7_pl <- out.psid_pl[[3]]
out8_pl <- out.psid_pl[[4]]
out9_pl <- out.psid_pl[[5]]
```

```{r, message=FALSE, warning=FALSE}
# collect all placebo results 
all_outs.pl <- c(list(out1_pl, out2_pl, out3_pl, out4_pl), out.psid_pl)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURED16. Placebo Test LCS: Number of Children in 1975 as the Outcome"}
# plot placebo results
band_pl <- out1_pl[1, 3:4]
est_pl  <- out1_pl[1, 1]
ylim_pl = c(-1.5, 1)
plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.8)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, "lcs_placebo")
```

```{r, warning=FALSE, message=FALSE}
result_mat_pl <- create_matrix_results(all_outs.pl, plot_titles)
knitr::kable(result_mat, booktabs = TRUE, caption = "Placebo ATT Estimates and SEs") %>% kable_styling(full_width = TRUE)
```

The placebo analysis shows that the experimental benchmark is close to zero and statistically insignificant, while all estimators applied to the observational datasets produce comparable results.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat_pl, "LCS_att_estimates_pl")
```

## Validation through sensitivity analyses
```{r, warning=FALSE, message=FALSE}
# define variables
Y <- "re79"
treat <- "treat"
# redefine covariates
covar <- c("age", "educ", "nodegree", "married", "black", "hisp", "re75", "u75")
bm <- c("re75")
```

```{r, warning=FALSE, message=FALSE}
# check for valid datasets 
datasets_sens <- c(list(lcs, lcs_psid, lcs_psid_plus), top5_datasets.psid)
filtered_datasets_sens <- check_filter_datasets(datasets_sens, Y, treat, covar, bm)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED17. Sensitivity Analyses LCS"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = plot_titles[idx+1])
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, "lcs")
```

The sensitivity analysis shows that treatment effect estimates in LCS-Experimental (A) are robust to unmeasured confounding, as expected. Observational samples instead show varying degrees of sensitivity, with the full observational sample (B) being more sensitive than the trimmed version (C). The top-ranked PSID1 subsamples (D-H) show that despite employing advanced criteria to improve balance and overlap, treatment effect estimates can exhibit increasing bias under plausible stronger confounding scenarios based on the reference confounder strength. 

## Summary
After reexamining the LaLonde-Calónico-Smith (LCS) data, the results confirm that, as with the NSW and LDW datasets, overlap between treated and control groups is generally stronger in the experimental sample than in the observational (PSID-1) controls. Augmenting the sample with experimental controls improves overlap but does not consistently resolve covariate imbalance.

The findings for the LCS sample closely mirror those from the LDW and NSW analyses: while certain methods can bring effect estimates closer to experimental benchmarks, substantial estimator-dependent variability and sensitivity to sample construction persist. Placebo and sensitivity analyses again show that unconfoundedness is difficult to verify, and that treatment effect estimates from observational data remain fragile. This underscores the ongoing challenge of obtaining reliable causal estimates for the LCS data.