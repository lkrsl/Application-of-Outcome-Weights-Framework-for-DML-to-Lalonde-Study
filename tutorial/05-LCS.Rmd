# LaLonde-Calónico-Smith (LCS) Data 

This section (5) examines the LaLonde female samples reconstructed by @calonico_smith_2017, referred to as the LaLonde-Calónico-Smith (LCS) sample (loaded as `lcs` below, similar to @imbens2024). 

For detailed explanations of the analysis steps and notes, please refer to section 2. Here, we only present and explain the LCS–specific results.

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lcs.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Load and preprocess data 
```{r, message=FALSE, warning=FALSE}
# expc = 0: experimental treated; 
# expc = 1: experimental control; 
# expc = 2: psid control;

lcs_psid$expc <- 0 
lcs_psid[lcs_psid$treat==0, ]$expc <- 2 
lcs_tr <- lcs[lcs$treat==1, ]
lcs_co <- lcs[lcs$treat==0, ]
lcs_co$treat <- 1
lcs_co$expc <- 1
lcs_psid_plus <- rbind.data.frame(lcs_psid, lcs_co)
```

### Inspect data
```{r, message=FALSE, warning=FALSE}
# collect datasets in a list
data <- list(lcs = lcs, lcs_psid = lcs_psid, lcs_psid_plus = lcs_psid_plus)

# inspect key metrics of each dataset
summary_stats <- inspect_data(data)
knitr::kable(summary_stats, caption = "Summary Statistics")
```

## Model
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re79"
treat <- "treat"
# redefine covariates: removing "nchildren75" to be used as placebo outcome
covar <- c("age", "educ", "nodegree", "married", "black", "hisp", 
           "re75", "u75")
```

<div class="callout-note">
In the following analysis, only PSID1 data is used as the original LaLonde study and its reconstruction by Calónico and Smith (2017) designate PSID1 as the appropriate nonexperimental control group for women, providing a comparable observational dataset that aligns with the experimental sample’s characteristics.
</div>

### Assessing overlap and covariate balance
#### Overlap
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1.',out.width='100%', fig.asp=0.5}
lcs.ps <- assess_overlap(data = lcs, treat = treat, cov = covar, xlim = c(-1.5, 1.5), breaks = 40)
lcs_psid.ps <- assess_overlap(data = lcs_psid, treat = treat, cov = covar, xlim = c(-11, 7), breaks = 40)
```

As anticipated, the LCS-Experimental data exhibit an almost perfect overlap. In contrast, the observational dataset LCS-PSID1 displays weak overlap. 
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED1. SubfigureC:LCS-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
lcs_psid_plus.ps <- assess_overlap(data = lcs_psid_plus, treat = treat, cov = covar, xlim = c(-15, 5))
```

With the expanded dataset LCS-PSID1, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater spread of log-odds densities across both samples.

```{r, message=FALSE, warning=FALSE}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

#### Covariate balance
```{r, warning=FALSE, message=FALSE, fig.cap='FIGURED2. SubfigureA:LDW-PSID1. SubfigureB:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
love.plot(lcs, lcs_psid, treat, covar = covar, title = "LCS-PSID1")
love.plot(lcs, lcs_psid_plus, treat, covar = covar, title = "LCS-PSID1-PLUS")
```

<div class="callout-note">
Due to computational constraints, we use a reduced set of matching methods, consistent with previous sections.
</div>

## Improving primarily covariate balance
### Matching 
#### Distance Matching
##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.psid.optimal_pair <- matchit(model, data = lcs_psid, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
m.out.psid.optimal_full <- matchit(model, data = lcs_psid, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios  
m.out.psid.general_full <- matchit(model, data = lcs_psid, method = "quick", distance = "logit")
```

#### Stratum matching
##### Coarsened matching (cem)
Strata = coarsened versions of covariates
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
m.out.psid.cem <- matchit(model, data = lcs_psid, method = "cem")
```

##### Subclassification 
Strata = bins of the propensity score
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
m.out.psid.subcl <- matchit(model, data = lcs_psid, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units
m.out.psid.card <- matchit(model, data = lcs_psid, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
# select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact
m.out.psid.profile <- matchit(model, data = lcs_psid, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs", time = 1200)
```

### Weighting
#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores with a parametric generalized linear model and converts them into weights
w.out.ipw <- WeightIt::weightit(model, data = lcs_psid, estimand = "ATT", method = "glm")
lcs_psid$ipw_weight <- w.out.ipw$weights
```

#### Stable balancing weights 
```{r, message=FALSE, warning=FALSE}
# estimates weights by solving a quadratic programming problem 
w.out.opt <- optweight::optweight(model, data = lcs_psid, estimand = "ATT")
lcs_psid$opt_weight <- w.out.opt$weights
```

#### Covariate balance propensity score weights
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores using generalized method of moments and then converts them into weights
w.out.cbps <- WeightIt::weightit(model, data = lcs_psid, estimand = "ATT", method = "cbps")
lcs_psid$cbps_weight <- w.out.cbps$weights
```

#### Entropy balancing weights
```{r, message=FALSE, warning=FALSE}
# estimates weights by minimizing the negative entropy of the weights subject to exact moment balancing constraints
w.out.ebal <- WeightIt::weightit(model, data = lcs_psid, estimand = "ATT", method = "ebal")
lcs_psid$ebal_weight <- w.out.ebal$weights
```

## Improving primarily overlap
### Truncation
```{r, message=FALSE, warning=FALSE}
# list of weight columns to apply truncation 
weight_columns <- c("ipw_weight", "opt_weight", "cbps_weight", "ebal_weight")
```

#### Fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum threshold
lcs_psid.fixed <- lcs_psid
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid.fixed)) {
    lcs_psid.fixed <- truncate_weights_fixed(lcs_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
lcs_psid.percent <- lcs_psid
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid.percent)) {
    lcs_psid.percent <- truncate_weights_percentile(lcs_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}
```

#### Adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
psid_results <- list()

for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid)) {
    psid_results[[wcol]] <- check_weights(lcs_psid, wcol)
  } else {
    warning(paste("Column", wcol, "not found in LCS-PSID1"))
  }
}

var_psid_table <- bind_rows(psid_results)
knitr::kable(var_psid_table, caption = "Variance of Weights")
```

Regarding these results we can apply adaptive weight truncation to all considered weights.
```{r, message=FALSE, warning=FALSE}
# truncate adaptively at mean + 3 standard deviations 
lcs_psid.adapt <- lcs_psid
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid.adapt)) {
    lcs_psid.adapt <- truncate_weights_adaptive(lcs_psid.adapt, weight_col = wcol, c = 3)
  }
}
```
 
### Trimming 
#### Propensity score threshold trimming 
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
lcs_psid.trim <- ps_trim(lcs_psid.ps, threshold = 0.9)

# re-estimate propensity scores on trimmed data 
lcs_psid.trim <- ps_estimate(data = lcs_psid.trim, Y = "re79", treat = "treat", cov = covar)
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
lcs_psid.common  <- common_range_trim(lcs_psid.ps)

# re-estimate propensity scores on trimmed data 
lcs_psid.common <- ps_estimate(data = lcs_psid.common, Y = "re79", treat = "treat", cov = covar)
```

#### Crump trimming 
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
lcs_psid.crump <- crump_trim(lcs_psid.ps, lower = 0.1, upper = 0.9)

# re-estimate propensity scores on trimmed data 
lcs_psid.crump <- ps_estimate(data = lcs_psid.crump, Y = "re79", treat = "treat", cov = covar)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
lcs_psid.stuermer <- stuermer_trim(lcs_psid.ps)

# re-estimate propensity scores on trimmed data 
lcs_psid.stuermer <- ps_estimate(data = lcs_psid.stuermer, Y = "re79", treat = "treat", cov = covar)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
lcs_psid.walker  <- walker_trim(lcs_psid.ps)

# re-estimate propensity scores on trimmed data 
lcs_psid.walker <- ps_estimate(data = lcs_psid.walker, Y = "re79", treat = "treat", cov = covar)
```

## Integrated methods
### Trimming and matching
#### Propensity score threshold trimming and nn matching
(Similar to tutorial of @imbens2024)
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
lcs_psid_trim <- ps_trim(lcs_psid_plus.ps, threshold = 0.9)

# exclude experimental controls
lcs_psid_trim_match <- subset(lcs_psid_trim, expc %in% c(0, 2) & ps_assoverlap)

# re-estimate propensity scores and employ 1:1 matching
lcs_psid_trim_match <- psmatch(data = lcs_psid_trim_match, Y = "re79", treat = "treat", cov = covar)

# trim experimental data
lcs_trim_psid <- subset(lcs_psid_trim, expc %in% c(0, 1))
lcs_trim_psid$treat[which(lcs_trim_psid$expc == 1)] <- 0
```

### Trimming and weighting
```{r, message=FALSE, warning=FALSE}
# list trimming objects
all_trim.psid  <- list(ps_threshold = lcs_psid.trim, 
                     common_range = lcs_psid.common, 
                     stuermer = lcs_psid.stuermer, 
                     walker = lcs_psid.walker, 
                     crump = lcs_psid.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply inverse probability weighting (IPW) with trimming and attach IPW weights
ipw_comb.psid <- trim_attach_weights(all_trim.psid, model, "ipw_weight")
```

#### Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply stable balancing with trimming and attach stable balance weights
opt_comb.psid <- trim_attach_weights(all_trim.psid, model, "opt_weight")
```

#### Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply propensity score weighting with trimming and attach propensity score weights
cbps_comb.psid <- trim_attach_weights(all_trim.psid, model, "cbps_weight")
```

#### Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
ebal_comb.psid <- trim_attach_weights(all_trim.psid, model, "ebal_weight")
```

## Reassessing methods
### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching objects
all_match.psid <- list(
  optimal_pair = m.out.psid.optimal_pair,
  optimal_full = m.out.psid.optimal_full,
  gen_full = m.out.psid.general_full,
  cem = m.out.psid.cem,
  card = m.out.psid.card,
  profile = m.out.psid.profile,
  subcl = m.out.psid.subcl
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_matchit.psid <- compute_abs_smd_matchit(all_match.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# calculate balance statistics 
bal.psid <- cobalt::bal.tab(model, data = lcs_psid, un = TRUE, weights = all_match.psid, s.d.denom = "treated")
```

```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_matchit.psid <- compute_ess_matchit(bal.psid)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED3.'}
# visualize covariate balance 
plot_matching_balance(all_match.psid, title = "LCS-PSID1")
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
all_weight.psid <- list(
  ipw_weight = lcs_psid$ipw_weight,
  opt_weight = lcs_psid$opt_weight,
  cbps_weight = lcs_psid$cbps_weight,
  ebal_weight = lcs_psid$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_weight.psid <- compute_abs_smd_weight(lcs_psid, treat, covar, all_weight.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_weight.psid <- compute_ess_weight(lcs_psid, treat, covar, all_weight.psid)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED4.'}
# visualize covariate balance
plot_weighting_balance(lcs_psid, treat, covar, all_weight.psid, "LCS-PSID1")
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
all_trunc.psid <- list(
  fix_max_value = lcs_psid.fixed,
  at_perc = lcs_psid.percent,
  adap_weight = lcs_psid.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trunc.psid <- compute_abs_smd_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trunc.psid <- compute_ess_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED5.'}
# visualize covariate balance
plot_trunc_balance(all_trunc.psid, "treat", covar, weight_columns, "LCS-PSID1")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming object plus original
all_trim.psid <- list(
  original = lcs_psid,
  ps_threshold = lcs_psid.trim,
  common_range = lcs_psid.common,
  crump = lcs_psid.crump,
  stuermer = lcs_psid.stuermer,
  walker = lcs_psid.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trim.psid <- compute_abs_smd_trim(all_trim.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trim.psid <- compute_ess_trim(all_trim.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED6.'}
# visualize overlap
plot_trim_overlap(all_trim.psid, treat, covar, prefix = "LCS-PSID1")
```

## Integrated methods
### Trimming and matching
(Similar to tutorial by @imbens2024)
```{r, message=FALSE, warning=FALSE}
# list all trimmed and matched samples
comb_psid <- list(
  ps_threshold_match = lcs_psid_trim_match
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_all_comb_meth.psid_plus <- compute_abs_smd_trim(comb_psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.psid_plus <- compute_ess_trim(comb_psid, "treat", covar)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGURED7.'}
# visualize overlap
par(mfrow = c(1, 3))
plot_trim_overlap(comb_psid, treat, covar, prefix = "LCS-PSID1-PLUS")
```

### Trimming and weighting
```{r, message=FALSE, warning=FALSE}
# list all combined results
comb.psid <- list(
  ipw = ipw_comb.psid,
  opt = opt_comb.psid,
  cbps = cbps_comb.psid,
  ebal = ebal_comb.psid
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_all_comb_meth.psid <- compute_abs_smd_comb(comb.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.psid <- compute_ess_comb(comb.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURED8.'}
# visualize overlap
plot_comb_overlap(comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix_psid = "LCS-PSID1")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_comb_hist(comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix = "lcs", prefix_psid = "lcs_psid1")
```

## Identifying best methods
```{r, message=FALSE, warning=FALSE}
# combine all results
all_psid <- combine_results("psid") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_psid, "lcs_psid1_all_results")
```

```{r, message=FALSE, warning=FALSE}
# assess and rank methods
ranked_psid <- assess_methods(all_psid)
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods
top5_methods.psid <- get_top_methods(ranked_psid, top_n = 5)

# print results
top5_methods_df.psid <- ranked_psid %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.psid, caption = "Top 5 Methods", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_psid, "lcs_psid1_all_results")
```

The table shows that for PSID1 the top methods include only matching and integrated approaches, with `card` as the best method.
```{r}
dataset_list_psid <- list(
  "All" = lcs_psid,
  "original" = lcs_psid,
  "card" = m.out.psid.card,
  "optimal_full" = m.out.psid.optimal_full,
  "optimal_pair" = m.out.psid.optimal_pair,
  "gen_full" = m.out.psid.general_full,
  "subcl" = m.out.psid.subcl,
  "profile" = m.out.psid.profile,
  "ipw_weight" = lcs_psid$ipw_weight, 
  "opt_weight" = lcs_psid$opt_weight,
  "cbps_weight" = lcs_psid$cbps_weight,
  "ebal_weight" = lcs_psid$ebal_weight,
  "fix_max_value_ipw_weight" = lcs_psid.fixed$ipw_weight,
  "fix_max_value_opt_weight" = lcs_psid.fixed$opt_weight,
  "fix_max_value_cbps_weight" = lcs_psid.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = lcs_psid.fixed$ebal_weight,
  "at_perc_ipw_weight" = lcs_psid.percent$ipw_weight,
  "at_perc_opt_weight" = lcs_psid.percent$opt_weight,
  "at_perc_cbps_weight" = lcs_psid.percent$cbps_weight,
  "at_perc_ebal_weight" = lcs_psid.percent$ebal_weight,
  "adap_weight_ipw_weight" = lcs_psid.adapt$ipw_weight,
  "adap_weight_opt_weight" = lcs_psid.adapt$opt_weight,
  "adap_weight_cbps_weight" = lcs_psid.adapt$cbps_weight,
  "adap_weight_ebal_weight" = lcs_psid.adapt$ebal_weight,
  "ps_threshold" = lcs_psid.trim,
  "common_range" = lcs_psid.common,
  "stuermer" = lcs_psid.stuermer,
  "walker" = lcs_psid.walker,
  "crump" = lcs_psid.crump,
  "ipw_common_range" = ipw_comb.psid[[1]],
  "ipw_crump"= ipw_comb.psid[[2]],
  "ipw_ps_threshold"= ipw_comb.psid[[3]],
  "ipw_stuermer"= ipw_comb.psid[[4]],
  "ipw_walker" = ipw_comb.psid[[5]],
  "opt_common_range" = opt_comb.psid[[1]],
  "opt_crump" = opt_comb.psid[[2]],
  "opt_ps_threshold" = opt_comb.psid[[3]],
  "opt_stuermer" = opt_comb.psid[[4]],
  "opt_walker" = opt_comb.psid[[5]],
  "cbps_common_range" = cbps_comb.psid[[1]],
  "cbps_crump" = cbps_comb.psid[[2]],
  "cbps_ps_threshold"  = cbps_comb.psid[[3]],
  "cbps_stuermer" = cbps_comb.psid[[4]],
  "cbps_walker"= cbps_comb.psid[[5]],
  "ebal_common_range" = ebal_comb.psid[[1]],
  "ebal_crump" = ebal_comb.psid[[2]],
  "ebal_ps_threshold" = ebal_comb.psid[[3]],
  "ebal_stuermer" = ebal_comb.psid[[4]],
  "ebal_walker" = ebal_comb.psid[[5]])
```

```{r, message=FALSE, warning=FALSE}
# create the datasets from combined lists for your top 5 methods:
top5_datasets.psid <- create_top5_datasets(dataset_list_psid, top5_methods.psid)
```

```{r, message=FALSE, warning=FALSE}
# save them into .RData files
save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = "lcs_psid1")
```

## Estimating
### Average treatment effect on the treated (ATT)
```{r, message=FALSE, warning=FALSE}
# get estimates
out1 <- estimate_all(lcs, "re79", "treat", covar)
out2 <- estimate_all(lcs_psid, "re79", "treat", covar)

out.psid <- lapply(top5_datasets.psid, function(d) estimate_all(d, "re79", "treat", covar))
out3 <- out.psid[[1]]
out4 <- out.psid[[2]]
out5 <- out.psid[[3]]
out6 <- out.psid[[4]]
out7 <- out.psid[[5]]

load("data/lcs.RData")
out8 <- estimate_all(lcs_trim_psid, Y, "treat", covar)
out9 <- estimate_all(lcs_psid_trim, Y, "treat", covar)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED10. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1. SubfigureC-G:Top-LCS-PSID1. ATT Estimates Given Unconfoundedness using LCS Samples"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))

# experimental benchmarks
band.exp <- out1[1, 3:4]
est.exp  <- out1[1, 1]

# plot results
plot_coef(out1,  band = band.exp, line = est.exp, 
          ylim = c(-15500, 5500), main = "(A) LCS-Experimental")

plot_coef(out2,  band = band.exp, line = est.exp, 
          ylim = c(-15500, 5500), main = "(B) LCS-PSID1")

for (i in seq_along(out.psid)) {
  this_title <- paste0("(", LETTERS[i+2], ") Top PSID1: ", top5_methods.psid[i])
  plot_coef(out.psid[[i]], band = band.exp, line = est.exp,
            ylim = c(-15500, 5500), main = this_title)
}
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED10. SubfigureH:LCS-PSID1-PLUS. ATT Estimates Given Unconfoundedness using LCS Samples"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))
par(cex.main = 0.9)

# nonexperimtenal benchmarks
band.psid_plus <- out8[1, 3:4]
est.psid_plus <- out8[1, 1]

# plot results
plot_coef(out9, band = band.psid_plus, line = est.psid_plus, 
          ylim = c(-15500, 5500), main = "(H) Trimmed LCS-PSID1-PLUS")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(
  out_list = list(out1, out2),
  plot_titles = c("(A) LCS-Experimental", "(B) LCS-PSID1"),
  band_list = list(band.exp, band.exp),
  est_list  = list(est.exp, est.exp),
  prefix = "lcs_est_exp"
)

save_att_panels(
  out_list = out.psid,
  plot_titles = paste0("(", LETTERS[3:7], ") Top PSID1: ", top5_methods.psid),
  band_list = replicate(length(out.psid), band.exp, simplify = FALSE),
  est_list  = replicate(length(out.psid), est.exp, simplify = FALSE),
  prefix = "ldw_model_a_est_top_psid"
)

save_att_panels(
  out_list = list(out9),
  plot_titles = c("(H) Trimmed LCS-CPS1-PLUS"),
  band_list = list(band.psid_plus),
  est_list  = list(est.psid_plus),
  prefix = "ldw_model_a_est_plus"
)
```

The above figures show the ATT estimates and their 95% confidence intervals for eight samples: LCS-Experimental, LCS-PSID1, a series of top-ranked subsamples of LCS-PSID1 based on various matching, weighting, truncation, trimming or integrated criteria, as well as a trimmed version of the LCS-PSID1-PLUS sample (analogous to @imbens2024).

Figure (A) presents the benchmark from the experimental sample (LCS-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) shows results for the observational sample LCS-PSID1 and figures (C) through (G) display results for LCS-PSID1-based top-ranked subsamples. Figure (H) shows results for a trimmed version of LCS-PSID1-PLUS, replicating the tutorial results of Imbens & Xu (2024). 

Across the LCS-PSID1 dataset and its top-ranked subsamples, all estimators yield ATT estimates that largely cluster around the experimental benchmark except `Diff-in-Means`, which tends to produce estimates that deviate slightly more from the benchmark.
```{r, message=FALSE, warning=FALSE}
# get all outputs
all_outs <- c(list(out1, out2), 
              out.psid, 
              list(out9))

# get plot titles
all_plot_titles <- c("(A) LCS-Experimental", "(B) LCS-PSID1",
                      paste0("(", LETTERS[3:7], ") Top PSID1: ", top5_methods.psid),
                      "(H) Trimmed LCS-PSID1-PLUS")

# evaluate results
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- all_plot_titles

# print results
knitr::kable(att_summary, caption = "ATT Summary Statistics", booktabs = TRUE) %>%
  kable_styling(full_width = TRUE)
```

The ATT results are presented in the table below:
```{r, message=FALSE, warning=FALSE}
# create result matrix
result_mat <- create_matrix_results(all_outs, all_plot_titles)

# render formatted table output
knitr::kable(result_mat, booktabs = TRUE, caption = "ATT Estimates and SEs") %>%
  kable_styling(full_width = TRUE) %>%
  scroll_box(height = "800px", width = "100%")
```

The tabulated results confirm visual patterns: Column (A) reports the estimates for the LCS-Experimental sample, column (B) for the LCS-PSID1 sample, columns (D)-(H) for the top-ranked subsample of LCS-PSID1, and column (C) for its trimmed version of LCS-PSID-PLUS.

For all PSID1-based samples, the ATT estimates remain overly positive. However, the estimates obtained with the `Diff-in-Means` estimator are consistently negative, except for the sample constructed with the `card` method, where the estimates are positive across all estimators.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "lcs_att_est")
```

### Conditional average treatment effect on the treated (CATT)
```{r, warning=FALSE, message=FALSE}
catt.lcs <- catt(lcs, Y, treat, covar)
catt.psid <- catt(lcs_psid, Y, treat, covar)
catt.top5_psid <- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar))
```

```{r, warning=FALSE, message=FALSE}
catt.lcs.psid <- catt(lcs_trim_psid, Y, treat, covar)
catt.psid.trim <- catt(lcs_psid_trim, Y, treat, covar)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED11. SubfigureB:LCS-PSID1. SubfigureC-G:Top-LCS-PSID1. SubfigureH:LCS-PSID1-PLUS. CATT Estimates using LCS Data: Experimental vs. Nonexperimental"}
# plot results
par(mfrow = c(2,2)) 
par(cex.main = 0.9)
plot_catt(
  catt1 = catt.lcs$catt,
  catt2 = catt.psid$catt,
  att1  = catt.lcs$att[1],
  att2  = catt.psid$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (CPS1)",
  main  = "(B) LCS-PSID1", 
  axes.range = c(-8000, 8000)
)

plot_catt_panels(
  exp_catt = catt.lcs,
  catt_list  = catt.top5_psid,
  plot_titles = paste0("(", LETTERS[3:7], ") Top PSID1: ", top5_methods.psid)
)

plot_catt(
  catt1 <- catt.lcs.psid$catt,
  catt2 <- catt.psid.trim$catt,
  att1 <- catt.lcs.psid$att[1],
  att2 <- catt.psid.trim$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (PSID1-PLUS-Trimmed)",
  main  = "(H) Trimmed LCS-PSID1-PLUS",
  axes.range = c(-8000, 8000)
)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED12. CATT Estimates using LCS Data"}
# combine all catt objects 
all_catt <- c(list(catt.lcs, catt.psid), 
              catt.top5_psid, 
              list(catt.psid.trim))

all_catt_eval <- eval_catt(all_catt, all_plot_titles)
knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

With LCS-PSID1, CATT estimates span from $-3,149.81 to $2,395.66, contrasting with the CATT estimated from experimental data which ranges from $-478.45 to $2,895.23, with a mean CATT estimate of $886.31. 

In contract, across the LCS-PSID1-based subsamples, the ranges of CATT estimates are relatively similar. Importantly, the mean CATT estimates remain positive in all cases and for the `card` subsample as well as the trimmed plus-sample the mean CATT values are notably reduced.
```{r, message=FALSE, warning=FALSE}
save_main_catt_panels(
  catt_refs = list(catt.lcs),
  catt_comps = list(catt.psid),
  ylabels = c("CATT (PSID1)"),
  prefix = "lcs_catt_main_panels",
  main_titles = c("(B) LCS-PSID1")
)

save_catt_panels(
  exp_catt = catt.lcs,
  catt_list  = catt.top5_psid,
  plot_titles = paste0("(", LETTERS[3:7], ") Top PSID1: ", top5_methods.psid),
  prefix = "lcs_catt_top5_psid"
)

save_plus_catt_panels(
  catt1_list = list(catt.lcs.psid),
  catt2_list = list(catt.psid.trim),
  ylabels = c("CATT (PSID1-PLUS-Trimmed)"),
  prefix = "lcs_catt_plus_panels",
  main_titles = c("(H) Trimmed LCS-PSID1-PLUS")
)
```

### Quantile treatment effect on the treated (QTET)
```{r, message=FALSE, warning=FALSE}
qte.lcs <- est_qte(Y, treat, covar, data = lcs, cores = 4)
qte.lcs_psid <- est_qte(Y, treat, covar, data = lcs_psid)
qte.top5_psid <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.lcs.psid <- est_qte(Y, treat, NULL, data = lcs_trim_psid)
qte.lcs_psid.trim <- est_qte(Y, treat, covar, data = lcs_psid_trim)
```

```{r, message=FALSE, warning=FALSE}
qte.lcs0 <- est_qte(Y, treat, NULL, data = lcs)
qte.lcs_psid0 <- est_qte(Y, treat, NULL, data = lcs_psid)
qte.top5_psid0 <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.lcs_psid.trim0 <- est_qte(Y, treat, NULL, data = lcs_psid_trim)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED13. SubfigureB:LCS-PSID1.  SubfigureC-G:Top-LCS-PSID1. SubfigureH:LCS-PSID1-PLUS. QTET Estimates using LCS Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.9)
ylim = c(-25000, 15000)
# PSID1
plot_qte(qte.lcs_psid, qte.lcs_psid0, qte.lcs, main = "(B) LCS-PSID1", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
       lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1 top methods
plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.lcs, all_plot_titles, main_start = 3)

# PSID1-PLUS trimmed
plot_qte(qte.lcs_psid.trim, qte.lcs_psid.trim0, qte.lcs.psid, main = "(H) LCS-PSID1-PLUS (Trimmed)", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")
```

These figures present QTET estimates obtained from LCS-Experimental sample and several observational samples. The QTETs estimated from both the original and trimmed LCS-PSID1 samples (B and C), as well as from the top-ranked subsamples (E through H), align comparatively close with the true QTET. However, the QTETs from subsample (F) exhibit a stronger bias, suggesting greater estimation uncertainty.
```{r, message=FALSE, warning=FALSE}
# list results
plots_lcs <- list(
  list(mod = qte.lcs_psid, mod0 = qte.lcs_psid0, bm = qte.lcs, 
       main = "(B) LCS-PSID1"),
  list(mod = qte.lcs_psid.trim, mod0 = qte.lcs_psid.trim0, bm = qte.lcs.psid, 
       main = "(H) LCS-PSID1-PLUS (Trimmed)")
)

# save results
save_qtet(plots_lcs, prefix = "lcs")
save_qte_top(qte.top5_psid, qte.top5_psid0, qte.lcs, all_plot_titles, 
             main_start = 13, prefix = "lcs_top")
```

### Assessing outcome weights (OW)
```{r, warning=FALSE, message=FALSE}
# list all datasets
all_datasets <- c(list(lcs, lcs_psid), 
                  top5_datasets.psid, 
                  list(lcs_trim_psid))
```

```{r, warning=FALSE, message=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r,  message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED14. Outcome Weights using LCS Data"}
par(mfrow = c(2,2))
par(cex.main = 0.9)
# plot outcome weights distribution
plot_ow(ow_att, all_plot_titles) 
```

```{r, warning=FALSE, message=FALSE}
# evaluate results
res_ow <- eval_ow(ow_att, all_datasets, all_plot_titles, treat, "AIPW-ATT")
knitr::kable(res_ow, caption = "Outcome Weights for Treated and Untreated", booktabs = TRUE) %>%
  kable_styling(full_width = TRUE) 
```

Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero.
```{r, message=FALSE, warning=FALSE}
# save results
save_ow(ow_att, all_plot_titles, prefix = "lcs")
```

## Validation through placebo analyses
```{r, warning=FALSE, message=FALSE}
# define variables
Y <- "nchildren75"
treat <- "treat"
covar <- c("age", "educ", "nodegree", "married", "black", "hisp", "re75", "u75")
```

```{r, warning=FALSE, message=FALSE}
# estimate placebo ATT on original and observational dataset
out1_pl <- estimate_all(lcs, Y, "treat", covar)
out2_pl <- estimate_all(lcs_psid, Y, "treat", covar)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on top ranked datasets
out.psid_pl <- lapply(top5_datasets.psid, function(d) estimate_all(d, Y, "treat", covar))
out3_pl <- out.psid_pl[[1]]
out4_pl <- out.psid_pl[[2]]
out5_pl <- out.psid_pl[[3]]
out6_pl <- out.psid_pl[[4]]
out7_pl <- out.psid_pl[[5]]
```

```{r, warning=FALSE, message=FALSE}
# estimate placebo ATT on plus datasets
load("data/trimmed.RData")
out8_pl <- estimate_all(lcs_trim_psid, Y, "treat", covar)
out9_pl <- estimate_all(lcs_psid_trim, Y, "treat", covar)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED15. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1. SubfigureC-G:Top-LCS-PSID1. Placebo Test: Number of Children in 1975 as the Outcome"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))

# experimental benchmarks
band.exp_pl <- out1_pl[1, 3:4]
est.exp_pl <- out1_pl[1, 1]

# plot placebo results
plot_coef(out1_pl,  band = band.exp_pl, line = est.exp_pl, 
          ylim = c(-1.5, 1), main = "(A) LCS-Experimental")

plot_coef(out2_pl,  band = band.exp_pl, line = est.exp_pl,
          ylim = c(-1.5, 1), main = "(B) LCS-PSID1")

for (i in seq_along(out.psid_pl)) {
  this_title <- paste0("(", LETTERS[i+2], ") Top PSID1: ", top5_methods.psid[i])
  plot_coef(out.psid_pl[[i]], band = band.exp_pl, line = est.exp_pl,
            ylim = c(-1.5, 1), main = this_title)
}
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA15. SubfigureH:LCS-PSID1-PLUS. Placebo Test: Number of Children in 1975 as the Outcome"}
par(mfrow = c(4, 1))

# nonexperimtenal benchmarks
band.psid_plus_pl <- out8_pl[1, 3:4]
est.psid_plus_pl <- out8_pl[1, 1]

# plot results
plot_coef(out9_pl, band = band.psid_plus_pl, line = est.psid_plus_pl, 
          ylim = c(-1.5, 1), main = "(H) LCS-PSID1-PLUS (Trimmed)")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(
  out_list = list(out1_pl, out2_pl),
  plot_titles = c("(A) LCS-Experimental", "(B) LCS-CPS1"),
  band_list = list(band.exp_pl, band.exp_pl),
  est_list  = list(est.exp_pl, est.exp_pl),
  prefix = "lcs_pl_est_exp"
)

save_att_panels(
  out_list = out.psid_pl,
  plot_titles = paste0("(", LETTERS[3:7], ") Top PSID1: ", top5_methods.psid),
  band_list = replicate(length(out.psid_pl), band.exp_pl, simplify = FALSE),
  est_list  = replicate(length(out.psid_pl), est.exp_pl, simplify = FALSE),
  prefix = "lcs_pl_est_top_psid"
)

save_att_panels(
  out_list = list(out9_pl),
  plot_titles = c("(H) LCS-PSID1-PLUS (Trimmed)"),
  band_list = list(band.psid_plus_pl),
  est_list  = list(est.psid_plus_pl),
  prefix = "lcs_pl_est_plus",
  ylim = c(-12000, 2000)
)
```

```{r, message=FALSE, warning=FALSE}
# print placebo results
all_outs.pl <- c(list(out1_pl, out2_pl), 
                 out.psid_pl, 
                 list(out9_pl))

result_mat_pl <- create_matrix_results(all_outs.pl, all_plot_titles)

knitr::kable(result_mat_pl, booktabs = TRUE, caption = "Placebo ATT Estimates and SEs") %>%
  kable_styling(full_width = TRUE) %>%
  scroll_box(height = "800px", width = "100%")
```

The placebo analysis shows that the experimental benchmark is close to zero and statistically insignificant, while all estimators applied to the observational datasets produce comparable results.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat_pl, "lcs_att_estimates_pl")
```

## Validation through sensitivity analyses
```{r, warning=FALSE, message=FALSE}
# define variables
Y <- "re79"
treat <- "treat"
# redefine covariates
covar <- c("age", "educ", "nodegree", "married", "black", "hisp", "re75", "u75")
bm <- c("re75")
```

```{r, warning=FALSE, message=FALSE}
# check for valid datasets 
filtered_datasets_sens <- check_filter_datasets(all_datasets, Y, treat, covar, bm)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURED16. Sensitivity Analyses LCS"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = all_plot_titles[idx]) 
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, all_plot_titles, "lcs")
```

The sensitivity analysis shows that treatment effect estimates in LCS-Experimental (A) are robust to unmeasured confounding, as expected. Observational samples instead show varying degrees of sensitivity, with the full observational sample (B) being more sensitive than the trimmed version (H). The top-ranked PSID1 subsamples (C-G) show that despite employing advanced criteria to improve balance and overlap, treatment effect estimates can exhibit increasing bias under plausible stronger confounding scenarios based on the reference confounder strength. 

## Summary
After reexamining the LaLonde-Calónico-Smith (LCS) data, the results confirm that, as with the NSW and LDW datasets, overlap between treated and control groups is generally stronger in the experimental sample than in the observational (PSID-1) controls. Augmenting the sample with experimental controls improves overlap but does not consistently resolve covariate imbalance.

The findings for the LCS sample closely mirror those from the LDW and NSW analyses: while certain methods can bring effect estimates closer to experimental benchmarks, substantial estimator-dependent variability and sensitivity to sample construction persist. Placebo and sensitivity analyses again show that unconfoundedness is difficult to verify, and that treatment effect estimates from observational data remain fragile. This underscores the ongoing challenge of obtaining reliable causal estimates for the LCS data.