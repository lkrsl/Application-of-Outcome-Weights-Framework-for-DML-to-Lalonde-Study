# LaLonde-Calónico-Smith (LCS) Data 

This section (5) examines the LaLonde female samples reconstructed by @calonico_smith_2017, referred to as the LaLonde-Calónico-Smith (LCS) sample (loaded as `lcs` below, similar to @imbens2024). 

For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only present and explain the LCS–specific results.

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lcs.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Load and preprocess data 
```{r, message=FALSE, warning=FALSE}
# expc = 0: experimental treated; 
# expc = 1: experimental control; 
# expc = 2: psid control;

lcs_psid$expc <- 0 
lcs_psid[lcs_psid$treat==0, ]$expc <- 2 
lcs_tr <- lcs[lcs$treat==1, ]
lcs_co <- lcs[lcs$treat==0, ]
lcs_co$treat <-  1
lcs_co$expc <- 1
lcs_psid_plus <- rbind.data.frame(lcs_psid, lcs_co)
```

```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re79"
treat <- "treat"
# redefine covariates: removing "nchildren75" to be used as placebo outcome
covar <- c("age", "educ", "nodegree", "married", "black", "hisp", 
           "re75", "u75")
```

<div class="callout-note">
In the following analysis, only PSID1 data is used as the original LaLonde study and its reconstruction by Calónico and Smith (2017) designate PSID1 as the appropriate nonexperimental control group for women, providing a comparable observational dataset that aligns with the experimental sample’s characteristics.
</div>

### Assessing overlap and covariate balance
#### Overlap
```{r, fig.cap='FIGURE1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1.',out.width='100%', fig.asp=0.5}
# assess overlap
lcs.ps <- assess_overlap(data = lcs, treat = treat, cov = covar, xlim = c(-1.5, 1.5), breaks = 40)
lcs_psid.ps <- assess_overlap(data = lcs_psid, treat = treat, cov = covar, xlim = c(-11, 7), breaks = 40)
```

As anticipated, the LCS-Experimental data exhibit an almost perfect overlap. In contrast, the observational dataset LCS-PSID1 displays weak overlap. 
```{r, fig.cap='FIGURE2. SubfigureC:LCS-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
# assess overlap
lcs_psid_plus.ps <- assess_overlap(data = lcs_psid_plus, treat = treat, cov = covar, xlim = c(-15, 5))
```

With the expanded dataset LCS-PSID1, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater spread of log-odds densities across both samples.

```{r, message=FALSE, warning=FALSE}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

#### Covariate balance
```{r, message=FALSE, warning=FALSE}
love.plot(lcs, lcs_psid, treat, covar = covar, title = "LCS-PSID1")
love.plot(lcs, lcs_psid_plus, treat, covar = covar, title = "LCS-PSID1-PLUS")
```

<div class="callout-note">
Due to computational constraints, we use a reduced set of matching methods, consistent with previous sections.
</div>

## Improving primarily covariate balance
### Matching 
#### Distance Matching
##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.psid_plus.optimal_pair <- matchit(model, data = lcs_psid_plus, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
m.out.psid_plus.optimal_full <- matchit(model, data = lcs_psid_plus, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios 
m.out.psid_plus.general_full <- matchit(model, data = lcs_psid_plus, method = "quick", distance = "logit")
```

#### Stratum matching
##### Coarsened matching (cem)
Strata = coarsened versions of covariates
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
m.out.psid_plus.cem <- matchit(model, data = lcs_psid_plus, method = "cem")
```

##### Subclassification 
Strata = bins of the propensity score
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
m.out.psid_plus.subcl <- matchit(model, data = lcs_psid_plus, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances
m.out.psid_plus.card <- matchit(model, data = lcs_psid_plus, method = "cardinality", tols = 0.1, ratio = 1)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
# matching by directly optimizing balance profile measures across covariates
m.out.psid_plus.profile <- matchit_profile(lcs_psid_plus, treat, covar)
```

### Weighting
#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# compute weights as inverse of estimated propensity scores 
w.out.psid_plus.ipw <- weightit(model, data = lcs_psid_plus, method = "ps", estimand = "ATT")

lcs_psid_plus$ipw_weight <- w.out.psid_plus.ipw$weights
```

#### Standardized mortality ratio (SMR) treated weights
```{r, message=FALSE, warning=FALSE}
# calculate weights for ATT by assigning weight = 1 to treated units and weights proportional to odds of treatment for control
lcs_psid_plus$smr_weight <- create_smr_weights(lcs_psid_plus, model, "ATT")
```

#### Matching weights
```{r, message=FALSE, warning=FALSE}
# derive optimal matching weights intending to minimize covariate imbalance while targeting ATT
w.out.psid_plus.opt <- weightit(model, data = lcs_psid_plus, method = "optweight", estimand = "ATT")

lcs_psid_plus$opt_weight <- w.out.psid_plus.opt$weights
```

#### Overlap weights
```{r, message=FALSE, warning=FALSE}
# calculate overlap weights emphasizing units with propensity scores near 0.5
lcs_psid_plus$overlap_weight <- create_overlap_weights(lcs_psid_plus, model)
```

#### Entropy weights
```{r, message=FALSE, warning=FALSE}
# compute entropy balancing weights 
w.out.psid_plus.ebal <- weightit(model, data = lcs_psid_plus, method = "ebal", estimand = "ATT")

lcs_psid_plus$ebal_weight <- w.out.psid_plus.ebal$weights
```

## Improving primarily overlap
### Truncation
```{r, message=FALSE, warning=FALSE}
# list of weight columns to apply truncation 
weight_columns <- c("ipw_weight", "smr_weight", "opt_weight", "overlap_weight", "ebal_weight")
```

#### Fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a maximum threshold of 10
lcs_psid_plus.fixed <- lcs_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid_plus.fixed)) {
    lcs_psid_plus.fixed <- truncate_weights_fixed(lcs_psid_plus.fixed, weight_col = wcol, max_weight = 10)
  }
}
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values above the 99th percentile are capped
lcs_psid_plus.percent <- lcs_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid_plus.percent)) {
    lcs_psid_plus.percent <- truncate_weights_percentile(lcs_psid_plus.percent, weight_col = wcol, percentile = 0.99)
  }
}
```

#### Adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
results_list <- list() 

for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid_plus)) {
    results_list[[wcol]] <- check_weights(lcs_psid_plus, wcol)
  } else {
    warning(paste("Column", wcol, "not found in lcs_psid_plus"))
  }
}

variance_table <- bind_rows(results_list)
knitr::kable(variance_table, caption = "Variance of Weights")
```

Regarding these results we can apply adaptive weight truncation to all considered weights.
```{r, message=FALSE, warning=FALSE}
# truncate adaptively at mean + 3 standard deviations 
lcs_psid_plus.adapt <- lcs_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(lcs_psid_plus.adapt)) {
    lcs_psid_plus.adapt <- truncate_weights_adaptive(lcs_psid_plus.adapt, weight_col = wcol, c = 3)
  }
}
```

### Trimming 
#### Propensity score threshold trimming 
(Similar to tutorial of @imbens2024)
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
lcs_psid_trim <- ps_trim(lcs_psid_plus.ps, threshold = 0.9)

# exclude experimental controls, subset trimmed data appropriately
lcs_psid.trim_match <- subset(lcs_psid_trim, expc %in% c(0,2) & ps_assoverlap)

# re-estimate propensity scores on trimmed data and perform 1:1 matching
lcs_psid.trim_match <- psmatch(data = lcs_psid.trim_match, Y = "re79", treat = "treat", cov = covar)

# trim experimental data and re-assign treat variable for controls in sample 3 or 4 (non-treated group)
#lcs_trim_psid <- subset(lcs_psid_trim, expc %in% c(0, 1))
#lcs_trim_psid$treat[lcs_trim_psid$expc == 1] <- 0
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
lcs_psid_plus.common  <- common_range_trim(lcs_psid_plus.ps)
```

#### Propensity score trimming (Crump)
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
lcs_psid_plus.crump <- crump_trim(lcs_psid_plus.ps, lower = 0.1, upper = 0.9)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
lcs_psid_plus.stuermer <- stuermer_trim(lcs_psid_plus.ps)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
lcs_psid_plus.walker  <- walker_trim(lcs_psid_plus.ps)
```

### Combination of methods
```{r, message=FALSE, warning=FALSE}
# list trimming methods
trim_names <- c("ps_threshold", "common_range", "stuermer", "walker", "crump")
trimmed_psid <- list(ps_threshold = lcs_psid_trim, common_range = lcs_psid_plus.common, stuermer = lcs_psid_plus.stuermer, walker = lcs_psid_plus.walker, crump = lcs_psid_plus.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply inverse probability weighting (IPW) with trimming and attach IPW weights
ipw_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, "ipw_weight")),
  trim_names
)
```

#### SMR treated weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply standardized mortality ratio (SMR) weighting with trimming and attach SMR weights
smr_treat_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, "smr_weight")),
  trim_names
)
```

#### Overlap weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply overlap weighting with trimming and attach overlap weights
ov_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, "overlap_weight")),
  trim_names
)
```

#### Entropy weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
entropy_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, "ebal_weight")),
  trim_names
)
```

## Reassessing methods
### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching methods
methods.psid_plus <- list(
  optimal_pair = m.out.psid_plus.optimal_pair,
  optimal_full = m.out.psid_plus.optimal_full,
  gen_full = m.out.psid_plus.general_full,
  cem = m.out.psid_plus.cem,
  card = m.out.psid_plus.card,
  profile = m.out.psid_plus.profile,
  subcl = m.out.psid_plus.subcl
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_matchit.psid_plus <- compute_abs_smd_matchit(methods.psid_plus)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# calculate balance statistics 
bal.psid_plus <- cobalt::bal.tab(model, data = lcs_psid_plus, un = TRUE, weights = methods.psid_plus, s.d.denom = "treated")
```

```{r, message=FALSE, warning=FALSE}
# compute effective sample sizes (ESS)
ess_matchit.psid_plus <- compute_ess_matchit(bal.psid_plus)
```

#### Visuals
```{r, fig.cap='FIGURE3.'}
# visualize covariate balance 
plot_matchit(methods.psid_plus, "LCS-PSID1-PLUS")
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
weight.psid_plus <- list(
  ipw = lcs_psid_plus$ipw_weight,
  smr_tr = lcs_psid_plus$smr_weight,
  mw = lcs_psid_plus$opt_weight,
  ow = lcs_psid_plus$overlap_weight,
  ew = lcs_psid_plus$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_weight.psid_plus <- compute_abs_smd_weight(lcs_psid_plus, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_weight.psid_plus <- compute_ess_weight(lcs_psid_plus, "treat", covar, weight_columns)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURE4.'}
# visualize covariate balance
plot_weighting_methods(lcs_psid_plus, "treat", covar, weight.psid_plus, "LCS-PSID1-PLUS")
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
trunc.psid_plus <- list(
  fix_max_value_trunc.psid_plus = lcs_psid_plus.fixed,
  at_perc_trunc.psid_plus = lcs_psid_plus.percent,
  adap_weight_trunc.psid_plus = lcs_psid_plus.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trunc.psid_plus <- compute_abs_smd_trunc(trunc.psid_plus, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trunc.psid_plus <- compute_ess_trunc(trunc.psid_plus, "treat", covar, weight_columns)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURE5.'}
# visualize covariate balance
plot_trunc_methods(trunc.psid_plus, "treat", covar, weight_columns, "LCS-PSID-PLUS")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming object
trim.psid_plus <- list(
  original = lcs_psid_plus,
  ps_threshold = lcs_psid.trim_match,
  common_range = lcs_psid_plus.common,
  crump = lcs_psid_plus.crump,
  stuermer = lcs_psid_plus.stuermer,
  walker = lcs_psid_plus.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trim.psid_plus <- compute_abs_smd_trim(trim.psid_plus, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trim.psid_plus <- compute_ess_trim(trim.psid_plus, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURE6.'}
# visualize overlap
plot_trim(trim.psid_plus, treat, covar)
```

```{r, fig.cap='FIGURE7.'}
# visualize covariate balance
love.plot(lcs_psid, lcs_psid.trim_match, treat, covar = covar, title = "LCS-PSID1-PLUS - propensity threshold trimming")
love.plot(lcs_psid, lcs_psid_plus.common, treat, covar, title = "LCS-PSID1-PLUS - common range trimming")
love.plot(lcs_psid, lcs_psid_plus.crump, treat, covar, title = "LCS-PSID1-PLUS - crump trimming")
love.plot(lcs_psid, lcs_psid_plus.stuermer, treat, covar, title = "LCS-PSID1-PLUS - stuermer trimming")
love.plot(lcs_psid, lcs_psid_plus.walker,  treat, covar, title = "LCS-PSID1-PLUS - walker trimming")
```

## Integrated methods
```{r, message=FALSE, warning=FALSE}
# list all combined method results
comb_meth.psid_plus <- list(
  ipw = ipw_comb.psid_plus,
  smr_treated = smr_treat_comb.psid_plus,
  overlap = ov_comb.psid_plus,
  entropy = entropy_comb.psid_plus
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_all_comb_meth.psid_plus <- compute_smd_all_datasets(comb_meth.psid_plus, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.psid_plus <- compute_ess_all_datasets(comb_meth.psid_plus, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURE A8.'}
# visualize overlap
plot_comb_overlap(comb_meth_psid = comb_meth.psid_plus, treat = "treat", covar = covar, prefix_psid = "LCS-PSID1")
```

```{r, message=FALSE, warning=FALSE, fig.cap='FIGURE A9.'} 
# visualize covariate balance
plot_comb_love_plots(comb_meth_psid = comb_meth.psid_plus, treat = "treat", covar = covar, prefix_cps = "LCS-PSID1")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_comb_hist(comb_meth_psid = comb_meth.psid_plus, treat = "treat", covar = covar, prefix = "lcs", prefix_psid = "LCS-PSID1")
save_comb_loveplots(comb_meth_psid = comb_meth.psid_plus, treat = "treat", covar = covar, prefix = "lcs", prefix_cps = "LCS-CPS1")
```

### Top methods and datasets
```{r, message=FALSE, warning=FALSE}
# combine all results
all_psid_plus <- combine_results("psid_plus") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_psid_plus, "PSID1_PLUS_all_results_lcs")
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
ranked_psid_plus <- assess_methods(all_psid_plus)

top5_methods.psid_plus <- get_top_methods(ranked_psid_plus, top_n = 5)

# print results
top5_methods_df.psid_plus <- ranked_psid_plus %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.psid_plus, caption = "Top 5 Methods", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.psid_plus, "PSID1_PLUS_top5_methods_lcs")
```

The table shows that CPS1 and PSID1 share the same top five methods, with the exception of one differing method and a variation in their ordering for PSID1.
```{r}
dataset_list_psid <- list(
  "All" = lcs_psid_plus, 
  "original" = lcs_psid_plus, 
  "card" = m.out.psid_plus.card,
  "optimal_full" = m.out.psid_plus.optimal_full,
  "optimal_pair" = m.out.psid_plus.optimal_pair,
  "gen_full" = m.out.psid_plus.general_full,
  "subcl" = m.out.psid_plus.subcl,
  "profile" = m.out.psid_plus.profile,
  "ipw_weight" = lcs_psid_plus$ipw_weight, 
  "smr_weight" = lcs_psid_plus$smr_weight,
  "opt_weight" = lcs_psid_plus$opt_weight,
  "overlap_weight" = lcs_psid_plus$overlap_weight,
  "ebal_weight" = lcs_psid_plus$ebal_weight,
  "fix_max_value_trunc_ebal_weight" = lcs_psid_plus.fixed,
  "fix_max_value_trunc_ipw_weight" = lcs_psid_plus.fixed,
  "fix_max_value_trunc_opt_weight" = lcs_psid_plus.fixed,
  "fix_max_value_trunc_overlap_weight" = lcs_psid_plus.fixed,
  "fix_max_value_trunc_smr_weight" = lcs_psid_plus.fixed,
  "at_perc_trunc_ebal_weight" = lcs_psid_plus.percent,
  "at_perc_trunc_ipw_weight" = lcs_psid_plus.percent,
  "at_perc_trunc_opt_weight" = lcs_psid_plus.percent,
  "at_perc_trunc_overlap_weight" = lcs_psid_plus.percent,
  "at_perc_trunc_smr_weight" = lcs_psid_plus.percent,
  "adap_weight_trunc_ebal_weight" = lcs_psid_plus.adapt,
  "adap_weight_trunc_ipw_weight" = lcs_psid_plus.adapt,
  "adap_weight_trunc_opt_weight" = lcs_psid_plus.adapt,
  "adap_weight_trunc_overlap_weight" = lcs_psid_plus.adapt,
  "adap_weight_trunc_smr_weight" = lcs_psid_plus.adapt,
  "ps_threshold" = lcs_psid.trim_match,
  "common_range" = lcs_psid_plus.common,
  "stuermer" = lcs_psid_plus.stuermer,
  "walker" = lcs_psid_plus.walker,
  "crump" = lcs_psid_plus.crump,
  "ipw_common_range" = ipw_comb.psid_plus[[1]],
  "ipw_crump"= ipw_comb.psid_plus[[2]],
  "ipw_ps_threshold"= ipw_comb.psid_plus[[3]],
  "ipw_stuermer"= ipw_comb.psid_plus[[4]],
  "ipw_walker" = ipw_comb.psid_plus[[5]],
  "smr_treated_common_range" = smr_treat_comb.psid_plus[[1]],
  "smr_treated_crump"= smr_treat_comb.psid_plus[[2]],
  "smr_treated_ps_threshold" = smr_treat_comb.psid_plus[[3]],
  "smr_treated_stuermer" = smr_treat_comb.psid_plus[[4]],
  "smr_treated_walker" = smr_treat_comb.psid_plus[[5]],
  "overlap_common_range" = ov_comb.psid_plus[[1]],
  "overlap_crump" = ov_comb.psid_plus[[2]],
  "overlap_ps_threshold"  = ov_comb.psid_plus[[3]],
  "overlap_stuermer" = ov_comb.psid_plus[[4]],
  "overlap_walker"= ov_comb.psid_plus[[5]],
  "entropy_common_range" = entropy_comb.psid_plus[[1]],
  "entropy_crump" = entropy_comb.psid_plus[[2]],
  "entropy_ps_threshold" = entropy_comb.psid_plus[[3]],
  "entropy_stuermer" = entropy_comb.psid_plus[[4]],
  "entropy_walker" = entropy_comb.psid_plus[[5]])
```

```{r, message=FALSE, warning=FALSE}
# create the datasets from combined lists for your top 5 methods:
top5_datasets.psid_plus <- create_top5_datasets(dataset_list_psid, top5_methods.psid_plus)
```

```{r, message=FALSE, warning=FALSE}
# save them into .RData files
save_top5_individual_files(dataset_list_psid, top5_methods.psid_plus, prefix = "lcs_psid")
```

## Estimating
### Average treatment effect on the treated (ATT)
```{r, message=FALSE, warning=FALSE}
# get estimates
out1 <- estimate_all(lcs, "re79", "treat", covar)
out2 <- estimate_all(lcs_psid, "re79", "treat", covar)
out3 <- estimate_all(lcs_psid.trim_match, "re79", "treat", covar)

out.psid_plus <- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, "re79", "treat", covar))
out4 <- out.psid_plus[[1]]
out5 <- out.psid_plus[[2]]
out6 <- out.psid_plus[[3]]
out7 <- out.psid_plus[[4]]
out8 <- out.psid_plus[[5]]
```

```{r, message=FALSE, warning=FALSE}
# build plot titles 
base_titles <- c("(A) LCS-Experimental", "(B) LCS-PSID1" , "(C) Trimmed LCS-PSID1")
top_start <- 4 # D is 4th letter
num_psid <- length(top5_methods.psid_plus)
top_letters_psid <- LETTERS[top_start:(top_start + num_psid - 1)]
top5_titles.psid_plus <- paste0("(", top_letters_psid, ") Top PSID1: ", top5_methods.psid_plus)
plot_titles <- c(base_titles, top5_titles.psid_plus)

# combine all results
all_outs <- c(list(out1, out2, out3), out.psid_plus)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 10. ATT Estimates Given Unconfoundedness using LCS Samples"}
# plot results
band <- out1[1, 3:4]
est  <- out1[1, 1]
plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs, plot_titles, band, est, "lcs")
```

The above figures show the ATT estimates and their 95% confidence intervals for eight samples: LCS-Experimental, LCS-PSID1, a trimmed version of the LCS-PSID1 sample (analogous to @imbens2024) and a series of top-ranked subsamples of LCS-PSID1 based on various matching, weighting, truncation and trimming criteria.

Figure (A) presents the benchmark from the experimental sample (LCS-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) shows results for the observational sample LCS-PSID1 and figure (C) for its trimmed version, replicating the tutorial results of Imbens & Xu (2024). Figures (D) through (H) display results for PSID1-based subsamples. 

Across the LCS-PSID1 dataset and its top-ranked subsamples, all estimators yield ATT estimates that largely cluster around the experimental benchmark except `Diff-in-Means`, which tends to produce estimates that deviate more noticeably from the benchmark.
```{r, warning=FALSE, message=FALSE}
# prepare all results in the order shown in the plots
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- plot_titles
knitr::kable(att_summary, caption = "ATT Summary Statistics", booktabs = TRUE)
```

```{r, warning=FALSE, message=FALSE}
# get result matrix
result_mat <- create_matrix_results(all_outs, plot_titles)
knitr::kable(result_mat, booktabs = TRUE, caption = "ATT Estimates and SEs")
```

The tabulated results confirm visual patterns: Column (A) reports the estimates for the LCS-Experimental sample, column (B) for the LCS-PSID1 sample, and column (C) for its trimmed version. Columns (D)-(H) show results of the top-ranked subsample of LCS-PSID1.

For all PSID1-based samples, the ATT estimates remain overly positive. However, the estimates obtained with the `Diff-in-Means` estimator are consistently negative. Likewise, for the sample constructed with the `card` method, the estimates remain negative across all estimators. 
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "LCS_att_estimates")
```

### Conditional average treatment effect on the treated (CATT)
```{r, warning=FALSE, message=FALSE}
catt.lcs <- catt(lcs, Y, treat, covar)
catt.psid <- catt(lcs_psid, Y, treat, covar)
catt.psid.trim <- catt(lcs_psid.trim_match, Y, treat, covar)
```

```{r, warning=FALSE, message=FALSE}
catt.top5_psid_plus <- lapply(top5_datasets.psid_plus, function(d) catt(d, Y, treat, covar))
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 11. CATT Estimates using LCS Data"}
# combine all catt objects 
all_catt <- c(list(catt.lcs,catt.psid, catt.psid.trim), catt.top5_psid_plus)

# plot results
par(mfrow = c(2,2))
par(cex.main = 0.8)
plot_catt_panels(all_catt, plot_titles)
```

```{r, warning=FALSE, message=FALSE}
all_catt_eval <- eval_catt(all_catt, plot_titles)
knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

With LCS-PSID1, CATT estimates span from $-3,357.48 to $2,404.33, contrasting with the CATT estimated from experimental data which ranges from $-359.43 to $2,719.14, with a mean CATT estimate of $863.51. 

In contract, across the LCS-PSID1-based subsamples, the ranges of CATT estimates are relatively similar. Importantly, the mean CATT estimates remain positive in all cases, except for `card` subsample, that produces a mean CATT estimate of $-415.71.
```{r, message=FALSE, warning=FALSE}
# save results
save_catt_panels(all_catt, plot_titles, prefix = "lcs")
```

### Quantile treatment effect on the treated (QTET)
```{r, message=FALSE, warning=FALSE}
qte.lcs <- est_qte(Y, treat, covar, data = lcs, cores = 4)
```

```{r, message=FALSE, warning=FALSE}
qte.lcs_psid <- est_qte(Y, treat, covar, data = lcs_psid)
qte.lcs_psid.trim <- est_qte(Y, treat, covar, data = lcs_psid.trim_match) 
```

```{r, message=FALSE, warning=FALSE}
qte.top5_psid_plus <- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.lcs0 <- est_qte(Y, treat, NULL, data = lcs)
qte.lcs_psid0 <- est_qte(Y, treat, NULL, data = lcs_psid)
qte.lcs_psid.trim0 <- est_qte(Y, treat, NULL, data = lcs_psid.trim_match)
qte.top5_psid_plus0 <- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE C12. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.8)

# PSID
plot_qte(qte.lcs_psid, qte.lcs_psid0, qte.lcs, main = "(B) LCS-PSID", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID trimmed
plot_qte(qte.lcs_psid.trim, qte.lcs_psid.trim0, qte.lcs_psid, main = "(C) LCS-PSID (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID top methods
plot_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.lcs_psid, plot_titles, main_start = 2, ylim = c(-25000, 15000))
```

These figures present QTET estimates obtained from LCS-Experimental sample and several observational samples. The QTETs estimated from both the original and trimmed LCS-PSID1 samples (B and C), as well as from the top-ranked subsamples (E through H), align comparatively close with the true QTET. However, the QTETs from subsample (F) exhibit a stronger bias, suggesting greater estimation uncertainty.
```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 12. QTET Estimates using LCS Data: Experimental vs. Nonexperimental"}
plots_lcs <- list(
  list(mod = qte.lcs_psid, mod0 = qte.lcs_psid0, bm = qte.lcs, main = "(B) LCS PSID"),
  list(mod = qte.lcs_psid.trim, mod0 = qte.lcs_psid.trim0, bm = qte.lcs_psid, main = "(D) LCS PSID (Trimmed)")
)

save_qtet(plots_lcs, prefix = "lcs", ylim = c(-25000, 15000))
save_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.lcs_psid, plot_titles, main_start = 4, ylim = c(-25000, 15000), prefix = "lcs_top")
```

### Assessing outcome weights (OW)
```{r, warning=FALSE, message=FALSE}
# list all datasets
all_datasets <- c(list(lcs, lcs_psid, lcs_psid.trim_match), top5_datasets.psid_plus)
```

```{r, warning=FALSE, message=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE A14. Outcome Weights using LCS Data"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# plot outcome weights distribution
plot_ow(ow_att, plot_titles) 
```

```{r, warning=FALSE, message=FALSE}
# evaluate results
res_ow <- eval_ow(ow_att, all_datasets, plot_titles, treat_var = treat, estimator = "AIPW-ATT")
knitr::kable(res_ow, caption = "Outcome Weights for Treated and Untreated", booktabs = TRUE) 
```

Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero.
```{r, message=FALSE, warning=FALSE}
# save results
save_ow(ow_att, plot_titles, prefix = "lcs")
```

## Validation through placebo analyses
```{r, warning=FALSE, message=FALSE}
# define variables
Y_pl <- "nchildren75"
treat <- "treat"
covar_pl <- c("age", "educ", "nodegree", "married", "black", "hisp", "re75", "u75")
```

```{r, warning=FALSE, message=FALSE}
# estimate placebo ATT on original and observational datasets
out1_pl <- estimate_all(lcs, Y_pl, "treat", covar_pl)
out2_pl <- estimate_all(lcs_psid, Y_pl, "treat", covar_pl)
```

```{r, warning=FALSE, message=FALSE}
# estimate placebo ATT on trimmed datasets (analogous to tutorial of @imbens2024)
out3_pl <- estimate_all(lcs_psid_trim, Y_pl, "treat", covar_pl)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on top ranked datasets
out.psid_pl <- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, Y_pl, "treat", covar_pl))
out4_pl <- out.psid_pl[[1]]
out5_pl <- out.psid_pl[[2]]
out6_pl <- out.psid_pl[[3]]
out7_pl <- out.psid_pl[[4]]
out8_pl <- out.psid_pl[[5]]
```

```{r, message=FALSE, warning=FALSE}
# collect all placebo results 
all_outs.pl <- c(list(out1_pl, out2_pl, out3_pl), out.psid_pl)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 13. Placebo Test LCS: Number of Children in 1975 as the Outcome"}
# plot placebo results
band_pl <- out1_pl[1, 3:4]
est_pl  <- out1_pl[1, 1]
ylim_pl = c(-1.5, 1)
plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl = c(-15500, 5500), textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, "lcs_placebo")
```

```{r, warning=FALSE, message=FALSE}
result_mat_pl <- create_matrix_results(all_outs.pl, plot_titles)
knitr::kable(result_mat_pl, caption = "Placebo ATT Estimates and SEs", booktabs = TRUE)
```

The placebo analysis shows that the experimental benchmark is close to zero and statistically insignificant, while all estimators applied to the observational datasets produce comparable results.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat_pl, "LCS_att_estimates_pl")
```

## Validation through sensitivity analyses
```{r, warning=FALSE, message=FALSE}
# define variables
Y <- "re79"
treat <- "treat"
# redefine covariates
covar <- c("age", "educ", "nodegree", "married", "black", "hisp", "re75", "u75")
bm <- c("re75")
```

```{r, warning=FALSE, message=FALSE}
# check for valid datasets 
datasets_sens <- c(list(lcs, lcs_psid), top5_datasets.psid_plus)
filtered_datasets_sens <- check_filter_datasets(datasets_sens, Y, treat, covar, bm)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGURE 14. Sensitivity Analyses LCS"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = plot_titles[idx])
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, "lcs")
```

The sensitivity analysis shows that treatment effect estimates in LCS-Experimental (A) are robust to unmeasured confounding, as expected. Observational samples instead show varying degrees of sensitivity, with the full observational sample (B) being more sensitive than the trimmed version (C). The top-ranked PSID1 subsamples (D-H) show that despite employing advanced criteria to improve balance and overlap, treatment effect estimates can exhibit increasing bias under plausible stronger confounding scenarios based on the reference confounder strength. 

## Summary
After reexamining the LaLonde-Calónico-Smith (LCS) data, the results confirm that, as with the NSW and LDW datasets, overlap between treated and control groups is generally stronger in the experimental sample than in the observational (PSID-1) controls. Augmenting the sample with experimental controls improves overlap but does not consistently resolve covariate imbalance.

The findings for the LCS sample closely mirror those from the LDW and NSW analyses: while certain methods can bring effect estimates closer to experimental benchmarks, substantial estimator-dependent variability and sensitivity to sample construction persist. Placebo and sensitivity analyses again show that unconfoundedness is difficult to verify, and that treatment effect estimates from observational data remain fragile. This underscores the ongoing challenge of obtaining reliable causal estimates for the LCS data.