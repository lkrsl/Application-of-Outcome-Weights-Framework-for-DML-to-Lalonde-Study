# LaLonde (NSW) Data 
This section (4) examines the effect of the treatment (participation in the job training program) on the participants’ earnings in 1978 (`re78`) in the original LaLonde dataset (loaded as `nsw`, similar to Imbens & Xu). 

For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the nsw–specific results.

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lalonde.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Load and preprocess data 
```{r, message=FALSE, warning=FALSE}
treat <- "treat"
nsw_co$treat <- 1

# drop re74, u74, tau from CPS1 and PSID1 and merge data
cps1a <- subset(cps1, select =  -c(re74, u74))
nsw_cps <- rbind.data.frame(nsw_tr, cps1a)

psid1a <- subset(psid1, select =  -c(re74, u74))
nsw_psid <- rbind.data.frame(nsw_tr, psid1a)

nsw_cps_plus <- rbind.data.frame(nsw_cps, nsw_co)
nsw_psid_plus <- rbind.data.frame(nsw_psid, nsw_co)
```

### Inspect data
```{r, message=FALSE, warning=FALSE}
# collect datasets in a list
data <- list(nsw = nsw, nsw_cps = nsw_cps, nsw_psid = nsw_psid, nsw_cps_plus = nsw_cps_plus, nsw_psid_plus = nsw_psid_plus)

# inspect key metrics of each dataset
summary_stats <- inspect_data(data)
knitr::kable(summary_stats, caption = "Summary Statistics")
```

## NSW
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78" 
treat <- "treat" 
covar <- c("age", "education", "black", "hispanic", "married", 
           "nodegree", "re75", "u75")
```

### Assessing overlap and covariate balance
#### Overlap
```{r, fig.cap='FIGUREC1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1.',out.width='100%', fig.asp=0.5}
# assess overlap
nsw.ps <- assess_overlap(data = nsw, treat = treat, cov = covar)
nsw_cps.ps <- assess_overlap(data = nsw_cps, treat = treat, cov = covar) 
nsw_psid.ps <- assess_overlap(data = nsw_psid, treat = treat, cov = covar) 
```

As anticipated, the NSW-Experimental data exhibit an almost perfect overlap. In contrast, the observational datasets NSW-CPS1 and NSW-PSID1 display weak overlap. 
```{r, fig.cap='FIGUREC1. SubfigureD:NSW-CPS1-PLUS. SubfigureE:NSW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
# assess overlap
nsw_cps_plus.ps <- assess_overlap(data = nsw_cps_plus, treat = treat, cov = covar) 
nsw_psid_plus.ps <- assess_overlap(data = nsw_psid_plus, treat = treat, cov = covar)
```

With the expanded datasets NSW-CPS1-PLUS and NSW-PSID1-PLUS, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater coverage of log-odds densities across both samples.
```{r}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

#### Covariate balance
```{r, fig.cap='FIGUREC2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
love.plot(nsw, nsw_cps, treat, covar = covar, title = "NSW-CPS1")
love.plot(nsw, nsw_cps_plus, treat, covar = covar, title = "NSW-CPS1-PLUS")
love.plot(nsw, nsw_psid, treat, covar = covar, title = "NSW-PSID1")
love.plot(nsw, nsw_psid_plus, treat, covar = covar, title = "NSW-PSID1-PLUS")
```

Neither NSW-CPS1-PLUS nor NSW-PSID1-PLUS shows consistently improved covariate balance compared with their non-plus counterparts based on raw standardized differences. Although some specific covariates improve slightly, most show the same or increased imbalance.

<div class="callout-note">
In the subsequent analysis, that is focused on improving covariate balance and overlap, only the two datasets NSW-CPS1-PLUS and NSW-PSID1-PLUS are considered. The NSW-Experimental data is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 
</div>

## Improving primarily covariate balance
### Matching 
#### Distance Matching
##### 1:1 Nearest neighbor matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with k=1, logistic propensity score and replacement
m.out.cps.nearest <- matchit(model, data = nsw_cps, method = "nearest", distance = "logit", replace = TRUE)
m.out.psid.nearest <- matchit(model, data = nsw_psid, method = "nearest", distance = "logit", replace = TRUE)
```

##### k:1 matching (k=2)
```{r, message=FALSE, warning=FALSE}
k<-2
# perform nearest neighbor matching with k=2, logistic propensity score and replacement
m.out.cps.k2 <- matchit(model, data = nsw_cps, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid.k2 <- matchit(model, data = nsw_psid, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### k:1 matching (k=3)
```{r, message=FALSE, warning=FALSE}
k<-3
# perform nearest neighbor matching with k=3, logistic propensity score and replacement
m.out.cps.k3 <- matchit(model, data = nsw_cps, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid.k3 <- matchit(model, data = nsw_psid, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### Caliper matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score 
m.out.cps.caliper <- matchit(model, data = nsw_cps, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
m.out.psid.caliper <- matchit(model, data = nsw_psid, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
```

##### Common support restriction matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with exclusion of units outside common support
m.out.cps.cs <- matchit(model, data = nsw_cps, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
m.out.psid.cs <- matchit(model, data = nsw_psid, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
```

##### Mahalanobis distance matching (mahvars) 
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching using mahalanobis distance on selected covariates
m.out.cps.mahvars <- matchit(model, data = nsw_cps, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE)
m.out.psid.mahvars <- matchit(model, data = nsw_psid, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE)
```

##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.cps.optimal_pair <- matchit(model, data = nsw_cps, method = "optimal", distance = "logit")
m.out.psid.optimal_pair <- matchit(model, data = nsw_psid, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
m.out.cps.optimal_full <- matchit(model, data = nsw_cps, method = "full", distance = "logit")
m.out.psid.optimal_full <- matchit(model, data = nsw_psid, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios 
m.out.cps.general_full <- matchit(model, data = nsw_cps, method = "quick", distance = "logit")
m.out.psid.general_full <- matchit(model, data = nsw_psid, method = "quick", distance = "logit")
```

##### Genetic matching
```{r, message=FALSE, warning=FALSE}
# perform genetic matching 
m.out.cps.genetic <- matchit(model, data = nsw_cps, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
m.out.psid.genetic <- matchit(model, data = nsw_psid, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
```

#### Stratum matching
##### Exact matching (exact)
Strata = unique covariate profiles (raw covariates)
```{r, message=FALSE, warning=FALSE}
# match units exactly by raw covariate profiles 
m.out.cps.exact <- matchit(model, data = nsw_cps, method = "exact")
m.out.psid.exact <- matchit(model, data = nsw_psid, method = "exact")
```

##### Coarsened matching (cem)
Strata = coarsened versions of covariates
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
m.out.cps.cem <- matchit(model, data = nsw_cps, method = "cem")
m.out.psid.cem <- matchit(model, data = nsw_psid, method = "cem")
```

##### Subclassification 
Strata = bins of the propensity score
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
m.out.cps.subcl <- matchit(model, data = nsw_cps, method = "subclass", subclass = 5)
m.out.psid.subcl <- matchit(model, data = nsw_psid, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units
m.out.cps.card <- matchit(model, data = nsw_cps, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
m.out.psid.card <- matchit(model, data = nsw_psid, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
# select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact
m.out.cps.profile <- matchit(model, data = nsw_cps, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs", time = 1200)
m.out.psid.profile <- matchit(model, data = nsw_psid, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs", time = 1200)
```

### Weighting
#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# 
w.out.cps.ipw <- WeightIt::weightit(model, data = nsw_cps, estimand = "ATT", method = "glm")
nsw_cps$ipw_weight <- w.out.cps.ipw$weights
w.out.psid.ipw <- WeightIt::weightit(model, data = nsw_psid, estimand = "ATT", method = "glm")
nsw_psid$ipw_weight <- w.out.psid.ipw$weights
```

#### Stable balancing weights 
```{r, message=FALSE, warning=FALSE}
#
w.out.cps.opt <- optweight::optweight(model, data = nsw_cps, estimand = "ATT")
nsw_cps$opt_weight <- w.out.cps.opt$weights
w.out.psid.opt <- optweight::optweight(model, data = nsw_psid, estimand = "ATT")
nsw_psid$opt_weight <- w.out.psid.opt$weights
```

#### Propensity score weights
```{r, message=FALSE, warning=FALSE}
w.out.cps.cbps <- WeightIt::weightit(model, data = nsw_cps, estimand = "ATT", method = "cbps")
nsw_cps$cbps_weight <- w.out.cps.cbps$weights
w.out.psid.cbps <- WeightIt::weightit(model, data = nsw_psid, estimand = "ATT", method = "cbps")
nsw_psid$cbps_weight <- w.out.psid.cbps$weights
```

#### Entropy balancing weights
```{r, message=FALSE, warning=FALSE}
#
w.out.cps.ebal <- WeightIt::weightit(model, data = nsw_cps, estimand = "ATT", method = "ebal")
nsw_cps$ebal_weight <- w.out.cps.ebal$weights
w.out.psid.ebal <- WeightIt::weightit(model, data = nsw_psid, estimand = "ATT", method = "ebal")
nsw_psid$ebal_weight <- w.out.psid.ebal$weights
```

## Improving primarily overlap
### Truncation
```{r, message=FALSE, warning=FALSE}
# list weight columns to apply truncation 
weight_columns <- c("ipw_weight", "opt_weight", "cbps_weight", "ebal_weight")
```

#### Fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum threshold
nsw_cps.fixed <- nsw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(nsw_cps.fixed)) {
    nsw_cps.fixed <- truncate_weights_fixed(nsw_cps.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}

nsw_psid.fixed <- nsw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(nsw_psid.fixed)) {
    nsw_psid.fixed <- truncate_weights_fixed(nsw_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
nsw_cps.percent <- nsw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(nsw_cps.percent)) {
    nsw_cps.percent <- truncate_weights_percentile(nsw_cps.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}

nsw_psid.percent <- nsw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(nsw_psid.percent)) {
    nsw_psid.percent <- truncate_weights_percentile(nsw_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}
```

#### Adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
# inspect variance of weights 
cps_results <- list()
psid_results <- list()

for (wcol in weight_columns) {
  if (wcol %in% names(nsw_cps)) {
    cps_results[[paste0("cps_", wcol)]] <- check_weights(nsw_cps, wcol)
  } else {
    warning(paste("Column", wcol, "not found in NSW-CPS1"))
  }
}

for (wcol in weight_columns) {
  if (wcol %in% names(nsw_psid)) {
    psid_results[[paste0("psid_", wcol)]] <- check_weights(nsw_psid, wcol)
  } else {
    warning(paste("Column", wcol, "not found in NSW-PSID1"))
  }
}

var_cps_table <- bind_rows(cps_results)
var_psid_table <- bind_rows(psid_results)

knitr::kable(var_cps_table, caption = "Variance of Weights (NSW-CPS1)")
knitr::kable(var_psid_table, caption = "Variance of Weights (NSW-PSID1)")
```

Regarding these results we apply adaptive weight truncation to all considered weights.
```{r, message=FALSE, warning=FALSE}
# truncate adaptively at mean + 3 standard deviations 
nsw_cps.adapt <- nsw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(nsw_cps.adapt)) {
    nsw_cps.adapt <- truncate_weights_adaptive(nsw_cps.adapt, weight_col = wcol, c = 3)
  }
}

nsw_psid.adapt <- nsw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(nsw_psid.adapt)) {
    nsw_psid.adapt <- truncate_weights_adaptive(nsw_psid.adapt, weight_col = wcol, c = 3)
  }
}
```

### Trimming 
#### Propensity score threshold trimming 
(Similar to Imbens & Xu (2024))
```{r, message=FALSE, warning=FALSE}
# apply trimming with thresholds 0.85 
nsw_cps_plus.trim <- ps_trim(nsw_cps_plus.ps, threshold = 0.85)
nsw_psid_plus.trim <- ps_trim(nsw_psid_plus.ps, threshold = 0.85)

# exclude experimental controls, subset trimmed data appropriately
nsw_cps_plus.trim.match <- subset(nsw_cps_plus.trim, sample %in% c(0,3) & ps_assoverlap)
nsw_psid_plus.trim.match <- subset(nsw_psid_plus.trim, sample %in% c(0,4) & ps_assoverlap)

# re-assign treat variable for controls in sample 3 or 4 (non-treated group)
nsw_cps_plus.trim.match$treat[nsw_cps_plus.trim.match$sample == 0.5] <- 0
nsw_psid_plus.trim.match$treat[nsw_psid_plus.trim.match$sample == 0.5] <- 0

# re-estimate propensity scores on trimmed data and perform 1:1 matching
nsw_cps_plus.trim.match <- psmatch(data = nsw_cps_plus.trim.match, Y = "re78", treat = "treat", cov = covar)
nsw_psid_plus.trim.match <- psmatch(data = nsw_psid_plus.trim.match, Y = "re78", treat = "treat", cov = covar)
```

#### Propensity score threshold trimming 
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
nsw_cps.trim <- ps_trim(nsw_cps.ps, threshold = 0.9)
nsw_psid.trim <- ps_trim(nsw_psid.ps, threshold = 0.9)

# re-estimate propensity scores on trimmed data 
nsw_cps.trim <- ps_estimate(data = nsw_cps.trim, Y = "re78", treat = "treat", cov = covar)
nsw_psid.trim <- ps_estimate(data = nsw_psid.trim, Y = "re78", treat = "treat", cov = covar)
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
nsw_cps.common   <- common_range_trim(nsw_cps.ps)
nsw_psid.common  <- common_range_trim(nsw_psid.ps)

# re-estimate propensity scores on trimmed data 
nsw_cps.common <- ps_estimate(data = nsw_cps.common, Y = "re78", treat = "treat", cov = covar)
nsw_psid.common <- ps_estimate(data = nsw_psid.common, Y = "re78", treat = "treat", cov = covar)
```

#### Crump trimming 
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
nsw_cps.crump  <- crump_trim(nsw_cps.ps, lower = 0.1, upper = 0.9)
nsw_psid.crump <- crump_trim(nsw_psid.ps, lower = 0.1, upper = 0.9)

# re-estimate propensity scores on trimmed data 
nsw_cps.crump <- ps_estimate(data = nsw_cps.crump, Y = "re78", treat = "treat", cov = covar)
nsw_psid.crump <- ps_estimate(data = nsw_psid.crump, Y = "re78", treat = "treat", cov = covar)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
nsw_cps.stuermer  <- stuermer_trim(nsw_cps.ps)
nsw_psid.stuermer <- stuermer_trim(nsw_psid.ps)

# re-estimate propensity scores on trimmed data 
nsw_cps.stuermer <- ps_estimate(data = nsw_cps.stuermer, Y = "re78", treat = "treat", cov = covar)
nsw_psid.stuermer <- ps_estimate(data = nsw_psid.stuermer, Y = "re78", treat = "treat", cov = covar)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
nsw_cps.walker   <- walker_trim(nsw_cps.ps)
nsw_psid.walker  <- walker_trim(nsw_psid.ps)

# re-estimate propensity scores on trimmed data 
nsw_cps.walker <- ps_estimate(data = nsw_cps.walker, Y = "re78", treat = "treat", cov = covar)
nsw_psid.walker <- ps_estimate(data = nsw_psid.walker, Y = "re78", treat = "treat", cov = covar)
```

### Integrated methods
```{r, message=FALSE, warning=FALSE}
# list trimming methods
all_trim.cps  <- list(ps_threshold = nsw_cps.trim, 
                     common_range = nsw_cps.common, 
                     stuermer = nsw_cps.stuermer, 
                     walker = nsw_cps.walker, 
                     crump = nsw_cps.crump)
all_trim.psid  <- list(ps_threshold = nsw_psid.trim, 
                     common_range = nsw_psid.common, 
                     stuermer = nsw_psid.stuermer, 
                     walker = nsw_psid.walker, 
                     crump = nsw_psid.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply inverse probability weighting (IPW) with trimming and attach IPW weights
ipw_comb.cps <- trim_attach_weights(all_trim.cps, model, "ipw_weight")
ipw_comb.psid <- trim_attach_weights(all_trim.psid, model, "ipw_weight")
```

#### Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply stable balancing with trimming and attach stable balance weights
opt_comb.cps <- trim_attach_weights(all_trim.cps, model, "opt_weight")
opt_comb.psid <- trim_attach_weights(all_trim.psid, model, "opt_weight")
```

#### Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply propensity score weighting with trimming and attach propensity score weights
cbps_comb.cps <- trim_attach_weights(all_trim.cps, model, "cbps_weight")
cbps_comb.psid <- trim_attach_weights(all_trim.psid, model, "cbps_weight")
```

#### Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
ebal_comb.cps <- trim_attach_weights(all_trim.cps, model, "ebal_weight")
ebal_comb.psid <- trim_attach_weights(all_trim.psid, model, "ebal_weight")
```

## Reassessing methods
### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching objects
all_match.cps <- list(
  nn = m.out.cps.nearest,
  k2 = m.out.cps.k2,
  k3 = m.out.cps.k3,
  caliper = m.out.cps.caliper,
  cS = m.out.cps.cs,
  mahvars = m.out.cps.mahvars,
  optimal_pair = m.out.cps.optimal_pair,
  optimal_full = m.out.cps.optimal_full,
  gen_full = m.out.cps.general_full,
  genetic = m.out.cps.genetic,
  exact = m.out.cps.exact,
  cem = m.out.cps.cem,
  card = m.out.cps.card,
  profile = m.out.cps.profile,
  subcl = m.out.cps.subcl
)

all_match.psid <- list(
  nn = m.out.psid.nearest,
  k2 = m.out.psid.k2,
  k3 = m.out.psid.k3,
  caliper = m.out.psid.caliper,
  cs = m.out.psid.cs,
  mahvars = m.out.psid.mahvars,
  optimal_pair = m.out.psid.optimal_pair,
  optimal_full = m.out.psid.optimal_full,
  gen_full = m.out.psid.general_full,
  genetic = m.out.psid.genetic,
  exact = m.out.psid.exact,
  cem = m.out.psid.cem,
  card = m.out.psid.card,
  profile = m.out.psid.profile,
  subcl = m.out.psid.subcl
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_matchit.cps <- compute_abs_smd_matchit(all_match.cps)
smd_matchit.psid <- compute_abs_smd_matchit(all_match.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# calculate balance statistics 
bal.cps <- cobalt::bal.tab(model, data = nsw_cps, un = TRUE, weights = all_match.cps, s.d.denom = "treated")
bal.psid <- cobalt::bal.tab(model, data = nsw_psid, un = TRUE, weights = all_match.psid, s.d.denom = "treated")
```

```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_matchit.cps <- compute_ess_matchit(bal.cps)
ess_matchit.psid <- compute_ess_matchit(bal.psid)
```

#### Visuals
```{r, fig.cap='FIGUREC3.'}
# visualize covariate balance 
plot_matching_balance(all_match.cps, title = "NSW-CPS1")
plot_matching_balance(all_match.psid, title = "NSW-PSID1")
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
all_weight.cps <- list(
  ipw_weight = nsw_cps$ipw_weight,
  opt_weight = nsw_cps$opt_weight,
  cbps_weight = nsw_cps$cbps_weight,
  ebal_weight = nsw_cps$ebal_weight
)

all_weight.psid <- list(
  ipw_weight = nsw_psid$ipw_weight,
  opt_weight = nsw_psid$opt_weight,
  cbps_weight = nsw_psid$cbps_weight,
  ebal_weight = nsw_psid$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_weight.cps <- compute_abs_smd_weight(nsw_cps, treat, covar, all_weight.cps)
smd_weight.psid <- compute_abs_smd_weight(nsw_psid, treat, covar, all_weight.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_weight.cps <- compute_ess_weight(nsw_cps, treat, covar, all_weight.cps)
ess_weight.psid <- compute_ess_weight(nsw_psid, treat, covar, all_weight.psid)
```

#### Visuals
```{r, fig.cap='FIGUREC4.'}
# visualize covariate balance
plot_weighting_balance(nsw_cps, treat, covar, all_weight.cps, "NSW-CPS1") 
plot_weighting_balance(nsw_psid, treat, covar, all_weight.psid, "NSW-PSID1")
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
all_trunc.cps <- list(
  fix_max_value = nsw_cps.fixed,
  at_perc = nsw_cps.percent,
  adap_weight = nsw_cps.adapt
)

all_trunc.psid <- list(
  fix_max_value = nsw_psid.fixed,
  at_perc = nsw_psid.percent,
  adap_weight = nsw_psid.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trunc.cps <- compute_abs_smd_trunc(all_trunc.cps, "treat", covar, weight_columns)
smd_trunc.psid <- compute_abs_smd_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trunc.cps <- compute_ess_trunc(all_trunc.cps, "treat", covar, weight_columns)
ess_trunc.psid <- compute_ess_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### Visuals
```{r, fig.cap='FIGUREC5.'}
# visualize covariate balance
plot_trunc_balance(all_trunc.cps, "treat", covar, weight_columns, "NSW-CPS1")
plot_trunc_balance(all_trunc.psid, "treat", covar, weight_columns, "NSW-PSID1")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming objects plus original
all_trim.cps <- list(
  original = nsw_cps,
  ps_threshold = nsw_cps.trim,
  common_range = nsw_cps.common,
  crump = nsw_cps.crump,
  stuermer = nsw_cps.stuermer,
  walker = nsw_cps.walker
)

all_trim.psid <- list(
  original = nsw_psid,
  ps_threshold = nsw_psid.trim,
  common_range = nsw_psid.common,
  crump = nsw_psid.crump,
  stuermer = nsw_psid.stuermer,
  walker = nsw_psid.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMDs
smd_trim.cps <- compute_abs_smd_trim(all_trim.cps, "treat", covar)
smd_trim.psid <- compute_abs_smd_trim(all_trim.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trim.cps <- compute_ess_trim(all_trim.cps, "treat", covar)
ess_trim.psid <- compute_ess_trim(all_trim.psid, "treat", covar)
```

#### Visuals
```{r, fig.cap='FIGUREC6.'}
# visualize overlap
plot_trim_overlap(all_trim.cps, treat, covar, prefix = "NSW-CPS1")
plot_trim_overlap(all_trim.psid, treat, covar, prefix = "NSW-PSID1")
```

## Integrated methods
```{r, message=FALSE, warning=FALSE}
# list all combined results
comb.cps <- list(
  ipw = ipw_comb.cps,
  opt = opt_comb.cps,
  cbps = cbps_comb.cps,
  ebal = ebal_comb.cps
)

comb.psid <- list(
  ipw = ipw_comb.psid,
  opt = opt_comb.psid,
  cbps = cbps_comb.psid,
  ebal = ebal_comb.psid
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_all_comb_meth.cps <- compute_smd_all_datasets(comb.cps, "treat", covar)
smd_all_comb_meth.psid <- compute_smd_all_datasets(comb.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.cps <- compute_ess_all_datasets(comb.cps, "treat", covar)
ess_all_comb_meth.psid <- compute_ess_all_datasets(comb.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREC7.'}
# visualize overlap
plot_comb_overlap(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix_cps = "NSW-CPS1", prefix_psid = "NSW-PSID1")
```

```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREC8.'} 
# visualize covariate balance
plot_comb_balance(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, orig_cps = nsw_cps, orig_psid = nsw_psid, prefix_cps = "NSW-CPS1", prefix_psid = "NSW-PSID1")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_comb_hist(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix = "nsw", prefix_cps = "nsw_cps1", prefix_psid = "nsw_psid1")
save_comb_loveplots(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix = "nsw", prefix_cps = "nsw_cps1", prefix_psid = "nsw_psid1")
```

## Identifying best methods
```{r, message=FALSE, warning=FALSE}
# combine all results
all_cps <- combine_results("cps")
all_psid <- combine_results("psid") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_cps, "nsw_cps1_all_results")
save_csv(all_psid, "nsw_psid1_all_results")
```

```{r, message=FALSE, warning=FALSE}
# rank methods 
ranked_cps  <- assess_methods(all_cps)
ranked_psid <- assess_methods(all_psid)
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
top5_methods.cps <- get_top_methods(ranked_cps, top_n = 5)
top5_methods.psid <- get_top_methods(ranked_psid, top_n = 5)

# print results
top5_methods_df.cps <- ranked_cps %>% arrange(desc(Score)) %>% head(5)
top5_methods_df.psid <- ranked_psid %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.cps, caption = "Top 5 Methods for CPS1", booktabs = TRUE)
knitr::kable(top5_methods_df.psid, caption = "Top 5 Methods for PSID1", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.cps, "nsw_cps1_top5_methods")
save_csv(top5_methods.psid, "nsw_psid1_top5_methods")
```

The table shows that CPS1 and PSID1 share the same top five methods, with the exception of one differing method and a variation in their ordering for PSID1.
```{r, message=FALSE, warning=FALSE}
dataset_list_cps <- list(
  "All" = nsw_cps,
  "original" = nsw_cps,
  "nn" = m.out.cps.nearest, 
  "caliper" = m.out.cps.caliper,
  "card" = m.out.cps.card,
  "cem" = m.out.cps.cem,
  "cS" = m.out.cps.cs,
  "k2"  = m.out.cps.k2,
  "k3" = m.out.cps.k3,
  "mahvars" = m.out.cps.mahvars,
  "optimal_full" = m.out.cps.optimal_full,
  "optimal_pair" = m.out.cps.optimal_pair,
  "gen_full" = m.out.cps.general_full,
  "genetic" = m.out.cps.genetic,
  "exact" = m.out.cps.exact,
  "subcl" = m.out.cps.subcl,
  "profile"  = m.out.cps.profile,
  "ipw_weight" = nsw_cps$ipw_weight, 
  "opt_weight" = nsw_cps$opt_weight,
  "cbps_weight" = nsw_cps$cbps_weight,
  "ebal_weight" = nsw_cps$ebal_weight,
  "fix_max_value_ipw_weight" = nsw_cps.fixed$ipw_weight,
  "fix_max_value_opt_weight" = nsw_cps.fixed$opt_weight,
  "fix_max_value_cbps_weight" = nsw_cps.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = nsw_cps.fixed$ebal_weight,
  "at_perc_ipw_weight" = nsw_cps.percent$ipw_weight,
  "at_perc_opt_weight" = nsw_cps.percent$opt_weight,
  "at_perc_cbps_weight" = nsw_cps.percent$cbps_weight,
  "at_perc_ebal_weight" = nsw_cps.percent$ebal_weight,
  "adap_weight_ipw_weight" = nsw_cps.adapt$ipw_weight,
  "adap_weight_opt_weight" = nsw_cps.adapt$opt_weight,
  "adap_weight_cbps_weight" = nsw_cps.adapt$cbps_weight,
  "adap_weight_ebal_weight" = nsw_cps.adapt$ebal_weight,
  "ps_threshold" = nsw_cps.trim,
  "common_range" = nsw_cps.common,
  "stuermer" = nsw_cps.stuermer,
  "walker" = nsw_cps.walker,
  "crump" = nsw_cps.crump,
  "ipw_common_range" = ipw_comb.cps[[1]],
  "ipw_crump"= ipw_comb.cps[[2]],
  "ipw_ps_threshold"= ipw_comb.cps[[3]],
  "ipw_stuermer"= ipw_comb.cps[[4]],
  "ipw_walker" = ipw_comb.cps[[5]],
  "opt_common_range" = opt_comb.cps[[1]],
  "opt_crump" = opt_comb.cps[[2]],
  "opt_ps_threshold" = opt_comb.cps[[3]],
  "opt_stuermer" = opt_comb.cps[[4]],
  "opt_walker" = opt_comb.cps[[5]],
  "cbps_common_range" = cbps_comb.cps[[1]],
  "cbps_crump" = cbps_comb.cps[[2]],
  "cbps_ps_threshold"  = cbps_comb.cps[[3]],
  "cbps_stuermer" = cbps_comb.cps[[4]],
  "cbps_walker"= cbps_comb.cps[[5]],
  "ebal_common_range" = ebal_comb.cps[[1]],
  "ebal_crump" = ebal_comb.cps[[2]],
  "ebal_ps_threshold" = ebal_comb.cps[[3]],
  "ebal_stuermer" = ebal_comb.cps[[4]],
  "ebal_walker" = ebal_comb.cps[[5]])

dataset_list_psid <- list(
  "All" = nsw_psid,
  "original" = nsw_psid,
  "nn" = m.out.psid.nearest, 
  "caliper" = m.out.psid.caliper,
  "card" = m.out.psid.card,
  "cem" = m.out.psid.cem,
  "cS" = m.out.psid.cs,
  "k2"  = m.out.psid.k2,
  "k3" = m.out.psid.k3,
  "mahvars" = m.out.psid.mahvars,
  "optimal_full" = m.out.psid.optimal_full,
  "optimal_pair" = m.out.psid.optimal_pair,
  "gen_full" = m.out.psid.general_full,
  "genetic" = m.out.psid.genetic,
  "exact" = m.out.psid.exact,
  "subcl" = m.out.psid.subcl,
  "profile"  = m.out.psid.profile,
  "ipw_weight" = nsw_psid$ipw_weight, 
  "opt_weight" = nsw_psid$opt_weight,
  "cbps_weight" = nsw_psid$cbps_weight,
  "ebal_weight" = nsw_psid$ebal_weight,
  "fix_max_value_ipw_weight" = nsw_psid.fixed$ipw_weight,
  "fix_max_value_opt_weight" = nsw_psid.fixed$opt_weight,
  "fix_max_value_cbps_weight" = nsw_psid.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = nsw_psid.fixed$ebal_weight,
  "at_perc_ipw_weight" = nsw_psid.percent$ipw_weight,
  "at_perc_opt_weight" = nsw_psid.percent$opt_weight,
  "at_perc_cbps_weight" = nsw_psid.percent$cbps_weight,
  "at_perc_ebal_weight" = nsw_psid.percent$ebal_weight,
  "adap_weight_ipw_weight" = nsw_psid.adapt$ipw_weight,
  "adap_weight_opt_weight" = nsw_psid.adapt$opt_weight,
  "adap_weight_cbps_weight" = nsw_psid.adapt$cbps_weight,
  "adap_weight_ebal_weight" = nsw_psid.adapt$ebal_weight,
  "ps_threshold" = nsw_psid.trim,
  "common_range" = nsw_psid.common,
  "stuermer" = nsw_psid.stuermer,
  "walker" = nsw_psid.walker,
  "crump" = nsw_psid.crump,
  "ipw_common_range" = ipw_comb.psid[[1]],
  "ipw_crump"= ipw_comb.psid[[2]],
  "ipw_ps_threshold"= ipw_comb.psid[[3]],
  "ipw_stuermer"= ipw_comb.psid[[4]],
  "ipw_walker" = ipw_comb.psid[[5]],
  "opt_common_range" = opt_comb.psid[[1]],
  "opt_crump" = opt_comb.psid[[2]],
  "opt_ps_threshold" = opt_comb.psid[[3]],
  "opt_stuermer" = opt_comb.psid[[4]],
  "opt_walker" = opt_comb.psid[[5]],
  "cbps_common_range" = cbps_comb.psid[[1]],
  "cbps_crump" = cbps_comb.psid[[2]],
  "cbps_ps_threshold"  = cbps_comb.psid[[3]],
  "cbps_stuermer" = cbps_comb.psid[[4]],
  "cbps_walker"= cbps_comb.psid[[5]],
  "ebal_common_range" = ebal_comb.psid[[1]],
  "ebal_crump" = ebal_comb.psid[[2]],
  "ebal_ps_threshold" = ebal_comb.psid[[3]],
  "ebal_stuermer" = ebal_comb.psid[[4]],
  "ebal_walker" = ebal_comb.psid[[5]])
```

```{r, message=FALSE, warning=FALSE}
# create datasets corresponding to the top 5 methods for each dataset
top5_datasets.cps <- create_top5_datasets(dataset_list_cps, top5_methods.cps)
top5_datasets.psid <- create_top5_datasets(dataset_list_psid, top5_methods.psid)
```

```{r, message=FALSE, warning=FALSE}
# save datasets into .RData files
save_top5_individual_files(dataset_list_cps, top5_methods.cps, prefix = "nsw_cps1")
save_top5_individual_files(dataset_list_psid, top5_methods.psid, prefix = "nsw_psid1")
```

## Estimating
### Average treatment effect on the treated (ATT)
```{r, message=FALSE, warning=FALSE}
# estimate ATT
out1 <- estimate_all(nsw, "re78", "treat", covar)
out2 <- estimate_all(nsw_cps, "re78", "treat", covar)
out3 <- estimate_all(nsw_psid, "re78", "treat", covar)
out4 <- estimate_all(nsw_cps_plus.trim, "re78", "treat", covar)
out5 <- estimate_all(nsw_psid_plus.trim, "re78", "treat", covar)
out6 <- estimate_all(nsw_cps.trim, "re78", "treat", covar) 
out7 <- estimate_all(nsw_psid.trim, "re78", "treat", covar)

out.cps <- lapply(top5_datasets.cps, function(d) estimate_all(d, "re78", "treat", covar))
out.psid <- lapply(top5_datasets.psid, function(d) estimate_all(d, "re78", "treat", covar))

out8 <- out.cps[[1]]
out9 <- out.cps[[2]]
out10 <- out.cps[[3]]
out11 <- out.cps[[4]]
out12 <- out.cps[[5]]

out13 <- out.psid[[1]]
out14 <- out.psid[[2]]
out15 <- out.psid[[3]]
out16 <- out.psid[[4]]
out17 <- out.psid[[5]]
```

```{r, message=FALSE, warning=FALSE}
# build plot titles 
base_titles <- c("(A) NSW-Experimental", "(B) NSW-CPS1" , "(C) NSW-PSID1", "(D) Trimmed NSW-CPS1 ", "(E) Trimmed NSW-PSID1", "(F) Trimmed NSW-CPS1-PLUS ", "(G) Trimmed NSW-PSID1-PLUS")
top_start <- 8 # H is 8th letter
num_cps <- length(top5_methods.cps)
num_psid <- length(top5_methods.psid)
top_letters_cps <- LETTERS[top_start:(top_start + num_cps - 1)]
top_letters_psid <- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)]
top5_titles.cps <- paste0("(", top_letters_cps, ") Top CPS1: ", top5_methods.cps)
top5_titles.psid <- paste0("(", top_letters_psid, ") Top PSID1: ", top5_methods.psid)
plot_titles <- c(base_titles, top5_titles.cps, top5_titles.psid)

# combine all results
all_outs <- c(list(out1, out2, out3, out4, out5, out6, out7), out.cps, out.psid)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGUREC9. ATT Estimates Given Unconfoundedness using NSW Samples"}
# plot results
band <- out1[1, 3:4]
est  <- out1[1, 1]
plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs, plot_titles, band, est, "nsw")
```

The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: NSW-Experimental, NSW-CPS1, NSW-PSID1, trimmed versions of the NSW-CPS1 and NSW-PSID1 samples (analogous to Imbens & Xu (2024)) and a series of top-ranked subsamples of both NSW-CPS1 and NSW-PSID1 based on various matching, weighting, truncation and trimming criteria.

Figure (A) presents the benchmark from the experimental sample (NSW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the observational samples, NSW-CPS1 and NSW-PSID1, while figures (D) and (E) present those for the trimmed versions, replicating the tutorial results of Imbens & Xu (2024). Figures (F) through (J) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-based subsamples under parallel rules.

Across the NSW-CPS1 and its top-ranked subsamples, all estimators produce ATT estimates that closely align with the experimental benchmark, though all estimates are negative. Some larger deviations occur for the `Diff-in-Means` estimator within the `overlap_crump` and `adapt_weight_trunc_ipw_weight` subsamples. Nevertheless, these ATT estimates deviate more from the benchmark than those obtained under models A and B in previous sections using LDW data. 

In comparison, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors than NSW-CPS1 samples, consistent with previous observations from LDW data. All ATT estimates remain negatively aligned, reflecting heightened methodological uncertainty within these samples.
```{r, message=FALSE, warning=FALSE}
# prepare all results in the order shown in the plots
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- plot_titles
knitr::kable(att_summary, caption = "ATT Summary Statistics", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# get result matrix
result_mat <- create_matrix_results(all_outs, plot_titles)
knitr::kable(result_mat, booktabs = TRUE, caption = "ATT Estimates and SEs") %>% kable_styling(full_width = TRUE)
```

The tabulated results confirm visual patterns: Column (A) reports the estimates for the NSW-Experimental sample, column (B) for the NSW-CPS1 sample, and column (C) for the NSW-PSID1 sample. Columns (D)-(O) summarize results for the trimmed and top-ranked samples for both NSW-CPS1 and NSW-PSID1.

For all CPS1-based samples, ATT estimates remain negative, but are relatively close to the experimental benchmark. In contrast, the PSID1-based estimates exhibit larger negative magnitudes, and increased standard errors, underscoring the heightened difficulty of achieving covariate balance and overlap in this observational dataset. 

Overall, consistent with findings from models A and B, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain methods can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "nsw_att_estimates")
```

### Conditional average treatment effect on the treated (CATT)
```{r, message=FALSE, warning=FALSE}
# estimate CATT
catt.ldw <- catt(nsw, Y, treat, covar)
catt.cps <- catt(nsw_cps, Y, treat, covar)
catt.psid <- catt(nsw_psid, Y, treat, covar)
catt.cps.trim <- catt(nsw_cps.trim, Y, treat, covar)
catt.psid.trim <- catt(nsw_psid.trim, Y, treat, covar)
catt.cps_plus.trim <- catt(nsw_cps_plus.trim, Y, treat, covar) # similar to Imbens & Xu (2024)
catt.psid_plus.trim <- catt(nsw_psid_plus.trim, Y, treat, covar) # similar to Imbens & Xu (2024)
```

```{r, message=FALSE, warning=FALSE}
catt.top5_cps <- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar))
catt.top5_psid <- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar))
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGUREC10. CATT Estimates using NSW Data"}
# combine all catt objects 
all_catt <- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim, catt.cps_plus.trim, catt.psid_plus.trim), catt.top5_cps, catt.top5_psid)

# plot results
par(mfrow = c(2,2))
par(cex.main = 0.9)
plot_catt_panels(all_catt, plot_titles)
```

```{r, message=FALSE, warning=FALSE}
all_catt_eval <- eval_catt(all_catt, plot_titles)
knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

With NSW-CPS1, the CATT estimates range from $-8,652.64 to $6,452.97, contrasting with the benchmark where CATT estimates span from $-1,179.03 to $3,339.96, with a mean CATT estimate of $812.17. Alike in the previous sections, the NSW-PSID1 data exhibits a narrower CATT estimates range compared to NSW-CPS1, spanning from $-8,591.86 to $1,170.55. Yet its mean CATT estimate remains substantially negative, at approximately $-2,321.86, contrary to the positive mean CATT estimates observed in models A and B.

Among the trimmed and top-ranked NSW-CPS1 subsamples, CATT estimates exhibit substantial variability. Subsamples such as `overlap_crump` or `adap_weight_trunc_ipw_weight` yield notably negative minimum CATT values alongside moderately negative mean CATT estimates. Similarly, `card` and `mahvars` subsamples produce consistently negative mean CATT estimates, although weaker alignment with the experimental benchmark. The `ps_threshold` subsample yields improved estimates with highest min CATT and mean CATTs estimates closest to the experimental benchmark, while still negative.

The NSW-PSID1 trimmed and top-ranked subsamples deliver substantially decreased mean CATT estimates and wider extremes compared to their NSW-CPS1 counterparts, reflecting greater difficulties in producing reliable effect estimates.

This variation in range and means across samples, as observed in previous sections, reflects substantial heterogeneity in treatment effect estimation but also indicates that while certain criteria improve alignment with the experimental benchmark, others introduce considerable discrepancies and spread in estimated heterogeneous effects.
```{r, message=FALSE, warning=FALSE}
# save results
save_catt_panels(all_catt, plot_titles, prefix = "nsw")
```

### Quantile treatment effect on the treated (QTET)
```{r, message=FALSE, warning=FALSE}
qte.nsw <- est_qte(Y, treat, covar, data = nsw, cores = 4)
```

```{r, message=FALSE, warning=FALSE}
qte.nsw_cps <- est_qte(Y, treat, covar, data = nsw_cps)
qte.nsw_psid <- est_qte(Y, treat, covar, data = nsw_psid)
qte.nsw_cps_plus <- est_qte(Y, treat, covar, data = nsw_cps_plus)
qte.nsw_psid_plus <- est_qte(Y, treat, covar, data = nsw_psid_plus)
qte.nsw_cps.trim <- est_qte(Y, treat, covar, data = nsw_cps.trim)
qte.nsw_psid.trim <- est_qte(Y, treat, covar, data = nsw_psid.trim) 
qte.nsw_cps_plus.trim <- est_qte(Y, treat, covar, data = nsw_cps_plus.trim)
qte.nsw_psid_plus.trim <- est_qte(Y, treat, covar, data = nsw_psid_plus.trim) 
```

```{r, message=FALSE, warning=FALSE}
qte.top5_cps  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, covar, data = d))
qte.top5_psid <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.nsw0 <- est_qte(Y, treat, NULL, data = nsw)
qte.nsw.cps0 <- est_qte(Y, treat, NULL, data = nsw_cps)
qte.nsw.psid0 <- est_qte(Y, treat, NULL, data = nsw_psid)
qte.nsw_cps.trim0 <- est_qte(Y, treat, NULL, data = nsw_cps.trim)
qte.nsw_psid.trim0 <- est_qte(Y, treat, NULL, data = nsw_psid.trim)
qte.nsw_cps_plus.trim0 <- est_qte(Y, treat, NULL, data = nsw_cps_plus.trim)
qte.nsw_psid_plus.trim0 <- est_qte(Y, treat, NULL, data = nsw_psid_plus.trim)
qte.top5_cps0  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, NULL, data = d))
qte.top5_psid0 <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGUREC11. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.8)

# CPS1
plot_qte(qte.nsw_cps, qte.nsw.cps0, qte.nsw, main = "(B) NSW-CPS1", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1
plot_qte(qte.nsw_psid, qte.nsw.psid0, qte.nsw, main = "(C) NSW-PSID1", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

## CPS1 trimmed
plot_qte(qte.nsw_cps.trim, qte.nsw_cps.trim0, qte.nsw_cps, main = "(D) NSW-CPS1 (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1 trimmed
plot_qte(qte.nsw_psid.trim, qte.nsw_psid.trim0, qte.nsw_psid, main = "(E) NSW-PSID1 (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

## CPS1-PLUS trimmed
plot_qte(qte.nsw_cps_plus.trim, qte.nsw_cps_plus.trim0, qte.nsw_cps_plus, main = "(F) NSW-CPS1-PLUS (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1-PLUS trimmed
plot_qte(qte.nsw_psid_plus.trim, qte.nsw_psid_plus.trim0, qte.nsw_psid_plus, main = "(G) NSW-PSID1-PLUS (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# CPS1 top methods
plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.nsw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000))

# PSID1 top methods
plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.nsw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000))
```

These figures display QTET estimates derived from both the NSW experimental and various observational samples. The QTETs estimated from trimmed NSW-CPS1 sample (D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original NSW-CPS1, the original NSW-PSID1 and its trimmed subsample (B, C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked subsamples, CPS1-based QTETs (F–J) consistently track the true QTET closely. In contrast, PSID1-based QTETs (K–O) generally perform well, aligning closely with the true QTET, except for subsamples `mahvars` and `card`, which exhibit increased bias and noticeably wider confidence intervals, reflecting greater estimation uncertainty.
```{r, message=FALSE, warning=FALSE}
# list results
plots_nsw <- list(
  list(mod = qte.nsw_cps, mod0 = qte.nsw.cps0, bm = qte.nsw, main = "(B) NSW CPS1"),
  list(mod = qte.nsw_psid, mod0 = qte.nsw.psid0, bm = qte.nsw, main = "(C) NSW PSID1"),
  list(mod = qte.nsw_cps.trim, mod0 = qte.nsw_cps.trim0, bm = qte.nsw_cps, main = "(D) NSW CPS1 (Trimmed)"),
  list(mod = qte.nsw_psid.trim, mod0 = qte.nsw_psid.trim0, bm = qte.nsw_psid, main = "(E) NSW PSID1 (Trimmed)"),
  list(mod = qte.nsw_cps_plus.trim, mod0 = qte.nsw_cps_plus.trim0, bm = qte.nsw_cps_plus, main = "(F) NSW CPS1-PLUS (Trimmed)"),
  list(mod = qte.nsw_psid_plus.trim, mod0 = qte.nsw_psid_plus.trim0, bm = qte.nsw_psid_plus, main = "(G) NSW PSID1-PLUS (Trimmed)")
)

# save results
save_qtet(plots_nsw, prefix = "nsw", ylim = c(-25000, 15000))
save_qte_top(qte.top5_cps, qte.top5_cps0, qte.nsw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000), prefix = "nsw_top")
save_qte_top(qte.top5_psid, qte.top5_psid0, qte.nsw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000), prefix = "nsw_top")
```

### Assessing outcome weights (OW)
```{r, message=FALSE, warning=FALSE}
# list all datasets
all_datasets <- c(list(nsw, nsw_cps, nsw_psid, nsw_cps.trim, nsw_psid.trim, nsw_cps_plus.trim.match, nsw_psid_plus.trim.match), top5_datasets.cps, top5_datasets.psid)
```

```{r, message=FALSE, warning=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGUREC12. Outcome Weights using NSW Data"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# plot outcome weights distribution
plot_ow(ow_att, plot_titles) 
```

```{r, message=FALSE, warning=FALSE}
#evaluate results
res_ow <- eval_ow(ow_att, all_datasets, plot_titles, treat, "AIPW-ATT")
knitr::kable(res_ow, caption = "Outcome Weights for Treated and Untreated", booktabs = TRUE) 
```

```{r, message=FALSE, warning=FALSE}
#save results
save_ow(ow_att, plot_titles, prefix = "nsw")
```

Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero.

<div class="callout-tip">
A placebo test is not performed as the NSW data comes from a randomized controlled trial (RCT), which ensures internal validity and unbiased treatment effect estimates, without confounding.
</div>

## Validation through sensitivity analyses
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "re75", "u75")
bm <- c("re75")
```

```{r, message=FALSE, warning=FALSE}
# check for valid datasets 
filtered_datasets_sens <- check_filter_datasets(all_datasets, Y, treat, covar, bm)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGUREC13. Sensitivity Analyses NSW"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = plot_titles[idx])
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, "nsw")
```

The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of `re78`. 

## Summary
After reexamining the original LaLonde (NSW) dataset, the results confirm that the NSW-Experimental data shows nearly perfect overlap between treated and control groups, while the observational datasets (NSW-CPS1 and NSW-PSID1) display weak overlap, with many treated units outside the control range. Expanding these datasets with experimental controls improves overlap but does not consistently enhance covariate balance. 

These findings reinforce the lessons from previous LDW analyses: even with improved overlap and some gains in covariate balance, achieving consistent and reliable effect estimation remains difficult, especially with non-experimental data. The results highlight the persistent limitations of observational samples in replicating experimental benchmarks.
