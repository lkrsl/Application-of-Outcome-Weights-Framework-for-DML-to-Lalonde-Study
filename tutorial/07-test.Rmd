
### Weighting

The purpose of weighting is to reweight the units in order to create a synthetic population in which the distributions of observed characteristics is balanced between treatment and control groups. In the following, several weighting methods, as outlined by @Greifer_4_2025 and @Stuermer_2021 are applied.

#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores (PS) with a parametric generalized linear model and converts them into weights
w.out.cps.ipw <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "glm")
ldw_cps.ps$ipw_weight <- w.out.cps.ipw$weights
w.out.psid.ipw <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "glm")
ldw_psid.ps$ipw_weight <- w.out.psid.ipw$weights
```

#### Covariate balance propensity score weights
```{r, message=FALSE, warning=FALSE}
# estimates PS using generalized method of moments and then converts them into weights
w.out.cps.cbps <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "cbps")
ldw_cps.ps$cbps_weight <- w.out.cps.cbps$weights
w.out.psid.cbps <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "cbps")
ldw_psid.ps$cbps_weight <- w.out.psid.cbps$weights
```

#### Stable balancing weights 
```{r, message=FALSE, warning=FALSE}
# estimates weights by minimizing the variance of the weights
w.out.cps.opt <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "optweight")
ldw_cps.ps$opt_weight <- w.out.cps.opt$weights
w.out.psid.opt <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "optweight")
ldw_psid.ps$opt_weight <- w.out.psid.opt$weights
```

#### Entropy balancing weights
```{r, message=FALSE, warning=FALSE}
# estimates weights by minimizing the negative entropy of the weights subject to exact moment balancing constraints
w.out.cps.ebal <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "ebal")
ldw_cps.ps$ebal_weight <- w.out.cps.ebal$weights
w.out.psid.ebal <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "ebal")
ldw_psid.ps$ebal_weight <- w.out.psid.ebal$weights
```

## Improving primarily overlap

Truncation aims at limiting the influence of extreme weights by capping them at a specified threshold. This helps to reduce variance and improve the stability of causal effect estimates. In the following, several truncation methods are applied, following similar approaches outlined by @Matsouaka_2023 and @Schwab_2013.

### Truncation
#### Fixed value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum 
ldw_cps.ps_fixed <- truncate_ps_fixed(ldw_cps.ps, treat = "treat", ps = "ps_assoverlap", lower = 0.05, upper = 0.95)
ldw_psid.ps_fixed <- truncate_ps_fixed(ldw_psid.ps, treat = "treat", ps = "ps_assoverlap", lower = 0.05, upper = 0.95)
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
ldw_cps.ps_percent <- truncate_ps_percentile(ldw_cps.ps, ps = "ps_assoverlap", lower_percentile = 5, upper_percentile = 95)
ldw_psid.ps_percent <- truncate_ps_percentile(ldw_psid.ps, ps = "ps_assoverlap", lower_percentile = 5, upper_percentile = 95)
```

#### Adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights using data-driven quantile selection
ldw_cps.ps_adapt <- truncate_ps_adaptive(ldw_cps.ps, treat = "treat", ps = "ps_assoverlap", folds = 5, 
                                         lower_grid = seq(0.01, 0.10, by = 0.01), 
                                         upper_grid = seq(0.90, 0.99, by = 0.01))
ldw_psid.ps_adapt <- truncate_ps_adaptive(ldw_psid.ps, treat = "treat", ps = "ps_assoverlap", folds = 5,
                                         lower_grid = seq(0.01, 0.10, by = 0.01),
                                         upper_grid = seq(0.90, 0.99, by = 0.01))
```

### Trimming 

The purpose of trimming is to remove units whose propensity scores are too dissimilar from the opposite group, thereby improving covariate balance between treated and control groups. Below, we employ several trimming methods in line with the approaches proposed by @Stuermer_2021 and @imbens2024.

#### Propensity score threshold trimming 
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
ldw_cps.ps_trim <- ps_trim(ldw_cps.ps, threshold = 0.9)
ldw_psid.ps_trim <- ps_trim(ldw_psid.ps, threshold = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_trim <- ps_estimate(data = ldw_cps.ps_trim, treat = treat, cov = covar)
ldw_psid.ps_trim <- ps_estimate(data = ldw_psid.ps_trim, treat = treat, cov = covar)
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
ldw_cps.ps_common   <- common_range_trim(ldw_cps.ps)
ldw_psid.ps_common  <- common_range_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_common <- ps_estimate(data = ldw_cps.ps_common, treat = treat, cov = covar)
ldw_psid.ps_common <- ps_estimate(data = ldw_psid.ps_common, treat = treat, cov = covar)
```

#### Crump trimming 
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
ldw_cps.ps_crump  <- crump_trim(ldw_cps.ps, lower = 0.1, upper = 0.9)
ldw_psid.ps_crump <- crump_trim(ldw_psid.ps, lower = 0.1, upper = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_crump <- ps_estimate(data = ldw_cps.ps_crump, treat = treat, cov = covar)
ldw_psid.ps_crump <- ps_estimate(data = ldw_psid.ps_crump, treat = treat, cov = covar)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
ldw_cps.ps_stuermer  <- stuermer_trim(ldw_cps.ps)
ldw_psid.ps_stuermer <- stuermer_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_stuermer <- ps_estimate(data = ldw_cps.ps_stuermer, treat = treat, cov = covar)
ldw_psid.ps_stuermer <- ps_estimate(data = ldw_psid.ps_stuermer, treat = treat, cov = covar)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
ldw_cps.ps_walker  <- walker_trim(ldw_cps.ps)
ldw_psid.ps_walker <- walker_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_walker <- ps_estimate(data = ldw_cps.ps_walker, treat = treat, cov = covar)
ldw_psid.ps_walker <- ps_estimate(data = ldw_psid.ps_walker, treat = treat, cov = covar)
```



### Trimming and weighting

#### Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# apply stable balancing with trimming and attach stable balance weights
opt_comb.cps <- attach_weights(all_trim.cps, model, "opt_weight")
opt_comb.psid <- attach_weights(all_trim.psid, model, "opt_weight")
```

#### Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# apply propensity score weighting with trimming and attach propensity score weights
cbps_comb.cps <- attach_weights(all_trim.cps, model, "cbps_weight")
cbps_comb.psid <- attach_weights(all_trim.psid, model, "cbps_weight")
```

#### Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
ebal_comb.cps <- attach_weights(all_trim.cps, model, "ebal_weight")
ebal_comb.psid <- attach_weights(all_trim.psid, model, "ebal_weight")
```


#### Prepare weight Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores (PS) with a parametric generalized linear model and converts them into weights
w.out.cps.ipw <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "glm")
ldw_cps.ps$ipw_weight <- w.out.cps.ipw$weights
w.out.psid.ipw <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "glm")
ldw_psid.ps$ipw_weight <- w.out.psid.ipw$weights
```

#### Covariate balance propensity score weights
```{r, message=FALSE, warning=FALSE}
# estimates PS using generalized method of moments and then converts them into weights
w.out.cps.cbps <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "cbps")
ldw_cps.ps$cbps_weight <- w.out.cps.cbps$weights
w.out.psid.cbps <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "cbps")
ldw_psid.ps$cbps_weight <- w.out.psid.cbps$weights
```

#### Stable balancing weights 
```{r, message=FALSE, warning=FALSE}
# estimates weights by minimizing the variance of the weights
w.out.cps.opt <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "optweight")
ldw_cps.ps$opt_weight <- w.out.cps.opt$weights
w.out.psid.opt <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "optweight")
ldw_psid.ps$opt_weight <- w.out.psid.opt$weights
```

#### Entropy balancing weights
```{r, message=FALSE, warning=FALSE}
# estimates weights by minimizing the negative entropy of the weights subject to exact moment balancing constraints
w.out.cps.ebal <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "ebal")
ldw_cps.ps$ebal_weight <- w.out.cps.ebal$weights
w.out.psid.ebal <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "ebal")
ldw_psid.ps$ebal_weight <- w.out.psid.ebal$weights
```

### Truncation and weighting
```{r, message=FALSE, warning=FALSE}
# list weight columns to apply truncation 
weight_columns <- c("ipw_weight", "opt_weight", "cbps_weight", "ebal_weight")
```

#### IPW, stable balancing, propensity score and entropy weights with 1) fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum threshold
fixed_comb.cps <- ldw_cps.ps
for (wcol in weight_columns) {
  if (wcol %in% names(fixed_comb.cps)) {
    fixed_comb.cps <- truncate_weights_fixed(fixed_comb.cps, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}

fixed_comb.psid <- ldw_psid.ps
for (wcol in weight_columns) {
  if (wcol %in% names(fixed_comb.psid)) {
    fixed_comb.psid <- truncate_weights_fixed(fixed_comb.psid, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}
```

#### IPW, stable balancing, propensity score and entropy weights with 2) at percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
percent_comb.cps <- ldw_cps.ps
for (wcol in weight_columns) {
  if (wcol %in% names(percent_comb.cps)) {
    percent_comb.cps <- truncate_weights_percentile(percent_comb.cps, weight_col = wcol, lower = 0.05, upper = 0.95)
  }
}

percent_comb.psid <- ldw_psid.ps
for (wcol in weight_columns) {
  if (wcol %in% names(percent_comb.psid)) {
    percent_comb.psid <- truncate_weights_percentile(percent_comb.psid, weight_col = wcol, lower = 0.05, upper = 0.95)
  }
}
```

#### IPW, stable balancing, propensity score and entropy weights with 3) adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights using data-driven quantile selection
adapt_comb.cps <- ldw_cps.ps
for (wcol in weight_columns) {
  if (wcol %in% names(adapt_comb.cps)) {
    adapt_comb.cps <- truncate_weights_adaptive(adapt_comb.cps, weight_col = wcol)
  }
}

adapt_comb.psid <- ldw_cps.ps
for (wcol in weight_columns) {
  if (wcol %in% names(adapt_comb.psid)) {
    adapt_comb.psid <- truncate_weights_adaptive(adapt_comb.psid, weight_col = wcol)
  }
}
```

## Reassessing methods

We now systematically reassess all methods described above by evaluating covariate balance and effective sample size. Specifically, we examine the SMD and ESS for each approach and use visual diagnostics to assess covariate balance and overlap between treated and control groups.

### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching objects
all_match.cps <- list(
  nn = m.out.cps.nearest,
  k2 = m.out.cps.k2,
  k3 = m.out.cps.k3,
  caliper = m.out.cps.caliper,
  cS = m.out.cps.cs,
  mahvars = m.out.cps.mahvars,
  optimal_pair = m.out.cps.optimal_pair,
  optimal_full = m.out.cps.optimal_full,
  gen_full = m.out.cps.general_full,
  genetic = m.out.cps.genetic,
  exact = m.out.cps.exact,
  cem = m.out.cps.cem,
  card = m.out.cps.card,
  profile = m.out.cps.profile,
  subcl = m.out.cps.subcl
)

all_match.psid <- list(
  nn = m.out.psid.nearest,
  k2 = m.out.psid.k2,
  k3 = m.out.psid.k3,
  caliper = m.out.psid.caliper,
  cs = m.out.psid.cs,
  mahvars = m.out.psid.mahvars,
  optimal_pair = m.out.psid.optimal_pair,
  optimal_full = m.out.psid.optimal_full,
  gen_full = m.out.psid.general_full,
  genetic = m.out.psid.genetic,
  exact = m.out.psid.exact,
  cem = m.out.psid.cem,
  card = m.out.psid.card,
  profile = m.out.psid.profile,
  subcl = m.out.psid.subcl
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_matchit.cps <- compute_abs_smd_matchit(all_match.cps)
smd_matchit.psid <- compute_abs_smd_matchit(all_match.psid)
```

#### OVL
```{r, message=FALSE, warning=FALSE}
# calculate overlap coefficient
ovl_matchit.cps <- compute_ovl_matchit(all_match.cps, ps_col = "distance", treat_col = "treat", covar = covar)
ovl_matchit.psid <- compute_ovl_matchit(all_match.psid, ps_col = "distance", treat_col = "treat", covar = covar)
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
all_weight.cps <- list(
  ipw_weight = ldw_cps.ps$ipw_weight, 
  opt_weight = ldw_cps.ps$opt_weight,
  cbps_weight = ldw_cps.ps$cbps_weight,
  ebal_weight = ldw_cps.ps$ebal_weight
)

all_weight.psid <- list(
  ipw_weight = ldw_psid.ps$ipw_weight,
  opt_weight = ldw_psid.ps$opt_weight,
  cbps_weight = ldw_psid.ps$cbps_weight,
  ebal_weight = ldw_psid.ps$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_weight.cps <- compute_abs_smd_weight(ldw_cps.ps, treat, covar, all_weight.cps)
smd_weight.psid <- compute_abs_smd_weight(ldw_psid.ps, treat, covar, all_weight.psid)
```

#### OVL 
```{r message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_weight.cps <- compute_ovl_weight(data = ldw_cps.ps, treat_col = "treat", ps_col = "ps_assoverlap",  weights_list = all_weight.cps, covar = covar, n_points = 512)
ovl_weight.psid <- compute_ovl_weight(data = ldw_psid.ps, treat_col = "treat", ps_col = "ps_assoverlap", weights_list = all_weight.psid, covar = covar, n_points = 512)
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
all_trunc.cps <- list(
  fix_value = ldw_cps.ps_fixed,
  at_perc = ldw_cps.ps_percent,
  adapt = ldw_cps.ps_adapt
)

all_trunc.psid <- list(
  fix_value = ldw_psid.ps_fixed,
  at_perc = ldw_psid.ps_percent,
  adapt = ldw_psid.ps_adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trunc.cps <- compute_abs_smd_trunc(all_trunc.cps, "treat", covar, "ps_assoverlap")
smd_trunc.psid <- compute_abs_smd_trunc(all_trunc.psid, "treat", covar, "ps_assoverlap")
```

#### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trunc.cps <- compute_ovl_trunc(all_trunc.cps, "ps_assoverlap", "treat")
ovl_trunc.psid <- compute_ovl_trunc(all_trunc.psid, "ps_assoverlap", "treat")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming objects plus original
all_trim.cps <- list(
  original = ldw_cps.ps,
  ps_threshold = ldw_cps.ps_trim,
  common_range = ldw_cps.ps_common,
  crump = ldw_cps.ps_crump,
  stuermer = ldw_cps.ps_stuermer,
  walker = ldw_cps.ps_walker
)

all_trim.psid <- list(
  original = ldw_cps.ps,
  ps_threshold = ldw_psid.ps_trim,
  common_range = ldw_psid.ps_common,
  crump = ldw_psid.ps_crump,
  stuermer = ldw_psid.ps_stuermer,
  walker = ldw_psid.ps_walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trim.cps <- compute_abs_smd_trim(all_trim.cps, "treat", covar)
smd_trim.psid <- compute_abs_smd_trim(all_trim.psid, "treat", covar)
```

#### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trim.cps <- compute_ovl_trim(all_trim.cps, "ps_assoverlap", "treat")
ovl_trim.psid <- compute_ovl_trim(all_trim.psid, "ps_assoverlap", "treat")
```

## Integrated methods
### Trimming and matching
(Similar to tutorial by @imbens2024)
```{r, message=FALSE, warning=FALSE}
# list all trimmed and matched samples
trim_match_comb.cps <- list(
  ps_threshold_match = ldw_cps.trim_match
)

trim_match_comb.psid <- list(
  ps_threshold_match = ldw_psid.trim_match
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trim_match_comb.cps <- compute_abs_smd_trim(trim_match_comb.cps, "treat", covar)
smd_trim_match_comb.psid <- compute_abs_smd_trim(trim_match_comb.psid, "treat", covar)
```

#### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trim_match_comb.cps <- compute_ovl_trim_match(trim_match_comb.cps, ps_col = "distance", treat_col = "treat", covar = covar)
ovl_trim_match_comb.psid <- compute_ovl_trim_match(trim_match_comb.psid, ps_col = "distance", treat_col = "treat", covar = covar)
```

### Trimming and weighting
```{r, message=FALSE, warning=FALSE}
# list all combined results
trim_weight_comb.cps <- list(
  ipw = ipw_comb.cps,
  opt = opt_comb.cps,
  cbps = cbps_comb.cps,
  ebal = ebal_comb.cps
)

trim_weight_comb.psid <- list(
  ipw = ipw_comb.psid,
  opt = opt_comb.psid,
  cbps = cbps_comb.psid,
  ebal = ebal_comb.psid
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trim_weight_comb.cps <- compute_abs_smd_trim_weight(trim_weight_comb.cps, "treat", covar)
smd_trim_weight_comb.psid <- compute_abs_smd_trim_weight(trim_weight_comb.psid, "treat", covar)
```

#### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trim_weight_comb.cps <- compute_ovl_trim_weight(trim_weight_comb.cps, treat_col = "treat", ps_col = "ps_assoverlap")
ovl_trim_weight_comb.psid <- compute_ovl_trim_weight(trim_weight_comb.psid, treat_col = "treat", ps_col = "ps_assoverlap")
```

### Truncation and weighting
```{r, message=FALSE, warning=FALSE}
# list all combined results
trunc_weight_comb.cps <- list(
  fix_value = fixed_comb.cps,
  at_perc = percent_comb.cps,
  adapt = adapt_comb.cps
)

trunc_weight_comb.psid <- list(
  fix_value = fixed_comb.psid,
  at_perc = percent_comb.psid,
  adapt = adapt_comb.psid
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trunc_weight_comb.cps <- compute_abs_smd_trunc_weight(trunc_weight_comb.cps, "treat", covar, weight_columns)
smd_trunc_weight_comb.psid <- compute_abs_smd_trunc_weight(trunc_weight_comb.psid, "treat", covar, weight_columns)
```

#### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trunc_weight_comb.cps <- compute_ovl_trunc_weight(trunc_weight_comb.cps, treat_col = "treat", ps_col = "ps_assoverlap")
ovl_trunc_weight_comb.psid <- compute_ovl_trunc_weight(trunc_weight_comb.psid, treat_col = "treat", ps_col = "ps_assoverlap")
```

## Identifying best methods

### Ranking
#### Initial datasets
To identify the top five methods for each observational dataset, we first combine for each dataset all results of the absolute SMD and OVL into a single data frame. This allows for a comprehensive comparison across all methods.

<div class="callout-note">
Only results based on the non-plus datasets are included in the identification of the best methods, as the objective is to identify the overall best-performing methods for the original observational samples. 
</div>
```{r, message=FALSE, warning=FALSE}
# combine all results
all_cps <- combine_results("cps")
all_psid <- combine_results("psid") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_cps, "ldw_model_a_cps1_all_results")
save_csv(all_psid, "ldw_model_a_psid1_all_results")
```

Next, we evaluate each method by constructing a composite score that is build on two separate scores equally weighted:
- `smd_score` rescales the absolute SMD to a 0-1 range, where a lower value leads to a higher score
- `ovl_score` measures the overlap coefficient of the density distributions of the treated and control group, where a higher value leads to a higher score
```{r, message=FALSE, warning=FALSE}
# rank comparatively
ranked_cps  <- assess_methods(all_cps)
ranked_psid <- assess_methods(all_psid)
```

Based on the composite scores, we rank all methods and select the top five for each dataset.
```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
top5_methods.cps <- get_top_methods(ranked_cps, top_n = 5)
top5_methods.psid <- get_top_methods(ranked_psid, top_n = 5)
```

```{r, message=FALSE, warning=FALSE}
# print results
top5_methods_df.cps <- ranked_cps %>% arrange(desc(Score)) %>% head(5)
top5_methods_df.psid <- ranked_psid %>% arrange(desc(Score)) %>% head(5)

datatable(top5_methods_df.cps, caption = "Top 5 Methods for CPS1",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
datatable(top5_methods_df.psid, caption = "Top 5 Methods for PSID1",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.cps, "ldw_model_a_cps1_top5_methods")
save_csv(top5_methods.psid, "ldw_model_a_psid1_top5_methods")
```

#### Extended datasets
As a point of reference, we also examine the score for the trimmed and matched plus‑datasets. 
<div class="callout-note">
The plus‑datasets are included only to evaluate how incorporating experimental controls and the integrated trimming and matching approach affects method performance. Their results are not directly comparable to the main scoring and are not used in subsequent analyses. 
</div>
```{r, message=FALSE, warning=FALSE}
# combine results
all_cps_plus  <- combine_results_plus("cps")
all_psid_plus <- combine_results_plus("psid")
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_cps_plus, "ldw_model_a_cps1_plus_all_results")
save_csv(all_psid_plus, "ldw_model_a_psid1_plus_all_results")
```

```{r, message=FALSE, warning=FALSE}
# assess composite scores
ranked_cps_plus  <- assess_methods(all_cps_plus)
ranked_psid_plus <- assess_methods(all_psid_plus)
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
top5_methods.cps_plus <- get_top_methods(ranked_cps_plus, top_n = 5)
top5_methods.psid_plus <- get_top_methods(ranked_psid_plus, top_n = 5)
```

```{r, message=FALSE, warning=FALSE}
# print results
top5_methods_df.cps_plus <- ranked_cps_plus %>% arrange(desc(Score)) %>% head(5)
top5_methods_df.psid_plus <- ranked_psid_plus %>% arrange(desc(Score)) %>% head(5)

datatable(top5_methods_df.cps_plus, caption = "Top 5 Methods for CPS1 and CPS1-PLUS",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
datatable(top5_methods_df.psid_plus, caption = "Top 5 Methods for PSID1 and PSID1-PLUS",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.cps_plus, "ldw_model_a_cps1_plus_top5_methods")
save_csv(top5_methods.psid_plus, "ldw_model_a_psid1_plus_top5_methods")
```

These results indicate that the top‑ranked methods for both CPS1 and PSID1 change once the trimmed and matched plus‑datasets are included, suggesting that either the integration of additional experimental control units or the combined trimming and matching approach enhances performance. Consequently, it is advisable to repeat the full analysis using only the plus‑datasets while systematically applying integrated trimming and matching methods.

### Dataset construction
For the subsequent estimation, we need to construct datasets of the top‑ranked methods. Therefore, we match all method names back to their corresponding datasets, objects or vectors and construct corresponding datasets. 
```{r, message=FALSE, warning=FALSE}
list_cps <- list(
  "All" = ldw_cps,
  "original" = ldw_cps.ps,
  "nn" = m.out.cps.nearest, 
  "k2"  = m.out.cps.k2,
  "k3" = m.out.cps.k3,
  "caliper" = m.out.cps.caliper,
  "cS" = m.out.cps.cs,
  "mahvars" = m.out.cps.mahvars,
  "card" = m.out.cps.card,
  "cem" = m.out.cps.cem,
  "optimal_full" = m.out.cps.optimal_full,
  "optimal_pair" = m.out.cps.optimal_pair,
  "gen_full" = m.out.cps.general_full,
  "genetic" = m.out.cps.genetic,
  "exact" = m.out.cps.exact,
  "subcl" = m.out.cps.subcl,
  "profile"  = m.out.cps.profile,
  "ipw_weight" = ldw_cps.ps$ipw_weight, 
  "opt_weight" = ldw_cps.ps$opt_weight,
  "cbps_weight" = ldw_cps.ps$cbps_weight,
  "ebal_weight" = ldw_cps.ps$ebal_weight,
  "ps_threshold" = ldw_cps.ps_trim,
  "common_range" = ldw_cps.ps_common,
  "stuermer" = ldw_cps.ps_stuermer,
  "walker" = ldw_cps.ps_walker,
  "crump" = ldw_cps.ps_crump,
  "adapt" = ldw_cps.ps_fixed,
  "at_perc" = ldw_cps.ps_percent,
  "fix_value" = ldw_cps.ps_adapt, 
  "fix_value_ipw_weight" = fixed_comb.cps$ipw_weight,
  "fix_value_opt_weight" = fixed_comb.cps$opt_weight,
  "fix_value_cbps_weight" = fixed_comb.cps$cbps_weight,
  "fix_value_ebal_weight" = fixed_comb.cps$ebal_weight,
  "at_perc_ipw_weight" = percent_comb.cps$ipw_weight,
  "at_perc_opt_weight" = percent_comb.cps$opt_weight,
  "at_perc_cbps_weight" = percent_comb.cps$cbps_weight,
  "at_perc_ebal_weight" = percent_comb.cps$ebal_weight,
  "adapt_ipw_weight" = adapt_comb.cps$ipw_weight,
  "adapt_opt_weight" = adapt_comb.cps$opt_weight,
  "adapt_cbps_weight" = adapt_comb.cps$cbps_weight,
  "adapt_ebal_weight" = adapt_comb.cps$ebal_weight,
  "ipw_ps_threshold"= ipw_comb.cps[[1]],
  "ipw_common_range" = ipw_comb.cps[[2]],
  "ipw_stuermer"= ipw_comb.cps[[3]],
  "ipw_walker" = ipw_comb.cps[[4]],
  "ipw_crump"= ipw_comb.cps[[5]],
  "opt_ps_threshold" = opt_comb.cps[[1]],
  "opt_common_range" = opt_comb.cps[[2]],
  "opt_stuermer" = opt_comb.cps[[3]],
  "opt_walker" = opt_comb.cps[[4]],
  "opt_crump" = opt_comb.cps[[5]],
  "cbps_ps_threshold"  = cbps_comb.cps[[1]],
  "cbps_common_range" = cbps_comb.cps[[2]],
  "cbps_stuermer" = cbps_comb.cps[[3]],
  "cbps_walker"= cbps_comb.cps[[4]],
  "cbps_crump" = cbps_comb.cps[[5]],
  "ebal_ps_threshold" = ebal_comb.cps[[1]],
  "ebal_common_range" = ebal_comb.cps[[2]],
  "ebal_stuermer" = ebal_comb.cps[[3]],
  "ebal_walker" = ebal_comb.cps[[4]],
  "ebal_crump" = ebal_comb.cps[[5]],
  "ps_threshold_match" = ldw_cps.trim_match)

list_psid <- list(
  "All" = ldw_psid,
  "original" = ldw_psid,
  "nn" = m.out.psid.nearest, 
  "caliper" = m.out.psid.caliper,
  "card" = m.out.psid.card,
  "cem" = m.out.psid.cem,
  "cS" = m.out.psid.cs,
  "k2"  = m.out.psid.k2,
  "k3" = m.out.psid.k3,
  "mahvars" = m.out.psid.mahvars,
  "optimal_full" = m.out.psid.optimal_full,
  "optimal_pair" = m.out.psid.optimal_pair,
  "gen_full" = m.out.psid.general_full,
  "genetic" = m.out.psid.genetic,
  "exact" = m.out.psid.exact,
  "subcl" = m.out.psid.subcl,
  "profile"  = m.out.psid.profile,
  "ipw_weight" = ldw_psid.ps$ipw_weight, 
  "opt_weight" = ldw_psid.ps$opt_weight,
  "cbps_weight" = ldw_psid.ps$cbps_weight,
  "ebal_weight" = ldw_psid.ps$ebal_weight,
  "ps_threshold" = ldw_psid.ps_trim,
  "common_range" = ldw_psid.ps_common,
  "stuermer" = ldw_psid.ps_stuermer,
  "walker" = ldw_psid.ps_walker,
  "crump" = ldw_psid.ps_crump,
  "adapt" = ldw_psid.ps_fixed, 
  "at_perc" = ldw_psid.ps_percent,
  "fix_value" = ldw_psid.ps_adapt, 
  "fix_value_ipw_weight" = fixed_comb.psid$ipw_weight,
  "fix_value_opt_weight" = fixed_comb.psid$opt_weight,
  "fix_value_cbps_weight" = fixed_comb.psid$cbps_weight,
  "fix_value_ebal_weight" = fixed_comb.psid$ebal_weight,
  "at_perc_ipw_weight" = percent_comb.psid$ipw_weight,
  "at_perc_opt_weight" = percent_comb.psid$opt_weight,
  "at_perc_cbps_weight" = percent_comb.psid$cbps_weight,
  "at_perc_ebal_weight" = percent_comb.psid$ebal_weight,
  "adapt_ipw_weight" = adapt_comb.psid$ipw_weight,
  "adapt_opt_weight" = adapt_comb.psid$opt_weight,
  "adapt_cbps_weight" = adapt_comb.psid$cbps_weight,
  "adapt_ebal_weight" = adapt_comb.psid$ebal_weight,
  "ipw_ps_threshold"= ipw_comb.psid[[1]],
  "ipw_common_range" = ipw_comb.psid[[2]],
  "ipw_stuermer"= ipw_comb.psid[[3]],
  "ipw_walker" = ipw_comb.psid[[4]],
  "ipw_crump"= ipw_comb.psid[[5]],
  "opt_ps_threshold" = opt_comb.psid[[1]],
  "opt_common_range" = opt_comb.psid[[2]],
  "opt_stuermer" = opt_comb.psid[[3]],
  "opt_walker" = opt_comb.psid[[4]],
  "opt_crump" = opt_comb.psid[[5]],
  "cbps_ps_threshold"  = cbps_comb.psid[[1]],
  "cbps_common_range" = cbps_comb.psid[[2]],
  "cbps_stuermer" = cbps_comb.psid[[3]],
  "cbps_walker"= cbps_comb.psid[[4]],
  "cbps_crump" = cbps_comb.psid[[5]],
  "ebal_ps_threshold" = ebal_comb.psid[[1]],
  "ebal_common_range" = ebal_comb.psid[[2]],
  "ebal_stuermer" = ebal_comb.psid[[3]],
  "ebal_walker" = ebal_comb.psid[[4]],
  "ebal_crump" = ebal_comb.psid[[5]],
  "ps_threshold_match" = ldw_psid.trim_match)
```

```{r, message=FALSE, warning=FALSE}
# create datasets corresponding to the top 5 methods for each dataset
top5_datasets.cps <- create_top5_datasets(list_cps, top5_methods.cps)
top5_datasets.psid <- create_top5_datasets(list_psid, top5_methods.psid)
```

```{r, message=FALSE, warning=FALSE}
# save datasets into .RData files
save_top5_datasets(list_cps, top5_methods.cps, prefix = "ldw_model_a_cps1")
save_top5_datasets(list_psid, top5_methods.psid, prefix = "ldw_model_a_psid1")
```

### Visuals
```{r, message=FALSE, warning=FALSE}
# visualize results
top5_objects.cps <- list_cps[top5_methods.cps]
top5_objects.psid <- list_psid[top5_methods.psid]

# covariate balance
plot_matchit_balance(top5_objects.cps, title = "CPS1 Top 5 Methods")
plot_matchit_balance(top5_objects.psid, title = "PSID1 Top 5 Methods")

# overlap
plot_matchit_overlap(top5_objects.cps, treat_col = "treat", covar = covar, prefix = "CPS1", ylim = c(-1, 1))
plot_matchit_overlap(top5_objects.psid, treat_col = "treat", covar = covar, prefix = "PSID1", ylim = c(-1, 1))
```

```{r, message=FALSE, warning=FALSE}
# save results
```

```{r, message=FALSE, warning=FALSE}
# visualize covariate balance of specific results (sort for type)
top5_objects.cps_plus <- list_cps[top5_methods.cps_plus]
top5_objects.psid_plus <- list_psid[top5_methods.psid_plus]

top5_matchit_objects.cps_plus <- top5_objects.cps_plus[c(1,2,4,5)]
top5_data_objects.cps_plus <- top5_objects.cps_plus[[3]]

top5_matchit_objects.psid_plus <- top5_objects.psid_plus[c(2,3,4,5)]
top5_data_objects.psid_plus <- top5_objects.psid_plus[[1]]

# covariate balance
plot_matchit_balance(top5_matchit_objects.cps_plus, title = "CPS1-PLUS Top 5 Methods")
plot_balance(ldw_cps_plus.ps, top5_data_objects.cps_plus, treat_col = "treat", covar = covar, title = "CPS1-PLUS Top 5 Methods")

plot_matchit_balance(top5_matchit_objects.psid_plus, title = "PSID1-PLUS Top 5 Methods")
plot_balance(ldw_psid_plus.ps, top5_data_objects.psid_plus, treat_col = "treat", covar = covar, title = "PSID1-PLUS Top 5 Methods", name = "ps_threshold_match")

# overlap
plot_matchit_overlap(top5_matchit_objects.cps_plus, treat_col = "treat", covar = covar, prefix = "CPS1-PLUS")
plot_overlap(top5_data_objects.cps_plus, treat_col = "treat", covar = covar, prefix = "CPS1-PLUS", name = "ps_threshold_match")
plot_matchit_overlap(top5_matchit_objects.psid_plus, treat_col = "treat", covar = covar, prefix = "PSID1-PLUS")
plot_overlap(top5_data_objects.psid_plus, treat_col = "treat", covar = covar, prefix = "PSID1-PLUS", name = "ps_threshold_match")
```

```{r, message=FALSE, warning=FALSE}
# save results 
```












```{r, message=FALSE, warning=FALSE}
# estimate ATT
load("data/trimmed.RData")
out14 <- estimate_all(ldw_trim_cps, "re78", "treat", covar)
out15 <- estimate_all(ldw_trim_psid, "re78", "treat", covar)
out16 <- estimate_all(ldw_cps_trim, "re78", "treat", covar)
out17 <- estimate_all(ldw_psid_trim, "re78", "treat", covar)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA10. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))

# experimental benchmarks
band.exp <- out1[1, 3:4]
est.exp  <- out1[1, 1]

# plot results
plot_coef(out1,  band = band.exp, line = est.exp, 
          ylim = c(-15500, 5500), main = "(A) LDW-Experimental")

plot_coef(out2,  band = band.exp, line = est.exp, 
          ylim = c(-15500, 5500), main = "(B) LDW-CPS1")

plot_coef(out3,  band = band.exp, line = est.exp,
          ylim = c(-15500, 5500), main = "(C) LDW-PSID1")

for (i in seq_along(out.cps)) {
  this_title <- paste0("(", LETTERS[i+3], ") Top CPS1: ", top5_methods.cps[i])
  plot_coef(out.cps[[i]], band = band.exp, line = est.exp,
            ylim = c(-15500, 5500), main = this_title)
}

for (i in seq_along(out.psid)) {
  this_title <- paste0("(", LETTERS[i+7], ") Top PSID1: ", top5_methods.psid[i])
  plot_coef(out.psid[[i]], band = band.exp, line = est.exp,
            ylim = c(-15500, 5500), main = this_title)
}

# nonexperimtenal benchmarks
band.cps_plus <- out14[1, 3:4]
est.cps_plus <- out14[1, 1]
band.psid_plus <- out15[1, 3:4]
est.psid_plus <- out15[1, 1]

# plot results
plot_coef(out16, band = band.cps_plus, line = est.cps_plus, 
          ylim = c(-15500, 5500), main = "(N) Trimmed LDW-CPS1-PLUS")


plot_coef(out17, band = band.psid_plus, line = est.psid_plus, 
          ylim = c(-15500, 5500), main = "(O) Trimmed LDW-PSID1-PLUS")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(
  out_list = list(out1, out2, out3),
  plot_titles = c("(A) LDW-Experimental", "(B) LDW-CPS1", "(C) LDW-PSID1"),
  band_list = list(band.exp, band.exp, band.exp),
  est_list  = list(est.exp, est.exp, est.exp),
  prefix = "ldw_model_a_est_exp"
)

save_att_panels(
  out_list = out.cps,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps),
  band_list = replicate(length(out.cps), band.exp, simplify = FALSE),
  est_list  = replicate(length(out.cps), est.exp, simplify = FALSE),
  prefix = "ldw_model_a_est_top_cps"
)

save_att_panels(
  out_list = out.psid,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid),
  band_list = replicate(length(out.psid), band.exp, simplify = FALSE),
  est_list  = replicate(length(out.psid), est.exp, simplify = FALSE),
  prefix = "ldw_model_a_est_top_psid"
)

save_att_panels(
  out_list = list(out16, out17),
  plot_titles = c("(N) Trimmed LDW-CPS1-PLUS", "(O) Trimmed LDW-PSID1-PLUS"),
  band_list = list(band.cps_plus, band.psid_plus),
  est_list  = list(est.cps_plus, est.psid_plus),
  prefix = "ldw_model_a_est_plus"
)
```

The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria and trimmed and matched versions of the LDW-CPS1 and LDW-PSID1 samples (similar to @imbens2024).

Figure (A) presents the benchmark from the experimental sample (LDW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the original observational samples, LDW-CPS1 and LDW-PSID1, while figures (D) through (H) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (I) through (M) summarize results for the corresponding PSID1-based subsamples under parallel rules. Figures (N) and (O) present results for the trimmed and matched versions, replicating the tutorial results of Imbens & Xu (2024). 

Across the LDW-CPS1 dataset and its top-ranked subsamples, all estimators generally produce ATT estimates that closely cluster around the experimental benchmark. However, the `ebal_weight` sample exhibit somewhat larger deviations. While most estimates are positive, the `ebal_weight` subsample results include one negative ATT estimates.

In contrast, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors compared to LDW-CPS1 samples. While most ATT estimates are positive, all methods exhibit some negative ATT estimators across various estimators. 
```{r, message=FALSE, warning=FALSE}
# get all outputs
all_outs <- c(list(out1, out2, out3), 
              out.cps, out.psid, 
              list(out16, out17))

# get plot titles
all_plot_titles <- c("(A) LDW-Experimental", "(B) LDW-CPS1", "(C) LDW-PSID1",
                      paste0("(", LETTERS[6:10], ") Top CPS1: ", top5_methods.cps),
                      paste0("(", LETTERS[11:15], ") Top PSID1: ", top5_methods.psid),
                      "(N) Trimmed LDW-CPS1-PLUS", "(O) Trimmed LDW-PSID1-PLUS")

# evaluate results
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- all_plot_titles

# print results
datatable(att_summary, caption = "ATT Summary Statistics",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

The ATT results are presented in the table below:
```{r, message=FALSE, warning=FALSE}
# create result matrix
result_mat <- create_matrix_results(all_outs, all_plot_titles)

# render formatted table output
datatable(result_mat, caption = "ATT Estimates and SEs",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

<div class="callout-note">
The first value in each cell represents the point estimate from the respective estimator and sample. The number in brackets directly following it is the robust standard error (SE) associated with that estimate, indicating the uncertainty or variability around the point estimate.
</div>

The tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. 

For most LDW-CPS1-based samples, estimates remain not only positive but also comparatively close to the experimental benchmark, with modest variance inflation. In contrast, the LDW-PSID1-based estimates exhibit greater variability, more frequently negative values, and larger standard errors, reflecting an increased challenge of achieving balance and overlap in this observational dataset.

Overall, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "ldw_att_est_model_a")
```

<div class="callout-tip">
Improved overlap and covariate balance generally leads to estimates closer to the experimental benchmark, but often at the cost of increased standard errors. This trade-off highlights the need to carefully balance bias reduction against precision when selecting methods for robust causal inference.
</div>

Next, we explore alternative estimands such as heterogeneous treatment effects and quantile treatment effects, which may provide deeper insights into the validity of the unconfoundedness assumption.

### Conditional average treatment effect on the treated (CATT)

CATT enables analysis of treatment effect heterogeneity across covariate-defined subpopulations. We estimate the CATT for the same samples previously considered in the ATT estimation by applying the Augmented Inverse Probability Weighting Generalized Random Forest (AIPW-GRF) method via the `catt()` function from Imbens and Xu (2024).
```{r, message=FALSE, warning=FALSE}
# estimate CATT
catt.ldw <- catt(ldw, Y, treat, covar)
catt.cps <- catt(ldw_cps, Y, treat, covar)
catt.psid <- catt(ldw_psid, Y, treat, covar)
catt.top5_cps <- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar))
catt.top5_psid <- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar))
```

```{r, message=FALSE, warning=FALSE}
# similar to Imbens & Xu (2024) 
catt.trim_cps <- catt(ldw_trim_cps, Y, treat, covar) 
catt.trim_psid <- catt(ldw_trim_psid, Y, treat, covar) 
catt.cps_trim <- catt(ldw_cps_trim, Y, treat, covar)  
catt.psid_trim <- catt(ldw_psid_trim, Y, treat, covar) 
```

Then, we employ a modified version of the function `plot_catt()` from @imbens2024 to visualize the results by plotting the estimated CATTs for all samples at the covariate values of each treated unit against their corresponding experimental benchmarks. 

<div class="callout-note">
Gray dots represent pairs of CATT estimates at covariate values of treated units, while the red crosses indicate pairs of estimated ATTs.
</div>
```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA11. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental"}
# plot results
par(mfrow = c(2,2)) 
par(cex.main = 0.9)
plot_catt(
  catt1 = catt.ldw$catt,
  catt2 = catt.cps$catt,
  att1  = catt.ldw$att[1],
  att2  = catt.cps$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (CPS1)",
  main  = "(B) LDW-CPS1", 
  axes.range = c(-8000, 8000)
)

plot_catt(
  catt1 = catt.ldw$catt,
  catt2 = catt.psid$catt,
  att1  = catt.ldw$att[1],
  att2  = catt.psid$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (PSID1)",
  main  = "(C) LDW-PSID1",
  axes.range = c(-8000, 8000)
)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA11. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental"}
# plot results
par(mfrow = c(2,2)) 
par(cex.main = 0.9)
plot_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_cps,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps)
)

plot_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_psid,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid)
)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA11. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental"}
# plot results
par(mfrow = c(2,2)) 
par(cex.main = 0.9)
plot_catt(
  catt1 <- catt.trim_cps$catt,
  catt2 <- catt.cps_trim$catt,
  att1 <- catt.trim_cps$att[1],
  att2 <- catt.cps_trim$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (CPS1-PLUS-Trimmed)",
  main  = "(N) Trimmed LDW-CPS1-PLUS", 
  axes.range = c(-8000, 8000)
)

plot_catt(
  catt1 <- catt.trim_psid$catt,
  catt2 <- catt.psid_trim$catt,
  att1 <- catt.trim_psid$att[1],
  att2 <- catt.psid_trim$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (PSID1-PLUS-Trimmed)",
  main  = "(O) Trimmed LDW-PSID1-PLUS",
  axes.range = c(-8000, 8000)
)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA12. CATT Estimates Model A using LDW Data"}
# combine all catt objects 
all_catt <- c(list(catt.ldw, catt.cps, catt.psid), 
              catt.top5_cps, catt.top5_psid, 
              list(catt.cps_trim, catt.psid_trim))

all_catt_eval <- eval_catt(all_catt, all_plot_titles)
datatable(all_catt_eval, caption = "CATT Summary Statistics",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

Specifically, with LDW-CPS1, CATT estimates span from $-4,979.99 to $7,201.81, contrasting with the CATT estimated from experimental data which ranges from $-189.40	to $3,835.95, with a mean CATT estimate of $1,713.26. The LDW-PSID1 data shows an even broader CATT estimate range, spanning from $-8,643.02 to $4,903.22, and a notably lower mean of approximately $820.77.

Among the trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary substantially. Specific samples such as `card` or `overlap_crump` subsamples produce minimum CATTs that are considerably negative, but produce positive mean estimates. Subsamples like `ps_threshold`, and `optimal_pair` also deliver positive mean CATT estimates, though with smaller negative minimums, while `mahvars` is the only method among these to produce a negative mean CATT. Importantly, across all methods, the mean CATT estimates are far away from experimental mean estimate. 

The CATT estimates for the LDW-PSID1 trimmed and top-ranked subsamples reveal substantially decreased mean values and wider extremes compared to their CPS1 counterparts, reflecting greater difficulties in producing reliable treatment effect estimates.

This variation in range and means across methods and samples reflects substantial heterogeneity in treatment effect estimation, indicating that while some criteria improve alignment with experimental benchmarks, others introduce considerable discrepancies and variability in estimated heterogeneous effects.
```{r, message=FALSE, warning=FALSE}
# save results
save_main_catt_panels(
  catt_refs = list(catt.ldw),
  catt_comps = list(catt.cps, catt.psid),
  ylabels = c("CATT (CPS1)", "CATT (PSID1)"),
  prefix = "ldw_model_a_catt_main_panels",
  main_titles = c("(B) LDW-CPS1", "(C) LDW-PSID1")
)

save_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_cps,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps),
  prefix = "ldw_model_a_catt_top5_cps"
)

save_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_psid,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid),
  prefix = "ldw_model_a_catt_top5_psid"
)

save_plus_catt_panels(
  catt1_list = list(catt.trim_cps, catt.trim_psid),
  catt2_list = list(catt.cps_trim, catt.psid_trim),
  ylabels = c("CATT (CPS1-PLUS-Trimmed)", "CATT (PSID1-PLUS-Trimmed)"),
  prefix = "ldw_model_a_catt_plus_panels",
  main_titles = c("(N) LDW-CPS1-PLUS", "(O) LDW-PSID1-PLUS")
)
```

Although the AIPW estimator can produce ATT estimates closely aligned with the experimental benchmark using LDW data, its performance for revealing the true CATT is considerably worse. 

### Quantile treatment effect on the treated (QTET)

QTET provides a robust way to analyze treatment effect heterogeneity while being less impacted by outliers compared to average treatment effect measures. The QTET estimates are obtained using the propensity score re-weighting method introduced by Firpo (2007). Implementation leverages the `qte()` function from Imbens and Xu (2024), while visualization employs a modified version of their `plot_qte()` function.
```{r, message=FALSE, warning=FALSE}
qte.ldw <- est_qte(Y, treat, covar, data = ldw, cores = 4)
qte.ldw_cps <- est_qte(Y, treat, covar, data = ldw_cps)
qte.ldw_psid <- est_qte(Y, treat, covar, data = ldw_psid)
qte.top5_cps  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, covar, data = d))
qte.top5_psid <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.trim.ldw_cps <- est_qte(Y, treat, NULL, data = ldw_trim_cps)
qte.trim.ldw_psid <- est_qte(Y, treat, NULL, data = ldw_trim_psid)
qte.ldw_cps.trim <- est_qte(Y, treat, covar, data = ldw_cps_trim) 
qte.ldw_psid.trim <- est_qte(Y, treat, covar, data = ldw_psid_trim) 
```

```{r, message=FALSE, warning=FALSE}
qte.ldw0 <- est_qte(Y, treat, NULL, data = ldw)
qte.ldw_cps0 <- est_qte(Y, treat, NULL, data = ldw_cps)
qte.ldw_psid0 <- est_qte(Y, treat, NULL, data = ldw_psid)
qte.top5_cps0  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, NULL, data = d))
qte.top5_psid0 <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.ldw_cps.trim0 <- est_qte(Y, treat, NULL, data = ldw_cps_trim)
qte.ldw_psid.trim0 <- est_qte(Y, treat, NULL, data = ldw_psid_trim)
```

Each plot displays three distinct series for every dataset analyzed: (1) The blue line with diamond-shaped points represents QTET estimates derived from the experimental sample, serving as the benchmark. (2) The red line with triangles shows QTET estimates from the observational data before any adjustment. (3) The black line with circles presents QTET estimates for the observational data after applying covariate adjustment.
```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA13. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.9)
ylim = c(-25000, 15000)
# CPS1
plot_qte(qte.ldw_cps, qte.ldw_cps0, qte.ldw, main = "(B) LDW-CPS1", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
       lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1
plot_qte(qte.ldw_psid, qte.ldw_psid0, qte.ldw, main = "(C) LDW-PSID1", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
       lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# CPS1 top methods
plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw, all_plot_titles, main_start = 4)

# PSID1 top methods
plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw, all_plot_titles, main_start = 9)

# CPS1-PLUS trimmed
plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.trim.ldw_cps, main = "(N) LDW-CPS1-PLUS (Trimmed)", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
       lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1-PLUS trimmed
plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.trim.ldw_psid, main = "(O) LDW-PSID1-PLUS (Trimmed)", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")
```

These figures display QTET estimates derived from both the experimental and various observational samples. The QTETs estimated from the original and trimmed LDW-CPS1 sample (B and D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original and trimmed LDW-PSID1 subsample (C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked LDW-CPS1-based subsamples, QTETs (F - J) continue to track the true experimental effect well, whereas LDW-PSID1-based subsamples produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty.
```{r, message=FALSE, warning=FALSE}
# list results
plots_ldw <- list(
  list(mod = qte.ldw_cps, mod0 = qte.ldw_cps0, bm = qte.ldw, 
       main = "(B) LDW-CPS1"),
  list(mod = qte.ldw_psid, mod0 = qte.ldw_psid0, bm = qte.ldw, 
       main = "(C) LDW-PSID1"),
  list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.trim.ldw_cps, 
       main = "(N) LDW-CPS1-PLUS (Trimmed)"),
  list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.trim.ldw_psid, 
       main = "(O) LDW-PSID1-PLUS (Trimmed)")
)

# save results
save_qtet(plots_ldw, prefix = "ldw_model_a")
save_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw, all_plot_titles, 
             main_start = 8, prefix = "ldw_model_a_top")
save_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw, all_plot_titles, 
             main_start = 13, prefix = "ldw_model_a_top")
```

### Assessing outcome weights (OW)
```{r, message=FALSE, warning=FALSE}
# list all datasets
all_datasets <- c(list(ldw, ldw_cps, ldw_psid), top5_datasets.cps, top5_datasets.psid, list(ldw_trim_cps, ldw_trim_psid))
```

```{r, message=FALSE, warning=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA14. Outcome Weights Model A using LDW Data"}
par(mfrow = c(2,2))
par(cex.main = 0.9)
# plot outcome weights distribution
plot_ow(ow_att, all_plot_titles) 
```

```{r, message=FALSE, warning=FALSE}
# evaluate results
res_ow <- eval_ow(ow_att, all_datasets, all_plot_titles, treat, "AIPW-ATT")
datatable(res_ow, caption = "Outcome Weights for Treated and Untreated",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

<div class="callout-caution">
The outcome weights are not obtained directly from the ATT point estimates due to computational design of other methods. Instead, the ATT is separately estimated for each dataset following the approach developed by @OW_Package.
</div>

The evaluation reveals that across each sample the estimated outcome weights sum to one within the treated group and minus one within the untreated group, resulting in an overall sum of zero.
```{r, message=FALSE, warning=FALSE}
#save results
save_ow(ow_att, all_plot_titles, prefix = "model_a")
```

## Validation through placebo analyses

To further evaluate the credibility of the unconfoundedness assumption, a placebo analysis is performed by designating 1975 earnings (re75) as the outcome variable and omitting both re75 and u75 from the list of covariates. The analysis utilizes all previously considered samples and recomputes the ATT via the function `estimate_all`, conditioning only on the remaining set of covariates.
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re75"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "re74", "u74")
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on original and observational datasets
out1_pl <- estimate_all(ldw, Y, "treat", covar)
out2_pl <- estimate_all(ldw_cps, Y, "treat", covar)
out3_pl <- estimate_all(ldw_psid, Y, "treat", covar)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on top ranked datasets
out.cps_pl <- lapply(top5_datasets.cps, function(d) estimate_all(d, Y, "treat", covar))
out.psid_pl <- lapply(top5_datasets.psid, function(d) estimate_all(d, Y, "treat", covar))

out4_pl <- out.cps_pl[[1]]
out5_pl <- out.cps_pl[[2]]
out6_pl <- out.cps_pl[[3]]
out7_pl <- out.cps_pl[[4]]
out8_pl <- out.cps_pl[[5]]

out9_pl <- out.psid_pl[[1]]
out10_pl <- out.psid_pl[[2]]
out11_pl <- out.psid_pl[[3]]
out12_pl <- out.psid_pl[[4]]
out13_pl <- out.psid_pl[[5]]
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on plus datasets
load("data/trimmed.RData")
out14_pl <- estimate_all(ldw_trim_cps_pl, Y, "treat", covar)
out15_pl <- estimate_all(ldw_trim_psid_pl, Y, "treat", covar)
out16_pl <- estimate_all(ldw_cps_trim_pl, Y, "treat", covar)
out17_pl <- estimate_all(ldw_psid_trim_pl, Y, "treat", covar)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA15. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. Placebo Test Model A: '75 Earnings as the Outcome"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))

# experimental benchmarks
band.exp_pl <- out1_pl[1, 3:4]
est.exp_pl <- out1_pl[1, 1]

# plot placebo results
plot_coef(out1_pl,  band = band.exp_pl, line = est.exp_pl, 
          ylim = c(-15500, 5500), main = "(A) LDW-Experimental")

plot_coef(out2_pl,  band = band.exp_pl, line = est.exp_pl, 
          ylim = c(-15500, 5500), main = "(B) LDW-CPS1")

plot_coef(out3_pl,  band = band.exp_pl, line = est.exp_pl,
          ylim = c(-15500, 5500), main = "(C) LDW-PSID1")

for (i in seq_along(out.cps_pl)) {
  this_title <- paste0("(", LETTERS[i+2], ") Top CPS1: ", top5_methods.cps[i])
  plot_coef(out.cps_pl[[i]], band = band.exp_pl, line = est.exp_pl,
            ylim = c(-15500, 5500), main = this_title)
}

for (i in seq_along(out.psid_pl)) {
  this_title <- paste0("(", LETTERS[i+7], ") Top PSID1: ", top5_methods.psid[i])
  plot_coef(out.psid_pl[[i]], band = band.exp_pl, line = est.exp_pl,
            ylim = c(-15500, 5500), main = this_title)
}
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA15. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. Placebo Test Model A: '75 Earnings as the Outcome"}
par(mfrow = c(4, 1))

# nonexperimtenal benchmarks
band.cps_plus_pl <- out14_pl[1, 3:4]
est.cps_plus_pl <- out14_pl[1, 1]
band.psid_plus_pl <- out15_pl[1, 3:4]
est.psid_plus_pl <- out15_pl[1, 1]

# plot results
plot_coef(out16_pl, band = band.cps_plus_pl, line = est.cps_plus_pl, 
          ylim = c(-12000, 2000), main = "(N) Trimmed LDW-CPS1-PLUS")

plot_coef(out17_pl, band = band.psid_plus_pl, line = est.psid_plus_pl, 
          ylim = c(-12000, 2000), main = "(O) Trimmed LDW-PSID1-PLUS")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(
  out_list = list(out1_pl, out2_pl, out3_pl),
  plot_titles = c("(A) LDW-Experimental", "(B) LDW-CPS1", "(C) LDW-PSID1"),
  band_list = list(band.exp_pl, band.exp_pl, band.exp_pl),
  est_list  = list(est.exp_pl, est.exp_pl, est.exp_pl),
  prefix = "ldw_model_a_pl_est_exp"
)

save_att_panels(
  out_list = out.cps_pl,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps),
  band_list = replicate(length(out.cps_pl), band.exp_pl, simplify = FALSE),
  est_list  = replicate(length(out.cps_pl), est.exp_pl, simplify = FALSE),
  prefix = "ldw_model_a_pl_est_top_cps"
)

save_att_panels(
  out_list = out.psid_pl,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid),
  band_list = replicate(length(out.psid_pl), band.exp_pl, simplify = FALSE),
  est_list  = replicate(length(out.psid_pl), est.exp_pl, simplify = FALSE),
  prefix = "ldw_model_a_pl_est_top_psid"
)

save_att_panels(
  out_list = list(out16_pl, out17_pl),
  plot_titles = c("(P) Trimmed LDW-CPS1-PLUS", "(Q) Trimmed LDW-PSID1-PLUS"),
  band_list = list(band.cps_plus_pl, band.psid_plus_pl),
  est_list  = list(est.cps_plus_pl, est.psid_plus_pl),
  prefix = "ldw_model_a_pl_est_plus",
  ylim = c(-12000, 2000)
)
```

The placebo ATT results are presented in the table below:
```{r, message=FALSE, warning=FALSE}
# print placebo results
all_outs.pl <- c(list(out1_pl, out2_pl, out3_pl), 
                 out.cps_pl, out.psid_pl, 
                 list(out16_pl, out17_pl))

result_mat_pl <- create_matrix_results(all_outs.pl, all_plot_titles)

datatable(result_mat_pl, caption = "Placebo ATT Estimates and SEs",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

The placebo analysis reveals that the experimental benchmarks are positive, near zero and statistically insignificant, while all estimators applied to the observational datasets, LDW-CPS1 and LDW-PSID1, yield by majority large, negative ATT estimates.

For LDW-CPS1, most ATT estimates are negative. The `overlap_crump` subsample shows a modest improvement toward the experimental benchmark compared to LDW-CPS1 (B) results, but also produces notably poorer estimates for certain estimators. The trimmed subsamples (D) and (I), which use similar approaches, further improve upon the LDW-CPS1 (B) results. The `optimal_pair` and `card` subsamples provide even greater improvement. The `mahvars` (G) subsample delivers ATT estimates closest to the experimental benchmark and is the only case to yield positive ATT estimates across the LDW-CPS1 samples.

For LDW-PSID1, the subsample (O) applying the `overlap_common_range` method shows no improvement compared to the LDW-PSID1 sample (C) except for the `Diff-in-Means` estimator. The `overlap_crump` subsample generally delivers ATT estimates closer to the experimental benchmark, while the `card` and `mahvars` subsamples producing estimates even closer to the experimental benchmark. The trimmed subsamples (E) and (N), which use similar approaches, achieve the closest alignment with the benchmark.

Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis reveals substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underlines the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat_pl, "ldw_att_estimates_pl_model_a")
```

## Validation through sensitivity analyses

Finally, a sensitivity analyses using the LDW data is conducted and results are depicted in contour plots using the function `sens_ana` of Imbens & Xu (2024).
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "re75", "u74", "u75")
bm <- c("re75") 
```

```{r, message=FALSE, warning=FALSE}
# check for valid datasets 
filtered_datasets_sens <- check_filter_datasets(all_datasets, Y, treat, covar, bm)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREA16. Sensitivity Analyses Model A"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = all_plot_titles[idx]) 
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, all_plot_titles, "ldw_model_a")
```

The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of `re75`. Notably, some samples such as LDW-PSID1 exhibit a greater sensitivity with more pronounced swings including negative estimates at higher confounder strengths, contrasting with consistent positive effects in LDW-CPS1 variants. This highlights sample-specific differences in robustness against potential unobserved confounding.

<div class="callout-tip">
The analyses suggest that some samples maintain stable treatment effect estimates despite increasing confounder strength, while others show greater sensitivity. This highlights the importance of assessing robustness across different samples (respectively methods used to derive specific samples) to account for potential unobserved bias.
</div>

## Inspection of re74 and re75

### Correlation 
```{r, message=FALSE, warning=FALSE}
cor_results <- sapply(all_datasets, function(d) cor(d$re74, d$re75, use = "complete.obs"))
cor_table <- data.frame(Method = all_plot_titles, Correlation = cor_results)
datatable(cor_table, caption = "Correlation between re74 and re75 across Datasets",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

### Distributional balance
```{r, message=FALSE, warning=FALSE}
bal.plot(top5_objects.cps, var.name = "re75", which = "both")
bal.plot(top5_objects.psid, var.name = "re75", which = "both")

bal.plot(top5_objects.cps, var.name = "re74", which = "both")
bal.plot(top5_objects.psid, var.name = "re74", which = "both")
```

## Summary
After reexamining model A, that is based on the LaLonde-Dehejia-Wahba (LDW) data and its augmented versions with control groups from CPS-1 and PSID-1, several insights into causal inference challenges emerge. First, we confirm that ensuring overlap between treated and control groups remains crucial for credible causal estimation. The LDW-Experimental data exhibit excellent overlap, while the observational datasets (LDW-CPS1 and LDW-PSID1) show weaker overlap, with many treated units outside the control range. Augmenting these datasets with experimental controls improves overlap but does not consistently improve covariate balance.

Second, controlling for covariates such as age, education, race, and prior earnings, and using various methods including matching, weighting, truncation, trimming, and combined approaches, largely yields consistent effects. The propensity score plays an important role in assessing overlap and balancing covariates across groups.

Third, the LDW dataset is somewhat unique in that most methods approximate the experimental benchmark well for average treatment effects on the treated (ATT), an achievement not fully replicated in the original LaLonde samples. However, placebo tests using pre-treatment earnings and sensitivity analyses reveal lingering concerns about the unconfoundedness assumption and robustness of some estimators.

Overall, this chapter highlights the importance of overlap and covariate balance, the utility of propensity scores, and the need for rigorous validation of treatment assignment assumptions to produce credible causal estimates. Despite improvements in data and methods, tests of unconfoundedness via placebo outcomes suggest caution in interpreting causal effects.