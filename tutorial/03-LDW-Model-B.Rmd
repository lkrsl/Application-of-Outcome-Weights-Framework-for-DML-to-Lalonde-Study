# LaLonde-Dehejia-Wahba (LDW) Data
This section (3) covers model B, which, similar to model A, uses 1978 earnings (`re78`) as the outcome variable but adjusts for a slightly different set of covariates: age, education, race indicators (`black`, `hispanic`), marital status, lack of a high school degree, 1975 earnings (`re75`), and unemployment status in 1974 and 1975 (`u74`, `u75`), explicitly excluding 1974 earnings (`re74`) to test the model’s robustness. The model is specified via a regression formula based on these covariates. To enhance covariate balance between treated and untreated groups, the same comprehensive suite of methods is employed as in model A, organized into five categories. From these approaches, the best five methods are selected based on a score defined by absolute standardized mean differences (SMD) and the effective sample size (ESS), and their resulting datasets are used to estimate the average treatment effect on the treated (ATT). This estimation process also incorporates the augmented inverse probability weighting (AIPW) estimator from the `OutcomeWeights` R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (`re75`) as the outcome variable to assess potential biases and the validity of the unconfoundedness assumption. Finally, sensitivity analyses are performed to evaluate the robustness of the treatment effect estimates to violations of these assumptions.

For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the model B–specific results.

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lalonde.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Inspect data
```{r, message=FALSE, warning=FALSE}
# collect datasets in a list
data <- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid)

# inspect key metrics of each dataset
summary_stats <- inspect_data(data)
knitr::kable(summary_stats, caption = "Summary Statistics")
```

### Load and preprocess data 
```{r, message=FALSE, warning=FALSE}
# assigns 1 to the experimental controls
ldw_co$treat <- 1

# merge experimental data with CPS1 data
ldw_cps_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 observations)
  ldw_cps    # CPS1 data (16177 observations)
)

# merge experimental data with PSID1 data
ldw_psid_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 observations)
  ldw_psid   # PSID1 data (2675 observations)
)

datasets <- list(ldw_cps_plus  = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus)

# inspect each dataset
summary_stats_plus <- inspect_data(datasets)
knitr::kable(summary_stats_plus, caption = "Summary Statistics")
```

## Model B
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78" 
treat <- "treat" 
covar <- c("age", "education", "black", "hispanic", "married", 
           "nodegree", "re75", "u74", "u75") #re74 excluded
```

### Assessing overlap and covariate balance
#### Overlap
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1.',out.width='100%', fig.asp=0.5}
# assess overlap
ldw.ps <- assess_overlap(data = ldw, treat = treat, cov = covar)
ldw_cps.ps <- assess_overlap(data = ldw_cps, treat = treat, cov = covar) 
ldw_psid.ps <- assess_overlap(data = ldw_psid, treat = treat, cov = covar) 
```

```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
# assess overlap
ldw_cps_plus.ps <- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) 
ldw_psid_plus.ps <- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar)
```

```{r, message=FALSE, warning=FALSE}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

#### Covariate balance
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
love.plot(ldw, ldw_cps, treat, covar = covar, title = "LDW-CPS1")
love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = "LDW-CPS1-PLUS")
love.plot(ldw, ldw_psid, treat, covar = covar, title = "LDW-PSID1")
love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = "LDW-PSID1-PLUS")
```

## Improving primarily covariate balance
### Matching 
#### Distance Matching
##### 1:1 Nearest neighbor matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with k=1, logistic propensity score and replacement
m.out.cps.nearest <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", replace = TRUE)
m.out.psid.nearest <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", replace = TRUE)
```

##### k:1 matching (k=2)
```{r, message=FALSE, warning=FALSE}
k<-2
# perform nearest neighbor matching with k=2, logistic propensity score and replacement
m.out.cps.k2 <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid.k2 <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### k:1 matching (k=3)
```{r, message=FALSE, warning=FALSE}
k<-3
# perform nearest neighbor matching with k=3, logistic propensity score and replacement
m.out.cps.k3 <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid.k3 <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### Caliper matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score 
m.out.cps.caliper <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
m.out.psid.caliper <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
```

##### Common support restriction matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with exclusion of units outside common support
m.out.cps.cs <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
m.out.psid.cs <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
```

##### Mahalanobis distance matching (mahvars) 
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching using mahalanobis distance on selected covariates
m.out.cps.mahvars <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE)
m.out.psid.mahvars <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE)
```

##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.cps.optimal_pair <- matchit(model, data = ldw_cps, method = "optimal", distance = "logit")
m.out.psid.optimal_pair <- matchit(model, data = ldw_psid, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
m.out.cps.optimal_full <- matchit(model, data = ldw_cps, method = "full", distance = "logit")
m.out.psid.optimal_full <- matchit(model, data = ldw_psid, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios 
m.out.cps.general_full <- matchit(model, data = ldw_cps, method = "quick", distance = "logit")
m.out.psid.general_full <- matchit(model, data = ldw_psid, method = "quick", distance = "logit")
```

##### Genetic matching
```{r, message=FALSE, warning=FALSE}
# perform genetic matching 
m.out.cps.genetic <- matchit(model, data = ldw_cps, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
m.out.psid.genetic <- matchit(model, data = ldw_psid, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
```

#### Stratum matching
##### Exact matching (exact)
```{r, message=FALSE, warning=FALSE}
# match units exactly by raw covariate profiles 
m.out.cps.exact <- matchit(model, data = ldw_cps, method = "exact")
m.out.psid.exact <- matchit(model, data = ldw_psid, method = "exact")
```

##### Coarsened matching (cem)
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
m.out.cps.cem <- matchit(model, data = ldw_cps, method = "cem")
m.out.psid.cem <- matchit(model, data = ldw_psid, method = "cem")
```

##### Subclassification 
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
m.out.cps.subcl <- matchit(model, data = ldw_cps, method = "subclass", subclass = 5)
m.out.psid.subcl <- matchit(model, data = ldw_psid, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units
m.out.cps.card <- matchit(model, data = ldw_cps, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
m.out.psid.card <- matchit(model, data = ldw_psid, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
# select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact
m.out.cps.profile <- matchit(model, data = ldw_cps, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs", time = 1200)
m.out.psid.profile <- matchit(model, data = ldw_psid, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs", time = 1200)
```

### Weighting
#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
#
w.out.cps.ipw <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "glm")
ldw_cps$ipw_weight <- w.out.cps.ipw$weights
w.out.psid.ipw <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "glm")
ldw_psid$ipw_weight <- w.out.psid.ipw$weights
```

#### Stable balancing weights 
```{r, message=FALSE, warning=FALSE}
#
w.out.cps.opt <- optweight::optweight(model, data = ldw_cps, estimand = "ATT")
ldw_cps$opt_weight <- w.out.cps.opt$weights
w.out.psid.opt <- optweight::optweight(model, data = ldw_psid, estimand = "ATT")
ldw_psid$opt_weight <- w.out.psid.opt$weights
```

#### Propensity score weights
```{r, message=FALSE, warning=FALSE}
w.out.cps.cbps <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "cbps")
ldw_cps$cbps_weight <- w.out.cps.cbps$weights
w.out.psid.cbps <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "cbps")
ldw_psid$cbps_weight <- w.out.psid.cbps$weights
```

#### Entropy balancing weights
```{r, message=FALSE, warning=FALSE}
#
w.out.cps.ebal <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "ebal")
ldw_cps$ebal_weight <- w.out.cps.ebal$weights
w.out.psid.ebal <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "ebal")
ldw_psid$ebal_weight <- w.out.psid.ebal$weights
```

## Improving primarily overlap
### Truncation
```{r, message=FALSE, warning=FALSE}
# list weight columns to apply truncation 
weight_columns <- c("ipw_weight", "opt_weight", "cbps_weight", "ebal_weight")
```

#### Fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum threshold
ldw_cps.fixed <- ldw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps.fixed)) {
    ldw_cps.fixed <- truncate_weights_fixed(ldw_cps.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}

ldw_psid.fixed <- ldw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid.fixed)) {
    ldw_psid.fixed <- truncate_weights_fixed(ldw_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
ldw_cps.percent <- ldw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps.percent)) {
    ldw_cps.percent <- truncate_weights_percentile(ldw_cps.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}

ldw_psid.percent <- ldw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid.percent)) {
    ldw_psid.percent <- truncate_weights_percentile(ldw_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}
```

#### Adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
# inspect variance of weights 
cps_results <- list()
psid_results <- list()

for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps)) {
    cps_results[[paste0("cps_", wcol)]] <- check_weights(ldw_cps, wcol)
  } else {
    warning(paste("Column", wcol, "not found in LDW-CPS1"))
  }
}

for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid)) {
    psid_results[[paste0("psid_", wcol)]] <- check_weights(ldw_psid, wcol)
  } else {
    warning(paste("Column", wcol, "not found in LDW-PSID1"))
  }
}

var_cps_table <- bind_rows(cps_results)
var_psid_table <- bind_rows(psid_results)

knitr::kable(var_cps_table, caption = "Variance of Weights (LDW-CPS1)")
knitr::kable(var_psid_table, caption = "Variance of Weights (LDW-PSID1)")
```

Regarding these results we can apply adaptive weight truncation to all considered weights, where it may help mitigate the influence of extreme weights. 
```{r, message=FALSE, warning=FALSE}
# truncate adaptively at mean + 3 standard deviations 
ldw_cps.adapt <- ldw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps.adapt)) {
    ldw_cps.adapt <- truncate_weights_adaptive(ldw_cps.adapt, weight_col = wcol, c = 3)
  }
}

ldw_psid.adapt <- ldw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid.adapt)) {
    ldw_psid.adapt <- truncate_weights_adaptive(ldw_psid.adapt, weight_col = wcol, c = 3)
  }
}
```

### Trimming 
#### Propensity score threshold trimming and nn matching
(Similar to tutorial of @imbens2024)
```{r, message=FALSE, warning=FALSE}
# apply trimming with thresholds 0.9 and 0.8 
ldw_cps_plus.trim <- ps_trim(ldw_cps_plus.ps, threshold = 0.9)
ldw_psid_plus.trim <- ps_trim(ldw_psid_plus.ps, threshold = 0.8)

# exclude experimental controls, subset trimmed data appropriately
ldw_cps_plus.trim.match <- subset(ldw_cps_plus.trim, sample %in% c(1,3) & ps_assoverlap)
ldw_psid_plus.trim.match <- subset(ldw_psid_plus.trim, sample %in% c(1,4) & ps_assoverlap)

# re-assign treat variable for controls in sample 3 or 4 (non-treated group)
ldw_cps_plus.trim.match$treat[ldw_cps_plus.trim.match$sample == 3] <- 0
ldw_psid_plus.trim.match$treat[ldw_psid_plus.trim.match$sample == 4] <- 0

# re-estimate propensity scores on trimmed data and perform 1:1 matching
ldw_cps_plus.trim.match <- psmatch(data = ldw_cps_plus.trim.match, Y = "re78", treat = "treat", cov = covar)
ldw_psid_plus.trim.match <- psmatch(data = ldw_psid_plus.trim.match, Y = "re78", treat = "treat", cov = covar)
```

#### Propensity score threshold trimming 
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
ldw_cps.trim <- ps_trim(ldw_cps.ps, threshold = 0.9)
ldw_psid.trim <- ps_trim(ldw_psid.ps, threshold = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.trim <- ps_estimate(data = ldw_cps.trim, Y = "re78", treat = "treat", cov = covar)
ldw_psid.trim <- ps_estimate(data = ldw_psid.trim, Y = "re78", treat = "treat", cov = covar)
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
ldw_cps.common   <- common_range_trim(ldw_cps.ps)
ldw_psid.common  <- common_range_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.common <- ps_estimate(data = ldw_cps.common, Y = "re78", treat = "treat", cov = covar)
ldw_psid.common <- ps_estimate(data = ldw_psid.common, Y = "re78", treat = "treat", cov = covar)
```

#### Crump trimming 
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
ldw_cps.crump  <- crump_trim(ldw_cps.ps, lower = 0.1, upper = 0.9)
ldw_psid.crump <- crump_trim(ldw_psid.ps, lower = 0.1, upper = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.crump <- ps_estimate(data = ldw_cps.crump, Y = "re78", treat = "treat", cov = covar)
ldw_psid.crump <- ps_estimate(data = ldw_psid.crump, Y = "re78", treat = "treat", cov = covar)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
ldw_cps.stuermer  <- stuermer_trim(ldw_cps.ps)
ldw_psid.stuermer <- stuermer_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.stuermer <- ps_estimate(data = ldw_cps.stuermer, Y = "re78", treat = "treat", cov = covar)
ldw_psid.stuermer <- ps_estimate(data = ldw_psid.stuermer, Y = "re78", treat = "treat", cov = covar)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
ldw_cps.walker   <- walker_trim(ldw_cps.ps)
ldw_psid.walker  <- walker_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.walker <- ps_estimate(data = ldw_cps.walker, Y = "re78", treat = "treat", cov = covar)
ldw_psid.walker <- ps_estimate(data = ldw_psid.walker, Y = "re78", treat = "treat", cov = covar)
```

### Integrated methods
```{r, message=FALSE, warning=FALSE}
# list trimming methods
all_trim.cps  <- list(ps_threshold = ldw_cps.trim, 
                     common_range = ldw_cps.common, 
                     stuermer = ldw_cps.stuermer, 
                     walker = ldw_cps.walker, 
                     crump = ldw_cps.crump)
all_trim.psid  <- list(ps_threshold = ldw_psid.trim, 
                     common_range = ldw_psid.common, 
                     stuermer = ldw_psid.stuermer, 
                     walker = ldw_psid.walker, 
                     crump = ldw_psid.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply inverse probability weighting (IPW) with trimming and attach IPW weights
ipw_comb.cps <- trim_attach_weights(all_trim.cps, model, "ipw_weight")
ipw_comb.psid <- trim_attach_weights(all_trim.psid, model, "ipw_weight")
```

#### Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply stable balancing with trimming and attach stable balance weights
opt_comb.cps <- trim_attach_weights(all_trim.cps, model, "opt_weight")
opt_comb.psid <- trim_attach_weights(all_trim.psid, model, "opt_weight")
```

#### Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply propensity score weighting with trimming and attach propensity score weights
cbps_comb.cps <- trim_attach_weights(all_trim.cps, model, "cbps_weight")
cbps_comb.psid <- trim_attach_weights(all_trim.psid, model, "cbps_weight")
```

#### Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
ebal_comb.cps <- trim_attach_weights(all_trim.cps, model, "ebal_weight")
ebal_comb.psid <- trim_attach_weights(all_trim.psid, model, "ebal_weight")
```

## Reassessing methods
### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching objects
all_match.cps <- list(
  nn = m.out.cps.nearest,
  k2 = m.out.cps.k2,
  k3 = m.out.cps.k3,
  caliper = m.out.cps.caliper,
  cS = m.out.cps.cs,
  mahvars = m.out.cps.mahvars,
  optimal_pair = m.out.cps.optimal_pair,
  optimal_full = m.out.cps.optimal_full,
  gen_full = m.out.cps.general_full,
  genetic = m.out.cps.genetic,
  exact = m.out.cps.exact,
  cem = m.out.cps.cem,
  card = m.out.cps.card,
  profile = m.out.cps.profile,
  subcl = m.out.cps.subcl
)

all_match.psid <- list(
  nn = m.out.psid.nearest,
  k2 = m.out.psid.k2,
  k3 = m.out.psid.k3,
  caliper = m.out.psid.caliper,
  cs = m.out.psid.cs,
  mahvars = m.out.psid.mahvars,
  optimal_pair = m.out.psid.optimal_pair,
  optimal_full = m.out.psid.optimal_full,
  gen_full = m.out.psid.general_full,
  genetic = m.out.psid.genetic,
  exact = m.out.psid.exact,
  cem = m.out.psid.cem,
  card = m.out.psid.card,
  profile = m.out.psid.profile,
  subcl = m.out.psid.subcl
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_matchit.cps <- compute_abs_smd_matchit(all_match.cps)
smd_matchit.psid <- compute_abs_smd_matchit(all_match.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# calculate balance statistics 
bal.cps <- cobalt::bal.tab(model, data = ldw_cps, un = TRUE, weights = all_match.cps, s.d.denom = "treated")
bal.psid <- cobalt::bal.tab(model, data = ldw_psid, un = TRUE, weights = all_match.psid, s.d.denom = "treated")
```

```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_matchit.cps <- compute_ess_matchit(bal.cps)
ess_matchit.psid <- compute_ess_matchit(bal.psid)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB3.'}
# visualize covariate balance 
plot_matching_balance(all_match.cps, title = "LDW-CPS1")
plot_matching_balance(all_match.psid, title = "LDW-PSID1")
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
all_weight.cps <- list(
  ipw_weight = ldw_cps$ipw_weight,
  opt_weight = ldw_cps$opt_weight,
  cbps_weight = ldw_cps$cbps_weight,
  ebal_weight = ldw_cps$ebal_weight
)

all_weight.psid <- list(
  ipw_weight = ldw_psid$ipw_weight,
  opt_weight = ldw_psid$opt_weight,
  cbps_weight = ldw_psid$cbps_weight,
  ebal_weight = ldw_psid$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_weight.cps <- compute_abs_smd_weight(ldw_cps, treat, covar, all_weight.cps)
smd_weight.psid <- compute_abs_smd_weight(ldw_psid, treat, covar, all_weight.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_weight.cps <- compute_ess_weight(ldw_cps, treat, covar, all_weight.cps)
ess_weight.psid <- compute_ess_weight(ldw_psid, treat, covar, all_weight.psid)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB4.'}
# visualize covariate balance
plot_weighting_balance(ldw_cps, treat, covar, all_weight.cps, "LDW-CPS1") 
plot_weighting_balance(ldw_psid, treat, covar, all_weight.psid, "LDW-PSID1")
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
all_trunc.cps <- list(
  fix_max_value = ldw_cps.fixed,
  at_perc = ldw_cps.percent,
  adap_weight = ldw_cps.adapt
)

all_trunc.psid <- list(
  fix_max_value = ldw_psid.fixed,
  at_perc = ldw_psid.percent,
  adap_weight = ldw_psid.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trunc.cps <- compute_abs_smd_trunc(all_trunc.cps, "treat", covar, weight_columns)
smd_trunc.psid <- compute_abs_smd_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trunc.cps <- compute_ess_trunc(all_trunc.cps, "treat", covar, weight_columns)
ess_trunc.psid <- compute_ess_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB5.'}
# visualize covariate balance
plot_trunc_balance(all_trunc.cps, "treat", covar, weight_columns, "LDW-CPS1")
plot_trunc_balance(all_trunc.psid, "treat", covar, weight_columns, "LDW-PSID1")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming objects plus original
all_trim.cps <- list(
  original = ldw_cps,
  ps_threshold = ldw_cps.trim,
  common_range = ldw_cps.common,
  crump = ldw_cps.crump,
  stuermer = ldw_cps.stuermer,
  walker = ldw_cps.walker
)

all_trim.psid <- list(
  original = ldw_psid,
  ps_threshold = ldw_psid.trim,
  common_range = ldw_psid.common,
  crump = ldw_psid.crump,
  stuermer = ldw_psid.stuermer,
  walker = ldw_psid.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMDs
smd_trim.cps <- compute_abs_smd_trim(all_trim.cps, "treat", covar)
smd_trim.psid <- compute_abs_smd_trim(all_trim.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trim.cps <- compute_ess_trim(all_trim.cps, "treat", covar)
ess_trim.psid <- compute_ess_trim(all_trim.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB6.'}
# visualize overlap
plot_trim_overlap(all_trim.cps, treat, covar, prefix = "LDW-CPS1")
plot_trim_overlap(all_trim.psid, treat, covar, prefix = "LDW-PSID1")
```

## Integrated methods
```{r, message=FALSE, warning=FALSE}
# list all combined results
comb.cps <- list(
  ipw = ipw_comb.cps,
  opt = opt_comb.cps,
  cbps = cbps_comb.cps,
  ebal = ebal_comb.cps
)

comb.psid <- list(
  ipw = ipw_comb.psid,
  opt = opt_comb.psid,
  cbps = cbps_comb.psid,
  ebal = ebal_comb.psid
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_all_comb_meth.cps <- compute_smd_all_datasets(comb.cps, "treat", covar)
smd_all_comb_meth.psid <- compute_smd_all_datasets(comb.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.cps <- compute_ess_all_datasets(comb.cps, "treat", covar)
ess_all_comb_meth.psid <- compute_ess_all_datasets(comb.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB7.'}
# visualize overlap
plot_comb_overlap(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix_cps = "LDW-CPS1", prefix_psid = "LDW-PSID1")
```

```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB8.'} 
# visualize covariate balance
plot_comb_balance(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, orig_cps = ldw_cps, orig_psid = ldw_psid, prefix_cps = "LDW-CPS1", prefix_psid = "LDW-PSID1")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_comb_hist(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix = "model_b", prefix_cps = "ldw_cps1", prefix_psid = "ldw_psid1")
save_comb_loveplots(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar,  prefix = "model_b", prefix_cps = "ldw_cps1", prefix_psid = "ldw_psid1")
```


## Identifying best methods
```{r, message=FALSE, warning=FALSE}
# combine all results
all_cps <- combine_results("cps")
all_psid <- combine_results("psid") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_cps, "ldw_model_b_cps1_all_results")
save_csv(all_psid, "ldw_model_b_psid1_all_results")
```

```{r, message=FALSE, warning=FALSE}
# rank methods 
ranked_cps  <- assess_methods(all_cps)
ranked_psid <- assess_methods(all_psid)
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
top5_methods.cps <- get_top_methods(ranked_cps, top_n = 5)
top5_methods.psid <- get_top_methods(ranked_psid, top_n = 5)

# print results
top5_methods_df.cps <- ranked_cps %>% arrange(desc(Score)) %>% head(5)
top5_methods_df.psid <- ranked_psid %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.cps, caption = "Top 5 Methods for CPS1", booktabs = TRUE)
knitr::kable(top5_methods_df.psid, caption = "Top 5 Methods for PSID1", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.cps, "ldw_model_b_cps1_top5_methods")
save_csv(top5_methods.psid, "ldw_model_b_psid1_top5_methods")
```

```{r, message=FALSE, warning=FALSE}
dataset_list_cps <- list(
  "All" = ldw_cps,
  "original" = ldw_cps,
  "nn" = m.out.cps.nearest, 
  "caliper" = m.out.cps.caliper,
  "card" = m.out.cps.card,
  "cem" = m.out.cps.cem,
  "cS" = m.out.cps.cs,
  "k2"  = m.out.cps.k2,
  "k3" = m.out.cps.k3,
  "mahvars" = m.out.cps.mahvars,
  "optimal_full" = m.out.cps.optimal_full,
  "optimal_pair" = m.out.cps.optimal_pair,
  "gen_full" = m.out.cps.general_full,
  "genetic" = m.out.cps.genetic,
  "exact" = m.out.cps.exact,
  "subcl" = m.out.cps.subcl,
  "profile"  = m.out.cps.profile,
  "ipw_weight" = ldw_cps$ipw_weight, 
  "opt_weight" = ldw_cps$opt_weight,
  "cbps_weight" = ldw_cps$cbps_weight,
  "ebal_weight" = ldw_cps$ebal_weight,
  "fix_max_value_ipw_weight" = ldw_cps.fixed$ipw_weight,
  "fix_max_value_opt_weight" = ldw_cps.fixed$opt_weight,
  "fix_max_value_cbps_weight" = ldw_cps.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = ldw_cps.fixed$ebal_weight,
  "at_perc_ipw_weight" = ldw_cps.percent$ipw_weight,
  "at_perc_opt_weight" = ldw_cps.percent$opt_weight,
  "at_perc_cbps_weight" = ldw_cps.percent$cbps_weight,
  "at_perc_ebal_weight" = ldw_cps.percent$ebal_weight,
  "adap_weight_ipw_weight" = ldw_cps.adapt$ipw_weight,
  "adap_weight_opt_weight" = ldw_cps.adapt$opt_weight,
  "adap_weight_cbps_weight" = ldw_cps.adapt$cbps_weight,
  "adap_weight_ebal_weight" = ldw_cps.adapt$ebal_weight,
  "ps_threshold" = ldw_cps.trim,
  "common_range" = ldw_cps.common,
  "stuermer" = ldw_cps.stuermer,
  "walker" = ldw_cps.walker,
  "crump" = ldw_cps.crump,
  "ipw_common_range" = ipw_comb.cps[[1]],
  "ipw_crump"= ipw_comb.cps[[2]],
  "ipw_ps_threshold"= ipw_comb.cps[[3]],
  "ipw_stuermer"= ipw_comb.cps[[4]],
  "ipw_walker" = ipw_comb.cps[[5]],
  "opt_common_range" = opt_comb.cps[[1]],
  "opt_crump" = opt_comb.cps[[2]],
  "opt_ps_threshold" = opt_comb.cps[[3]],
  "opt_stuermer" = opt_comb.cps[[4]],
  "opt_walker" = opt_comb.cps[[5]],
  "cbps_common_range" = cbps_comb.cps[[1]],
  "cbps_crump" = cbps_comb.cps[[2]],
  "cbps_ps_threshold"  = cbps_comb.cps[[3]],
  "cbps_stuermer" = cbps_comb.cps[[4]],
  "cbps_walker"= cbps_comb.cps[[5]],
  "ebal_common_range" = ebal_comb.cps[[1]],
  "ebal_crump" = ebal_comb.cps[[2]],
  "ebal_ps_threshold" = ebal_comb.cps[[3]],
  "ebal_stuermer" = ebal_comb.cps[[4]],
  "ebal_walker" = ebal_comb.cps[[5]])

dataset_list_psid <- list(
  "All" = ldw_psid,
  "original" = ldw_psid,
  "nn" = m.out.psid.nearest, 
  "caliper" = m.out.psid.caliper,
  "card" = m.out.psid.card,
  "cem" = m.out.psid.cem,
  "cS" = m.out.psid.cs,
  "k2"  = m.out.psid.k2,
  "k3" = m.out.psid.k3,
  "mahvars" = m.out.psid.mahvars,
  "optimal_full" = m.out.psid.optimal_full,
  "optimal_pair" = m.out.psid.optimal_pair,
  "gen_full" = m.out.psid.general_full,
  "genetic" = m.out.psid.genetic,
  "exact" = m.out.psid.exact,
  "subcl" = m.out.psid.subcl,
  "profile"  = m.out.psid.profile,
  "ipw_weight" = ldw_psid$ipw_weight, 
  "opt_weight" = ldw_psid$opt_weight,
  "cbps_weight" = ldw_psid$cbps_weight,
  "ebal_weight" = ldw_psid$ebal_weight,
  "fix_max_value_ipw_weight" = ldw_psid.fixed$ipw_weight,
  "fix_max_value_opt_weight" = ldw_psid.fixed$opt_weight,
  "fix_max_value_cbps_weight" = ldw_psid.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = ldw_psid.fixed$ebal_weight,
  "at_perc_ipw_weight" = ldw_psid.percent$ipw_weight,
  "at_perc_opt_weight" = ldw_psid.percent$opt_weight,
  "at_perc_cbps_weight" = ldw_psid.percent$cbps_weight,
  "at_perc_ebal_weight" = ldw_psid.percent$ebal_weight,
  "adap_weight_ipw_weight" = ldw_psid.adapt$ipw_weight,
  "adap_weight_opt_weight" = ldw_psid.adapt$opt_weight,
  "adap_weight_cbps_weight" = ldw_psid.adapt$cbps_weight,
  "adap_weight_ebal_weight" = ldw_psid.adapt$ebal_weight,
  "ps_threshold" = ldw_psid.trim,
  "common_range" = ldw_psid.common,
  "stuermer" = ldw_psid.stuermer,
  "walker" = ldw_psid.walker,
  "crump" = ldw_psid.crump,
  "ipw_common_range" = ipw_comb.psid[[1]],
  "ipw_crump"= ipw_comb.psid[[2]],
  "ipw_ps_threshold"= ipw_comb.psid[[3]],
  "ipw_stuermer"= ipw_comb.psid[[4]],
  "ipw_walker" = ipw_comb.psid[[5]],
  "opt_common_range" = opt_comb.psid[[1]],
  "opt_crump" = opt_comb.psid[[2]],
  "opt_ps_threshold" = opt_comb.psid[[3]],
  "opt_stuermer" = opt_comb.psid[[4]],
  "opt_walker" = opt_comb.psid[[5]],
  "cbps_common_range" = cbps_comb.psid[[1]],
  "cbps_crump" = cbps_comb.psid[[2]],
  "cbps_ps_threshold"  = cbps_comb.psid[[3]],
  "cbps_stuermer" = cbps_comb.psid[[4]],
  "cbps_walker"= cbps_comb.psid[[5]],
  "ebal_common_range" = ebal_comb.psid[[1]],
  "ebal_crump" = ebal_comb.psid[[2]],
  "ebal_ps_threshold" = ebal_comb.psid[[3]],
  "ebal_stuermer" = ebal_comb.psid[[4]],
  "ebal_walker" = ebal_comb.psid[[5]])
```

```{r, message=FALSE, warning=FALSE}
# create datasets corresponding to the top 5 methods for each dataset
top5_datasets.cps <- create_top5_datasets(dataset_list_cps, top5_methods.cps)
top5_datasets.psid <- create_top5_datasets(dataset_list_psid, top5_methods.psid)
```

```{r, message=FALSE, warning=FALSE}
# save datasets into .RData files
save_top5_individual_files(dataset_list_cps, top5_methods.cps, prefix = "ldw_model_b_cps1")
save_top5_individual_files(dataset_list_psid, top5_methods.psid, prefix = "ldw_model_b_psid1")
```

## Estimating
### Average treatment effect on the treated (ATT)
```{r, message=FALSE, warning=FALSE}
# estimate ATT
out1 <- estimate_all(ldw, "re78", "treat", covar)
out2 <- estimate_all(ldw_cps, "re78", "treat", covar)
out3 <- estimate_all(ldw_psid, "re78", "treat", covar)
out4 <- estimate_all(ldw_cps_plus.trim, "re78", "treat", covar) 
out5 <- estimate_all(ldw_psid_plus.trim, "re78", "treat", covar)
out6 <- estimate_all(ldw_cps.trim, "re78", "treat", covar) 
out7 <- estimate_all(ldw_psid.trim, "re78", "treat", covar)

out.cps <- lapply(top5_datasets.cps, function(d) estimate_all(d, "re78", "treat", covar))
out.psid <- lapply(top5_datasets.psid, function(d) estimate_all(d, "re78", "treat", covar))

out8 <- out.cps[[1]]
out9 <- out.cps[[2]]
out10 <- out.cps[[3]]
out11 <- out.cps[[4]]
out12 <- out.cps[[5]]

out13 <- out.psid[[1]]
out14 <- out.psid[[2]]
out15 <- out.psid[[3]]
out16 <- out.psid[[4]]
out17 <- out.psid[[5]]
```

```{r, message=FALSE, warning=FALSE}
# build plot titles 
base_titles <- c("(A) LDW-Experimental", "(B) LDW-CPS1" , "(C) LDW-PSID1", "(D) Trimmed LDW-CPS1 ", "(E) Trimmed LDW-PSID1", "(F) Trimmed LDW-CPS1-PLUS ", "(G) Trimmed LDW-PSID1-PLUS")
top_start <- 8 # H is 8th letter
num_cps <- length(top5_methods.cps)
num_psid <- length(top5_methods.psid)
top_letters_cps <- LETTERS[top_start:(top_start + num_cps - 1)]
top_letters_psid <- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)]
top5_titles.cps <- paste0("(", top_letters_cps, ") Top CPS1: ", top5_methods.cps)
top5_titles.psid <- paste0("(", top_letters_psid, ") Top PSID1: ", top5_methods.psid)
plot_titles <- c(base_titles, top5_titles.cps, top5_titles.psid)

# combine all results
all_outs <- c(list(out1, out2, out3, out4, out5, out6, out7), out.cps, out.psid)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB9. ATT Estimates Model B Given Unconfoundedness using LDW Samples"}
# plot results
band <- out1[1, 3:4]
est  <- out1[1, 1]
plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs, plot_titles, band, est, "ldw_model_b")
```

As in model A, the above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, trimmed versions of the LDW-CPS1 and LDW-PSID1 samples (analogous to @imbens2024) and a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria. 

Again, figure (A) presents the benchmark, serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the LDW-CPS1 and LDW-PSID1y, while figures (D) and (E) present those for the trimmed versions. Figures (F) through (J) display results for CPS1-derived subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-derived subsamples under parallel rules.

For LDW-CPS1, the top-ranked subsamples are derived with the same methods as in model A, though they appear in a slightly different order. However, for the LDW-PSID1, the top-ranked subsamples are based on two different methods, `fix_max_value_trunc_overlap_weight` and `overlap_weight`.

Across the LDW-CPS1 and its top-ranked samples, all estimators generally yield ATT estimates that cluster near the experimental benchmark, overall slightly closer than in model A but with greater standard errors. Notable deviations from the experimental benchmark remain for the `optimal_pair` and `overlap_crump` subsamples.

For LDW-PSID1 and its subsamples, the ATT estimates continue to exhibit greater dispersion and considerably larger standard errors compared to LDW-CPS1 counterpart samples, yet they lie closer to the benchmark than in model A.
```{r, message=FALSE, warning=FALSE}
# prepare all results in the order shown in the plots
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- plot_titles
knitr::kable(att_summary, caption = "ATT Summary Statistics", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# get result matrix
result_mat <- create_matrix_results(all_outs, plot_titles)
knitr::kable(result_mat, booktabs = TRUE, caption = "ATT Estimates and SEs") %>% kable_styling(full_width = TRUE) 
```

As in model A, the tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. 

In model B, most LDW-CPS1-based samples yield ATT estimates that are closer to the experimental benchmark than in model A, with still modest variance. By contrast, the LDW-PSID1-based estimates, while somewhat closer to the experimental benchmark than in model A, continue to exhibit substantially larger standard errors compared to LDW-CPS1 samples. This again reflects the greater challenge of obtaining reliable estimates from the observational dataset LDW-PSID1.

Overall, figures and table jointly demonstrate again that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "ldw_att_estimates_model_b")
```

### Conditional average treatment effect on the treated (CATT)
```{r, message=FALSE, warning=FALSE}
# estimate CATT
catt.ldw <- catt(ldw, Y, treat, covar)
catt.cps <- catt(ldw_cps, Y, treat, covar)
catt.psid <- catt(ldw_psid, Y, treat, covar)
catt.cps.trim <- catt(ldw_cps.trim, Y, treat, covar)
catt.psid.trim <- catt(ldw_psid.trim, Y, treat, covar)
catt.cps_plus.trim <- catt(ldw_cps_plus.trim, Y, treat, covar) # similar to Imbens & Xu (2024)
catt.psid_plus.trim <- catt(ldw_psid_plus.trim, Y, treat, covar) # similar to Imbens & Xu (2024)
```

```{r, message=FALSE, warning=FALSE}
catt.top5_cps <- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar))
catt.top5_psid <- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar))
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB10. CATT Estimates Model B using LDW Data"}
# combine all catt objects 
all_catt <- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim, catt.cps_plus.trim, catt.psid_plus.trim), catt.top5_cps, catt.top5_psid)

# plot results
par(mfrow = c(2,2))
par(cex.main = 0.9)
plot_catt_panels(all_catt, plot_titles)
```

```{r, message=FALSE, warning=FALSE}
all_catt_eval <- eval_catt(all_catt, plot_titles)
knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

In model B, using LDW-CPS1, the CATT estimates range from $-3,868.54 to $7,128.42. This span is considerably narrower than in model A, but still performs worse when contrasted with the experimental benchmark, where CATT estimates range from $-213.93 to $3,858.52 with a mean of $1,720.13. The experimental mean CATT estimate remains closer to its corresponding ATT estimate than in model A. Further, LDW-PSID1 shows a narrower CATT estimate range, from $-6,772.16 to	$5,032.31, compared to LDW-CPS1 and model A, with a mean CATT estimate of about $557.39, which deviates further from the experimental benchmark, indicating poorer performance.

For trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary considerably, yet the mean estimates are generally closer to the experimental benchmark, as in model A. Moreover, the minimum CATT estimates are less negative, which reduces the spread between minimum and maximum estimates.

Top-ranked LDW-PSID1 subsamples, on the other hand, again yield more negative mean CATT estimates and wider ranges compared to their LDW-CPS1 counterparts, signaling persistent difficulties in generating reliable effect estimates. Still, compared to model A, the minimum CATT estimates are less strongly negative, though the mean CATTs only improve marginally in their proximity to the experimental benchmark.

Hence, alike model A, these results show that the variation in ranges and means across methods and samples reflects substantial heterogeneity in treatment effect estimation. While certain criteria may improve consistency with experimental benchmarks, they may also introduce notable discrepancies and variability in estimated heterogeneous effects. 
```{r, message=FALSE, warning=FALSE}
# save results
save_catt_panels(all_catt, plot_titles, prefix = "model_b")
```

### Quantile treatment effect on the treated (QTET)
```{r, message=FALSE, warning=FALSE}
qte.ldw <- est_qte(Y, treat, covar, data = ldw, cores = 4)
```

```{r, message=FALSE, warning=FALSE}
qte.ldw_cps <- est_qte(Y, treat, covar, data = ldw_cps)
qte.ldw_psid <- est_qte(Y, treat, covar, data = ldw_psid)
qte.ldw_cps_plus <- est_qte(Y, treat, covar, data = ldw_cps_plus)
qte.ldw_psid_plus <- est_qte(Y, treat, covar, data = ldw_psid_plus)
qte.ldw_cps.trim <- est_qte(Y, treat, covar, data = ldw_cps.trim)
qte.ldw_psid.trim <- est_qte(Y, treat, covar, data = ldw_psid.trim) 
qte.ldw_cps_plus.trim <- est_qte(Y, treat, covar, data = ldw_cps_plus.trim)
qte.ldw_psid_plus.trim <- est_qte(Y, treat, covar, data = ldw_psid_plus.trim) 
```

```{r, message=FALSE, warning=FALSE}
qte.top5_cps  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, covar, data = d))
qte.top5_psid <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.ldw0 <- est_qte(Y, treat, NULL, data = ldw)
qte.ldw.cps0 <- est_qte(Y, treat, NULL, data = ldw_cps)
qte.ldw.psid0 <- est_qte(Y, treat, NULL, data = ldw_psid)
qte.ldw_cps.trim0 <- est_qte(Y, treat, NULL, data = ldw_cps.trim)
qte.ldw_psid.trim0 <- est_qte(Y, treat, NULL, data = ldw_psid.trim)
qte.ldw_cps_plus.trim0 <- est_qte(Y, treat, NULL, data = ldw_cps_plus.trim)
qte.ldw_psid_plus.trim0 <- est_qte(Y, treat, NULL, data = ldw_psid_plus.trim)
qte.top5_cps0  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, NULL, data = d))
qte.top5_psid0 <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB11. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.8)

# CPS1
plot_qte(qte.ldw_cps, qte.ldw.cps0, qte.ldw, main = "(B) LDW-CPS1", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1
plot_qte(qte.ldw_psid, qte.ldw.psid0, qte.ldw, main = "(C) LDW-PSID1", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

## CPS1 trimmed
plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.ldw_cps, main = "(D) LDW-CPS1 (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1 trimmed
plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.ldw_psid, main = "(E) LDW-PSID1 (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

## CPS1-PLUS trimmed
plot_qte(qte.ldw_cps_plus.trim, qte.ldw_cps_plus.trim0, qte.ldw_cps_plus, main = "(F) LDW-CPS1-PLUS (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1-PLUS trimmed
plot_qte(qte.ldw_psid_plus.trim, qte.ldw_psid_plus.trim0, qte.ldw_psid_plus, main = "(G) LDW-PSID1-PLUS (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# CPS1 top methods
plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000))

# PSID1 top methods
plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000))
```

These figures display QTET estimates derived from both the experimental and various non-experimental samples. Compared to model A, the QTET results of all samples closely resemble those of their respective counterparts. The QTETs estimated from the original and trimmed LDW-CPS1 sample continue to correspond well with the true QTET, although the estimates often suffer from low power. The QTET estimates from the original and trimmed LDW-PSID1 subsample show clear biases when compared to the experimental benchmark, which clusters near zero. The QTET estimates derived from the top-ranked subsamples of LDW-CPS1 (F - J) track the true experimental effect well. In contrast, the top-ranked subsamples of LDW-PSID1-based produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty.
```{r, message=FALSE, warning=FALSE}
# list results
plots_ldw <- list(
  list(mod = qte.ldw_cps, mod0 = qte.ldw.cps0, bm = qte.ldw, main = "(B) LDW CPS1"),
  list(mod = qte.ldw_psid, mod0 = qte.ldw.psid0, bm = qte.ldw, main = "(C) LDW PSID1"),
  list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.ldw_cps, main = "(D) LDW CPS1 (Trimmed)"),
  list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.ldw_psid, main = "(E) LDW PSID1 (Trimmed)"),
  list(mod = qte.ldw_cps_plus.trim, mod0 = qte.ldw_cps_plus.trim0, bm = qte.ldw_cps_plus, main = "(F) LDW CPS1-PLUS (Trimmed)"),
  list(mod = qte.ldw_psid_plus.trim, mod0 = qte.ldw_psid_plus.trim0, bm = qte.ldw_psid_plus, main = "(G) LDW PSID1-PLUS (Trimmed)")
)

# save results
save_qtet(plots_ldw, prefix = "ldw_model_b", ylim = c(-25000, 15000))
save_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000), prefix = "ldw_model_b_top")
save_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000), prefix = "ldw_model_b_top")
```

### Assessing outcome weights (OW)
```{r, message=FALSE, warning=FALSE}
# list all datasets
all_datasets <- c(list(ldw, ldw_cps, ldw_psid, ldw_cps.trim, ldw_psid.trim, ldw_cps_plus.trim.match, ldw_psid_plus.trim.match), top5_datasets.cps, top5_datasets.psid)
```

```{r, message=FALSE, warning=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB12. Outcome Weights Model B using LDW Data"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# plot outcome weights distribution
plot_ow(ow_att, plot_titles) 
```

```{r, message=FALSE, warning=FALSE}
# evaluate results
res_ow <- eval_ow(ow_att, all_datasets, plot_titles, treat, "AIPW-ATT")
knitr::kable(res_ow, caption = "Outcome Weights for Treated and Untreated", booktabs = TRUE) 
```

```{r, message=FALSE, warning=FALSE}
#save results
save_ow(ow_att, plot_titles, prefix = "model_b")
```

In model B, the evaluation once again confirms that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero.

## Validation through placebo analyses
```{r, message=FALSE, warning=FALSE}
# define variables
Y_pl <- "re75"
treat <- "treat"
covar_pl <- c("age", "education", "black", "hispanic", "married", "nodegree", "re74", "u74")
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on original and observational datasets
out1_pl <- estimate_all(ldw, Y_pl, "treat", covar_pl)
out2_pl <- estimate_all(ldw_cps, Y_pl, "treat", covar_pl)
out3_pl <- estimate_all(ldw_psid, Y_pl, "treat", covar_pl)
out4_pl <- estimate_all(ldw_cps_plus.trim, Y_pl, "treat", covar_pl)
out5_pl <- estimate_all(ldw_psid_plus.trim, Y_pl, "treat", covar_pl)
out6_pl <- estimate_all(ldw_cps.trim, Y_pl, "treat", covar_pl) 
out7_pl <- estimate_all(ldw_psid.trim, Y_pl, "treat", covar_pl)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on top ranked datasets
out.cps_pl <- lapply(top5_datasets.cps, function(d) estimate_all(d, Y_pl, "treat", covar_pl))
out.psid_pl <- lapply(top5_datasets.psid, function(d) estimate_all(d, Y_pl, "treat", covar_pl))

out8 <- out.cps_pl[[1]]
out9 <- out.cps_pl[[2]]
out10 <- out.cps_pl[[3]]
out11 <- out.cps_pl[[4]]
out12 <- out.cps_pl[[5]]

out13 <- out.psid_pl[[1]]
out14 <- out.psid_pl[[2]]
out15 <- out.psid_pl[[3]]
out16 <- out.psid_pl[[4]]
out17 <- out.psid_pl[[5]]
```

```{r, message=FALSE, warning=FALSE}
# collect all placebo results 
all_outs.pl <- c(list(out1_pl, out2_pl, out3_pl, out4_pl, out5_pl, out6_pl, out7_pl), out.cps_pl, out.psid_pl)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB13. Placebo Test Model B: '75 Earnings as the Outcome"}
# plot placebo results
band_pl <- out1_pl[1, 3:4]
est_pl  <- out1_pl[1, 1]
ylim_pl = c(-15500, 5500)
plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, "ldw_model_b_placebo")
```

```{r, message=FALSE, warning=FALSE}
# print placebo results
result_mat_pl <- create_matrix_results(all_outs.pl, plot_titles)
knitr::kable(result_mat_pl, booktabs = TRUE, caption = "Placebo ATT Estimates and SEs") %>% kable_styling(full_width = TRUE) 
```

The placebo analysis shows that the experimental benchmarks remain close to zero and statistically insignificant, closely mirroring the results in model A. The results for LDW-CPS1 and LDW-PSID1 are identical to those observed in model A.

For LDW-CPS1 samples (B and F through J), ATT estimates remain consistently negative. The `overlap_crump` estimates show modest improvement toward the benchmark compared to LDW-CPS1 (B) results, but also yields notably worse estimates for certain estimators. Further gains are observed with the trimmed sample (D), `ps_threshold` (I), `card` (G) and `optimal_pair`. The `mahvars` (G) sample performs best, producing ATT estimates closest to the experimental results. However, compared to model A, no clear pattern emerges: some methods perform better, while others produce poorer estimates.

For LDW-PSID1, the sample (O) applying `fix_max_value_truncation_overlap_weight` shows some improvement relative to the PSID1 sample (C), though it also produces worse results for certain estimators. A similar pattern holds for the `overlap_weight` sample. The `card` (K), `mahvars` (L), trimmed sample (E) and the`ps_threshold` (M) further reduce discrepancies, drawing estimates closer to the experimental benchmark results. Still, their performance not markedly surpass that of model A. 

Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis continues to reveal substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underscores the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat_pl, "ldw_att_estimates_pl_model_b")
```

## Validation through sensitivity analyses
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "re75", "u74", "u75")
bm <- c("re75") 
```

```{r, message=FALSE, warning=FALSE}
# check for valid datasets 
filtered_datasets_sens <- check_filter_datasets(all_datasets, Y, treat, covar, bm)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB14. Sensitivity Analyses Model B"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = plot_titles[idx])
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, "ldw_model_b")
```

The sensitivity analysis demonstrates identical results for LDW-Experimental, LDW-CPS1 and LDW-PSID1 as in model A and indicates once again that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of `re75`. However, compared to Model A, these estimates tend to shift upwards, exhibiting somewhat more positive values across variants. 

## Summary
After reexamining model B, which uses the LaLonde-Dehejia-Wahba (LDW) data with a revised set of covariates, we find that changing the covariate set leads to noticeable shifts in effect estimates. For CPS-1, estimates are generally more consistent and remain close to the experimental benchmark, though standard errors are somewhat larger than in model A. In contrast, PSID-1 continues to show greater dispersion and substantially larger standard errors, highlighting persistent challenges with this observational sample.

Conditional and quantile treatment effect analyses confirm that, while some methods bring estimates closer to the experimental benchmark, considerable heterogeneity and estimator-dependent variability remain. Placebo tests using pre-treatment earnings as the outcome reveal that, despite some improvements, bias and deviation from the true effect persist. Sensitivity analyses indicate that most treatment effect estimates are fairly robust to increasing confounder strength, but some upward shifts are observed compared to model A.

Overall, these results reinforce the importance of overlap, covariate balance, and careful method selection, while underscoring the ongoing difficulty of recovering unbiased causal effects from observational data.