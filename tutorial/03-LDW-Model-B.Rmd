# LaLonde-Dehejia-Wahba (LDW) Data
This section (3) covers model B, which, similar to model A, uses 1978 earnings (`re78`) as the outcome variable but adjusts for a slightly different set of covariates: age, education, race indicators (`black`, `hispanic`), marital status, lack of a high school degree, 1975 earnings (`re75`), and unemployment status in 1974 and 1975 (`u74`, `u75`), explicitly excluding 1974 earnings (`re74`) to test the model’s robustness. The model is specified via a regression formula based on these covariates. To enhance covariate balance between treated and untreated groups, the same comprehensive suite of methods is employed as in model A, organized into five categories. From these approaches, the best five methods are selected based on a score defined by absolute standardized mean differences (SMD) and the effective sample size (ESS), and their resulting datasets are used to estimate the average treatment effect on the treated (ATT). This estimation process also incorporates the augmented inverse probability weighting (AIPW) estimator from the `OutcomeWeights` R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (`re75`) as the outcome variable to assess potential biases and the validity of the unconfoundedness assumption. Finally, sensitivity analyses are performed to evaluate the robustness of the treatment effect estimates to violations of these assumptions.

For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the model B–specific results.

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lalonde.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Inspect data
```{r, message=FALSE, warning=FALSE}
# collect datasets in a list
data <- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid)

# inspect key metrics of each dataset
summary_stats <- inspect_data(data)
knitr::kable(summary_stats, caption = "Summary Statistics")
```

### Load and preprocess data 
```{r, message=FALSE, warning=FALSE}
# assigns 1 to the experimental controls
ldw_co$treat <- 1

# merge experimental data with CPS1 data
ldw_cps_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 observations)
  ldw_cps    # CPS1 data (16177 observations)
)

# merge experimental data with PSID1 data
ldw_psid_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 observations)
  ldw_psid   # PSID1 data (2675 observations)
)

datasets <- list(ldw_cps_plus  = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus)

# inspect each dataset
summary_stats_plus <- inspect_data(datasets)
knitr::kable(summary_stats_plus, caption = "Summary Statistics")
```

## Model B
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78" 
treat <- "treat" 
covar <- c("age", "education", "black", "hispanic", "married", 
           "nodegree", "re75", "u74", "u75") #re74 excluded
```

### Assessing overlap and covariate balance
#### Overlap
```{r, fig.cap='FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1.',out.width='100%', fig.asp=0.5}
ldw.ps <- assess_overlap(data = ldw, treat = treat, cov = covar)
ldw_cps.ps <- assess_overlap(data = ldw_cps, treat = treat, cov = covar) 
ldw_psid.ps <- assess_overlap(data = ldw_psid, treat = treat, cov = covar) 
```

```{r, fig.cap='FIGUREB1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
ldw_cps_plus.ps <- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) 
ldw_psid_plus.ps <- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar)
```

```{r, message=FALSE, warning=FALSE}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

#### Covariate balance
```{r, warning=FALSE, message=FALSE, fig.cap='FIGUREB2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
love.plot(ldw, ldw_cps, treat, covar = covar, title = "LDW-CPS1")
love.plot(ldw, ldw_psid, treat, covar = covar, title = "LDW-PSID1")
love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = "LDW-CPS1-PLUS")
love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = "LDW-PSID1-PLUS")
```

## Improving primarily covariate balance
### Matching 
#### Distance Matching
##### 1:1 Nearest neighbor matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with k=1, logistic propensity score and replacement
m.out.cps.nearest <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", replace = TRUE)
m.out.psid.nearest <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", replace = TRUE)
```

##### k:1 matching (k=2)
```{r, message=FALSE, warning=FALSE}
k<-2
# perform nearest neighbor matching with k=2, logistic propensity score and replacement
m.out.cps.k2 <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid.k2 <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### k:1 matching (k=3)
```{r, message=FALSE, warning=FALSE}
k<-3
# perform nearest neighbor matching with k=3, logistic propensity score and replacement
m.out.cps.k3 <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid.k3 <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### Caliper matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score 
m.out.cps.caliper <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
m.out.psid.caliper <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
```

##### Common support restriction matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with exclusion of units outside common support
m.out.cps.cs <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", discard = "both", reestimate = TRUE, replace = TRUE)
m.out.psid.cs <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", discard = "both", reestimate = TRUE, replace = TRUE)
```

##### Mahalanobis distance matching (mahvars) 
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching using mahalanobis distance on selected covariates
m.out.cps.mahvars <- matchit(model, data = ldw_cps, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE)
m.out.psid.mahvars <- matchit(model, data = ldw_psid, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE)
```

##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.cps.optimal_pair <- matchit(model, data = ldw_cps, method = "optimal", distance = "logit")
m.out.psid.optimal_pair <- matchit(model, data = ldw_psid, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
m.out.cps.optimal_full <- matchit(model, data = ldw_cps, method = "full", distance = "logit")
m.out.psid.optimal_full <- matchit(model, data = ldw_psid, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios 
m.out.cps.general_full <- matchit(model, data = ldw_cps, method = "quick", distance = "logit")
m.out.psid.general_full <- matchit(model, data = ldw_psid, method = "quick", distance = "logit")
```

##### Genetic matching
```{r, message=FALSE, warning=FALSE}
# perform genetic matching 
m.out.cps.genetic <- matchit(model, data = ldw_cps, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
m.out.psid.genetic <- matchit(model, data = ldw_psid, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
```

#### Stratum matching
##### Exact matching (exact)
Strata = unique covariate profiles (raw covariates)
```{r, message=FALSE, warning=FALSE}
# match units exactly by raw covariate profiles 
m.out.cps.exact <- matchit(model, data = ldw_cps, method = "exact")
m.out.psid.exact <- matchit(model, data = ldw_psid, method = "exact")
```

##### Coarsened matching (cem)
Strata = coarsened versions of covariates
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
m.out.cps.cem <- matchit(model, data = ldw_cps, method = "cem")
m.out.psid.cem <- matchit(model, data = ldw_psid, method = "cem")
```

##### Subclassification 
Strata = bins of the propensity score
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
m.out.cps.subcl <- matchit(model, data = ldw_cps, method = "subclass", subclass = 5)
m.out.psid.subcl <- matchit(model, data = ldw_psid, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units
m.out.cps.card <- matchit(model, data = ldw_cps, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
m.out.psid.card <- matchit(model, data = ldw_psid, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
# select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact
m.out.cps.profile <- matchit(model, data = ldw_cps, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs", time = 1200)
m.out.psid.profile <- matchit(model, data = ldw_psid, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs", time = 1200)
```

### Weighting
#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores with a parametric generalized linear model and converts them into weights
w.out.cps.ipw <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "glm")
ldw_cps$ipw_weight <- w.out.cps.ipw$weights
w.out.psid.ipw <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "glm")
ldw_psid$ipw_weight <- w.out.psid.ipw$weights
```

#### Stable balancing weights 
```{r, message=FALSE, warning=FALSE}
# estimates weights by solving a quadratic programming problem 
w.out.cps.opt <- optweight::optweight(model, data = ldw_cps, estimand = "ATT")
ldw_cps$opt_weight <- w.out.cps.opt$weights
w.out.psid.opt <- optweight::optweight(model, data = ldw_psid, estimand = "ATT")
ldw_psid$opt_weight <- w.out.psid.opt$weights
```

#### Covariate balance propensity score weights
```{r, message=FALSE, warning=FALSE}
# estimates propensity scores using generalized method of moments and then converts them into weights
w.out.cps.cbps <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "cbps")
ldw_cps$cbps_weight <- w.out.cps.cbps$weights
w.out.psid.cbps <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "cbps")
ldw_psid$cbps_weight <- w.out.psid.cbps$weights
```

#### Entropy balancing weights
```{r, message=FALSE, warning=FALSE}
# estimates weights by minimizing the negative entropy of the weights subject to exact moment balancing constraints
w.out.cps.ebal <- WeightIt::weightit(model, data = ldw_cps, estimand = "ATT", method = "ebal")
ldw_cps$ebal_weight <- w.out.cps.ebal$weights
w.out.psid.ebal <- WeightIt::weightit(model, data = ldw_psid, estimand = "ATT", method = "ebal")
ldw_psid$ebal_weight <- w.out.psid.ebal$weights
```

## Improving primarily overlap
### Truncation
```{r, message=FALSE, warning=FALSE}
# list weight columns to apply truncation 
weight_columns <- c("ipw_weight", "opt_weight", "cbps_weight", "ebal_weight")
```

#### Fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum threshold
ldw_cps.fixed <- ldw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps.fixed)) {
    ldw_cps.fixed <- truncate_weights_fixed(ldw_cps.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}

ldw_psid.fixed <- ldw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid.fixed)) {
    ldw_psid.fixed <- truncate_weights_fixed(ldw_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
ldw_cps.percent <- ldw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps.percent)) {
    ldw_cps.percent <- truncate_weights_percentile(ldw_cps.percent, weight_col = wcol, lower = 0.05, upper = 0.95)
  }
}

ldw_psid.percent <- ldw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid.percent)) {
    ldw_psid.percent <- truncate_weights_percentile(ldw_psid.percent, weight_col = wcol, lower = 0.05, upper = 0.95)
  }
}
```

#### Adaptive weight truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights using data-driven quantile selection
ldw_cps.adapt <- ldw_cps
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps.adapt)) {
    ldw_cps.adapt <- truncate_weights_adaptive(ldw_cps.adapt, weight_col = wcol, treat_col = "treat")
  }
}

ldw_psid.adapt <- ldw_psid
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid.adapt)) {
    ldw_psid.adapt <- truncate_weights_adaptive(ldw_psid.adapt, weight_col = wcol, treat_col = "treat")
  }
}
```

### Trimming 
#### Propensity score threshold trimming 
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
ldw_cps.trim <- ps_trim(ldw_cps.ps, threshold = 0.9)
ldw_psid.trim <- ps_trim(ldw_psid.ps, threshold = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.trim <- ps_estimate(data = ldw_cps.trim, Y = "re78", treat = "treat", cov = covar)
ldw_psid.trim <- ps_estimate(data = ldw_psid.trim, Y = "re78", treat = "treat", cov = covar)
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
ldw_cps.common   <- common_range_trim(ldw_cps.ps)
ldw_psid.common  <- common_range_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.common <- ps_estimate(data = ldw_cps.common, Y = "re78", treat = "treat", cov = covar)
ldw_psid.common <- ps_estimate(data = ldw_psid.common, Y = "re78", treat = "treat", cov = covar)
```

#### Crump trimming 
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
ldw_cps.crump  <- crump_trim(ldw_cps.ps, lower = 0.1, upper = 0.9)
ldw_psid.crump <- crump_trim(ldw_psid.ps, lower = 0.1, upper = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.crump <- ps_estimate(data = ldw_cps.crump, Y = "re78", treat = "treat", cov = covar)
ldw_psid.crump <- ps_estimate(data = ldw_psid.crump, Y = "re78", treat = "treat", cov = covar)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
ldw_cps.stuermer  <- stuermer_trim(ldw_cps.ps)
ldw_psid.stuermer <- stuermer_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.stuermer <- ps_estimate(data = ldw_cps.stuermer, Y = "re78", treat = "treat", cov = covar)
ldw_psid.stuermer <- ps_estimate(data = ldw_psid.stuermer, Y = "re78", treat = "treat", cov = covar)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
ldw_cps.walker   <- walker_trim(ldw_cps.ps)
ldw_psid.walker  <- walker_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.walker <- ps_estimate(data = ldw_cps.walker, Y = "re78", treat = "treat", cov = covar)
ldw_psid.walker <- ps_estimate(data = ldw_psid.walker, Y = "re78", treat = "treat", cov = covar)
```

### Integrated methods
### Trimming and matching
#### Propensity score threshold trimming 
(Similar to tutorial by @imbens2024)
```{r, message=FALSE, warning=FALSE}
ldw_cps_trim <- ps_trim(ldw_cps_plus.ps, threshold = 0.9)
ldw_psid_trim <- ps_trim(ldw_psid_plus.ps, threshold = 0.8)

# excluding the experimental controls
ldw_cps.trim_match <- subset(ldw_cps_trim, sample %in% c(1,3) & ps_assoverlap)
ldw_psid.trim_match <- subset(ldw_psid_trim, sample %in% c(1,4) & ps_assoverlap)

# re-estimate propensity scores and employ 1:1 matching
ldw_cps.trim_match <- psmatch(data = ldw_cps.trim_match, Y = "re78", treat = "treat", cov = covar)
ldw_psid.trim_match <- psmatch(data = ldw_psid.trim_match, Y = "re78", treat = "treat", cov = covar)

# further subset data and re-assign treat variable 
ldw_trim_cps <- subset(ldw_cps_trim, sample %in% c(1,2) & ps_assoverlap <= 0.9)
ldw_trim_cps$treat[which(ldw_trim_cps$sample == 2)] <- 0

ldw_trim_psid <- subset(ldw_psid_trim, sample %in% c(1,2) & ps_assoverlap <= 0.8)
ldw_trim_psid$treat[which(ldw_trim_psid$sample == 2)] <- 0
```

### Trimming and weighting
```{r, message=FALSE, warning=FALSE}
# list trimming methods
all_trim.cps  <- list(ps_threshold = ldw_cps.trim, 
                     common_range = ldw_cps.common, 
                     stuermer = ldw_cps.stuermer, 
                     walker = ldw_cps.walker, 
                     crump = ldw_cps.crump)
all_trim.psid  <- list(ps_threshold = ldw_psid.trim, 
                     common_range = ldw_psid.common, 
                     stuermer = ldw_psid.stuermer, 
                     walker = ldw_psid.walker, 
                     crump = ldw_psid.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply inverse probability weighting (IPW) with trimming and attach IPW weights
ipw_comb.cps <- trim_attach_weights(all_trim.cps, model, "ipw_weight")
ipw_comb.psid <- trim_attach_weights(all_trim.psid, model, "ipw_weight")
```

#### Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply stable balancing with trimming and attach stable balance weights
opt_comb.cps <- trim_attach_weights(all_trim.cps, model, "opt_weight")
opt_comb.psid <- trim_attach_weights(all_trim.psid, model, "opt_weight")
```

#### Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply propensity score weighting with trimming and attach propensity score weights
cbps_comb.cps <- trim_attach_weights(all_trim.cps, model, "cbps_weight")
cbps_comb.psid <- trim_attach_weights(all_trim.psid, model, "cbps_weight")
```

#### Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
ebal_comb.cps <- trim_attach_weights(all_trim.cps, model, "ebal_weight")
ebal_comb.psid <- trim_attach_weights(all_trim.psid, model, "ebal_weight")
```

## Reassessing methods
### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching objects
all_match.cps <- list(
  nn = m.out.cps.nearest,
  k2 = m.out.cps.k2,
  k3 = m.out.cps.k3,
  caliper = m.out.cps.caliper,
  cS = m.out.cps.cs,
  mahvars = m.out.cps.mahvars,
  optimal_pair = m.out.cps.optimal_pair,
  optimal_full = m.out.cps.optimal_full,
  gen_full = m.out.cps.general_full,
  genetic = m.out.cps.genetic,
  exact = m.out.cps.exact,
  cem = m.out.cps.cem,
  card = m.out.cps.card,
  profile = m.out.cps.profile,
  subcl = m.out.cps.subcl
)

all_match.psid <- list(
  nn = m.out.psid.nearest,
  k2 = m.out.psid.k2,
  k3 = m.out.psid.k3,
  caliper = m.out.psid.caliper,
  cs = m.out.psid.cs,
  mahvars = m.out.psid.mahvars,
  optimal_pair = m.out.psid.optimal_pair,
  optimal_full = m.out.psid.optimal_full,
  gen_full = m.out.psid.general_full,
  genetic = m.out.psid.genetic,
  exact = m.out.psid.exact,
  cem = m.out.psid.cem,
  card = m.out.psid.card,
  profile = m.out.psid.profile,
  subcl = m.out.psid.subcl
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_matchit.cps <- compute_abs_smd_matchit(all_match.cps)
smd_matchit.psid <- compute_abs_smd_matchit(all_match.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# calculate balance statistics 
bal.cps <- cobalt::bal.tab(model, data = ldw_cps, un = TRUE, weights = all_match.cps, s.d.denom = "treated")
bal.psid <- cobalt::bal.tab(model, data = ldw_psid, un = TRUE, weights = all_match.psid, s.d.denom = "treated")
```

```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_matchit.cps <- compute_ess_matchit(bal.cps)
ess_matchit.psid <- compute_ess_matchit(bal.psid)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGUREB3.'}
# visualize covariate balance 
plot_matching_balance(all_match.cps, title = "LDW-CPS1")
plot_matching_balance(all_match.psid, title = "LDW-PSID1")
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
all_weight.cps <- list(
  ipw_weight = ldw_cps$ipw_weight,
  opt_weight = ldw_cps$opt_weight,
  cbps_weight = ldw_cps$cbps_weight,
  ebal_weight = ldw_cps$ebal_weight
)

all_weight.psid <- list(
  ipw_weight = ldw_psid$ipw_weight,
  opt_weight = ldw_psid$opt_weight,
  cbps_weight = ldw_psid$cbps_weight,
  ebal_weight = ldw_psid$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_weight.cps <- compute_abs_smd_weight(ldw_cps, treat, covar, all_weight.cps)
smd_weight.psid <- compute_abs_smd_weight(ldw_psid, treat, covar, all_weight.psid)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_weight.cps <- compute_ess_weight(ldw_cps, treat, covar, all_weight.cps)
ess_weight.psid <- compute_ess_weight(ldw_psid, treat, covar, all_weight.psid)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGUREB4.'}
# visualize covariate balance
plot_weighting_balance(ldw_cps, treat, covar, all_weight.cps, "LDW-CPS1") 
plot_weighting_balance(ldw_psid, treat, covar, all_weight.psid, "LDW-PSID1")
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
all_trunc.cps <- list(
  fix_max_value = ldw_cps.fixed,
  at_perc = ldw_cps.percent,
  adap_weight = ldw_cps.adapt
)

all_trunc.psid <- list(
  fix_max_value = ldw_psid.fixed,
  at_perc = ldw_psid.percent,
  adap_weight = ldw_psid.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trunc.cps <- compute_abs_smd_trunc(all_trunc.cps, "treat", covar, weight_columns)
smd_trunc.psid <- compute_abs_smd_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trunc.cps <- compute_ess_trunc(all_trunc.cps, "treat", covar, weight_columns)
ess_trunc.psid <- compute_ess_trunc(all_trunc.psid, "treat", covar, weight_columns)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGUREB5.'}
# visualize covariate balance
plot_trunc_balance(all_trunc.cps, "treat", covar, weight_columns, "LDW-CPS1")
plot_trunc_balance(all_trunc.psid, "treat", covar, weight_columns, "LDW-PSID1")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming objects plus original
all_trim.cps <- list(
  original = ldw_cps,
  ps_threshold = ldw_cps.trim,
  common_range = ldw_cps.common,
  crump = ldw_cps.crump,
  stuermer = ldw_cps.stuermer,
  walker = ldw_cps.walker
)

all_trim.psid <- list(
  original = ldw_psid,
  ps_threshold = ldw_psid.trim,
  common_range = ldw_psid.common,
  crump = ldw_psid.crump,
  stuermer = ldw_psid.stuermer,
  walker = ldw_psid.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMDs
smd_trim.cps <- compute_abs_smd_trim(all_trim.cps, "treat", covar)
smd_trim.psid <- compute_abs_smd_trim(all_trim.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trim.cps <- compute_ess_trim(all_trim.cps, "treat", covar)
ess_trim.psid <- compute_ess_trim(all_trim.psid, "treat", covar)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGUREB6.'}
# visualize overlap
plot_trim_overlap(all_trim.cps, treat, covar, prefix = "LDW-CPS1")
plot_trim_overlap(all_trim.psid, treat, covar, prefix = "LDW-PSID1")
```

## Integrated methods
### Trimming and matching
(Similar to tutorial by @imbens2024)
```{r, message=FALSE, warning=FALSE}
# list all trimmed and matched samples
comb_cps <- list(
  ps_threshold_match = ldw_cps.trim_match
)

comb_psid <- list(
  ps_threshold_match = ldw_psid.trim_match
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_all_comb_meth.cps_plus <- compute_abs_smd_trim(comb_cps, "treat", covar)
smd_all_comb_meth.psid_plus <- compute_abs_smd_trim(comb_psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.cps_plus <- compute_ess_trim(comb_cps, "treat", covar)
ess_all_comb_meth.psid_plus <- compute_ess_trim(comb_psid, "treat", covar)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGUREA6.'}
# visualize overlap
par(mfrow = c(1, 3))
plot_trim_overlap(comb_cps, treat, covar, prefix = "LDW-CPS1-PLUS")
plot_trim_overlap(comb_psid, treat, covar, prefix = "LDW-PSID1-PLUS")
```

### Trimming and weighting
```{r, message=FALSE, warning=FALSE}
# list all combined results
comb.cps <- list(
  ipw = ipw_comb.cps,
  opt = opt_comb.cps,
  cbps = cbps_comb.cps,
  ebal = ebal_comb.cps
)

comb.psid <- list(
  ipw = ipw_comb.psid,
  opt = opt_comb.psid,
  cbps = cbps_comb.psid,
  ebal = ebal_comb.psid
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_all_comb_meth.cps <- compute_abs_smd_comb(comb.cps, "treat", covar)
smd_all_comb_meth.psid <- compute_abs_smd_comb(comb.psid, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.cps <- compute_ess_comb(comb.cps, "treat", covar)
ess_all_comb_meth.psid <- compute_ess_comb(comb.psid, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGUREB7.'}
# visualize overlap
plot_comb_overlap(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix_cps = "LDW-CPS1", prefix_psid = "LDW-PSID1")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_comb_hist(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = "treat", covar = covar, prefix = "model_b", prefix_cps = "ldw_cps1", prefix_psid = "ldw_psid1")
```

## Identifying best methods
```{r, message=FALSE, warning=FALSE}
# combine all results
all_cps <- combine_results("cps")
all_psid <- combine_results("psid") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_cps, "ldw_model_b_cps1_all_results")
save_csv(all_psid, "ldw_model_b_psid1_all_results")
```

```{r, message=FALSE, warning=FALSE}
# rank comparatively
ranked_cps  <- assess_methods(all_cps)
ranked_psid <- assess_methods(all_psid)
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
top5_methods.cps <- get_top_methods(ranked_cps, top_n = 5)
top5_methods.psid <- get_top_methods(ranked_psid, top_n = 5)

# print results
top5_methods_df.cps <- ranked_cps %>% arrange(desc(Score)) %>% head(5)
top5_methods_df.psid <- ranked_psid %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.cps, caption = "Top 5 Methods for CPS1", booktabs = TRUE)
knitr::kable(top5_methods_df.psid, caption = "Top 5 Methods for PSID1", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.cps, "ldw_model_b_cps1_top5_methods")
save_csv(top5_methods.psid, "ldw_model_b_psid1_top5_methods")
```

```{r, message=FALSE, warning=FALSE}
# combine results
all_cps_plus  <- combine_results_plus("cps")
all_psid_plus <- combine_results_plus("psid")
```

```{r, message=FALSE, warning=FALSE}
# assess composite scores
ranked_cps_plus  <- assess_methods(all_cps_plus)
ranked_psid_plus <- assess_methods(all_psid_plus)
```

```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
top5_methods.cps_plus <- get_top_methods(ranked_cps_plus, top_n = 5)
top5_methods.psid_plus <- get_top_methods(ranked_psid_plus, top_n = 5)

# print results
top5_methods_df.cps_plus <- ranked_cps_plus %>% arrange(desc(Score)) %>% head(5)
top5_methods_df.psid_plus <- ranked_psid_plus %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.cps_plus, caption = "Top 5 Methods for CPS1 incl. CPS1-PLUS", booktabs = TRUE)
knitr::kable(top5_methods_df.psid_plus, caption = "Top 5 Methods for PSID1 incl. PSID1-PLUS", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
dataset_list_cps <- list(
  "All" = ldw_cps,
  "original" = ldw_cps,
  "nn" = m.out.cps.nearest, 
  "caliper" = m.out.cps.caliper,
  "card" = m.out.cps.card,
  "cem" = m.out.cps.cem,
  "cS" = m.out.cps.cs,
  "k2"  = m.out.cps.k2,
  "k3" = m.out.cps.k3,
  "mahvars" = m.out.cps.mahvars,
  "optimal_full" = m.out.cps.optimal_full,
  "optimal_pair" = m.out.cps.optimal_pair,
  "gen_full" = m.out.cps.general_full,
  "genetic" = m.out.cps.genetic,
  "exact" = m.out.cps.exact,
  "subcl" = m.out.cps.subcl,
  "profile"  = m.out.cps.profile,
  "ipw_weight" = ldw_cps$ipw_weight, 
  "opt_weight" = ldw_cps$opt_weight,
  "cbps_weight" = ldw_cps$cbps_weight,
  "ebal_weight" = ldw_cps$ebal_weight,
  "fix_max_value_ipw_weight" = ldw_cps.fixed$ipw_weight,
  "fix_max_value_opt_weight" = ldw_cps.fixed$opt_weight,
  "fix_max_value_cbps_weight" = ldw_cps.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = ldw_cps.fixed$ebal_weight,
  "at_perc_ipw_weight" = ldw_cps.percent$ipw_weight,
  "at_perc_opt_weight" = ldw_cps.percent$opt_weight,
  "at_perc_cbps_weight" = ldw_cps.percent$cbps_weight,
  "at_perc_ebal_weight" = ldw_cps.percent$ebal_weight,
  "adap_weight_ipw_weight" = ldw_cps.adapt$ipw_weight,
  "adap_weight_opt_weight" = ldw_cps.adapt$opt_weight,
  "adap_weight_cbps_weight" = ldw_cps.adapt$cbps_weight,
  "adap_weight_ebal_weight" = ldw_cps.adapt$ebal_weight,
  "ps_threshold" = ldw_cps.trim,
  "common_range" = ldw_cps.common,
  "stuermer" = ldw_cps.stuermer,
  "walker" = ldw_cps.walker,
  "crump" = ldw_cps.crump,
  "ipw_common_range" = ipw_comb.cps[[1]],
  "ipw_crump"= ipw_comb.cps[[2]],
  "ipw_ps_threshold"= ipw_comb.cps[[3]],
  "ipw_stuermer"= ipw_comb.cps[[4]],
  "ipw_walker" = ipw_comb.cps[[5]],
  "opt_common_range" = opt_comb.cps[[1]],
  "opt_crump" = opt_comb.cps[[2]],
  "opt_ps_threshold" = opt_comb.cps[[3]],
  "opt_stuermer" = opt_comb.cps[[4]],
  "opt_walker" = opt_comb.cps[[5]],
  "cbps_common_range" = cbps_comb.cps[[1]],
  "cbps_crump" = cbps_comb.cps[[2]],
  "cbps_ps_threshold"  = cbps_comb.cps[[3]],
  "cbps_stuermer" = cbps_comb.cps[[4]],
  "cbps_walker"= cbps_comb.cps[[5]],
  "ebal_common_range" = ebal_comb.cps[[1]],
  "ebal_crump" = ebal_comb.cps[[2]],
  "ebal_ps_threshold" = ebal_comb.cps[[3]],
  "ebal_stuermer" = ebal_comb.cps[[4]],
  "ebal_walker" = ebal_comb.cps[[5]])

dataset_list_psid <- list(
  "All" = ldw_psid,
  "original" = ldw_psid,
  "nn" = m.out.psid.nearest, 
  "caliper" = m.out.psid.caliper,
  "card" = m.out.psid.card,
  "cem" = m.out.psid.cem,
  "cS" = m.out.psid.cs,
  "k2"  = m.out.psid.k2,
  "k3" = m.out.psid.k3,
  "mahvars" = m.out.psid.mahvars,
  "optimal_full" = m.out.psid.optimal_full,
  "optimal_pair" = m.out.psid.optimal_pair,
  "gen_full" = m.out.psid.general_full,
  "genetic" = m.out.psid.genetic,
  "exact" = m.out.psid.exact,
  "subcl" = m.out.psid.subcl,
  "profile"  = m.out.psid.profile,
  "ipw_weight" = ldw_psid$ipw_weight, 
  "opt_weight" = ldw_psid$opt_weight,
  "cbps_weight" = ldw_psid$cbps_weight,
  "ebal_weight" = ldw_psid$ebal_weight,
  "fix_max_value_ipw_weight" = ldw_psid.fixed$ipw_weight,
  "fix_max_value_opt_weight" = ldw_psid.fixed$opt_weight,
  "fix_max_value_cbps_weight" = ldw_psid.fixed$cbps_weight,
  "fix_max_value_ebal_weight" = ldw_psid.fixed$ebal_weight,
  "at_perc_ipw_weight" = ldw_psid.percent$ipw_weight,
  "at_perc_opt_weight" = ldw_psid.percent$opt_weight,
  "at_perc_cbps_weight" = ldw_psid.percent$cbps_weight,
  "at_perc_ebal_weight" = ldw_psid.percent$ebal_weight,
  "adap_weight_ipw_weight" = ldw_psid.adapt$ipw_weight,
  "adap_weight_opt_weight" = ldw_psid.adapt$opt_weight,
  "adap_weight_cbps_weight" = ldw_psid.adapt$cbps_weight,
  "adap_weight_ebal_weight" = ldw_psid.adapt$ebal_weight,
  "ps_threshold" = ldw_psid.trim,
  "common_range" = ldw_psid.common,
  "stuermer" = ldw_psid.stuermer,
  "walker" = ldw_psid.walker,
  "crump" = ldw_psid.crump,
  "ipw_common_range" = ipw_comb.psid[[1]],
  "ipw_crump"= ipw_comb.psid[[2]],
  "ipw_ps_threshold"= ipw_comb.psid[[3]],
  "ipw_stuermer"= ipw_comb.psid[[4]],
  "ipw_walker" = ipw_comb.psid[[5]],
  "opt_common_range" = opt_comb.psid[[1]],
  "opt_crump" = opt_comb.psid[[2]],
  "opt_ps_threshold" = opt_comb.psid[[3]],
  "opt_stuermer" = opt_comb.psid[[4]],
  "opt_walker" = opt_comb.psid[[5]],
  "cbps_common_range" = cbps_comb.psid[[1]],
  "cbps_crump" = cbps_comb.psid[[2]],
  "cbps_ps_threshold"  = cbps_comb.psid[[3]],
  "cbps_stuermer" = cbps_comb.psid[[4]],
  "cbps_walker"= cbps_comb.psid[[5]],
  "ebal_common_range" = ebal_comb.psid[[1]],
  "ebal_crump" = ebal_comb.psid[[2]],
  "ebal_ps_threshold" = ebal_comb.psid[[3]],
  "ebal_stuermer" = ebal_comb.psid[[4]],
  "ebal_walker" = ebal_comb.psid[[5]])
```

```{r, message=FALSE, warning=FALSE}
# create datasets corresponding to the top 5 methods for each dataset
top5_datasets.cps <- create_top5_datasets(dataset_list_cps, top5_methods.cps)
top5_datasets.psid <- create_top5_datasets(dataset_list_psid, top5_methods.psid)
```

```{r, message=FALSE, warning=FALSE}
# save datasets into .RData files
save_top5_datasets(dataset_list_cps, top5_methods.cps, prefix = "ldw_model_b_cps1")
save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = "ldw_model_b_psid1")
```

## Estimating
### Average treatment effect on the treated (ATT)
```{r, message=FALSE, warning=FALSE}
# estimate ATT
out1 <- estimate_all(ldw, "re78", "treat", covar)
out2 <- estimate_all(ldw_cps, "re78", "treat", covar)
out3 <- estimate_all(ldw_psid, "re78", "treat", covar)

out.cps <- lapply(top5_datasets.cps, function(d) estimate_all(d, "re78", "treat", covar))
out.psid <- lapply(top5_datasets.psid, function(d) estimate_all(d, "re78", "treat", covar))

out4 <- out.cps[[1]]
out5 <- out.cps[[2]]
out6 <- out.cps[[3]]
out7 <- out.cps[[4]]
out8 <- out.cps[[5]]

out9 <- out.psid[[1]]
out10 <- out.psid[[2]]
out11 <- out.psid[[3]]
out12 <- out.psid[[4]]
out13 <- out.psid[[5]]
```

```{r, message=FALSE, warning=FALSE}
# estimate ATT
load("data/trimmed.RData")
out14 <- estimate_all(ldw_trim_cps, "re78", "treat", covar)
out15 <- estimate_all(ldw_trim_psid, "re78", "treat", covar)
out16 <- estimate_all(ldw_cps_trim, "re78", "treat", covar)
out17 <- estimate_all(ldw_psid_trim, "re78", "treat", covar)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB10. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. ATT Estimates Model B Given Unconfoundedness using LDW Samples"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))

# experimental benchmarks
band.exp <- out1[1, 3:4]
est.exp  <- out1[1, 1]

# plot results
plot_coef(out1,  band = band.exp, line = est.exp, 
          ylim = c(-15500, 5500), main = "(A) LDW-Experimental")

plot_coef(out2,  band = band.exp, line = est.exp, 
          ylim = c(-15500, 5500), main = "(B) LDW-CPS1")

plot_coef(out3,  band = band.exp, line = est.exp,
          ylim = c(-15500, 5500), main = "(C) LDW-PSID1")

for (i in seq_along(out.cps)) {
  this_title <- paste0("(", LETTERS[i+2], ") Top CPS1: ", top5_methods.cps[i])
  plot_coef(out.cps[[i]], band = band.exp, line = est.exp,
            ylim = c(-15500, 5500), main = this_title)
}

for (i in seq_along(out.psid)) {
  this_title <- paste0("(", LETTERS[i+7], ") Top PSID1: ", top5_methods.psid[i])
  plot_coef(out.psid[[i]], band = band.exp, line = est.exp,
            ylim = c(-15500, 5500), main = this_title)
}
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB10. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model B Given Unconfoundedness using LDW Samples"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))
par(cex.main = 0.9)

# nonexperimtenal benchmarks
band.cps_plus <- out14[1, 3:4]
est.cps_plus <- out14[1, 1]
band.psid_plus <- out15[1, 3:4]
est.psid_plus <- out15[1, 1]

# plot results
plot_coef(out16, band = band.cps_plus, line = est.cps_plus, 
          ylim = c(-15500, 5500), main = "(N) Trimmed LDW-CPS1-PLUS")


plot_coef(out17, band = band.psid_plus, line = est.psid_plus, 
          ylim = c(-15500, 5500), main = "(O) Trimmed LDW-PSID1-PLUS")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(
  out_list = list(out1, out2, out3),
  plot_titles = c("(A) LDW-Experimental", "(B) LDW-CPS1", "(C) LDW-PSID1"),
  band_list = list(band.exp, band.exp, band.exp),
  est_list  = list(est.exp, est.exp, est.exp),
  prefix = "ldw_model_b_est_exp"
)

save_att_panels(
  out_list = out.cps,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps),
  band_list = replicate(length(out.cps), band.exp, simplify = FALSE),
  est_list  = replicate(length(out.cps), est.exp, simplify = FALSE),
  prefix = "ldw_model_b_est_top_cps"
)

save_att_panels(
  out_list = out.psid,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid),
  band_list = replicate(length(out.psid), band.exp, simplify = FALSE),
  est_list  = replicate(length(out.psid), est.exp, simplify = FALSE),
  prefix = "ldw_model_b_est_top_psid"
)

save_att_panels(
  out_list = list(out16, out17),
  plot_titles = c("(N) Trimmed LDW-CPS1-PLUS", "(O) Trimmed LDW-PSID1-PLUS"),
  band_list = list(band.cps_plus, band.psid_plus),
  est_list  = list(est.cps_plus, est.psid_plus),
  prefix = "ldw_model_b_est_plus"
)
```

As in model A, the above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, trimmed versions of the LDW-CPS1 and LDW-PSID1 samples (analogous to @imbens2024) and a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria. 

Again, figure (A) presents the benchmark, serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the LDW-CPS1 and LDW-PSID1y, while figures (D) and (E) present those for the trimmed versions. Figures (F) through (J) display results for CPS1-derived subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-derived subsamples under parallel rules.

For LDW-CPS1, the top-ranked subsamples are derived with the same methods as in model A, though they appear in a slightly different order. However, for the LDW-PSID1, the top-ranked subsamples are based on two different methods, `fix_max_value_trunc_overlap_weight` and `overlap_weight`.

Across the LDW-CPS1 and its top-ranked samples, all estimators generally yield ATT estimates that cluster near the experimental benchmark, overall slightly closer than in model A but with greater standard errors. Notable deviations from the experimental benchmark remain for the `optimal_pair` and `overlap_crump` subsamples.

For LDW-PSID1 and its subsamples, the ATT estimates continue to exhibit greater dispersion and considerably larger standard errors compared to LDW-CPS1 counterpart samples, yet they lie closer to the benchmark than in model A.
```{r, message=FALSE, warning=FALSE}
# get all outputs
all_outs <- c(list(out1, out2, out3), 
              out.cps, out.psid, 
              list(out16, out17))

# get plot titles
all_plot_titles <- c("(A) LDW-Experimental", "(B) LDW-CPS1", "(C) LDW-PSID1",
                      paste0("(", LETTERS[6:10], ") Top CPS1: ", top5_methods.cps),
                      paste0("(", LETTERS[11:15], ") Top PSID1: ", top5_methods.psid),
                      "(N) Trimmed LDW-CPS1-PLUS", "(O) Trimmed LDW-PSID1-PLUS")

# evaluate results
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- all_plot_titles

# print results
knitr::kable(att_summary, caption = "ATT Summary Statistics", booktabs = TRUE) %>%
  kable_styling(full_width = TRUE) 
```

```{r, message=FALSE, warning=FALSE}
# create result matrix
result_mat <- create_matrix_results(all_outs, all_plot_titles)

# render formatted table output
datatable(result_mat, caption = "ATT Estimates and SEs",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

As in model A, the tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. 

In model B, most LDW-CPS1-based samples yield ATT estimates that are closer to the experimental benchmark than in model A, with still modest variance. By contrast, the LDW-PSID1-based estimates, while somewhat closer to the experimental benchmark than in model A, continue to exhibit substantially larger standard errors compared to LDW-CPS1 samples. This again reflects the greater challenge of obtaining reliable estimates from the observational dataset LDW-PSID1.

Overall, figures and table jointly demonstrate again that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "ldw_att_est_model_b")
```

### Conditional average treatment effect on the treated (CATT)
```{r, message=FALSE, warning=FALSE}
# estimate CATT
catt.ldw <- catt(ldw, Y, treat, covar)
catt.cps <- catt(ldw_cps, Y, treat, covar)
catt.psid <- catt(ldw_psid, Y, treat, covar)
catt.top5_cps <- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar))
catt.top5_psid <- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar))
```

```{r, message=FALSE, warning=FALSE}
# similar to Imbens & Xu (2024) 
catt.trim_cps <- catt(ldw_trim_cps, Y, treat, covar) 
catt.trim_psid <- catt(ldw_trim_psid, Y, treat, covar) 
catt.cps_trim <- catt(ldw_cps_trim, Y, treat, covar)  
catt.psid_trim <- catt(ldw_psid_trim, Y, treat, covar) 
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB11. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. CATT Estimates Model B using LDW Data: Experimental vs. Nonexperimental"}
# plot results
par(mfrow = c(2,2)) 
par(cex.main = 0.9)
plot_catt(
  catt1 = catt.ldw$catt,
  catt2 = catt.cps$catt,
  att1  = catt.ldw$att[1],
  att2  = catt.cps$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (CPS1)",
  main  = "(B) LDW-CPS1", 
  axes.range = c(-8000, 8000)
)

plot_catt(
  catt1 = catt.ldw$catt,
  catt2 = catt.psid$catt,
  att1  = catt.ldw$att[1],
  att2  = catt.psid$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (PSID1)",
  main  = "(C) LDW-PSID1",
  axes.range = c(-8000, 8000)
)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB11. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. CATT Estimates Model BB using LDW Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2)) 
par(cex.main = 0.9)
plot_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_cps,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps)
)

plot_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_psid,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid)
)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB11. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. CATT Estimates Model B using LDW Data: Experimental vs. Nonexperimental"}
# plot results
par(mfrow = c(2,2)) 
par(cex.main = 0.9)
plot_catt(
  catt1 <- catt.trim_cps$catt,
  catt2 <- catt.cps_trim$catt,
  att1 <- catt.trim_cps$att[1],
  att2 <- catt.cps_trim$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (CPS1-PLUS-Trimmed)",
  main  = "(N) Trimmed LDW-CPS1-PLUS", 
  axes.range = c(-8000, 8000)
)

plot_catt(
  catt1 <- catt.trim_psid$catt,
  catt2 <- catt.psid_trim$catt,
  att1 <- catt.trim_psid$att[1],
  att2 <- catt.psid_trim$att[1],
  xlab  = "CATT (Experimental)",
  ylab  = "CATT (PSID1-PLUS-Trimmed)",
  main  = "(O) Trimmed LDW-PSID1-PLUS",
  axes.range = c(-8000, 8000)
)
```

```{r, out.width='100%', fig.asp=1, fig.cap="FIGUREB12. CATT Estimates Model B using LDW Data"}
# combine all catt objects 
all_catt <- c(list(catt.ldw, catt.cps, catt.psid), 
              catt.top5_cps, catt.top5_psid, 
              list(catt.cps_trim, catt.psid_trim))

all_catt_eval <- eval_catt(all_catt, all_plot_titles)
knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

In model B, using LDW-CPS1, the CATT estimates range from $-3,868.54 to $7,128.42. This span is considerably narrower than in model A, but still performs worse when contrasted with the experimental benchmark, where CATT estimates range from $-213.93 to $3,858.52 with a mean of $1,720.13. The experimental mean CATT estimate remains closer to its corresponding ATT estimate than in model A. Further, LDW-PSID1 shows a narrower CATT estimate range, from $-6,772.16 to	$5,032.31, compared to LDW-CPS1 and model A, with a mean CATT estimate of about $557.39, which deviates further from the experimental benchmark, indicating poorer performance.

For trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary considerably, yet the mean estimates are generally closer to the experimental benchmark, as in model A. Moreover, the minimum CATT estimates are less negative, which reduces the spread between minimum and maximum estimates.

Top-ranked LDW-PSID1 subsamples, on the other hand, again yield more negative mean CATT estimates and wider ranges compared to their LDW-CPS1 counterparts, signaling persistent difficulties in generating reliable effect estimates. Still, compared to model A, the minimum CATT estimates are less strongly negative, though the mean CATTs only improve marginally in their proximity to the experimental benchmark.

Hence, alike model A, these results show that the variation in ranges and means across methods and samples reflects substantial heterogeneity in treatment effect estimation. While certain criteria may improve consistency with experimental benchmarks, they may also introduce notable discrepancies and variability in estimated heterogeneous effects. 
```{r, message=FALSE, warning=FALSE}
# save results
save_main_catt_panels(
  catt_refs = list(catt.ldw),
  catt_comps = list(catt.cps, catt.psid),
  ylabels = c("CATT (CPS1)", "CATT (PSID1)"),
  prefix = "ldw_model_b_catt_main_panels",
  main_titles = c("(B) LDW-CPS1", "(C) LDW-PSID1")
)

save_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_cps,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps),
  prefix = "ldw_model_b_catt_top5_cps"
)

save_catt_panels(
  exp_catt = catt.ldw,
  catt_list  = catt.top5_psid,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid),
  prefix = "ldw_model_b_catt_top5_psid"
)

save_plus_catt_panels(
  catt1_list = list(catt.trim_cps, catt.trim_psid),
  catt2_list = list(catt.cps_trim, catt.psid_trim),
  ylabels = c("CATT (CPS1-PLUS-Trimmed)", "CATT (PSID1-PLUS-Trimmed)"),
  prefix = "ldw_model_b_catt_plus_panels",
  main_titles = c("(N) LDW-CPS1-PLUS", "(O) LDW-PSID1-PLUS")
)
```

```{r, message=FALSE, warning=FALSE}
# combine all catt objects 
all_catt <- c(list(catt.ldw, catt.cps, catt.psid),
              catt.top5_cps, catt.top5_psid,
              list(catt.trim_psid, catt.psid_trim)) 

all_catt_eval <- eval_catt(all_catt, all_plot_titles)

knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

### Quantile treatment effect on the treated (QTET)
```{r, message=FALSE, warning=FALSE}
qte.ldw <- est_qte(Y, treat, covar, data = ldw, cores = 4)
qte.ldw_cps <- est_qte(Y, treat, covar, data = ldw_cps)
qte.ldw_psid <- est_qte(Y, treat, covar, data = ldw_psid)
qte.top5_cps  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, covar, data = d))
qte.top5_psid <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.trim.ldw_cps <- est_qte(Y, treat, NULL, data = ldw_trim_cps)
qte.trim.ldw_psid <- est_qte(Y, treat, NULL, data = ldw_trim_psid)
qte.ldw_cps.trim <- est_qte(Y, treat, covar, data = ldw_cps_trim) 
qte.ldw_psid.trim <- est_qte(Y, treat, covar, data = ldw_psid_trim) 
```

```{r, message=FALSE, warning=FALSE}
qte.ldw0 <- est_qte(Y, treat, NULL, data = ldw)
qte.ldw_cps0 <- est_qte(Y, treat, NULL, data = ldw_cps)
qte.ldw_psid0 <- est_qte(Y, treat, NULL, data = ldw_psid)
qte.top5_cps0  <- lapply(top5_datasets.cps,  function(d) est_qte(Y, treat, NULL, data = d))
qte.top5_psid0 <- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d))
```

```{r, message=FALSE, warning=FALSE}
qte.ldw_cps.trim0 <- est_qte(Y, treat, NULL, data = ldw_cps_trim)
qte.ldw_psid.trim0 <- est_qte(Y, treat, NULL, data = ldw_psid_trim)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB13. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.9)
ylim = c(-25000, 15000)
# CPS1
plot_qte(qte.ldw_cps, qte.ldw_cps0, qte.ldw, main = "(B) LDW-CPS1", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
       lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1
plot_qte(qte.ldw_psid, qte.ldw_psid0, qte.ldw, main = "(C) LDW-PSID1", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
       lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# CPS1 top methods
plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw, all_plot_titles, main_start = 4)

# PSID1 top methods
plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw, all_plot_titles, main_start = 9)

# CPS1-PLUS trimmed
plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.trim.ldw_cps, main = "(N) LDW-CPS1-PLUS (Trimmed)", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
       lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID1-PLUS trimmed
plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.trim.ldw_psid, main = "(O) LDW-PSID1-PLUS (Trimmed)", ylim)
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")
```

These figures display QTET estimates derived from both the experimental and various non-experimental samples. Compared to model A, the QTET results of all samples closely resemble those of their respective counterparts. The QTETs estimated from the original and trimmed LDW-CPS1 sample continue to correspond well with the true QTET, although the estimates often suffer from low power. The QTET estimates from the original and trimmed LDW-PSID1 subsample show clear biases when compared to the experimental benchmark, which clusters near zero. The QTET estimates derived from the top-ranked subsamples of LDW-CPS1 (F - J) track the true experimental effect well. In contrast, the top-ranked subsamples of LDW-PSID1-based produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty.
```{r, message=FALSE, warning=FALSE}
# list results
plots_ldw <- list(
  list(mod = qte.ldw_cps, mod0 = qte.ldw_cps0, bm = qte.ldw, 
       main = "(B) LDW-CPS1"),
  list(mod = qte.ldw_psid, mod0 = qte.ldw_psid0, bm = qte.ldw, 
       main = "(C) LDW-PSID1"),
  list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.trim.ldw_cps, 
       main = "(N) LDW-CPS1-PLUS (Trimmed)"),
  list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.trim.ldw_psid, 
       main = "(O) LDW-PSID1-PLUS (Trimmed)")
)

# save results
save_qtet(plots_ldw, prefix = "ldw_model_b")
save_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw, all_plot_titles, 
             main_start = 8, prefix = "ldw_model_b_top")
save_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw, all_plot_titles, 
             main_start = 13, prefix = "ldw_model_b_top")
```

### Assessing outcome weights (OW)
```{r, message=FALSE, warning=FALSE}
# list all datasets
all_datasets <- c(list(ldw, ldw_cps, ldw_psid), top5_datasets.cps, top5_datasets.psid, list(ldw_trim_cps, ldw_trim_psid))
```

```{r, message=FALSE, warning=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB14. Outcome Weights Model B using LDW Data"}
par(mfrow = c(2,2))
par(cex.main = 0.9)
# plot outcome weights distribution
plot_ow(ow_att, all_plot_titles) 
```

```{r, message=FALSE, warning=FALSE}
# evaluate results
res_ow <- eval_ow(ow_att, all_datasets, all_plot_titles, treat, "AIPW-ATT")
knitr::kable(res_ow, caption = "Outcome Weights for Treated and Untreated", booktabs = TRUE) %>%
  kable_styling(full_width = TRUE) 
```

In model B, the evaluation once again confirms that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero.
```{r, message=FALSE, warning=FALSE}
#save results
save_ow(ow_att, all_plot_titles, prefix = "model_b")
```

## Validation through placebo analyses
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re75"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "u74")
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on original and observational datasets
out1_pl <- estimate_all(ldw, Y, "treat", covar)
out2_pl <- estimate_all(ldw_cps, Y, "treat", covar)
out3_pl <- estimate_all(ldw_psid, Y, "treat", covar)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on top ranked datasets
out.cps_pl <- lapply(top5_datasets.cps, function(d) estimate_all(d, Y, "treat", covar))
out.psid_pl <- lapply(top5_datasets.psid, function(d) estimate_all(d, Y, "treat", covar))

out4_pl <- out.cps_pl[[1]]
out5_pl <- out.cps_pl[[2]]
out6_pl <- out.cps_pl[[3]]
out7_pl <- out.cps_pl[[4]]
out8_pl <- out.cps_pl[[5]]

out9_pl <- out.psid_pl[[1]]
out10_pl <- out.psid_pl[[2]]
out11_pl <- out.psid_pl[[3]]
out12_pl <- out.psid_pl[[4]]
out13_pl <- out.psid_pl[[5]]
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on plus datasets
load("data/trimmed.RData")
out14_pl <- estimate_all(ldw_trim_cps_pl, Y, "treat", covar)
out15_pl <- estimate_all(ldw_trim_psid_pl, Y, "treat", covar)
out16_pl <- estimate_all(ldw_cps_trim_pl, Y, "treat", covar)
out17_pl <- estimate_all(ldw_psid_trim_pl, Y, "treat", covar)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB15. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. Placebo Test Model B: '75 Earnings as the Outcome"}
par(mfrow = c(4, 1), mar = c(4, 4, 2, 1))

# experimental benchmarks
band.exp_pl <- out1_pl[1, 3:4]
est.exp_pl <- out1_pl[1, 1]

# plot placebo results
plot_coef(out1_pl,  band = band.exp_pl, line = est.exp_pl, 
          ylim = c(-15500, 5500), main = "(A) LDW-Experimental")

plot_coef(out2_pl,  band = band.exp_pl, line = est.exp_pl, 
          ylim = c(-15500, 5500), main = "(B) LDW-CPS1")

plot_coef(out3_pl,  band = band.exp_pl, line = est.exp_pl,
          ylim = c(-15500, 5500), main = "(C) LDW-PSID1")

for (i in seq_along(out.cps_pl)) {
  this_title <- paste0("(", LETTERS[i+2], ") Top CPS1: ", top5_methods.cps[i])
  plot_coef(out.cps_pl[[i]], band = band.exp_pl, line = est.exp_pl,
            ylim = c(-15500, 5500), main = this_title)
}

for (i in seq_along(out.psid_pl)) {
  this_title <- paste0("(", LETTERS[i+7], ") Top PSID1: ", top5_methods.psid[i])
  plot_coef(out.psid_pl[[i]], band = band.exp_pl, line = est.exp_pl,
            ylim = c(-15500, 5500), main = this_title)
}
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB15. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. Placebo Test Model B: '75 Earnings as the Outcome"}
par(mfrow = c(4, 1))

# nonexperimtenal benchmarks
band.cps_plus_pl <- out14_pl[1, 3:4]
est.cps_plus_pl <- out14_pl[1, 1]
band.psid_plus_pl <- out15_pl[1, 3:4]
est.psid_plus_pl <- out15_pl[1, 1]

# plot results
plot_coef(out16_pl, band = band.cps_plus_pl, line = est.cps_plus_pl, 
          ylim = c(-12000, 2000), main = "(N) Trimmed LDW-CPS1-PLUS")

plot_coef(out17_pl, band = band.psid_plus_pl, line = est.psid_plus_pl, 
          ylim = c(-12000, 2000), main = "(O) Trimmed LDW-PSID1-PLUS")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(
  out_list = list(out1_pl, out2_pl, out3_pl),
  plot_titles = c("(A) LDW-Experimental", "(B) LDW-CPS1", "(C) LDW-PSID1"),
  band_list = list(band.exp_pl, band.exp_pl, band.exp_pl),
  est_list  = list(est.exp_pl, est.exp_pl, est.exp_pl),
  prefix = "ldw_model_b_pl_est_exp"
)

save_att_panels(
  out_list = out.cps_pl,
  plot_titles = paste0("(", LETTERS[4:8], ") Top CPS1: ", top5_methods.cps),
  band_list = replicate(length(out.cps_pl), band.exp_pl, simplify = FALSE),
  est_list  = replicate(length(out.cps_pl), est.exp_pl, simplify = FALSE),
  prefix = "ldw_model_b_pl_est_top_cps"
)

save_att_panels(
  out_list = out.psid_pl,
  plot_titles = paste0("(", LETTERS[9:13], ") Top PSID1: ", top5_methods.psid),
  band_list = replicate(length(out.psid_pl), band.exp_pl, simplify = FALSE),
  est_list  = replicate(length(out.psid_pl), est.exp_pl, simplify = FALSE),
  prefix = "ldw_model_b_pl_est_top_psid"
)

save_att_panels(
  out_list = list(out16_pl, out17_pl),
  plot_titles = c("(P) Trimmed LDW-CPS1-PLUS", "(Q) Trimmed LDW-PSID1-PLUS"),
  band_list = list(band.cps_plus_pl, band.psid_plus_pl),
  est_list  = list(est.cps_plus_pl, est.psid_plus_pl),
  prefix = "ldw_model_b_pl_est_plus",
  ylim = c(-12000, 2000)
)
```

```{r, message=FALSE, warning=FALSE}
# print placebo results
all_outs.pl <- c(list(out1_pl, out2_pl, out3_pl), 
                 out.cps_pl, out.psid_pl, 
                 list(out16_pl, out17_pl))

result_mat_pl <- create_matrix_results(all_outs.pl, all_plot_titles)

datatable(result_mat_pl, caption = "Placebo ATT Estimates and SEs",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

The placebo analysis shows that the experimental benchmarks remain close to zero and statistically insignificant, closely mirroring the results in model A. The results for LDW-CPS1 and LDW-PSID1 are identical to those observed in model A.

For LDW-CPS1 samples (B and F through J), ATT estimates remain consistently negative. The `overlap_crump` estimates show modest improvement toward the benchmark compared to LDW-CPS1 (B) results, but also yields notably worse estimates for certain estimators. Further gains are observed with the trimmed sample (D), `ps_threshold` (I), `card` (G) and `optimal_pair`. The `mahvars` (G) sample performs best, producing ATT estimates closest to the experimental results. However, compared to model A, no clear pattern emerges: some methods perform better, while others produce poorer estimates.

For LDW-PSID1, the sample (O) applying `fix_max_value_truncation_overlap_weight` shows some improvement relative to the PSID1 sample (C), though it also produces worse results for certain estimators. A similar pattern holds for the `overlap_weight` sample. The `card` (K), `mahvars` (L), trimmed sample (E) and the`ps_threshold` (M) further reduce discrepancies, drawing estimates closer to the experimental benchmark results. Still, their performance not markedly surpass that of model A. 

Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis continues to reveal substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underscores the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat_pl, "ldw_att_estimates_pl_model_b")
```

## Validation through sensitivity analyses
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "re75", "u74", "u75")
bm <- c("re75") 
```

```{r, message=FALSE, warning=FALSE}
# check for valid datasets 
filtered_datasets_sens <- check_filter_datasets(all_datasets, Y, treat, covar, bm)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGUREB16. Sensitivity Analyses Model B"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = all_plot_titles[idx]) 
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, all_plot_titles, "ldw_model_b")
```

The sensitivity analysis demonstrates identical results for LDW-Experimental, LDW-CPS1 and LDW-PSID1 as in model A and indicates once again that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of `re75`. However, compared to Model A, these estimates tend to shift upwards, exhibiting somewhat more positive values across variants. 

## Inspection of re74 and re75

### Correlation 
```{r, message=FALSE, warning=FALSE}
# correlation re74 and re75 
cor_results <- sapply(all_datasets, function(d) cor(d$re74, d$re75, use = "complete.obs"))
cor_table <- data.frame(Method = all_plot_titles, Correlation = cor_results)
knitr::kable(cor_table, caption = "Correlation between re74 and re75 across datasets", booktabs = TRUE) %>%
  kable_styling(full_width = TRUE)
```

## Summary
After reexamining model B, which uses the LaLonde-Dehejia-Wahba (LDW) data with a revised set of covariates, we find that changing the covariate set leads to noticeable shifts in effect estimates. For CPS-1, estimates are generally more consistent and remain close to the experimental benchmark, though standard errors are somewhat larger than in model A. In contrast, PSID-1 continues to show greater dispersion and substantially larger standard errors, highlighting persistent challenges with this observational sample.

Conditional and quantile treatment effect analyses confirm that, while some methods bring estimates closer to the experimental benchmark, considerable heterogeneity and estimator-dependent variability remain. Placebo tests using pre-treatment earnings as the outcome reveal that, despite some improvements, bias and deviation from the true effect persist. Sensitivity analyses indicate that most treatment effect estimates are fairly robust to increasing confounder strength, but some upward shifts are observed compared to model A.

Overall, these results reinforce the importance of overlap, covariate balance, and careful method selection, while underscoring the ongoing difficulty of recovering unbiased causal effects from observational data.