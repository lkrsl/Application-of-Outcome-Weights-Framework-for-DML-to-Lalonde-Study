# LaLonde-Dehejia-Wahba (LDW) Data
LaLonde (1986) evaluated the effect of the National Supported Work Demonstration (NSW) program on both female and male participants. While the female participants were drawn from the Aid to Families with Dependent Children (AFDC) program, the male participants were drawn from three other groups: former drug addicts, ex-criminal offenders, and high-school dropouts. LaLonde relied on two main data sources:
(1) CPS-SSA-1, based on Westat’s Matched Current Population Survey–Social Security Administration File for individuals under 55 matching specific criteria;
(2) PSID-1, based on Panel Study of Income Dynamics for household heads under 55 from specific years who were not retired in 1975, adjusted for factors like employment status and poverty level, resulting in four additional comparison groups;

Dehejia and Wahba (1999) constructed a subset of LaLonde's original data, retaining 62% of observations and restricting the focus to male participants based on their 1974 earnings. As the dataset was formed entirely on pretreatment information like employment records or month of assignment, treatment allocation was effectively independent of all pretreatment variables. Thus they concluded that this subset, known as the LaLonde-Dehejia-Wahba (LDW) data, constitutes a valid experimental sample.

The analysis in this section (2) and section 3 builds on the LDW data and considers in total three samples: 
(1) LDW-Experimental, consisting of 185 treated individuals and 280 controls from the experimental data;
(2) LDW-CPS1, which pairs the same treated sample with 15,992 controls from CPS-SSA-1;
(3) LDW-PSID1, featuring the same treated sample with 2,490 controls from PSID-1; 
In section 4, the analysis applies the same set of statistical tools to analyze a fourth sample as an additional demonstration:
(4) LaLonde male samples (1986).
In the last section, the analysis applies a reduced set of statistical tools to analyze a fifth sample again as an additional demonstration:
(5) LaLonde female samples (2017).

This section (2) covers model A, which includes the outcome variable 1978 earnings (`re78`) and adjusts for a set of covariates: age, education, race (black, hispanic), marital status, lack of high school degree, 1974 and 1975 earnings (`re74`, `re75`), and unemployment status in 1974 and 1975 (`u74`, `u75`). The model is defined by a regression formula for treatment assignment using these covariates. To improve covariate balance and overlap between treated and control groups, various methods are applied and are structured into five parts: Matching, Weighting, Truncation, Trimming and Combined Methods integrating these techniques. From these methods, the top 5 ranked are identified based on absolute standardized mean differences (SMDs) and effective sample size (ESS). The corresponding datasets are used to estimate the average treatment effect on the treated (ATT). Notably, the estimation incorporates the recently introduced augmented inverse probability weighting (AIPW) estimator, implemented via the `OutcomeWeights` R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify potential patterns in the contribution of individual observations to the ATT.  Placebo tests are then conducted using 1975 earnings (`re75`) as an outcome to assess potential biases and the validity of unconfoundedness assumptions. Finally, sensitivity analyses are performed to evaluate the robustness of treatment effect estimates to violations of these assumptions. 

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
# source functions
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lalonde.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Inspect data
```{r, message=FALSE, warning=FALSE}
# collect datasets in a list
data <- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid)

# inspect key metrics of each dataset
summary_stats <- inspect_data(data)
knitr::kable(summary_stats, caption = "Summary Statistics")
```

### Load and preprocess data

We merge the experimental controls from LDW-Experimental into LDW-CPS1 and LDW-PSID1 to augment the control groups with additional observations, following a similar approach as by @imbens2024.
```{r, message=FALSE, warning=FALSE}
# assigns 1 to the experimental controls
ldw_co$treat <- 1

# merge experimental data with CPS1 data
ldw_cps_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 observations)
  ldw_cps    # CPS1 data (16177 observations)
)

# merge experimental data with PSID1 data
ldw_psid_plus <- rbind.data.frame(
  ldw_co,    # experimental controls (260 observations)
  ldw_psid   # PSID1 data (2675 observations)
)

datasets <- list(ldw_cps_plus  = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus)

# inspect key metrics of each dataset
summary_stats_plus <- inspect_data(datasets)
knitr::kable(summary_stats_plus, caption = "Summary Statistics")
```

## Model A
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78" 
treat <- "treat" 
covar <- c("age", "education", "black", "hispanic", "married", 
           "nodegree", "re74", "re75", "u74", "u75") #re74 included
```

### Assessing overlap and covariate balance
#### Overlap
To identify the average causal effect under unconfoundedness (that asserts that the treatment assignment is independent of the potential outcomes), it must be ensured that one can estimate the average effect at every value for the covariates. Thus, overlaps between the treated and untreated units (meaning that for every combination of covariates, there are both treated and untreated units in the dataset) are required. The `assess_overlap()` function of @imbens2024 is used to assess overlaps in the propensity scores and to visualize results using histograms of their log-odds.

In a properly balanced experimental design, the distributions of the treatment group (red) and the control group (gray) would show considerable coverage.
```{r, fig.cap='FIGURE A1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1.',out.width='100%', fig.asp=0.5}
# assess overlap
ldw.ps <- assess_overlap(data = ldw, treat = treat, cov = covar)
ldw_cps.ps <- assess_overlap(data = ldw_cps, treat = treat, cov = covar) 
ldw_psid.ps <- assess_overlap(data = ldw_psid, treat = treat, cov = covar) 
```

As anticipated, LDW-Experimental exhibits an almost perfect overlap. In contrast, the observational datasets LDW-CPS1 and LDW-PSID1 show weak overlap. In particular, many treated units have propensity scores outside the range of the controls, while a large share of control units have propensity scores concentrated at very low log-odds.

Next, we examine the overlap of the expanded observational datasets. 
```{r, fig.cap='FIGURE A1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
# assess overlap
ldw_cps_plus.ps <- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) 
ldw_psid_plus.ps <- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) 
```

As expected, the datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS show an improved overlap compared to their non-plus states.

For the following analysis, we set up a model formula.
```{r, message=FALSE, warning=FALSE}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

#### Covariate balance

Initial covariate balance checks reveal the degree to which treatment and control groups differ on observed characteristics. We employ the `bal.tab()` function from the cobalt package to generate detailed balance statistics, complemented by visual summaries using `love.plot()`, which depicts standardized mean differences across covariates before and after adjustment.
```{r, warning=FALSE, message=FALSE, fig.cap='FIGURE A2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
love.plot(ldw, ldw_cps, treat, covar = covar, title = "LDW-CPS1")
love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = "LDW-CPS1-PLUS")
love.plot(ldw, ldw_psid, treat, covar = covar, title = "LDW-PSID1")
love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = "LDW-PSID1-PLUS")
```

Neither LDW-CPS1-PLUS nor LDW-PSID1-PLUS shows consistently improved covariate balance compared with their non-plus counterparts based on raw standardized mean differences. Although some specific covariates improve slightly, most show the same or increased imbalance.

<div class="callout-note">
For the subsequent analysis aimed at enhancing covariate balance and overlap, only the two datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS are used. The LDW-Experimental dataset is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 
</div>

## Improving primarily covariate balance
### Matching 

The purpose of matching is to create comparable treated and control groups by pairing units with similar covariate profiles, thereby reducing covariate imbalance and confounding bias. We apply several matching methods in the following.

#### Distance Matching
##### 1:1 Nearest neighbor matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with k=1, logistic propensity score and replacement
m.out.cps_plus.nearest <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", replace = TRUE)
m.out.psid_plus.nearest <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", replace = TRUE)
```

##### k:1 matching (k=2)
```{r, message=FALSE, warning=FALSE}
k<-2
# perform nearest neighbor matching with k=2, logistic propensity score and replacement
m.out.cps_plus.k2 <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid_plus.k2 <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### k:1 matching (k=3)
```{r, message=FALSE, warning=FALSE}
k<-3
# perform nearest neighbor matching with k=3, logistic propensity score and replacement
m.out.cps_plus.k3 <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
m.out.psid_plus.k3 <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", ratio = k, replace = TRUE)
```

##### Caliper matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score 
m.out.cps_plus.caliper <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
m.out.psid_plus.caliper <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", caliper = 0.1, replace = TRUE)
```

##### Common support restriction matching
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with exclusion of units outside common support
m.out.cps_plus.cs <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
m.out.psid_plus.cs <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", discard = "both", replace = TRUE)
```

##### Mahalanobis distance matching (mahvars) 
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching using mahalanobis distance on selected covariates
m.out.cps_plus.mahvars <- matchit(model, data = ldw_cps_plus, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re74 + re75, replace = FALSE)
m.out.psid_plus.mahvars <- matchit(model, data = ldw_psid_plus, method = "nearest", distance = "logit", caliper = 0.2, mahvars = ~ age + education + re74 + re75, replace = FALSE)
```

##### Optimal pair matching
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
m.out.cps_plus.optimal_pair <- matchit(model, data = ldw_cps_plus, method = "optimal", distance = "logit")
m.out.psid_plus.optimal_pair <- matchit(model, data = ldw_psid_plus, method = "optimal", distance = "logit")
```

##### Optimal full matching
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
m.out.cps_plus.optimal_full <- matchit(model, data = ldw_cps_plus, method = "full", distance = "logit")
m.out.psid_plus.optimal_full <- matchit(model, data = ldw_psid_plus, method = "full", distance = "logit")
```

##### Generalized full matching
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios 
m.out.cps_plus.general_full <- matchit(model, data = ldw_cps_plus, method = "quick", distance = "logit")
m.out.psid_plus.general_full <- matchit(model, data = ldw_psid_plus, method = "quick", distance = "logit")
```

##### Genetic matching
```{r, message=FALSE, warning=FALSE}
# perform genetic matching 
m.out.cps_plus.genetic <- matchit(model, data = ldw_cps_plus, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
m.out.psid_plus.genetic <- matchit(model, data = ldw_psid_plus, method = "genetic", distance = "logit", replace = TRUE, pop.size = 100)
```

#### Stratum matching
##### Exact matching (exact)
Strata = unique covariate profiles (raw covariates)
```{r, message=FALSE, warning=FALSE}
# match units exactly by raw covariate profiles 
m.out.cps_plus.exact <- matchit(model, data = ldw_cps_plus, method = "exact")
m.out.psid_plus.exact <- matchit(model, data = ldw_psid_plus, method = "exact")
```

##### Coarsened matching (cem)
Strata = coarsened versions of covariates
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
m.out.cps_plus.cem <- matchit(model, data = ldw_cps_plus, method = "cem")
m.out.psid_plus.cem <- matchit(model, data = ldw_psid_plus, method = "cem")
```

##### Subclassification 
Strata = bins of the propensity score
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
m.out.cps_plus.subcl <- matchit(model, data = ldw_cps_plus, method = "subclass", subclass = 5)
m.out.psid_plus.subcl <- matchit(model, data = ldw_psid_plus, method = "subclass", subclass = 5)
```

#### Pure subset selection
##### Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units
m.out.cps_plus.card <- matchit(model, data = ldw_cps_plus, method = "cardinality", tols = 0.1, ratio = 1)
m.out.psid_plus.card <- matchit(model, data = ldw_psid_plus, method = "cardinality", tols = 0.1, ratio = 1)
```

##### Profile matching
```{r, message=FALSE, warning=FALSE}
# select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact
m.out.cps_plus.profile <- matchit(model, data = ldw_cps_plus, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs")
m.out.psid_plus.profile <- matchit(model, data = ldw_psid_plus, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, solver = "highs")
```

### Weighting

The purpose of weighting is to reweight the units in order to create a synthetic population in which the distributions of covariates is balanced between treatment and control groups. In the following, several weighting methods are applied.

#### Inverse probability weights (IPW)
```{r, message=FALSE, warning=FALSE}
# calculate inverse probability weights (IPW) for ATE by assigning weight = 1/PS to treated units and weight = 1/(1-PS) to untreated units
ldw_cps_plus$ipw_weight <- create_iptw_weights(ldw_cps_plus, treat, covar)
ldw_psid_plus$ipw_weight <- create_iptw_weights(ldw_psid_plus, treat, covar)
```

#### Standardized mortality ratio (SMR) treated weights
```{r, message=FALSE, warning=FALSE}
# calculate weights for ATT by assigning weight = 1 to treated units and weight = PS/(1-PS) to control units
ldw_cps_plus$smr_weight <- create_smr_weights(ldw_cps_plus, treat, covar, "ATT")
ldw_psid_plus$smr_weight <- create_smr_weights(ldw_psid_plus, treat, covar, "ATT")
```

#### Matching weights
```{r, message=FALSE, warning=FALSE}
# calculate matching weights by assigning weight = min(PS, 1-PS)/PS to treated units and min(PS, 1-PS)/(1-PS) to controls
ldw_cps_plus$opt_weight <- create_matching_weights(ldw_cps_plus, treat, covar)
ldw_psid_plus$opt_weight <- create_matching_weights(ldw_psid_plus, treat, covar)
```

#### Overlap weights
```{r, message=FALSE, warning=FALSE}
# calculate overlap weights by assigning weight = 1-PS to treated units and weight = PS, emphasizing units with propensity scores near 0.5
ldw_cps_plus$overlap_weight <- create_overlap_weights(ldw_cps_plus, treat, covar)
ldw_psid_plus$overlap_weight <- create_overlap_weights(ldw_psid_plus, treat, covar)
```

#### Entropy weights
```{r, message=FALSE, warning=FALSE}
# calculate entropy weights by assigning weight = -[PS × log(PS) + (1 − PS) × log(1 − PS)]/PS to treated units and -[PS × log(PS) + (1 − PS) × log(1 − PS)]/(1 − PS) to control units
ldw_cps_plus$ebal_weight <- create_entropy_weights(ldw_cps_plus, treat, covar)
ldw_psid_plus$ebal_weight <- create_entropy_weights(ldw_psid_plus, treat, covar)
```

## Improving primarily overlap

Truncation aims at limiting the influence of extreme weights by capping them at a specified threshold. This helps to reduce variance and improve the stability of causal effect estimates. In the following, several truncation methods are applied.

### Truncation
```{r, message=FALSE, warning=FALSE}
# list weight columns to apply truncation 
weight_columns <- c("ipw_weight", "smr_weight", "opt_weight", "overlap_weight", "ebal_weight")
```

#### Fixed maximum value truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights by imposing a minimum and maximum threshold
ldw_cps_plus.fixed <- ldw_cps_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps_plus.fixed)) {
    ldw_cps_plus.fixed <- truncate_weights_fixed(ldw_cps_plus.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) 
  }
}

ldw_psid_plus.fixed <- ldw_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid_plus.fixed)) {
    ldw_psid_plus.fixed <- truncate_weights_fixed(ldw_psid_plus.fixed, weight_col = wcol, lower = 0.025, upper = 0.975)
  }
}
```

#### At percentile truncation
```{r, message=FALSE, warning=FALSE}
# truncate weights such that values below the 5th percentile and above the 95th percentile are capped
ldw_cps_plus.percent <- ldw_cps_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps_plus.percent)) {
    ldw_cps_plus.percent <- truncate_weights_percentile(ldw_cps_plus.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}

ldw_psid_plus.percent <- ldw_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid_plus.percent)) {
    ldw_psid_plus.percent <- truncate_weights_percentile(ldw_psid_plus.percent, weight_col = wcol, lower = 0.01, upper = 0.99)
  }
}
```

#### Adaptive weight truncation

We first inspect the variance of the weights. If variance is zero, adaptive weight truncation is not meaningful. 
```{r, message=FALSE, warning=FALSE}
# inspect variance of weights
cps_results <- list()
psid_results <- list()

for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps_plus)) {
    cps_results[[paste0("cps_", wcol)]] <- check_weights(ldw_cps_plus, wcol)
  } else {
    warning(paste("Column", wcol, "not found in ldw_cps_plus"))
  }
}

for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid_plus)) {
    psid_results[[paste0("psid_", wcol)]] <- check_weights(ldw_psid_plus, wcol)
  } else {
    warning(paste("Column", wcol, "not found in ldw_psid_plus"))
  }
}

var_cps_table <- bind_rows(cps_results)
var_psid_table <- bind_rows(psid_results)

knitr::kable(var_cps_table, caption = "Variance of Weights (CPS)")
knitr::kable(var_psid_table, caption = "Variance of Weights (PSID)")
```

Regarding above results, we apply adaptive weight truncation to all weights, where it may help mitigate the influence of extreme weights. 
```{r, message=FALSE, warning=FALSE}
# truncate adaptively at mean + 3 standard deviations 
ldw_cps_plus.adapt <- ldw_cps_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_cps_plus.adapt)) {
    ldw_cps_plus.adapt <- truncate_weights_adaptive(ldw_cps_plus.adapt, weight_col = wcol, c = 3)
  }
}

ldw_psid_plus.adapt <- ldw_psid_plus
for (wcol in weight_columns) {
  if (wcol %in% names(ldw_psid_plus.adapt)) {
    ldw_psid_plus.adapt <- truncate_weights_adaptive(ldw_psid_plus.adapt, weight_col = wcol, c = 3)
  }
}
```

### Trimming 

The purpose of trimming is to remove units whose propensity scores are too dissimilar from the opposite group, thereby improving covariate balance between treated and control groups. We employ several trimming methods below.

#### Propensity score threshold trimming (similar to tutorial by @imbens2024)
```{r, message=FALSE, warning=FALSE}
# apply trimming with thresholds 0.9 and 0.8 
ldw_cps_trim <- ps_trim(ldw_cps_plus.ps, threshold = 0.9)
ldw_psid_trim <- ps_trim(ldw_psid_plus.ps, threshold = 0.8)

# exclude experimental controls, subset trimmed data appropriately
ldw_cps.trim_match <- subset(ldw_cps_trim, sample %in% c(1,3) & ps_assoverlap)
ldw_psid.trim_match <- subset(ldw_psid_trim, sample %in% c(1,4) & ps_assoverlap)

# re-assign treat variable for controls in sample 3 or 4 (non-treated group)
ldw_cps.trim_match$treat[ldw_cps.trim_match$sample == 3] <- 0
ldw_psid.trim_match$treat[ldw_psid.trim_match$sample == 4] <- 0

# re-estimate propensity scores on trimmed data and perform 1:1 matching
ldw_cps.trim_match <- psmatch(data = ldw_cps.trim_match, Y = "re78", treat = "treat", cov = covar)
ldw_psid.trim_match <- psmatch(data = ldw_psid.trim_match, Y = "re78", treat = "treat", cov = covar)
```

#### Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
ldw_cps_plus.common   <- common_range_trim(ldw_cps_plus.ps)
ldw_psid_plus.common  <- common_range_trim(ldw_psid_plus.ps)
```

#### Propensity score trimming (Crump)
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
ldw_cps_plus.crump  <- crump_trim(ldw_cps_plus.ps, lower = 0.1, upper = 0.9)
ldw_psid_plus.crump <- crump_trim(ldw_psid_plus.ps, lower = 0.1, upper = 0.9)
```

#### Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
ldw_cps_plus.stuermer  <- stuermer_trim(ldw_cps_plus.ps)
ldw_psid_plus.stuermer <- stuermer_trim(ldw_psid_plus.ps)
```

#### Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
ldw_cps_plus.walker   <- walker_trim(ldw_cps_plus.ps)
ldw_psid_plus.walker  <- walker_trim(ldw_psid_plus.ps)
```

## Integrated methods

The purpose of combining trimming and weighting methods is to leverage the strengths of both approaches for causal effect estimation. Trimming enhances overlap and reduces the influence of outliers by excluding units with extreme or non-comparable propensity scores, while weighting further adjusts for remaining covariate imbalance among the retained units. 
```{r, message=FALSE, warning=FALSE}
# list trimming methods
trim_names <- c("ps_threshold", "common_range", "stuermer", "walker", "crump")
trimmed_cps  <- list(ps_threshold = ldw_cps_trim, common_range = ldw_cps_plus.common, stuermer = ldw_cps_plus.stuermer, walker = ldw_cps_plus.walker, crump = ldw_cps_plus.crump)
trimmed_psid <- list(ps_threshold = ldw_psid_trim, common_range = ldw_psid_plus.common, stuermer = ldw_psid_plus.stuermer, walker = ldw_psid_plus.walker, crump = ldw_psid_plus.crump)
```

#### IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply inverse probability weighting (IPW) with trimming and attach IPW weights
ipw_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "ipw_weight")),
  trim_names
)
ipw_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "ipw_weight")),
  trim_names
)
```

#### SMR treated weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply standardized mortality ratio (SMR) weighting with trimming and attach SMR weights
smr_treat_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "smr_weight")),
  trim_names
)
smr_treat_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "smr_weight")),
  trim_names
)
```

#### Overlap weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply overlap weighting with trimming and attach overlap weights
ov_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "overlap_weight")),
  trim_names
)
ov_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "overlap_weight")),
  trim_names
)
```

#### Entropy weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump
```{r, message=FALSE, warning=FALSE}
# apply entropy balancing weights with trimming and attach entropy weights
entropy_comb.cps_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, "ebal_weight")),
  trim_names
)
entropy_comb.psid_plus <- setNames(
  lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, "ebal_weight")),
  trim_names
)
```

## Reassessing methods

We now systematically reassess all methods described above by evaluating covariate balance and sample representativeness. Specifically, we examine SMDs and ESS for each approach and use visual diagnostics—such as love plots and histograms—to assess covariate balance and overlap between treated and control groups.

### Matching
```{r, message=FALSE, warning=FALSE}
# list all matching methods
methods.cps_plus <- list(
  nn = m.out.cps_plus.nearest,
  k2 = m.out.cps_plus.k2,
  k3 = m.out.cps_plus.k3,
  caliper = m.out.cps_plus.caliper,
  cS = m.out.cps_plus.cs,
  mahvars = m.out.cps_plus.mahvars,
  optimal_pair = m.out.cps_plus.optimal_pair,
  optimal_full = m.out.cps_plus.optimal_full,
  gen_full = m.out.cps_plus.general_full,
  genetic = m.out.cps_plus.genetic,
  exact = m.out.cps_plus.exact,
  cem = m.out.cps_plus.cem,
  card = m.out.cps_plus.card,
  profile = m.out.cps_plus.profile,
  subcl = m.out.cps_plus.subcl
)

methods.psid_plus <- list(
  nn = m.out.psid_plus.nearest,
  k2 = m.out.psid_plus.k2,
  k3 = m.out.psid_plus.k3,
  caliper = m.out.psid_plus.caliper,
  cs = m.out.psid_plus.cs,
  mahvars = m.out.psid_plus.mahvars,
  optimal_pair = m.out.psid_plus.optimal_pair,
  optimal_full = m.out.psid_plus.optimal_full,
  gen_full = m.out.psid_plus.general_full,
  genetic = m.out.psid_plus.genetic,
  exact = m.out.psid_plus.exact,
  cem = m.out.psid_plus.cem,
  card = m.out.psid_plus.card,
  profile = m.out.psid_plus.profile,
  subcl = m.out.psid_plus.subcl
)
```

```{r, message=FALSE, warning=FALSE}
# calculate balance statistics 
bal.cps_plus <- cobalt::bal.tab(model, data = ldw_cps_plus, un = TRUE, weights = methods.cps_plus, s.d.denom = "treated")
bal.psid_plus <- cobalt::bal.tab(model, data = ldw_psid_plus, un = TRUE, weights = methods.psid_plus, s.d.denom = "treated")
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_matchit.cps_plus <- compute_abs_smd_matchit(methods.cps_plus)
smd_matchit.psid_plus <- compute_abs_smd_matchit(methods.psid_plus)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_matchit.cps_plus <- compute_ess_matchit(bal.cps_plus)
ess_matchit.psid_plus <- compute_ess_matchit(bal.psid_plus)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGURE A3.'}
# visualize covariate balance 
plot_matchit(methods.cps_plus, "LDW-CPS1-PLUS")
plot_matchit(methods.psid_plus, "LDW-PSID1-PLUS")
```

### Weighting
```{r, message=FALSE, warning=FALSE}
# list all weights
weight.cps_plus <- list(
  ipw = ldw_cps_plus$ipw_weight,
  smr_tr = ldw_cps_plus$smr_weight,
  mw = ldw_cps_plus$opt_weight,
  ow = ldw_cps_plus$overlap_weight,
  ew = ldw_cps_plus$ebal_weight
)

weight.psid_plus <- list(
  ipw = ldw_psid_plus$ipw_weight,
  smr_tr = ldw_psid_plus$smr_weight,
  mw = ldw_psid_plus$opt_weight,
  ow = ldw_psid_plus$overlap_weight,
  ew = ldw_psid_plus$ebal_weight
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_weight.cps_plus <- compute_abs_smd_weight(ldw_cps_plus, "treat", covar, weight_columns)
smd_weight.psid_plus <- compute_abs_smd_weight(ldw_psid_plus, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_weight.cps_plus <- compute_ess_weight(ldw_cps_plus, "treat", covar, weight_columns)
ess_weight.psid_plus <- compute_ess_weight(ldw_psid_plus, "treat", covar, weight_columns)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGURE A4.'}
# visualize covariate balance
plot_weighting_methods(ldw_cps_plus, "treat", covar, weight.cps_plus, "LDW-CPS1-PLUS") 
plot_weighting_methods(ldw_psid_plus, "treat", covar, weight.psid_plus, "LDW-PSID1-PLUS")
```

### Truncation
```{r, message=FALSE, warning=FALSE}
# list truncation methods
trunc.cps_plus <- list(
  fix_max_value_trunc.cps_plus = ldw_cps_plus.fixed,
  at_perc_trunc.cps_plus = ldw_cps_plus.percent,
  adap_weight_trunc.cps_plus = ldw_cps_plus.adapt
)

trunc.psid_plus <- list(
  fix_max_value_trunc.psid_plus = ldw_psid_plus.fixed,
  at_perc_trunc.psid_plus = ldw_psid_plus.percent,
  adap_weight_trunc.psid_plus = ldw_psid_plus.adapt
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trunc.cps_plus <- compute_abs_smd_trunc(trunc.cps_plus, "treat", covar, weight_columns)
smd_trunc.psid_plus <- compute_abs_smd_trunc(trunc.psid_plus, "treat", covar, weight_columns)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trunc.cps_plus <- compute_ess_trunc(trunc.cps_plus, "treat", covar, weight_columns)
ess_trunc.psid_plus <- compute_ess_trunc(trunc.psid_plus, "treat", covar, weight_columns)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGURE A5.'}
# visualize covariate balance
plot_trunc_methods(trunc.cps_plus, "treat", covar, weight_columns, "LDW-CPS1-PLUS")
plot_trunc_methods(trunc.psid_plus, "treat", covar, weight_columns, "LDW-PSID1-PLUS")
```

### Trimming
```{r, message=FALSE, warning=FALSE}
# list trimming objects
trim.cps_plus <- list(
  original = ldw_cps_plus,  
  ps_threshold = ldw_cps.trim_match,  
  common_range = ldw_cps_plus.common,      
  crump = ldw_cps_plus.crump,      
  stuermer = ldw_cps_plus.stuermer,     
  walker = ldw_cps_plus.walker    
)

trim.psid_plus <- list(
  original = ldw_psid_plus,
  ps_threshold = ldw_psid.trim_match,
  common_range = ldw_psid_plus.common,
  crump = ldw_psid_plus.crump,
  stuermer = ldw_psid_plus.stuermer,
  walker = ldw_psid_plus.walker
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_trim.cps_plus <- compute_abs_smd_trim(trim.cps_plus, "treat", covar)
smd_trim.psid_plus <- compute_abs_smd_trim(trim.psid_plus, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_trim.cps_plus <- compute_ess_trim(trim.cps_plus, "treat", covar)
ess_trim.psid_plus <- compute_ess_trim(trim.psid_plus, "treat", covar)
```

#### Visuals
```{r, warning=FALSE, message=FALSE, fig.cap='FIGURE A6.'}
# visualize overlap
plot_trim(trim.cps_plus, treat, covar)
plot_trim(trim.psid_plus, treat, covar)
```

```{r, warning=FALSE, message=FALSE, fig.cap='FIGURE A7.'}
# visualize covariate balance
love.plot(ldw_cps, ldw_cps.trim_match, treat, covar = covar, title = "LDW-CPS1-PLUS - propensity threshold trimming")
love.plot(ldw_cps, ldw_cps_plus.common, treat, covar, title = "LDW-CPS1-PLUS - common range trimming")
love.plot(ldw_cps, ldw_cps_plus.crump,  treat, covar, title = "LDW-CPS1-PLUS - crump trimming") 
love.plot(ldw_cps, ldw_cps_plus.stuermer, treat, covar, title = "LDW-CPS1-PLUS - stuermer trimming")
love.plot(ldw_cps, ldw_cps_plus.walker,  treat, covar, title = "LDW-CPS1-PLUS - walker trimming")

love.plot(ldw_psid, ldw_psid.trim_match, treat, covar = covar, title = "LDW-PSID1-PLUS - propensity threshold trimming")
love.plot(ldw_psid, ldw_psid_plus.common, treat, covar, title = "LDW-PSID1-PLUS - common range trimming")
love.plot(ldw_psid, ldw_psid_plus.crump, treat, covar, title = "LDW-PSID1-PLUS - crump trimming")
love.plot(ldw_psid, ldw_psid_plus.stuermer, treat, covar, title = "LDW-PSID1-PLUS - stuermer trimming")
love.plot(ldw_psid, ldw_psid_plus.walker,  treat, covar, title = "LDW-PSID1-PLUS - walker trimming")
```

## Integrated methods
```{r, message=FALSE, warning=FALSE}
# list all combined method results
comb_meth.cps_plus <- list(
  ipw = ipw_comb.cps_plus,
  smr_treated = smr_treat_comb.cps_plus,
  overlap = ov_comb.cps_plus,
  entropy = entropy_comb.cps_plus
)

comb_meth.psid_plus <- list(
  ipw = ipw_comb.psid_plus,
  smr_treated = smr_treat_comb.psid_plus,
  overlap = ov_comb.psid_plus,
  entropy = entropy_comb.psid_plus
)
```

#### SMD
```{r, message=FALSE, warning=FALSE}
# compute SMD
smd_all_comb_meth.cps_plus <- compute_smd_all_datasets(comb_meth.cps_plus, "treat", covar)
smd_all_comb_meth.psid_plus <- compute_smd_all_datasets(comb_meth.psid_plus, "treat", covar)
```

#### ESS
```{r, message=FALSE, warning=FALSE}
# compute ESS
ess_all_comb_meth.cps_plus <- compute_ess_all_datasets(comb_meth.cps_plus, "treat", covar)
ess_all_comb_meth.psid_plus <- compute_ess_all_datasets(comb_meth.psid_plus, "treat", covar)
```

#### Visuals
```{r, message=FALSE, warning=FALSE, fig.cap='FIGURE A8.'}
# visualize overlap
plot_comb_overlap(comb_meth.cps_plus, comb_meth.psid_plus, "treat", covar, prefix_cps = "LDW-CPS1", prefix_psid = "LDW-PSID1")
```

```{r, message=FALSE, warning=FALSE, fig.cap='FIGURE A9.'} 
# visualize covariate balance
plot_comb_love_plots(comb_meth.cps_plus, comb_meth.psid_plus, "treat", covar, prefix_cps = "LDW-CPS1", prefix_psid = "LDW-PSID1")
```

```{r, message=FALSE, warning=FALSE}
# save results
save_comb_hist(comb_meth.cps_plus, comb_meth.psid_plus, "treat", covar, prefix = "model_a")
save_comb_loveplots(comb_meth.cps_plus, comb_meth.psid_plus, "treat", covar, prefix = "model_a")
```

## Top methods and datasets

To identify the top five methods for each observational dataset, we first combine all results for SMDs and ESS into a single data frame for each dataset. This allows for a comprehensive comparison across all methods.
```{r, message=FALSE, warning=FALSE}
# combine all results
all_cps_plus <- combine_results("cps_plus")
all_psid_plus <- combine_results("psid_plus") 
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_cps_plus, "CPS1_PLUS_all_results_model_a")
save_csv(all_psid_plus, "PSID1_PLUS_all_results_model_a")
```

Next, we evaluate each method by constructing a final score that is build on two separate scores equally weighted:
- `smd_score` rescales the mean absolute SMD to a 0-1 range, where a lower value leads to a higher score
- `ess_score` measures sample size effectiveness by combining ESS of treated and control groups and normalizing between 0 and 1.
```{r, message=FALSE, warning=FALSE}
ranked_cps_plus  <- assess_methods(all_cps_plus)
ranked_psid_plus <- assess_methods(all_psid_plus)
```

Based on the final scores, we rank all methods and select the top five for each dataset.
```{r, message=FALSE, warning=FALSE}
# get top 5 methods 
top5_methods.cps_plus <- get_top_methods(ranked_cps_plus, top_n = 5)
top5_methods.psid_plus <- get_top_methods(ranked_psid_plus, top_n = 5)

# print results
top5_methods_df.cps_plus <- ranked_cps_plus %>% arrange(desc(Score)) %>% head(5)
top5_methods_df.psid_plus <- ranked_psid_plus %>% arrange(desc(Score)) %>% head(5)
knitr::kable(top5_methods_df.cps_plus, caption = "Top 5 Methods for CPS1-PLUS", booktabs = TRUE)
knitr::kable(top5_methods_df.psid_plus, caption = "Top 5 Methods for PSID1-PLUS", booktabs = TRUE)
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(top5_methods.cps_plus, "CPS1_PLUS_top5_methods_model_a")
save_csv(top5_methods.psid_plus, "PSID1_PLUS_top5_methods_model_a")
```

For estimation, we match the selected top method names back to their corresponding datasets, objects or vectors and construct final datasets. 
```{r, message=FALSE, warning=FALSE}
dataset_list_cps <- list(
  "All" = ldw_cps_plus,
  "original" = ldw_cps_plus,
  "nn" = m.out.cps_plus.nearest, 
  "caliper" = m.out.cps_plus.caliper,
  "card" = m.out.cps_plus.card,
  "cem" = m.out.cps_plus.cem,
  "cS" = m.out.cps_plus.cs,
  "k2"  = m.out.cps_plus.k2,
  "k3" = m.out.cps_plus.k3,
  "mahvars" = m.out.cps_plus.mahvars,
  "optimal_full" = m.out.cps_plus.optimal_full,
  "optimal_pair" = m.out.cps_plus.optimal_pair,
  "gen_full" = m.out.cps_plus.general_full,
  "genetic" = m.out.cps_plus.genetic,
  "exact" = m.out.cps_plus.exact,
  "subcl" = m.out.cps_plus.subcl,
  "profile"  = m.out.cps_plus.profile,
  "ipw_weight" = ldw_cps_plus$ipw_weight, 
  "smr_weight" = ldw_cps_plus$smr_weight,
  "opt_weight" = ldw_cps_plus$opt_weight,
  "overlap_weight" = ldw_cps_plus$overlap_weight,
  "ebal_weight" = ldw_cps_plus$ebal_weight,
  "fix_max_value_trunc_ebal_weight" = ldw_cps_plus.fixed,
  "fix_max_value_trunc_ipw_weight" = ldw_cps_plus.fixed,
  "fix_max_value_trunc_opt_weight" = ldw_cps_plus.fixed,
  "fix_max_value_trunc_overlap_weight" = ldw_cps_plus.fixed,
  "fix_max_value_trunc_smr_weight" = ldw_cps_plus.fixed,
  "at_perc_trunc_ebal_weight" = ldw_cps_plus.percent,
  "at_perc_trunc_ipw_weight"  = ldw_cps_plus.percent,
  "at_perc_trunc_opt_weight"  = ldw_cps_plus.percent,
  "at_perc_trunc_overlap_weight" = ldw_cps_plus.percent,
  "at_perc_trunc_smr_weight" = ldw_cps_plus.percent,
  "adap_weight_trunc_ebal_weight" = ldw_cps_plus.adapt,
  "adap_weight_trunc_ipw_weight" = ldw_cps_plus.adapt,
  "adap_weight_trunc_opt_weight" = ldw_cps_plus.adapt,
  "adap_weight_trunc_overlap_weight" = ldw_cps_plus.adapt,
  "adap_weight_trunc_smr_weight" = ldw_cps_plus.adapt,
  "ps_threshold" = ldw_cps.trim_match,
  "common_range" = ldw_cps_plus.common,
  "stuermer" = ldw_cps_plus.stuermer,
  "walker" = ldw_cps_plus.walker,
  "crump" = ldw_cps_plus.crump,
  "ipw_common_range" = ipw_comb.cps_plus[[1]],
  "ipw_crump" = ipw_comb.cps_plus[[2]],
  "ipw_ps_threshold" = ipw_comb.cps_plus[[3]],
  "ipw_stuermer" = ipw_comb.cps_plus[[4]],
  "ipw_walker" = ipw_comb.cps_plus[[5]],
  "smr_treated_common_range" = smr_treat_comb.cps_plus[[1]],
  "smr_treated_crump" = smr_treat_comb.cps_plus[[2]],
  "smr_treated_ps_threshold" = smr_treat_comb.cps_plus[[3]],
  "smr_treated_stuermer" = smr_treat_comb.cps_plus[[4]],
  "smr_treated_walker" = smr_treat_comb.cps_plus[[5]],
  "overlap_common_range" = ov_comb.cps_plus[[1]],
  "overlap_crump" = ov_comb.cps_plus[[2]],
  "overlap_ps_threshold" = ov_comb.cps_plus[[3]],
  "overlap_stuermer" = ov_comb.cps_plus[[4]],
  "overlap_walker" = ov_comb.cps_plus[[5]],
  "entropy_common_range" = entropy_comb.cps_plus[[1]],
  "entropy_crump" = entropy_comb.cps_plus[[2]],
  "entropy_ps_threshold" = entropy_comb.cps_plus[[3]],
  "entropy_stuermer" = entropy_comb.cps_plus[[4]],
  "entropy_walker" = entropy_comb.cps_plus[[5]])

dataset_list_psid <- list(
  "All" = ldw_psid_plus, 
  "original" = ldw_psid_plus, 
  "nn" = m.out.psid_plus.nearest, 
  "caliper"= m.out.psid_plus.caliper,
  "card" = m.out.psid_plus.card,
  "cem" = m.out.psid_plus.cem,
  "cS" = m.out.psid_plus.cs,
  "k2" = m.out.psid_plus.k2,
  "k3" = m.out.psid_plus.k3,
  "mahvars" = m.out.psid_plus.mahvars,
  "optimal_full" = m.out.psid_plus.optimal_full,
  "optimal_pair" = m.out.psid_plus.optimal_pair,
  "gen_full" = m.out.psid_plus.general_full,
  "genetic" = m.out.psid_plus.genetic,
  "exact" = m.out.psid_plus.exact,
  "subcl" = m.out.psid_plus.subcl,
  "profile" = m.out.psid_plus.profile,
  "ipw_weight" = ldw_psid_plus$ipw_weight, 
  "smr_weight" = ldw_psid_plus$smr_weight,
  "opt_weight" = ldw_psid_plus$opt_weight,
  "overlap_weight" = ldw_psid_plus$overlap_weight,
  "ebal_weight" = ldw_psid_plus$ebal_weight,
  "fix_max_value_trunc_ebal_weight" = ldw_psid_plus.fixed,
  "fix_max_value_trunc_ipw_weight" = ldw_psid_plus.fixed,
  "fix_max_value_trunc_opt_weight" = ldw_psid_plus.fixed,
  "fix_max_value_trunc_overlap_weight" = ldw_psid_plus.fixed,
  "fix_max_value_trunc_smr_weight" = ldw_psid_plus.fixed,
  "at_perc_trunc_ebal_weight" = ldw_psid_plus.percent,
  "at_perc_trunc_ipw_weight" = ldw_psid_plus.percent,
  "at_perc_trunc_opt_weight" = ldw_psid_plus.percent,
  "at_perc_trunc_overlap_weight" = ldw_psid_plus.percent,
  "at_perc_trunc_smr_weight" = ldw_psid_plus.percent,
  "adap_weight_trunc_ebal_weight" = ldw_psid_plus.adapt,
  "adap_weight_trunc_ipw_weight" = ldw_psid_plus.adapt,
  "adap_weight_trunc_opt_weight" = ldw_psid_plus.adapt,
  "adap_weight_trunc_overlap_weight" = ldw_psid_plus.adapt,
  "adap_weight_trunc_smr_weight" = ldw_psid_plus.adapt,
  "ps_threshold" = ldw_psid.trim_match,
  "common_range" = ldw_psid_plus.common,
  "stuermer" = ldw_psid_plus.stuermer,
  "walker" = ldw_psid_plus.walker,
  "crump" = ldw_psid_plus.crump,
  "ipw_common_range" = ipw_comb.psid_plus[[1]],
  "ipw_crump"= ipw_comb.psid_plus[[2]],
  "ipw_ps_threshold"= ipw_comb.psid_plus[[3]],
  "ipw_stuermer"= ipw_comb.psid_plus[[4]],
  "ipw_walker" = ipw_comb.psid_plus[[5]],
  "smr_treated_common_range" = smr_treat_comb.psid_plus[[1]],
  "smr_treated_crump"= smr_treat_comb.psid_plus[[2]],
  "smr_treated_ps_threshold" = smr_treat_comb.psid_plus[[3]],
  "smr_treated_stuermer" = smr_treat_comb.psid_plus[[4]],
  "smr_treated_walker" = smr_treat_comb.psid_plus[[5]],
  "overlap_common_range" = ov_comb.psid_plus[[1]],
  "overlap_crump" = ov_comb.psid_plus[[2]],
  "overlap_ps_threshold"  = ov_comb.psid_plus[[3]],
  "overlap_stuermer" = ov_comb.psid_plus[[4]],
  "overlap_walker"= ov_comb.psid_plus[[5]],
  "entropy_common_range" = entropy_comb.psid_plus[[1]],
  "entropy_crump" = entropy_comb.psid_plus[[2]],
  "entropy_ps_threshold" = entropy_comb.psid_plus[[3]],
  "entropy_stuermer" = entropy_comb.psid_plus[[4]],
  "entropy_walker" = entropy_comb.psid_plus[[5]])
```

```{r, message=FALSE, warning=FALSE}
# create datasets corresponding to the top 5 methods for each dataset
top5_datasets.cps_plus <- create_top5_datasets(dataset_list_cps, top5_methods.cps_plus)
top5_datasets.psid_plus <- create_top5_datasets(dataset_list_psid, top5_methods.psid_plus)
```

```{r, message=FALSE, warning=FALSE}
# save datasets into .RData files
save_top5_individual_files(dataset_list_cps, top5_methods.cps_plus, prefix = "model_a_cps")
save_top5_individual_files(dataset_list_psid, top5_methods.psid_plus, prefix = "model_a_psid")
```

## Estimating
### Average treatment effect on the treated (ATT)

Next, we estimate the average treatment effect on the treated (ATT) using both the LDW-Experimental sample, the non-plus observational datasets and the newly constructed top five ranked samples for each observational dataset, LDW-CPS1 and LDW-PSID1, that achieved highest score results. 

We employ a broad set of estimators, including difference-in-means, regression, the Oaxaca-Blinder estimator, generalized random forests (GRF) as an outcome model, 1:5 nearest neighbor matching with bias correction, inverse probability weighting (IPW) with GRF-based propensity scores, covariate balancing propensity score (CBPS), entropy balancing, double/debiased machine learning using elastic net, and augmented inverse probability weighting (AIPW) via GRF. We also incorporate the recently introduced estimand-specific AIPW estimator implemented through an expansion of the `OutcomeWeights` R package by Knaus and Pfleiderer (2024).

We utilize the `estimate_all()` and `plot_coef()` functions as defined by @imbens2024.
```{r, message=FALSE, warning=FALSE}
# estimate ATT
out1 <- estimate_all(ldw, "re78", "treat", covar)
out2 <- estimate_all(ldw_cps, "re78", "treat", covar)
out3 <- estimate_all(ldw_psid, "re78", "treat", covar)
```

```{r, message=FALSE, warning=FALSE}
out4 <- estimate_all(ldw_cps.trim_match, "re78", "treat", covar) 
out5 <- estimate_all(ldw_psid.trim_match, "re78", "treat", covar)
```

```{r, message=FALSE, warning=FALSE}
out.cps_plus <- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, "re78", "treat", covar))
out.psid_plus <- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, "re78", "treat", covar))

out6 <- out.cps_plus[[1]]
out7 <- out.cps_plus[[2]]
out8 <- out.cps_plus[[3]]
out9 <- out.cps_plus[[4]]
out10 <- out.cps_plus[[5]]

out11 <- out.psid_plus[[1]]
out12 <- out.psid_plus[[2]]
out13 <- out.psid_plus[[3]]
out14 <- out.psid_plus[[4]]
out15 <- out.psid_plus[[5]]
```

```{r, message=FALSE, warning=FALSE}
# build plot titles 
base_titles <- c("(A) LDW-Experimental", "(B) LDW-CPS1" , "(C) LDW-PSID1", "(D) Trimmed LDW-CPS1 ", "(E) Trimmed LDW-PSID1")
top_start <- 6 # F is 6th letter
num_cps <- length(top5_methods.cps_plus)
num_psid <- length(top5_methods.psid_plus)
top_letters_cps <- LETTERS[top_start:(top_start + num_cps - 1)]
top_letters_psid <- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)]
top5_titles.cps_plus <- paste0("(", top_letters_cps, ") Top CPS1: ", top5_methods.cps_plus)
top5_titles.psid_plus <- paste0("(", top_letters_psid, ") Top PSID1: ", top5_methods.psid_plus)
plot_titles <- c(base_titles, top5_titles.cps_plus, top5_titles.psid_plus)
```

```{r, message=FALSE, warning=FALSE}
# combine all results
all_outs <- c(list(out1, out2, out3, out4, out5), out.cps_plus, out.psid_plus)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURE A10. ATT Estimates Model A Given Unconfoundedness using LDW Samples"}
# plot results
band <- out1[1, 3:4]
est  <- out1[1, 1]
plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs, plot_titles, band, est, "model_a")
```

The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, trimmed versions of the LDW-CPS1 and LDW-PSID1 samples (analogous to Imbens & Xu (2024)) and a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria.

Figure (A) presents the benchmark from the experimental sample (LDW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the observational samples, LDW-CPS1 and LDW-PSID1, while figures (D) and (E) present those for the trimmed versions, replicating the tutorial results of Imbens & Xu (2024). Figures (F) through (J) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-based subsamples under parallel rules.

Across the LDW-CPS1 dataset and its top-ranked subsamples, all estimators generally produce ATT estimates that closely cluster around the experimental benchmark. However, the `overlap_crump` and `overlap_pair` samples exhibit somewhat larger deviations. While most estimates are positive, the `overlap_crump` and `optimal_pair` subsample results include a few negative ATT estimates, and all ATT estimates for the `mahvars` subsample are consistently negative.

In contrast, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors compared to LDW-CPS1 samples. Most ATT estimates are negatively aligned, indicating increased methodological uncertainty in these samples. Positive ATT estimates emerge only for the subsample based on `overlap_crump`.
```{r, message=FALSE, warning=FALSE}
# prepare all results in the order shown in the plots
all_summaries <- lapply(all_outs, eval_att)
att_summary <- do.call(rbind, all_summaries)
rownames(att_summary) <- plot_titles
knitr::kable(att_summary, caption = "ATT Summary Statistics", booktabs = TRUE)
```

The ATT results are presented in the table below:
```{r, message=FALSE, warning=FALSE}
# get result matrix
result_mat <- create_matrix_results(all_outs, plot_titles)
knitr::kable(result_mat, booktabs = TRUE, caption = "ATT Estimates and SEs")
```

<div class="callout-note">
The first value in each cell represents the point estimate from the respective estimator and sample. The number in brackets directly following it is the robust standard error (SE) associated with that estimate, indicating the uncertainty or variability around the point estimate.
</div>

The tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. 

For most LDW-CPS1-based samples, estimates remain not only positive but also comparatively close to the experimental benchmark, with modest variance inflation. In contrast, the LDW-PSID1-based estimates exhibit greater variability, more frequently negative values, and larger standard errors, reflecting an increased challenge of achieving balance and overlap in this observational dataset.

Overall, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat, "LDW_att_estimates_model_a")
```

<div class="callout-tip">
Improved overlap and covariate balance generally leads to estimates closer to the experimental benchmark, but often at the cost of increased standard errors. This trade-off highlights the need to carefully balance bias reduction against precision when selecting methods for robust causal inference.
</div>

Next, we explore alternative estimands such as heterogeneous treatment effects and quantile treatment effects, which may provide deeper insights into the validity of the unconfoundedness assumption. 

### Conditional average treatment effect on the treated (CATT)

CATT enables analysis of treatment effect heterogeneity across covariate-defined subpopulations. We estimate the CATT for the same samples previously considered in the ATT estimation by applying the Augmented Inverse Probability Weighting Generalized Random Forest (AIPW-GRF) method via the `catt()` function from Imbens and Xu (2024).
```{r, message=FALSE, warning=FALSE}
# estimate CATT
catt.ldw <- catt(ldw, Y, treat, covar)
catt.cps <- catt(ldw_cps, Y, treat, covar)
catt.psid <- catt(ldw_psid, Y, treat, covar)
catt.cps.trim <- catt(ldw_cps.trim_match, Y, treat, covar)
catt.psid.trim <- catt(ldw_psid.trim_match, Y, treat, covar)
```

```{r, message=FALSE, warning=FALSE}
# estimate CATT
catt.top5_cps_plus <- lapply(top5_datasets.cps_plus, function(d) catt(d, Y, treat, covar))
catt.top5_psid_plus <- lapply(top5_datasets.psid_plus, function(d) catt(d, Y, treat, covar))
```

Then, we employ a modified version of the function `plot_catt()` from @imbens2024 to visualize the results by plotting the estimated CATTs for all samples at the covariate values of each treated unit against their corresponding experimental benchmarks. 

<div class="callout-note">
Gray dots represent pairs of CATT estimates at covariate values of treated units, while the red crosses indicate pairs of estimated ATTs.
</div>
```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURE A11. CATT Estimates Model A using LDW Data"}
# combine all catt objects 
all_catt <- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim), catt.top5_cps_plus, catt.top5_psid_plus)

# plot results
par(mfrow = c(2,2))
par(cex.main = 0.8)
plot_catt_panels(all_catt, plot_titles)
```

Although the AIPW estimator can produce ATT estimates closely aligned with the experimental benchmark using LDW data, its performance for revealing the true CATT is considerably worse. 
```{r, message=FALSE, warning=FALSE}
all_catt_eval <- eval_catt(all_catt, plot_titles)
knitr::kable(all_catt_eval, caption = "CATT Summary Statistics", booktabs = TRUE)
```

Specifically, with LDW-CPS1, CATT estimates span from $-4,979.99 to $7,201.81, contrasting with the CATT estimated from experimental data which ranges from $-189.40	to $3,835.95, with a mean CATT estimate of $1,713.26. The LDW-PSID1 data shows an even broader CATT estimate range, spanning from $-8,643.02 to $4,903.22, and a notably lower mean of approximately $820.77.

Among the trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary substantially. Specific samples such as `card` or `overlap_crump` subsamples produce minimum CATTs that are considerably negative, but produce positive mean estimates. Subsamples like `ps_threshold`, and `optimal_pair` also deliver positive mean CATT estimates, though with smaller negative minimums, while `mahvars` is the only method among these to produce a negative mean CATT. Importantly, across all methods, the mean CATT estimates are far away from experimental mean estimate. 

The CATT estimates for the LDW-PSID1 trimmed and top-ranked subsamples reveal substantially decreased mean values and wider extremes compared to their CPS1 counterparts, reflecting greater difficulties in producing reliable treatment effect estimates.

This variation in range and means across methods and samples reflects substantial heterogeneity in treatment effect estimation, indicating that while some criteria improve alignment with experimental benchmarks, others introduce considerable discrepancies and variability in estimated heterogeneous effects.
```{r, message=FALSE, warning=FALSE}
# save results
save_catt_panels(all_catt, plot_titles, prefix = "model_a")
```

### Quantile treatment effect on the treated (QTET)

QTET provides a robust way to analyze treatment effect heterogeneity while being less impacted by outliers compared to average treatment effect measures. The QTET estimates are obtained using the propensity score re-weighting method introduced by Firpo (2007). Implementation leverages the `qte()` function from Imbens and Xu (2024), while visualization employs a modified version of their `plot_qte()` function.
```{r, message=FALSE, warning=FALSE}
# estimate QTET
qte.ldw <- est_qte(Y, treat, covar, data = ldw, cores = 4)
qte.ldw_cps <- est_qte(Y, treat, covar, data = ldw_cps)
qte.ldw_psid <- est_qte(Y, treat, covar, data = ldw_psid)
qte.ldw_cps.trim <- est_qte(Y, treat, covar, data = ldw_cps.trim_match)
qte.ldw_psid.trim <- est_qte(Y, treat, covar, data = ldw_psid.trim_match) 
```

```{r, message=FALSE, warning=FALSE}
# estimate QTET
qte.top5_cps_plus  <- lapply(top5_datasets.cps_plus,  function(d) est_qte(Y, treat, covar, data = d))
qte.top5_psid_plus <- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, covar, data = d))
```

```{r, message=FALSE, warning=FALSE}
# estimate QTET
qte.ldw0 <- est_qte(Y, treat, NULL, data = ldw)
qte.ldw.cps0 <- est_qte(Y, treat, NULL, data = ldw_cps)
qte.ldw.psid0 <- est_qte(Y, treat, NULL, data = ldw_psid)
qte.ldw_cps.trim0 <- est_qte(Y, treat, NULL, data = ldw_cps.trim_match)
qte.ldw_psid.trim0 <- est_qte(Y, treat, NULL, data = ldw_psid.trim_match)
qte.top5_cps_plus0  <- lapply(top5_datasets.cps_plus,  function(d) est_qte(Y, treat, NULL, data = d))
qte.top5_psid_plus0 <- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, NULL, data = d))
```

Each plot displays three distinct series for every dataset analyzed: (1) The blue line with diamond-shaped points represents QTET estimates derived from the experimental sample, serving as the benchmark. (2) The red line with triangles shows QTET estimates from the observational data before any adjustment. (3) The black line with circles presents QTET estimates for the observational data after applying covariate adjustment.
```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURE A12. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental"}
par(mfrow = c(2,2))
par(cex.main = 0.8)

# CPS
plot_qte(qte.ldw_cps, qte.ldw.cps0, qte.ldw, main = "(B) LDW-CPS", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID
plot_qte(qte.ldw_psid, qte.ldw.psid0, qte.ldw, main = "(C) LDW-PSID", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

## CPS trimmed
plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.ldw_cps, main = "(D) LDW-CPS (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# PSID trimmed
plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.ldw_psid, main = "(E) LDW-PSID (Trimmed)", ylim = c(-25000, 15000))
legend("bottomleft", legend = c("Experimental", "Unadjusted", "Adjusted"), 
    lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = "n")

# CPS top methods
plot_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.ldw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000))

# PSID top methods
plot_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.ldw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000))
```

These figures display QTET estimates derived from both the experimental and various observational samples. The QTETs estimated from the original and trimmed LDW-CPS1 sample (B and D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original and trimmed LDW-PSID1 subsample (C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked LDW-CPS1-based subsamples, QTETs (F - J) continue to track the true experimental effect well, whereas LDW-PSID1-based subsamples produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty.
```{r, message=FALSE, warning=FALSE}
# list results
plots_ldw <- list(
  list(mod = qte.ldw_cps, mod0 = qte.ldw.cps0, bm = qte.ldw, main = "(A) LDW CPS1"),
  list(mod = qte.ldw_psid, mod0 = qte.ldw.psid0, bm = qte.ldw, main = "(B) LDW PSID1"),
  list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.ldw_cps, main = "(C) LDW CPS1 (Trimmed)"),
  list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.ldw_psid, main = "(D) LDW PSID1 (Trimmed)")
)

# save results
save_qtet(plots_ldw, prefix = "ldw_model_a", ylim = c(-25000, 15000))
save_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.ldw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000), prefix = "ldw_model_a_top")
save_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.ldw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000), prefix = "ldw_model_a_top")
```

### Assessing outcome weights (OW)
```{r, message=FALSE, warning=FALSE}
# list all datasets
all_datasets <- c(
  list(ldw, ldw_cps, ldw_psid, ldw_cps.trim_match, ldw_psid.trim_match),
  top5_datasets.cps_plus,
  top5_datasets.psid_plus
)
```

```{r, message=FALSE, warning=FALSE}
# estimate ATT 
res_att <- get_res_att(all_datasets, Y, treat, covar)
# extract outcome weights
ow_att <- derive_ow(res_att)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURE A13. Outcome Weights Model A using LDW Data"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# plot outcome weights distribution
plot_ow(ow_att, plot_titles) 
```

```{r, message=FALSE, warning=FALSE}
#evaluate results
res_ow <- eval_ow(ow_att, all_datasets, plot_titles, treat_var = treat, estimator = "AIPW-ATT")
knitr::kable(res_ow, caption = "Outcome Weights for Treated and Untreated", booktabs = TRUE) 
```

<div class="callout-caution">
The outcome weights are not obtained directly from the ATT point estimates due to computational design of other methods. Instead, the ATT is separately estimated for each dataset following the approach developed by @OW_Package.
</div>

The evaluation reveals that across each sample the estimated outcome weights sum to one within the treated group and minus one within the untreated group, resulting in an overall sum of zero.
```{r, message=FALSE, warning=FALSE}
#save results
save_ow(ow_att, plot_titles, prefix = "model_a")
```

## Validation through placebo analyses

To further evaluate the credibility of the unconfoundedness assumption, a placebo analysis is performed by designating 1975 earnings (re75) as the outcome variable and omitting both re75 and u75 from the list of covariates. The analysis utilizes all previously considered samples and recomputes the ATT via the function `estimate_all`, conditioning only on the remaining set of covariates.
```{r, message=FALSE, warning=FALSE}
# define variables
Y_pl <- "re75"
treat <- "treat"
covar_pl <- c("age", "education", "black", "hispanic", "married", "nodegree", "re74", "u74")
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on experimental and observational datasets
out1_pl <- estimate_all(ldw, Y_pl, "treat", covar_pl)
out2_pl <- estimate_all(ldw_cps, Y_pl, "treat", covar_pl)
out3_pl <- estimate_all(ldw_psid, Y_pl, "treat", covar_pl)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on trimmed datasets
out4_pl <- estimate_all(ldw_cps.trim_match, Y_pl, "treat", covar_pl)
out5_pl <- estimate_all(ldw_psid.trim_match, Y_pl, "treat", covar_pl)
```

```{r, message=FALSE, warning=FALSE}
# estimate placebo ATT on top ranked datasets
out.cps_pl <- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, Y_pl, "treat", covar_pl))
out.psid_pl <- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, Y_pl, "treat", covar_pl))
out6_pl <- out.cps_pl[[1]]
out7_pl <- out.cps_pl[[2]]
out8_pl <- out.cps_pl[[3]]
out9_pl <- out.cps_pl[[4]]
out10_pl <- out.cps_pl[[5]]
out11_pl <- out.psid_pl[[1]]
out12_pl <- out.psid_pl[[2]]
out13_pl <- out.psid_pl[[3]]
out14_pl <- out.psid_pl[[4]]
out15_pl <- out.psid_pl[[5]]
```

```{r, message=FALSE, warning=FALSE}
# collect all placebo results 
all_outs.pl <- c(list(out1_pl, out2_pl, out3_pl, out4_pl, out5_pl), out.cps_pl, out.psid_pl)
```

```{r, message=FALSE, warning=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURE A14. Placebo Test Model B: '75 Earnings as the Outcome"}
# plot placebo results
band_pl <- out1_pl[1, 3:4]
est_pl  <- out1_pl[1, 1]
ylim_pl = c(-15500, 5500)
plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.7)
```

```{r, message=FALSE, warning=FALSE}
# save results
save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, "model_a_placebo")
```

The placebo ATT results are presented in the table below:
```{r, message=FALSE, warning=FALSE}
# print placebo results
result_mat_pl <- create_matrix_results(all_outs.pl, plot_titles)
knitr::kable(result_mat_pl, booktabs = TRUE, caption = "Placebo ATT Estimates and SEs")
```

The placebo analysis reveals that the experimental benchmarks are positive, near zero and statistically insignificant, while all estimators applied to the observational datasets, LDW-CPS1 and LDW-PSID1, yield by majority large, negative ATT estimates.

For LDW-CPS1, most ATT estimates are negative. The `overlap_crump` subsample shows a modest improvement toward the experimental benchmark compared to LDW-CPS1 (B) results, but also produces notably poorer estimates for certain estimators. The trimmed subsamples (D) and (I), which use similar approaches, further improve upon the LDW-CPS1 (B) results. The `optimal_pair` and `card` subsamples provide even greater improvement. The `mahvars` (G) subsample delivers ATT estimates closest to the experimental benchmark and is the only case to yield positive ATT estimates across the LDW-CPS1 samples.

For LDW-PSID1, the subsample (O) applying the `overlap_common_range` method shows no improvement compared to the LDW-PSID1 sample (C) except for the `Diff-in-Means` estimator. The `overlap_crump` subsample generally delivers ATT estimates closer to the experimental benchmark, while the `card` and `mahvars` subsamples producing estimates even closer to the experimental benchmark. The trimmed subsamples (E) and (N), which use similar approaches, achieve the closest alignment with the benchmark.

Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis reveals substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underlines the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings.
```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(result_mat_pl, "LDW_att_estimates_pl_model_a")
```

## Validation through sensitivity analyses

Finally, a sensitivity analyses using the LDW data is conducted and results are depicted in contour plots using the function `sens_ana` of Imbens & Xu (2024).
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78"
treat <- "treat"
covar <- c("age", "education", "black", "hispanic", "married", "nodegree", "re74", "re75", "u74", "u75")
bm <- c("re75") 
```

```{r, message=FALSE, warning=FALSE}
# check for valid datasets 
datasets_sens <- c(list(ldw, ldw_cps, ldw_psid), top5_datasets.cps_plus, top5_datasets.psid_plus)
filtered_datasets_sens <- check_filter_datasets(datasets_sens, Y, treat, covar, bm)
```

```{r, warning=FALSE, message=FALSE, out.width='100%', fig.asp=1, fig.cap="FIGURE A15. Sensitivity Analyses Model A"}
par(mfrow = c(2,2))
par(cex.main = 0.8)
# loop over valid datasets and assign index
for (i in seq_along(filtered_datasets_sens)) {
    idx <- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]]))
    sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3)
    title(main = plot_titles[idx])
}
```

```{r, message=FALSE, warning=FALSE}
# save results
save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, "model_a")
```

The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of `re75`. Notably, some samples such as LDW-PSID1 exhibit a greater sensitivity with more pronounced swings including negative estimates at higher confounder strengths, contrasting with consistent positive effects in LDW-CPS1 variants. This highlights sample-specific differences in robustness against potential unobserved confounding.

<div class="callout-tip">
The analyses suggest that some samples maintain stable treatment effect estimates despite increasing confounder strength, while others show greater sensitivity. This highlights the importance of assessing robustness across different samples (respectively methods used to derive specific samples) to account for potential unobserved bias.
</div>

## Summary
After reexamining model A, that is based on the LaLonde-Dehejia-Wahba (LDW) data and its augmented versions with control groups from CPS-1 and PSID-1, several insights into causal inference challenges emerge. First, we confirm that ensuring overlap between treated and control groups remains crucial for credible causal estimation. The LDW-Experimental data exhibit excellent overlap, while the observational datasets (LDW-CPS1 and LDW-PSID1) show weaker overlap, with many treated units outside the control range. Augmenting these datasets with experimental controls improves overlap but does not consistently improve covariate balance.

Second, controlling for covariates such as age, education, race, and prior earnings, and using various methods including matching, weighting, truncation, trimming, and combined approaches, largely yields consistent effects. The propensity score plays an important role in assessing overlap and balancing covariates across groups.

Third, the LDW dataset is somewhat unique in that most methods approximate the experimental benchmark well for average treatment effects on the treated (ATT), an achievement not fully replicated in the original LaLonde samples. However, placebo tests using pre-treatment earnings and sensitivity analyses reveal lingering concerns about the unconfoundedness assumption and robustness of some estimators.

Overall, this chapter highlights the importance of overlap and covariate balance, the utility of propensity scores, and the need for rigorous validation of treatment assignment assumptions to produce credible causal estimates. Despite improvements in data and methods, tests of unconfoundedness via placebo outcomes suggest caution in interpreting causal effects.