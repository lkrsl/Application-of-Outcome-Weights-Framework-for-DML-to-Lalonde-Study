[["index.html", "Application of the Outcome Weights Framework for Double Machine Learning to the Lalonde Study Preface", " Application of the Outcome Weights Framework for Double Machine Learning to the Lalonde Study Laura Kreisel 2025-10-16 Preface This book replicates the LaLonde study by Imbens and Xu (2024) and extends it by comparing a full with a reduced covariate model to mitigate potential confounding. It evaluates various methods to improve overlap and covariate balance for robust treatment effect estimation and applies the outcome weights framework by Knaus and Pfleiderer (2024) to assess another estimator and analyse the distributional properties of outcome weights. The analysis draws on the original LaLonde dataset as well as the LaLonde–Dehejia–Wahba (LDW) and LaLonde–Calónico–Smith (LCS) datasets. Section 1 introduces required packages and wrapper functions used throughout the analysis. Section 2 replicates and extends the full covariate model from Imbens and Xu (2024) using the LaLonde-Dehejia-Wahba (LDW) dataset. Section 3 applies a reduced covariate set to the same LDW dataset. Section 4 analyzes the original LaLonde dataset following similar methods and section 5 explores the LaLonde-Calónico-Smith (LCS) dataset, focusing on female samples. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” "],["getting-started.html", "Chapter 1 Getting started 1.1 Installation 1.2 Wrapper functions", " Chapter 1 Getting started The functions presented below constitute the core wrapper functions utilized throughout the analysis, including three functions originally from the Imbens and Xu (2024) tutorial, that were modified to suit specific analytical purposes (highlighted by ***), as well as others that were integrated without modification. For the full collection of functions by Imbens and Xu (2024), please consult their official source code available on their GitHub repository. 1.1 Installation Several R packages are required for the data analysis and visualization. The code below checks for all required packages and installs those that are missing. Once installation is complete, the packages must be loaded. Since the analysis sources functions directly from the Imbens and Xu (2024) tutorial, the required packages are automatically installed and loaded as part of that process. Therefore, it is only necessary to install and load any additional packages as well as add custom functions that are required for the analysis. Packages: “data.table”, “dplyr”, “ebal”, “ggplot2”, “gridExtra”, “highr”, “highs” , “MatchIt”, “optmatch”, “optweight”, “quickmatch”, “readr”, “rgenoud”, “tidyr”, “tidyverse”, “WeightIt” # required packages packages &lt;- c(&quot;data.table&quot;, &quot;dplyr&quot;, &quot;ebal&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;highr&quot;, &quot;kableExtra&quot;, &quot;MatchIt&quot;, &quot;optmatch&quot;, &quot;optweight&quot;, &quot;quickmatch&quot;, &quot;readr&quot;, &quot;rgenoud&quot;, &quot;tidyr&quot;, &quot;tidyverse&quot;, &quot;WeightIt&quot; ) # install packages install_all &lt;- function(packages) { installed_pkgs &lt;- installed.packages()[, &quot;Package&quot;] for (pkg in packages) { if (!pkg %in% installed_pkgs) { install.packages(pkg) } } } install_all(packages) # load packages library(cobalt) library(data.table) library(dplyr) library(ebal) library(ggplot2) library(gridExtra) library(highr) library(highs) library(kableExtra) library(MatchIt) library(optmatch) library(optweight) library(quickmatch) library(readr) library(tidyr) library(tidyverse) library(WeightIt) 1.2 Wrapper functions Next, the wrapper functions designed to manage the datasets, address overlap and covariate balance, estimate treatment effects and analyze outcome weights are presented. To use the wrapper functions, the simplest method is to source the R script with the following code. source(&quot;tutorial/functions.R&quot;) If RStudio is used, the functions should now appear in the environment section. 1.2.1 Overview Function Description Code inspect_data() Inspects datasets. More truncate_weights_fixed(), truncate_weights_percentile(), check_weights(), truncate_weights_adaptive(), ps_estimate(), ps_trim(), common_range_trim(), crump_trim(), stuermer_trim (), walker_trim(), trim_attach_weights() Implements methods to improve covariate balancing and overlap. More get_smd_stats(), compute_abs_smd_matchit(), compute_ess_matchit(), plot_matching_balance(), compute_abs_smd_weight(), compute_ess_weight(), plot_weighting_balance(), compute_abs_smd_trunc(), compute_ess_trunc(), plot_trunc_balance(), compute_abs_smd_trim(), compute_ess_trim(), plot_trim_overlap(), compute_abs_smd_comb(), compute_ess_comb(), plot_comb_overlap(), plot_comb_balance(), save_comb_hist(), save_comb_loveplots(), combine_results(), save_csv(), assess_methods(), get_top_methods(), create_top5_datasets(), save_top5_datasets() Evaluates performance of previous methods through comparative metrics (absolute standardized mean differences (SMD) and effective sample size (ESS)). More estimate_all(), plot_coef(), plot_att_panels(), save_att_panels(), create_matrix_results(), eval_att(), plot_catt_panels(), save_catt_panels(), eval_catt(), plot_qte_top(), save_qtet(), save_qte_top() Computes and visualizes the Average Treatment Effect on the Treated (ATT) using a number of estimators. More get_res_att(), derive_ow(), plot_ow(), eval_ow(), save_ow() Analyses outcome weights of datasets. More check_filter_datasets(), save_sensitivity_plots() Validates and filters datasets. More 1.2.2 Inspection inspect_data() provides a structured summary of one or multiple datasets by returning a single data frame listing each dataset’s name, number of observations (rows), number of treated units, number of control units, number of variables (columns) and a concatenated string of variable names. inspect_data &lt;- function(data, treat = &quot;treat&quot;) { if (is.data.frame(data)) { data &lt;- list(dataset = data) } data.frame( dataset = names(data), num_obs = sapply(data, nrow), num_treated = sapply(data, function(df) sum(df[[treat]] == 1, na.rm = TRUE)), num_controls = sapply(data, function(df) sum(df[[treat]] == 0, na.rm = TRUE)), num_vars = sapply(data, ncol), name_vars = sapply(data, function(df) paste(names(df), collapse = &quot;, &quot;)), row.names = NULL ) } Argument data_list: A data frame or a list of data frames containing structured data. 1.2.3 Improving covariate balance and overlap 1.2.3.1 Matching NA 1.2.3.2 Weighting NA 1.2.3.3 Truncation truncate_weights_fixed() caps weights at a fixed maximum range (with absolute value restricted in [0.025, 0.975])). truncate_weights_fixed &lt;- function(data, weight_col, lower = 0.025, upper = 0.975) { data[[weight_col]] &lt;- pmax(data[[weight_col]], lower) data[[weight_col]] &lt;- pmin(data[[weight_col]], upper) return(data) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string. lower: Numeric value specifying the minimum allowed weight. Weights below this value are set to this lower bound. upper: Numeric value specifying the maximum allowed weight. Weights above this value are set to this upper bound. truncate_weights_percentile() caps weights at a specified percentile threshold. truncate_weights_percentile &lt;- function(data, weight_col, lower = 0.05, upper = 0.95) { quantiles &lt;- quantile(data[[weight_col]], probs = c(lower, upper), na.rm = TRUE) data[[weight_col]] &lt;- pmax(data[[weight_col]], quantiles[1]) data[[weight_col]] &lt;- pmin(data[[weight_col]], quantiles[2]) return(data) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string. lower: Numeric value between 0 and 1 specifying the lower quantile cutoff. Weights below this percentile are set to the value at this quantile. upper: Numeric value between 0 and 1 specifying the upper quantile cutoff. Weights above this percentile are set to the value at this quantile. check_weights() prints the variance of the specified weight vector to assess variability and relevance for adaptive truncation. check_weights &lt;- function(data, weight_col = &quot;weight&quot;) { w &lt;- data[[weight_col]] variance &lt;- var(w, na.rm = TRUE) data.frame( Weight_Column = weight_col, Variance = variance ) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string (default is weight) truncate_weights_adaptive() caps weights adaptively at a threshold defined by the mean plus a multiple of the standard deviation. truncate_weights_adaptive &lt;- function(data, weight_col, c = 3) { w &lt;- data[[weight_col]] # only apply if variance is above zero if (var(w, na.rm = TRUE) &gt; 0) { cutoff &lt;- mean(w, na.rm = TRUE) + c * sd(w, na.rm = TRUE) data[[weight_col]] &lt;- pmin(w, cutoff) } return(data) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string. c: The multiplier for the standard deviation added to the mean to define the cutoff value as integer. 1.2.3.4 Trimming ps_estimate() reestimates the propensity scores by fitting a probability forest with the treatment indicator as the target and the specified covariates as predictors. ps_estimate &lt;- function(data, Y, treat, covar, num.trees = 4000, seed = 42) { set.seed(seed) data$ps_estimate &lt;- probability_forest( X = data[, covar], Y = as.factor(data[, treat]), seed = seed, num.trees = num.trees )$predictions[, 2] return(data) } Arguments data: The data frame containing structured data. Y: String specifying the name of the outcome variable. treat: The column name of the (binary) treatment indicator as string (default is treat). covar: A vector of covariate names. num.trees:Integer specifying the number of trees to grow in the random forest model for propensity score estimation (default is 4000). seed: Integer to ensure reproducibility (default is 42). ps_trim() trims the dataset based on a specified propensity score threshold, removing observations whose propensity scores exceed the given cutoff value.*** ps_trim &lt;- function(data, ps = &quot;ps_assoverlap&quot;, threshold = 0.9) { sub &lt;- data[which(data[, ps] &lt; threshold), ] return(sub) } Arguments data: The data frame containing structured data. ps: The name of the propensity score variable as string. threshold: The upper limit for propensity score inclusion as numeric value. common_range_trim() trims the dataset to observations with propensity scores within the common support range for treated and control groups. It takes as lower cutpoint the highest of the lowest propensity scores in each group and as upper cutpoint the lowest of the highest propensity scores in each group. common_range_trim &lt;- function(data, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;) { lower_cut &lt;- max( min(data[[ps]][data[[treat]] == 1], na.rm = TRUE), min(data[[ps]][data[[treat]] == 0], na.rm = TRUE) ) upper_cut &lt;- min( max(data[[ps]][data[[treat]] == 1], na.rm = TRUE), max(data[[ps]][data[[treat]] == 0], na.rm = TRUE) ) sub &lt;- data[data[[ps]] &gt;= lower_cut &amp; data[[ps]] &lt;= upper_cut, ] return(sub) } Arguments data: The data frame containing structured data. ps: The column name of propensity scores as string (default is ps_assoverlap). treat: The column name of the (binary) treatment indicator as string (default is treat). crump_trim() trims the dataset to observations with propensity scores outside specified lower and upper bounds (default 0.1 and 0.9). Only those observations are kept that are within the specified interval (default 0.1 &lt;= PS &lt;= 0.9). crump_trim &lt;- function(data, ps = &quot;ps_assoverlap&quot;, lower = 0.1, upper = 0.9) { sub &lt;- data[data[[ps]] &gt;= lower &amp; data[[ps]] &lt;= upper, ] return(sub) } Arguments data: The data frame containing structured data. ps: The column name of propensity scores as string (default is ps_assoverlap). lower: The lower bound for inclusion as numeric value (default is 0.1). upper: The upper bound for inclusion as numeric value (default is 0.9). stuermer_trim () trims the dataset to observations based on propensity score quantiles separately for treated and control group. stuermer_trim &lt;- function(data, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, lower_percentile = 0.05, upper_percentile = 0.95) { treated_ps &lt;- data[[ps]][data[[treat]] == 1] untreated_ps &lt;- data[[ps]][data[[treat]] == 0] lower_cutoff &lt;- quantile(treated_ps, probs = lower_percentile, na.rm = TRUE) upper_cutoff &lt;- quantile(untreated_ps, probs = upper_percentile, na.rm = TRUE) sub &lt;- data[data[[ps]] &gt;= lower_cutoff &amp; data[[ps]] &lt;= upper_cutoff, ] return(sub) } Arguments data: The data frame containing structured data. treat: The column name of the (binary) treatment indicator as string (default is treat). ps: The column name of propensity scores as string (default is ps_assoverlap). lower_percentile: Numeric value between 0 and 1 specifying the lower quantile cutoff for propensity scores in the treated group (default is 0.05, i.e., 5th percentile). upper_percentile: Numeric value between 0 and 1 specifying the upper quantile cutoff for propensity scores in the untreated group (default is 0.95, i.e., 95th percentile). walker_trim() trims the dataset to observations based on preference scores that adjust for treatment prevalence using logit transformations. walker_trim &lt;- function(data, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, lower_cutoff = 0.3, upper_cutoff = 0.7) { treat_prevalence &lt;- mean(data[[treat]], na.rm = TRUE) logit_ps &lt;- log(data[[ps]] / (1 - data[[ps]])) logit_prevalence &lt;- log(treat_prevalence / (1 - treat_prevalence)) preference_score &lt;- 1 / (1 + exp(-(logit_ps - logit_prevalence))) sub &lt;- data[preference_score &gt;= lower_cutoff &amp; preference_score &lt;= upper_cutoff, ] return(sub) } Arguments data: The data frame containing structured data. treat: The column name of the (binary) treatment indicator as string (default is treat). ps: The column name of propensity scores as string (default is ps_assoverlap). lower_cutoff: Numeric value between 0 and 1 specifying the lower cutoff for the preference score (default is 0.3). upper_cutoff: Numeric value between 0 and 1 specifying the upper cutoff for the preference score (default is 0.7). 1.2.3.5 Combined methods trim_attach_weights() merges trimmed data with original weights, preserving corresponding weight values after trimming. trim_attach_weights &lt;- function(trimmed_list, model, weight_type = c(&quot;ipw_weight&quot;, &quot;opt_weight&quot;, &quot;cbps_weight&quot;, &quot;ebal_weight&quot;), estimand = &quot;ATT&quot;) { weight_type &lt;- match.arg(weight_type) weight_fun &lt;- function(data) { if (weight_type == &quot;ipw_weight&quot;) { w.obj &lt;- WeightIt::weightit(model, data = data, estimand = estimand, method = &quot;glm&quot;) data$ipw_weight &lt;- w.obj$weights } else if (weight_type == &quot;opt_weight&quot;) { w.obj &lt;- optweight::optweight(model, data = data, estimand = estimand) data$opt_weight &lt;- w.obj$weights } else if (weight_type == &quot;cbps_weight&quot;) { w.obj &lt;- WeightIt::weightit(model, data = data, estimand = estimand, method = &quot;cbps&quot;) data$cbps_weight &lt;- w.obj$weights } else if (weight_type == &quot;ebal_weight&quot;) { w.obj &lt;- WeightIt::weightit(model, data = data, estimand = estimand, method = &quot;ebal&quot;) data$ebal_weight &lt;- w.obj$weights } return(data) } weighted_list &lt;- lapply(trimmed_list, weight_fun) return(weighted_list) } Arguments trimmed_list: A list of data frames containing the subsetted dataset after trimming procedures. model: A model formula specifying the treatment and covariates to be used for calculating weights. weight_type: A character string specifying the type of weighting method to apply when attaching weights to the trimmed datasets. 1.2.4 Reassessing methods 1.2.4.1 Matching get_smd_stats() extracts mean and maximum absolute standardized mean differences (SMDs) from a balance object to assess covariate balance. get_smd_stats &lt;- function(match_object) { bal &lt;- bal.tab(match_object, stats = &quot;mean.diffs&quot;, un = TRUE, s.d.denom = &quot;treated&quot;) smds &lt;- bal$Balance$Diff.Adj smds &lt;- smds[!(rownames(bal$Balance) %in% c(&quot;distance&quot;))] mean_smd &lt;- mean(abs(smds), na.rm = TRUE) max_smd &lt;- max(abs(smds), na.rm = TRUE) return(c(Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd)) } Argument match_object: The balance / matching object, containing information on covariate balance. compute_abs_smd_matchit() computes absolute SMDs for a list of MatchIt objects and returns summary statistics. compute_abs_smd_matchit &lt;- function(match_list) { smd_list &lt;- lapply(match_list, get_smd_stats) smd_mat &lt;- do.call(rbind, smd_list) smd_df &lt;- data.frame( Method = names(match_list), Mean_Abs_SMD = smd_mat[, &quot;Mean_Abs_SMD&quot;], Max_Abs_SMD = smd_mat[, &quot;Max_Abs_SMD&quot;], row.names = NULL ) return(smd_df) } Argument match_list: A list of MatchIt objects. compute_ess_matchit() extracts and formats effective sample size (ESS) information from the balance summary of a MatchIt object. compute_ess_matchit &lt;- function(bal_tab_object) { samples &lt;- bal_tab_object$Observations df &lt;- as.data.frame(samples) df$Method &lt;- rownames(samples) df &lt;- df[, c(&quot;Method&quot;,&quot;Control&quot;, &quot;Treated&quot;)] rownames(df) &lt;- NULL df } plot_matching_balance() generates love plots for a list of MatchIt objects, visualizing covariate balance before and after matching. plot_matching_balance &lt;- function(matchit_objects, threshold = 0.1, title = NULL) { if (!is.list(matchit_objects)) { matchit_objects &lt;- list(single = matchit_objects) } plot_list &lt;- list() for (name in names(matchit_objects)) { matchit_object &lt;- matchit_objects[[name]] bal &lt;- cobalt::bal.tab(matchit_object, un = TRUE) smd_df &lt;- data.frame( Variable = rownames(bal$Balance), Pre = bal$Balance[,&quot;Diff.Un&quot;], Post = bal$Balance[,&quot;Diff.Adj&quot;] ) # remove propensity score or non-covariate rows if present smd_df &lt;- smd_df[!grepl(&quot;^distance$|^prop.score$|distance|prop.score&quot;, smd_df$Variable), ] # convert to long format smd_long &lt;- pivot_longer( smd_df, cols = c(&quot;Pre&quot;, &quot;Post&quot;), names_to = &quot;Matching&quot;, values_to = &quot;Std_Diff&quot; ) smd_long$Matching &lt;- factor( smd_long$Matching, levels = c(&quot;Pre&quot;, &quot;Post&quot;), labels = c(&quot;Pre-Matching&quot;, &quot;Post-Matching&quot;) ) # build titles plot_title &lt;- if (length(matchit_objects) &gt; 1) paste(title, &quot;-&quot;, name) else title # create ggplot p &lt;- ggplot(smd_long, aes(x = Variable, y = Std_Diff, color = Matching)) + geom_point(size = 3) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + geom_hline(yintercept = threshold, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept = -threshold, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + coord_flip() + labs(title = plot_title, x = &quot;Covariates&quot;, y = &quot;Standardized Mean Differences&quot;) + theme_minimal() + theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 1) , plot.title = element_text(face = &quot;plain&quot;, size = 11, hjust = 0.5)) + scale_color_manual(values = c(&quot;Pre-Matching&quot; = &quot;#00CFC1&quot;, &quot;Post-Matching&quot; = &quot;#FC766A&quot;)) plot_list[[name]] &lt;- p } if (length(plot_list) == 1) { return(plot_list[[1]]) } else { return(plot_list) } } Argument matchit_objects: A single MatchIt object or a named list of MatchIt objects, each containing matched data produced by the MatchIt package for different matching specifications. threshold: A numeric value specifying the acceptable limit for standardized mean differences (default is 0.1). title: An optional character string for the main title of the plot or, if plotting multiple objects, a prefix for individual plot titles. 1.2.4.2 Weighting compute_abs_smd_weight() calculates absolute SMDs for datasets weighted by specified weight vectors. compute_abs_smd_weight &lt;- function(data, treat, covar, weights_list) { smd_list &lt;- lapply(names(weights_list), function(method) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = weights_list[[method]], un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Adj) mean_smd &lt;- mean(smd_vals, na.rm = TRUE) max_smd &lt;- max(smd_vals, na.rm = TRUE) return(data.frame( Method = method, Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd )) }) do.call(rbind, smd_list) } Arguments data: The data frame containing structured data. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weights_list: A list of weight vectors. compute_ess_weight() extracts ESS associated with different weighting schemes. compute_ess_weight &lt;- function(data, treat, covar, weights_list) { ess_list &lt;- lapply(names(weights_list), function(method) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = weights_list[[method]], un = FALSE ) samples &lt;- bal_obj$Observations if (&quot;Adjusted&quot; %in% rownames(samples)) { df &lt;- samples[&quot;Adjusted&quot;, c(&quot;Control&quot;, &quot;Treated&quot;), drop = FALSE] } else { df &lt;- samples[1, c(&quot;Control&quot;, &quot;Treated&quot;), drop = FALSE] } df &lt;- cbind(Method = method, df) rownames(df) &lt;- NULL return(df) }) do.call(rbind, ess_list) } Arguments data: The data frame containing structured data. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weights_list: A list of weight vectors. plot_weighting_methods() generates love plots, visualizing covariate balance under different weighting methods. plot_weighting_balance &lt;- function(data, treat, covar, weight_list, title = NULL) { plot_list &lt;- list() for (wname in names(weight_list)) { bal &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = weight_list[[wname]], un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- data.frame( Variable = rownames(bal$Balance), Pre = bal$Balance[,&quot;Diff.Un&quot;], Post = bal$Balance[,&quot;Diff.Adj&quot;] ) smd_df &lt;- smd_df[!grepl(&quot;^distance$|^prop.score$|distance|prop.score&quot;, smd_df$Variable), ] smd_long &lt;- pivot_longer( smd_df, cols = c(&quot;Pre&quot;, &quot;Post&quot;), names_to = &quot;Weighting&quot;, values_to = &quot;Std_Diff&quot; ) smd_long$Weighting &lt;- factor( smd_long$Weighting, levels = c(&quot;Pre&quot;, &quot;Post&quot;), labels = c(&quot;Pre-Weighting&quot;, &quot;Post-Weighting&quot;) ) plot_title &lt;- if (length(weight_list) &gt; 1) paste(title, &quot;-&quot;, wname) else title p &lt;- ggplot(smd_long, aes(x = Variable, y = Std_Diff, color = Weighting)) + geom_point(size = 3) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + geom_hline(yintercept = 0.1, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept = -0.1, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + coord_flip() + labs(title = plot_title, x = &quot;Covariates&quot;, y = &quot;Standardized Mean Differences&quot;) + theme_minimal() + theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 1) , plot.title = element_text(face = &quot;plain&quot;, size = 11, hjust = 0.5)) + scale_color_manual(values = c(&quot;Pre-Weighting&quot; = &quot;#00CFC1&quot;, &quot;Post-Weighting&quot; = &quot;#FC766A&quot;)) plot_list[[wname]] &lt;- p } if (length(plot_list) == 1) { return(plot_list[[1]]) } else { return(plot_list) } } Arguments data: The data frame containing structured data. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_list: A list of weight vectors. dataset_name: The dataset name for plot titles. 1.2.4.3 Truncation compute_abs_smd_trunc() calculates absolute SMDs for truncated weight datasets across different truncation methods and weighting variables. compute_abs_smd_trunc &lt;- function(trunc_list, treat, covar, weight_cols) { all_smd &lt;- list() for(trunc_name in names(trunc_list)) { dataset &lt;- trunc_list[[trunc_name]] smd_list &lt;- lapply(weight_cols, function(wcol) { if (wcol %in% names(dataset)) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = dataset, weights = dataset[[wcol]], un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Adj) data.frame( Method = paste(trunc_name, wcol, sep = &quot;_&quot;), Mean_Abs_SMD = mean(smd_vals, na.rm = TRUE), Max_Abs_SMD = max(smd_vals, na.rm = TRUE) ) } else { NULL } }) all_smd[[trunc_name]] &lt;- do.call(rbind, smd_list) } smd_summary &lt;- do.call(rbind, all_smd) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments trunc_list: A list of data frames, each containing a dataset with truncated weights. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: The name of the columns holding the weights. compute_ess_trunc() computes ESS values for truncated weight datasets considering different methods and weights. compute_ess_trunc &lt;- function(trunc_list, treat, covar, weight_cols) { all_ess &lt;- list() for(trunc_name in names(trunc_list)) { dataset &lt;- trunc_list[[trunc_name]] ess_list &lt;- lapply(weight_cols, function(wcol) { if (wcol %in% names(dataset)) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = dataset, weights = dataset[[wcol]], un = FALSE, s.d.denom = &quot;treated&quot; ) samples &lt;- bal_obj$Observations if (&quot;Adjusted&quot; %in% rownames(samples)) { df &lt;- data.frame( Method = paste(trunc_name, wcol, sep = &quot;_&quot;), Control = samples[&quot;Adjusted&quot;, &quot;Control&quot;], Treated = samples[&quot;Adjusted&quot;, &quot;Treated&quot;] ) } else { df &lt;- data.frame( Method = paste(trunc_name, wcol, sep = &quot;_&quot;), Control = samples[1, &quot;Control&quot;], Treated = samples[1, &quot;Treated&quot;] ) } df } else { NULL } }) all_ess[[trunc_name]] &lt;- do.call(rbind, ess_list) } ess_summary &lt;- do.call(rbind, all_ess) rownames(ess_summary) &lt;- NULL return(ess_summary) } Arguments trunc_list: A list of data frames, each containing a dataset with truncated weights. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: The name of the columns holding the weights. plot_trunc_methods() produces love plots for various truncation methods and weight types, visualizing covariate balance before and after truncation. plot_trunc_balance &lt;- function(trunc_list, treat, covar, weight_cols, dataset_name = NULL, threshold = 0.1) { plot_list &lt;- list() for (trunc_name in names(trunc_list)) { dataset &lt;- trunc_list[[trunc_name]] for (wcol in weight_cols) { if (wcol %in% names(dataset)) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = dataset, weights = dataset[[wcol]], un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- data.frame( Variable = rownames(bal_obj$Balance), Pre = bal_obj$Balance[,&quot;Diff.Un&quot;], Post = bal_obj$Balance[,&quot;Diff.Adj&quot;] ) smd_df &lt;- smd_df[!grepl(&quot;^distance$|^prop.score$|distance|prop.score&quot;, smd_df$Variable), ] smd_long &lt;- pivot_longer( smd_df, cols = c(&quot;Pre&quot;, &quot;Post&quot;), names_to = &quot;Truncation&quot;, values_to = &quot;Std_Diff&quot; ) smd_long$Truncation &lt;- factor( smd_long$Truncation, levels = c(&quot;Pre&quot;, &quot;Post&quot;), labels = c(&quot;Pre-Truncation&quot;, &quot;Post-Truncation&quot;) ) plot_title &lt;- paste0( if (!is.null(dataset_name)) paste0(dataset_name, &quot; - &quot;) else &quot;&quot;, trunc_name, &quot;_&quot;, wcol, &quot; truncation&quot; ) p &lt;- ggplot(smd_long, aes(x = Variable, y = Std_Diff, color = Truncation)) + geom_point(size = 3) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + geom_hline(yintercept = threshold, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept = -threshold, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + coord_flip() + labs(title = plot_title, x = &quot;Covariates&quot;, y = &quot;Standardized Mean Differences&quot;) + theme_minimal() + theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 1), plot.title = element_text(face = &quot;plain&quot;, size = 11, hjust = 0.5)) + scale_color_manual(values = c(&quot;Pre-Truncation&quot; = &quot;#00CFC1&quot;, &quot;Post-Truncation&quot; = &quot;#FC766A&quot;)) plot_list[[paste(trunc_name, wcol, sep = &quot;_&quot;)]] &lt;- p } else { message(sprintf(&quot;Column %s not found in %s&quot;, wcol, trunc_name)) } } } if (length(plot_list) == 1) { return(plot_list[[1]]) } else { return(plot_list) } } Arguments trunc_list: A list of data frames, each containing a dataset with truncated weights. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: The name of the columns holding the weights. dataset_name: The dataset name for plot titles. threshold: A numeric value specifying the acceptable limit for standardized mean differences (default is 0.1). 1.2.4.4 Trimming compute_abs_smd_trim() computes absolute SMDs for multiple trimmed datasets. compute_abs_smd_trim &lt;- function(trimming_list, treat, covar) { smd_list &lt;- lapply(names(trimming_list), function(name) { data &lt;- trimming_list[[name]] bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Un) mean_smd &lt;- mean(smd_vals, na.rm = TRUE) max_smd &lt;- max(smd_vals, na.rm = TRUE) return(data.frame( Method = name, Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd )) }) smd_summary &lt;- do.call(rbind, smd_list) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments trimming_list: A list of data frames, each a trimmed dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. compute_ess_trim() extracts ESS information for multiple trimmed datasets. compute_ess_trim &lt;- function(trimming_list, treat, covar) { ess_list &lt;- lapply(trimming_list, function(data) { bal_obj &lt;- cobalt::bal.tab(as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, un = TRUE) samples &lt;- bal_obj$Observations df &lt;- as.data.frame(samples)[c(&quot;Control&quot;, &quot;Treated&quot;)] return(df) }) ess_df &lt;- do.call(rbind, ess_list) ess_df$Method &lt;- names(trimming_list) rownames(ess_df) &lt;- NULL ess_df &lt;- ess_df[, c(&quot;Method&quot;, &quot;Control&quot;, &quot;Treated&quot;)] return(ess_df) } Arguments trimming_list: A list of data frames, each a trimmed dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. plot_trim_overlap() plots overlap diagnostics for a set of trimmed datasets, visualizing covariate balance before and after matching. plot_trim_overlap &lt;- function(data_list, treat, covar, prefix = NULL, main.size = 1.1, lab.size = 1, axis.size = 1) { par(mfrow = c(2, 3), mar = c(4, 4, 1, 1), cex.lab = lab.size, font.lab = 1, cex.axis = axis.size, font.axis = 1) for (name in names(data_list)) { data_obj &lt;- data_list[[name]] assess_overlap(data_obj, treat = treat, cov = covar) title(main = paste0(prefix, &quot; - &quot;, name), cex.main = main.size, font.main = 1) } } Arguments data_list: A list of data frames to plot. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix: A string prefix for plot titles. main.size: Numeric value controlling the font size of main plot titles. lab.size: Numeric value controlling the font size of axis labels. axis.size: Numeric value controlling the font size of axis tick marks. 1.2.4.5 Combined methods compute_abs_smd_comb() aggregates absolute SMD statistics across multiple datasets, weighting methods, and trimming techniques. compute_abs_smd_comb &lt;- function(combined_list, treat, covar) { smd_list &lt;- lapply(names(combined_list), function(weight_method) { method_list &lt;- combined_list[[weight_method]] res &lt;- lapply(names(method_list), function(trim_method) { data &lt;- method_list[[trim_method]] # use equal weights if weight column missing if (!&quot;weight&quot; %in% colnames(data)) { data$weight &lt;- rep(1, nrow(data)) } bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = data$weight, un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Adj) method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) data.frame( Method = method_name, Mean_Abs_SMD = mean(smd_vals, na.rm = TRUE), Max_Abs_SMD = max(smd_vals, na.rm = TRUE) ) }) do.call(rbind, res) }) smd_summary &lt;- do.call(rbind, smd_list) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments combined_list: A list of data frames grouped by weighting and trimming methods. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. compute_ess_comb() aggregates ESS information across various datasets, weighting methods, and trimming techniques. compute_ess_comb &lt;- function(combined_list, treat, covar) { ess_list &lt;- lapply(names(combined_list), function(weight_method) { method_list &lt;- combined_list[[weight_method]] res &lt;- lapply(names(method_list), function(trim_method) { data &lt;- method_list[[trim_method]] # use equal weights if weight column missing if (!&quot;weight&quot; %in% colnames(data)) { data$weight &lt;- rep(1, nrow(data)) } bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = data$weight, un = TRUE, s.d.denom = &quot;treated&quot; ) samples &lt;- bal_obj$Observations if (&quot;Adjusted&quot; %in% rownames(samples)) { control_ess &lt;- samples[&quot;Adjusted&quot;, &quot;Control&quot;] treated_ess &lt;- samples[&quot;Adjusted&quot;, &quot;Treated&quot;] } else { control_ess &lt;- samples[1, &quot;Control&quot;] treated_ess &lt;- samples[1, &quot;Treated&quot;] } method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) data.frame( Method = method_name, Control = control_ess, Treated = treated_ess ) }) do.call(rbind, res) }) ess_summary &lt;- do.call(rbind, ess_list) rownames(ess_summary) &lt;- NULL return(ess_summary) } Arguments combined_list: A list of data frames grouped by weighting and trimming methods. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. plot_comb_overlap() creates plots assessing overlap for combinations of weighting and trimming methods across datasets. plot_comb_overlap &lt;- function(comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, prefix_cps = NULL, prefix_psid = NULL, main.size = 1.1, lab.size = 1, axis.size = 1) { all_combined_list &lt;- list() if (!is.null(comb_meth_cps)) all_combined_list$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_combined_list$PSID &lt;- comb_meth_psid for (ds_name in names(all_combined_list)) { combined_list &lt;- all_combined_list[[ds_name]] plot_list &lt;- list() method_names &lt;- character() for (weight_method in names(combined_list)) { for (trim_method in names(combined_list[[weight_method]])) { full_method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) plot_list[[full_method_name]] &lt;- combined_list[[weight_method]][[trim_method]] method_names &lt;- c(method_names, full_method_name) } } total_plots &lt;- length(plot_list) plots_per_page &lt;- 6 for (i in seq(1, total_plots, by = plots_per_page)) { start_idx &lt;- i end_idx &lt;- min(i + plots_per_page - 1, total_plots) par(mfrow = c(2, 3), mar = c(4, 4, 1, 1), cex.lab = lab.size, font.lab = 1, cex.axis = axis.size, font.axis = 1) for (j in start_idx:end_idx) { data &lt;- plot_list[[j]] prefix &lt;- if (ds_name == &quot;CPS&quot;) prefix_cps else prefix_psid invisible(assess_overlap(data, treat = treat, cov = covar)) title(main = paste0(prefix, &quot; - &quot;, method_names[j]), cex.main = main.size, font.main = 1) } if ((end_idx - start_idx + 1) &lt; plots_per_page) { for (k in seq_len(plots_per_page - (end_idx - start_idx + 1))) plot.new() } } } } Arguments comb_meth_cps: A list combining weighting and trimming results for CPS dataset. comb_meth_psid: A list combining weighting and trimming results for PSID dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix_cps: A string prefix for plot titles related to CPS results. prefix_psid: A string prefix for plot titles related to PSID results. main.size: Numeric value controlling the font size of main plot titles. lab.size: Numeric value controlling the font size of axis labels. axis.size: Numeric value controlling the font size of axis tick marks. plot_comb_love_plots() visualizes SMDs via love plots for combined weighting and trimming approaches. plot_comb_balance &lt;- function( comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, orig_cps = NULL, orig_psid = NULL, prefix_cps = NULL, prefix_psid = NULL, threshold = 0.1 ) { all_datasets &lt;- list() if (!is.null(comb_meth_cps)) all_datasets$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_datasets$PSID &lt;- comb_meth_psid orig_data_list &lt;- list(CPS = orig_cps, PSID = orig_psid) plot_list &lt;- list() plot_counter &lt;- 0 for (ds_name in names(all_datasets)) { method_list &lt;- all_datasets[[ds_name]] orig_data &lt;- orig_data_list[[ds_name]] for (weighting in names(method_list)) { trimmed_list &lt;- method_list[[weighting]] for (trim in names(trimmed_list)) { df &lt;- trimmed_list[[trim]] plot_counter &lt;- plot_counter + 1 method_name &lt;- paste(weighting, trim, sep = &quot;_&quot;) prefix &lt;- &quot;&quot; if (ds_name == &quot;CPS&quot; &amp;&amp; plot_counter &lt;= 25) prefix &lt;- prefix_cps if (ds_name == &quot;PSID&quot; &amp;&amp; plot_counter &lt;= 25) prefix &lt;- prefix_psid plot_title &lt;- paste(prefix, method_name, sep = &quot; - &quot;) weight_col &lt;- grep(&quot;weight&quot;, names(df), value = TRUE) if (length(weight_col) == 0) stop(&quot;No weight column found in trimmed dataset&quot;) weights &lt;- df[[weight_col]] bal_pre &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = orig_data, un = TRUE, s.d.denom = &quot;treated&quot; ) bal_post &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = df, weights = weights, un = FALSE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- data.frame( Variable = rownames(bal_pre$Balance), Pre = bal_pre$Balance[, &quot;Diff.Un&quot;], Post = bal_post$Balance[, &quot;Diff.Adj&quot;] ) smd_df &lt;- smd_df[!grepl(&quot;^distance$|^prop.score$|distance|prop.score&quot;, smd_df$Variable), ] smd_long &lt;- pivot_longer( smd_df, cols = c(&quot;Pre&quot;, &quot;Post&quot;), names_to = &quot;Weighting&quot;, values_to = &quot;Std_Diff&quot; ) smd_long$Weighting &lt;- factor( smd_long$Weighting, levels = c(&quot;Pre&quot;, &quot;Post&quot;), labels = c(&quot;Pre-Trimming-Weighting&quot;, &quot;Post-Trimming-Weighting&quot;) ) p &lt;- ggplot(smd_long, aes(x = Variable, y = Std_Diff, color = Weighting)) + geom_point(size = 3) + geom_hline(yintercept = 0, linetype = &quot;dashed&quot;, color = &quot;black&quot;) + geom_hline(yintercept = threshold, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + geom_hline(yintercept = -threshold, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + coord_flip() + labs(title = plot_title, x = &quot;Covariates&quot;, y = &quot;Standardized Mean Differences&quot;) + theme_minimal() + theme(panel.border = element_rect(color = &quot;black&quot;, fill = NA, size = 1) , plot.title = element_text(face = &quot;plain&quot;, size = 11, hjust = 0.5)) + scale_color_manual(values = c( &quot;Pre-Trimming-Weighting&quot; = &quot;#00CFC1&quot;, &quot;Post-Trimming-Weighting&quot; = &quot;#FC766A&quot; )) plot_list[[paste(ds_name, method_name, sep = &quot;_&quot;)]] &lt;- p } } } return(plot_list) } Arguments - comb_meth_cps: A list combining weighting and trimming results for CPS dataset. - comb_meth_psid: A list combining weighting and trimming results for PSID dataset. - treat: The name of the binary treatment indicator variable as string. - covar: A vector of covariate names. - orig_cps: The original unweighted CPS1 dataset prior to any weighting or trimming. - orig_psid: The original unweighted PSID1 dataset prior to any weighting or trimming. - prefix_cps: A string prefix for plot titles related to CPS results. - prefix_psid: A string prefix for plot titles related to PSID results. - threshold: Numeric value defining the acceptable standardized mean difference limit for covariate balance (default is 0.1). save_comb_hist() saves the histograms into a pdf file. save_comb_hist &lt;- function(comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, prefix = NULL, prefix_cps = NULL, prefix_psid = NULL, path = &quot;graphs/lalonde&quot;) { dir.create(path, showWarnings = FALSE, recursive = TRUE) print(getwd()) all_combined_list &lt;- list() if (!is.null(comb_meth_cps)) all_combined_list$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_combined_list$PSID &lt;- comb_meth_psid file_index &lt;- 1 for (ds_name in names(all_combined_list)) { combined_list &lt;- all_combined_list[[ds_name]] plot_list &lt;- list() method_names &lt;- character() for (weight_method in names(combined_list)) { for (trim_method in names(combined_list[[weight_method]])) { full_method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) plot_list[[full_method_name]] &lt;- combined_list[[weight_method]][[trim_method]] method_names &lt;- c(method_names, full_method_name) } } total_plots &lt;- length(plot_list) plots_per_page &lt;- 4 for (i in seq(1, total_plots, by = plots_per_page)) { start_idx &lt;- i end_idx &lt;- min(i + plots_per_page - 1, total_plots) pdf_file &lt;- file.path(path, sprintf(&quot;%s_ov_%d.pdf&quot;, prefix, file_index)) pdf(pdf_file, width = 10, height = 8) par(mfrow = c(2, 2), mar = c(4, 4, 2, 1), cex.lab = 1, font.lab = 1, cex.axis = 1, font.axis = 1) for (j in start_idx:end_idx) { data &lt;- plot_list[[j]] prefix_str &lt;- if (ds_name == &quot;CPS&quot;) prefix_cps else prefix_psid assess_overlap(data, treat = treat, cov = covar) title(main = paste0(prefix_str, &quot; - &quot;, method_names[j]), cex.main = 1, font.main = 1) } if ((end_idx - start_idx + 1) &lt; 4) { for (k in seq_len(4 - (end_idx - start_idx + 1))) plot.new() } dev.off() file_index &lt;- file_index + 1 } } } Arguments comb_meth_cps: A list combining weighting and trimming results for CPS dataset. comb_meth_psid: A list combining weighting and trimming results for PSID dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix: A string prefix for plot titles related to the respective dataset or model. prefix_cps: A string prefix for plot titles related to CPS results. prefix_psid: A string prefix for plot titles related to PSID results. path: A string specifying the output directory path where the generated histograms will be saved (default is “graphs/lalonde”). save_comb_loveplots() saves the loveplots into a pdf file. save_comb_loveplots &lt;- function(comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, prefix = NULL, prefix_cps = NULL, prefix_psid = NULL, path = &quot;graphs/lalonde&quot;) { dir.create(path, showWarnings = FALSE, recursive = TRUE) print(getwd()) all_datasets &lt;- list() if (!is.null(comb_meth_cps)) all_datasets$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_datasets$PSID &lt;- comb_meth_psid file_index &lt;- 1 for (ds_name in names(all_datasets)) { method_list &lt;- all_datasets[[ds_name]] method_names &lt;- unlist(lapply(names(method_list), function(weighting) { trimmed_list &lt;- method_list[[weighting]] sapply(names(trimmed_list), function(trim) paste(weighting, trim, sep = &quot;_&quot;)) })) for (weighting in names(method_list)) { trimmed_list &lt;- method_list[[weighting]] for (trim in names(trimmed_list)) { df &lt;- trimmed_list[[trim]] if (!&quot;weight&quot; %in% names(df)) df$weight &lt;- 1 bal &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = df, weights = df$weight, un = TRUE, s.d.denom = &quot;treated&quot; ) method_name &lt;- paste(weighting, trim, sep = &quot;_&quot;) prefix_str &lt;- ifelse(ds_name == &quot;CPS&quot;, prefix_cps, prefix_psid) pdf_file &lt;- file.path(path, sprintf(&quot;%s_balance_%d.pdf&quot;, prefix, file_index)) pdf(pdf_file, width = 8, height = 6) lp &lt;- cobalt::love.plot( bal, stats = &quot;mean.diffs&quot;, absolute = TRUE, var.order = &quot;unadjusted&quot;, thresholds = c(m = .1), title = paste(prefix_str, method_name, sep = &quot; - &quot;) ) print(lp) dev.off() file_index &lt;- file_index + 1 } } } } Arguments comb_meth_cps: A list combining weighting and trimming results for CPS dataset. comb_meth_psid: A list combining weighting and trimming results for PSID dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix: A string prefix used for saved file names to identify dataset. prefix_cps: A string prefix for plot titles related to CPS results. prefix_psid: A string prefix for plot titles related to PSID results. path: A string specifying the output directory path where the generated histograms will be saved (default is “graphs/lalonde”). 1.2.4.6 Getting top methods and datasets combine_results() merges and summarizes SMD and ESS statistics from various analysis stages into a final comparison table. combine_results &lt;- function(dataset_name) { dataset_lower &lt;- tolower(dataset_name) # retrieve matching results smd_matching &lt;- get(paste0(&quot;smd_matchit.&quot;, dataset_lower)) ess_matching &lt;- get(paste0(&quot;ess_matchit.&quot;, dataset_lower)) # retrieve trimming results smd_trimming &lt;- get(paste0(&quot;smd_trim.&quot;, dataset_lower)) ess_trimming &lt;- get(paste0(&quot;ess_trim.&quot;, dataset_lower)) # retrieve truncation results smd_trunc &lt;- get(paste0(&quot;smd_trunc.&quot;, dataset_lower)) ess_trunc &lt;- get(paste0(&quot;ess_trunc.&quot;, dataset_lower)) # retrieve weighting results smd_weighting &lt;- get(paste0(&quot;smd_weight.&quot;, dataset_lower)) ess_weighting &lt;- get(paste0(&quot;ess_weight.&quot;, dataset_lower)) # retrieve combined SMD and ESS smd_combined_var &lt;- paste0(&quot;smd_all_comb_meth.&quot;, dataset_lower) ess_combined_var &lt;- paste0(&quot;ess_all_comb_meth.&quot;, dataset_lower) smd_combined &lt;- get(smd_combined_var) ess_combined &lt;- get(ess_combined_var) # combine all SMD results smd_all &lt;- do.call(rbind, list( smd_matching, smd_trimming, smd_trunc, smd_weighting, smd_combined[, c(&quot;Method&quot;, &quot;Mean_Abs_SMD&quot;, &quot;Max_Abs_SMD&quot;)] )) # combine all ESS results ess_all &lt;- do.call(rbind, list( ess_matching, ess_trimming, ess_trunc, ess_weighting, ess_combined[, c(&quot;Method&quot;, &quot;Control&quot;, &quot;Treated&quot;)] )) # merge SMD and ESS results by Method final_df &lt;- merge(smd_all, ess_all, by = &quot;Method&quot;, all = TRUE) # remove dataset suffixes for clean labels final_df$Method &lt;- gsub(&quot;\\\\.psid&quot;, &quot;&quot;, final_df$Method, ignore.case = TRUE) final_df$Method &lt;- gsub(&quot;\\\\.cps&quot;, &quot;&quot;, final_df$Method, ignore.case = TRUE) # reset row names rownames(final_df) &lt;- NULL return(final_df) } Arguments dataset_name: The dataset name for which to combine SMD and ESS summaries. save_csv() saves the tables into a CSV file. save_csv &lt;- function(data, filename) { folder &lt;- &quot;tables&quot; if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) file_csv &lt;- file.path(folder, paste0(filename, &quot;.csv&quot;)) write.csv(data, file = file_csv, row.names = FALSE) } Arguments data: The dataset. filename: The name of the file that is to be saved as CSV. assess_methods() scores and ranks methods based on a weighted combination of balance and sample size metrics. assess_methods &lt;- function(data) { data %&gt;% mutate( # ess score ess_balance_ratio = pmin(Control, Treated) / pmax(Control, Treated), ess_total = Control + Treated, # normalize balance_ratio and ess_total ess_balance_score = (ess_balance_ratio - min(ess_balance_ratio, na.rm = TRUE)) / (max(ess_balance_ratio, na.rm = TRUE) - min(ess_balance_ratio, na.rm = TRUE)), ess_size_score = (ess_total - min(ess_total, na.rm = TRUE)) / (max(ess_total, na.rm = TRUE) - min(ess_total, na.rm = TRUE)), # combine size and balance equally ess_score = 0.5 * ess_balance_score + 0.5 * ess_size_score, # smd score smd_score = 1 - (Mean_Abs_SMD - min(Mean_Abs_SMD, na.rm = TRUE)) / (max(Mean_Abs_SMD, na.rm = TRUE) - min(Mean_Abs_SMD, na.rm = TRUE)), # composite score Score = 0.5 * smd_score + 0.5 * ess_score ) %&gt;% dplyr::select(Method, Score) %&gt;% arrange(desc(Score)) } Argument data: A data frame containing method performance metrics. get_top_methods() retrieves the top-performing methods based on combined scoring criteria. get_top_methods &lt;- function(summary_df, top_n = 5) { if (!all(c(&quot;Method&quot;, &quot;Score&quot;) %in% names(summary_df))) { stop(&quot;Data frame must contain columns &#39;Method&#39; and &#39;Score&#39;&quot;) } top_methods_df &lt;- summary_df %&gt;% arrange(desc(Score)) %&gt;% head(top_n) return(top_methods_df$Method) } Arguments summary_df: A data frame including columns used for ranking. top_n: Integer specifying the number of top-performing methods to return (default 5). create_top5_datasets() extracts datasets corresponding to the top five ranked methods for further analysis or presentation. create_top5_datasets &lt;- function(dataset_list, top5_method_names) { lapply(top5_method_names, function(method_name) { if (!method_name %in% names(dataset_list)) { stop(paste0(&quot;Method &#39;&quot;, method_name, &quot;&#39; not found in the dataset lookup list&quot;)) } ds &lt;- dataset_list[[method_name]] if (inherits(ds, &quot;matchit&quot;)) { # for matchit class, extract matched data return(as.data.frame(match.data(ds))) } else if (is.data.frame(ds)) { # if already dataframe, return as is return(ds) } else if (is.vector(ds)) { # merge with original data if (!&quot;original&quot; %in% names(dataset_list)) { stop(&quot;Original dataset not found in dataset_list to merge weights&quot;) } original_df &lt;- dataset_list[[&quot;original&quot;]] if (length(ds) != nrow(original_df)) { stop(paste0(&quot;Length of weight vector for method &#39;&quot;, method_name, &quot;&#39; does not match number of rows in original dataset&quot;)) } # create new data frame with weights appended weighted_df &lt;- original_df weighted_df[[&quot;weights&quot;]] &lt;- ds return(weighted_df) } else { stop(paste(&quot;Unsupported data type for method&quot;, method_name)) } }) } Arguments dataset_list: A list of datasets or MatchIt objects containing processed results for different methods. top5_method_names: A character vector of method names corresponding to the top-ranked datasets. save_top5_individual_files() saves datasets of the top five methods as individual files for reproducibility or sharing. save_top5_datasets &lt;- function(combined_methods_list, top5_method_names, prefix) { for (i in seq_along(top5_method_names)) { method_name &lt;- top5_method_names[i] if (!method_name %in% names(combined_methods_list)) { warning(paste0(&quot;Method &#39;&quot;, method_name, &quot;&#39; not found in combined methods list&quot;)) next } dataset_to_save &lt;- combined_methods_list[[method_name]] file_name &lt;- sprintf(&quot;data/top%d_%s_method_%s.RData&quot;, i, prefix, method_name) save(dataset_to_save, file = file_name) } } Arguments combined_methods_list: A list of all combined method results. top5_method_names: A character vector of method names corresponding to the top-ranked datasets. prefix: A string prefix used for saved file names to identify dataset. 1.2.5 Estimating 1.2.5.1 Average treatment effect of the treated (ATT) estimate_all() runs multiple treatment effect estimators on a dataset and returns point estimates, standard errors and confidence intervals.*** # difference in means # diff() diff &lt;- function(data, Y, treat) { fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) out &lt;- summary(lm_robust(fml, data = data, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] return(out) # extract coef, se, ci.lower, ci.upper } # regression adjustment # reg() reg &lt;- function(data, Y, treat, covar) { fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat, &quot;+&quot;, paste(covar, collapse = &quot; + &quot;))) out &lt;- summary(lm_robust(fml, data = data, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] # extract coef, se, ci.lower, ci.upper return(out) } # matching # library(Matching) # matching() matching &lt;- function(data, Y, treat, covar) { m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = data[, covar], Z = data[, covar], estimand = &quot;ATT&quot;, M = 5, replace = TRUE, ties = TRUE, BiasAdjust = TRUE) out &lt;- c(m.out$est[1], m.out$se[1], m.out$est[1] - 1.96 * m.out$se[1], m.out$est[1] + 1.96 * m.out$se[1]) return(out) } # psm() psm &lt;- function(data, Y, treat, covar) { ps &lt;- probability_forest(X = data[, covar], Y = as.factor(data[,treat]), seed = 42, num.trees = 4000)$predictions[,2] m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = matrix(ps, nrow(data), 1), estimand = &quot;ATT&quot;, M = 5, replace = TRUE, ties = FALSE, BiasAdjust = FALSE) if (is.null(m.out$se)==FALSE) { se &lt;- m.out$se[1] } else { se &lt;- m.out$se.standard[1] } out &lt;- c(m.out$est[1], se, m.out$est[1] - 1.96 * se, m.out$est[1] + 1.96 * se) return(out) } # OM (reg) # om.reg() om.reg &lt;- function(data, Y, treat, covar) { tr &lt;- which(data[, treat] == 1) co &lt;- which(data[, treat] == 0) fml &lt;- as.formula(paste(Y, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) out.co &lt;- lm(fml, data = data[co, ]) Y.tr.hat &lt;- predict(out.co, newdata = data[tr, covar, drop = FALSE]) newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr))) out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = &quot;stata&quot;))$coefficients[&quot;treat&quot;, c(1, 2, 5, 6)] return(out) } # OM (grf) # library(grf) # om.grf() om.grf &lt;- function(data, Y, treat, covar) { tr &lt;- which(data[, treat] == 1) co &lt;- which(data[, treat] == 0) out.co &lt;- regression_forest(X = data[co, covar, drop = FALSE], Y = as.vector(data[co, Y]) ) Y.tr.hat &lt;- as.vector(unlist(predict(out.co, newdata = data[tr, covar, drop = FALSE]))) newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr))) out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = &quot;stata&quot;))$coefficients[&quot;treat&quot;, c(1, 2, 5, 6)] return(out) } # IPW # ipw() ipw &lt;- function(data, Y, treat, covar) { ps &lt;- probability_forest(X = data[, covar, drop = FALSE], Y = as.factor(data[, treat]), seed = 42)$predictions[,2] fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) weights &lt;- rep(1, nrow(data)) co &lt;- which(data[, treat] == 0) weights[co] &lt;- ps[co]/(1-ps[co]) out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] # extract coef, se, ci.lower, ci.upper return(out) } # CBPS # library(&quot;CBPS&quot;) # cbps() cbps &lt;- function(data, Y, treat, covar) { fml &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) ps &lt;- quiet(CBPS(fml, data = data, standardize = TRUE)$fitted.values) fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) weights &lt;- rep(1, nrow(data)) co &lt;- which(data[, treat] == 0) weights[co] &lt;- ps[co]/(1-ps[co]) out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] return(out) } # ebal() #library(hbal) ebal &lt;- function(data, Y, treat, covar) { ebal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar, data = data, expand.degree = 1) out &lt;- hbal::att(ebal.out, dr = FALSE)[1, c(1, 2, 5, 6)] return(out) } # hbal # hbal &lt;- function(data, Y, treat, covar) { # hbal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar, data = data, expand.degree = 2, # cv = TRUE) # out &lt;- hbal::att(hbal.out, dr = FALSE)[1, c(1, 2, 5, 6)] # return(out) # } # aipw_grf() aipw &lt;- function(data, Y, treat, covar) { tryCatch({ #library(&quot;grf&quot;) for (var in c(Y, treat, covar)) { data[, var] &lt;- as.vector(data[, var]) } c.forest &lt;- causal_forest(X = data[, covar, drop = FALSE], Y = data[, Y], W = data[, treat], seed = 42) att &lt;- average_treatment_effect(c.forest, target.sample = &quot;treated&quot;, method = &quot;AIPW&quot;) att &lt;- c(att, att[1] - 1.96 * att[2], att[1] + 1.96 * att[2]) return(att) }, error = function(e) { cat(&quot;Error in aipw_grf method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } # aipw.match() aipw.match &lt;- function(data, Y, treat, covar) { # match on ps ps &lt;- probability_forest(X = data[, covar], Y = as.factor(data[, treat]), seed = 42)$predictions[,2] m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = ps, estimand = &quot;ATT&quot;, M = 1, replace = FALSE, ties = FALSE, BiasAdjust = FALSE) mb &lt;- quiet(MatchBalance(treat ~ ps, data = data, match.out = m.out, nboots= 0)) ks &lt;- mb$AfterMatching[[1]]$ks$ks$statistic s &lt;- data[c(m.out$index.treated, m.out$index.control), ] out &lt;- aipw(s, Y, treat, covar) # return(out) return(c(out, ks)) } # aipw_ow() *** aipw_ow &lt;- function(data, Y, treat, covar) { tryCatch({ for (var in c(Y, treat, covar)) { data[, var] &lt;- as.vector(data[, var]) } X &lt;- data[, covar, drop = FALSE] Y &lt;- data[, Y] W &lt;- data[, treat] # run dml_with_smoother with AIPW_ATT dml_fit &lt;- dml_with_smoother(Y = Y, D = W, X = X, estimators = c(&quot;AIPW_ATT&quot;), smoother = &quot;honest_forest&quot;, n_cf_folds = 5, n_reps = 1) # extract estimate and SE from summary summ &lt;- summary(dml_fit, quiet = TRUE) est &lt;- summ[&quot;AIPW-ATT&quot;, &quot;Estimate&quot;] se &lt;- summ[&quot;AIPW-ATT&quot;, &quot;SE&quot;] ci_lower &lt;- est - 1.96 * se ci_upper &lt;- est + 1.96 * se return(c(est, se, ci_lower, ci_upper)) }, error = function(e) { cat(&quot;Error in aipw_ow method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } ### This script checks for robustness by estimating original model ### using double/debiased machine learning using DoubleML package dml &lt;-function(data, Y = NULL, treat = NULL, covar = NULL, clust_var = NULL, ml_l = lrn(&quot;regr.lm&quot;), ml_m = lrn(&quot;regr.lm&quot;)){ tryCatch({ if(is.null(covar)){ stop(&quot;No controls in specification.&quot;) } #require(DoubleML) #require(mlr3learners) #require(fixest) #require(ggplot2) if(is.null(clust_var) == TRUE){ dat = data[,c(Y,treat,covar)] dat = na.omit(dat) dml_dat = DoubleMLData$new(dat, y_col = Y, d_cols = treat, use_other_treat_as_covariate = FALSE, x_cols = covar) }else{ dat = data[,c(Y, treat, covar, clust_var)] dat[,clust_var] = as.numeric(factor(dat[,clust_var])) dat = dat[is.na(dat[,Y]) == FALSE,] dat = dat[is.na(dat[,D]) == FALSE,] features = data.frame(model.matrix(formula(paste(c(&#39;~ 1&#39;,treat,covar), collapse=&quot;+&quot;)), dat)) dat = cbind(dat[,c(Y,clust_var)],features) dml_dat = DoubleMLClusterData$new(dat, y_col = Y, d_cols = treat, cluster_cols = clust_var, use_other_treat_as_covariate = FALSE, x_cols = covar) } # set active treatment treatment dml_dat$set_data_model(treat) # estimate with DML set.seed(pi) dml_mod = DoubleMLPLR$new(dml_dat, ml_l=ml_l, ml_m=ml_m) quiet(dml_mod$fit()) out = c(dml_mod$coef[treat], dml_mod$se[treat], dml_mod$confint()[treat,]) return(out) }, error = function(e) { cat(&quot;Error in dml method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } # estimate_all *** estimate_all &lt;- function(data, Y, treat, covar, methods = c(&quot;diff&quot;, &quot;reg&quot;, &quot;om.reg&quot;, &quot;om.grf&quot;, &quot;matching&quot;, &quot;psm&quot;, &quot;ipw&quot;, &quot;cbps&quot;, &quot;ebal&quot;, &quot;dml&quot;, &quot;aipw_grf&quot;, &quot;aipw_ow&quot;)) { results &lt;- as.data.frame(matrix(NA, length(methods), 4)) rownames(results) &lt;- methods colnames(results) &lt;- c(&quot;Estimate&quot;, &quot;SE&quot;, &quot;CI_lower&quot;, &quot;CI_upper&quot;) m &lt;- 1 if (&quot;diff&quot; %in% methods) { results[m, ] &lt;- diff(data, Y, treat) m &lt;- m + 1 } if (&quot;reg&quot; %in% methods) { results[m, ] &lt;- reg(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;om.reg&quot; %in% methods) { results[m, ] &lt;- om.reg(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;om.grf&quot; %in% methods) { results[m, ] &lt;- om.grf(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;matching&quot; %in% methods) { results[m, ] &lt;- matching(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;psm&quot; %in% methods) { results[m, ] &lt;- psm(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;ipw&quot; %in% methods) { results[m, ] &lt;- ipw(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;cbps&quot; %in% methods) { results[m, ] &lt;- cbps(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;ebal&quot; %in% methods) { results[m, ] &lt;- quiet(ebal(data, Y, treat, covar)) m &lt;- m + 1 } # if (&quot;hbal&quot; %in% methods) { # results[m, ] &lt;- quiet(hbal(data, Y, treat, covar)) # m &lt;- m + 1 # } if (&quot;dml&quot; %in% methods) { results[m, ] &lt;-dml(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;aipw_grf&quot; %in% methods) { results[m, ] &lt;- aipw(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;aipw_ow&quot; %in% methods) { results[m, ] &lt;- aipw_ow(data, Y, treat, covar) m &lt;- m + 1 } return(results) } Function calls quiet: Suppresses output from a function call. diff: Difference in means estimator. It runs a linear regression adjusting for robust standard errors and returns the coefficient, standard error, and confidence interval for the treatment variable. reg: Regression adjustment. Similar to diff but includes additional covariates in the regression model. matching: Propensity score matching using the Matching package. It aligns treated units to control units based on covariates and returns the estimated ATT and its confidence interval. psm: Propensity score matching using a probability forest, followed by matching and estimation of the ATT. om.reg: Outcome modeling using regression. It predicts the outcome for the treated units based on the model fitted to the control units, and then estimates the ATT. om.grf: Outcome modeling using generalized random forests, noted as GRF. ipw: Inverse probability weighting,denoted as IPW. It weights observations by the inverse of their estimated propensity scores and calculates the treatment effect with a weighted regression. cbps: Covariate balancing propensity score, noted as CBPS. It estimates propensity scores to achieve balance on covariates across groups. ebal: Entropy balancing. It reweights the data to balance the covariate distributions. hbal: Hierarchical balancing. It is an extension of ebal with more complex balancing methods. aipw: Augmented inverse probability weighting, noted as AIPW. aipw.match: Combines matching on propensity scores with AIPW. aipw_ow: AIPW computed via outcome weights. dml: Double machine learning. It uses machine learning algorithms to control for confounders when estimating treatment effects. plot_coef() plots treatment effect point estimates and corresponding confidence intervals comparatively across various estimators.*** plot_coef &lt;- function(out, methods = c(&quot;diff&quot;, &quot;reg&quot;, &quot;om.reg&quot;, &quot;om.grf&quot;, &quot;matching&quot;, &quot;psm&quot;, &quot;ipw&quot;, &quot;cbps&quot;, &quot;ebal&quot;, &quot;dml&quot;, &quot;aipw_grf&quot;, &quot;aipw_ow&quot;), labels = c(&quot;Diff-in-Means&quot;, &quot;Reg&quot;, &quot;OM: Reg&quot;, &quot;OM: GRF&quot;, &quot;NN\\nMatching&quot;, &quot;PS\\nMatching&quot;, &quot;IPW&quot;, &quot;CBPS&quot;, &quot;Ebal&quot;, &quot;DML\\nElasnet&quot;, &quot;AIPW-GRF&quot;, &quot;AIPW-OW&quot;), main = NULL, ylab = &quot;Estimate&quot;, band = NULL, line = NULL, grid = TRUE, main.pos = 1, main.line = -2, ylim = NULL, textsize = 0.8 ) { if (is.null(methods) == TRUE) { methods &lt;- rownames(out) } if (is.null(labels) == TRUE) { labels &lt;- methods } # # check # if (is.null(out)==FALSE) { # if (inherits(out, &quot;ivDiag&quot;) == FALSE) {stop(&quot;\\&quot;out\\&quot; needs to be a \\&quot;ltz\\&quot; object.&quot;)} # } # # # title # if (is.null(main)==TRUE) { # main &lt;- &quot;Estimates with 95% CIs&quot; # } # data for the plot data &lt;- out rg &lt;- range(data[,c(3,4)], na.rm = TRUE) adj &lt;- rg[2] - rg[1] if (is.null(ylim) == TRUE) { ylim &lt;- c(min(0, rg[1] - 0.3*adj), max(0, rg[2] + 0.35*adj)) } adj2 &lt;- ylim[2] - ylim[1] # Set up the plot ncoefs &lt;- length(methods) par(mar = c(2.5, 4, 1, 2)) plot(1: ncoefs, data[, 1], xlim = c(0.5, ncoefs + 0.5), ylim = ylim, ylab = &quot;&quot;, xlab = &quot;&quot;, main = &quot;&quot;, axes = FALSE, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, type = &quot;n&quot;) axis(1, at = 1: ncoefs, labels = labels, las = 1, cex.axis = 0.8) axis(2, cex.axis = 0.7) mtext(main, main.pos, line = main.line, cex = textsize) mtext(ylab, 2, line = 2.5) if (is.null(band) == FALSE) { rect(-0.5, band[1], ncoefs + 1, band[2], col = &quot;#ff000030&quot;, border = &quot;white&quot;) # label at bottom } if (is.null(line) == FALSE) { abline(h = line, col = &quot;red&quot;, lty = 2) } if (grid == TRUE) { abline(h = axTicks(2), lty = &quot;dotted&quot;, col = &quot;gray50&quot;) abline(v = c(0.5, c(1: ncoefs) + 0.5), lty = &quot;dotted&quot;, col = &quot;gray50&quot;) # horizontal grid } abline(h = 0, col = &quot;red&quot;, lwd = 2, lty = &quot;solid&quot;) segments(y0 = data[, 3], x0 = c(1: ncoefs), y1 = data[, 4], x1 = c(1: ncoefs), lwd = 2) #CI points(1: ncoefs, data[, 1], pch = 16, col = 1, cex = 1.2) #point coefs box() } plot_att_panels() produces panels of ATT estimates with confidence intervals for multiple methods and datasets. plot_att_panels &lt;- function(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), plots_per_page = 4, ylab = &quot;Estimate&quot;, textsize = 1) { num_pages &lt;- ceiling(length(all_outs) / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, length(all_outs)) par(mfrow = c(plots_per_page, 1), mar = c(3, 4, 3, 2)) for (i in start_idx:end_idx) { out &lt;- all_outs[[i]] plot_coef(out, band = band, line = est, ylim = ylim, main = plot_titles[i], ylab = ylab, textsize = textsize) } } } Arguments all_outs: A list of output objects containing ATT estimates and confidence intervals for different methods. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_outs. band: A numeric vector specifying the confidence interval bounds. est: A numeric value representing the point estimate. ylim: A numeric vector specifying the y-axis limits for the plots (default c(-15500, 5500)). plots_per_page: The number of plots to display per page / panel (default 4). ylab: The label for the y-axis (default “Estimate”). textsize: A numeric scaling factor for text size in plots (default 1). save_att_panels() generates and saves paginated pdf plots that display ATT estimates and their confidence bands from multiple methods. save_att_panels &lt;- function( all_outs, plot_titles, band, est, prefix, plots_per_page = 4, ylab = &quot;Estimate&quot;, textsize = 1) { folder &lt;- &quot;graphs/lalonde&quot; ylim &lt;- c(-15500, 5500) if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) num_pages &lt;- ceiling(length(all_outs) / plots_per_page) for (page in seq_len(num_pages)) { file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, page, &quot;.pdf&quot;)) pdf(file_name, width = 8, height = 11) par(mfrow = c(plots_per_page, 1), mar = c(3,4,3,2)) start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, length(all_outs)) for (i in start_idx:end_idx) { plot_coef(all_outs[[i]], band = band, line = est, ylim = ylim, main = plot_titles[i], ylab = ylab, textsize = textsize) } dev.off() } } Arguments all_outs: A list of output objects containing ATT estimates and confidence intervals for different methods. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_outs. band: A numeric vector specifying the confidence interval bounds. est: A numeric value representing the point estimate. prefix: A string prefix used for saved file names to identify dataset. plots_per_page: The number of plots to display per page / panel (default 4). ylab: The label for the y-axis (default “Estimate”). textsize: A numeric scaling factor for text size in plots (default 1). create_matrix_results() organizes estimation results into a formatted matrix suitable for reporting or tables. create_matrix_results &lt;- function(all_outs, sample_names) { n_samples &lt;- length(sample_names) n_estimators &lt;- nrow(all_outs[[1]]) result_mat &lt;- matrix(&quot;&quot;, nrow = n_estimators + 1, ncol = n_samples * 2) # set up alternating column names cnames &lt;- character(n_samples * 2) for (j in seq_along(sample_names)) { cnames[(j-1)*2 + 1] &lt;- sample_names[j] cnames[(j-1)*2 + 2] &lt;- &quot;&quot; # SE/parenthesis column } colnames(result_mat) &lt;- cnames estimator_names &lt;- rownames(all_outs[[1]]) rownames(result_mat) &lt;- c(&quot;Experimental Benchmark&quot;, estimator_names) # fill values for (j in seq_along(all_outs)) { out &lt;- all_outs[[j]] result_mat[1, (j-1)*2 + 1] &lt;- sprintf(&quot;%.2f&quot;, out[1, 1]) result_mat[1, (j-1)*2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, out[1, 2]), &quot;)&quot;) for (i in 2:(n_estimators+1)) { result_mat[i, (j-1)*2 + 1] &lt;- sprintf(&quot;%.2f&quot;, out[i-1, 1]) result_mat[i, (j-1)*2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, out[i-1, 2]), &quot;)&quot;) } } return(result_mat) } Arguments all_outs: A list of output objects containing ATT estimates and confidence intervals for different methods. sample_names: A character vector of sample / dataset names corresponding to all_outs. eval_att() computes summary statistics of the treatment effect estimates. eval_att &lt;- function(result) { data.frame( Mean_SE = mean(result[, &quot;SE&quot;], na.rm = TRUE), # mean standard error across all estimator results Min_Estimate = min(result[, &quot;Estimate&quot;], na.rm = TRUE), # maximum estimate of all estimator results Max_Estimate = max(result[, &quot;Estimate&quot;], na.rm = TRUE), # minimum estimate of all estimator results Diff_Estimate = max(result[, &quot;Estimate&quot;], na.rm = TRUE) - min(result[, &quot;Estimate&quot;], na.rm = TRUE) ) } Argument result: A data frame containing treatment effect estimation results. 1.2.5.2 Conditional average treatment effect on the treated (CATT) plot_catt_panels() visualizes CATT comparing multiple methods. plot_catt_panels &lt;- function(all_catt, plot_titles, plots_per_page = 4, range = c(-8000, 8000)) { num_pages &lt;- ceiling((length(all_catt) - 1) / plots_per_page) catt_ldw &lt;- all_catt[[1]]$catt att_ldw &lt;- all_catt[[1]]$att[1] id_ldw &lt;- if (!is.null(all_catt[[1]]$id)) all_catt[[1]]$id else seq_along(catt_ldw) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 2 # skip experimental vs itself end_idx &lt;- min(page * plots_per_page + 1, length(all_catt)) par(mfrow = c(plots_per_page, 1), mar = c(4.5, 5, 3, 2)) for (i in start_idx:end_idx) { other &lt;- all_catt[[i]] main_label &lt;- plot_titles[i] catt2 &lt;- other$catt att2 &lt;- other$att[1] id2 &lt;- if (!is.null(other$id)) other$id else seq_along(catt2) common_ids &lt;- intersect(id_ldw, id2) idx_ldw &lt;- match(common_ids, id_ldw) idx_other &lt;- match(common_ids, id2) catt1_plot &lt;- catt_ldw[idx_ldw] catt2_plot &lt;- catt2[idx_other] plot_catt( catt1 = catt1_plot, catt2 = catt2_plot, att1 = att_ldw, att2 = att2, xlab = &quot;CATT (Experimental)&quot;, ylab = main_label, main = main_label, axes.range = range ) } } } Arguments all_catt: A list of objects containing conditional average treatment effect on treated (CATT) estimates. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_catt. plots_per_page: The number of plots to display per page / panel (default 4). range: A numeric vector of axis limits for plots (default c(-8000, 8000)). save_catt_panels()generates and saves multi-page PDF plots comparing CATT estimates across different methods. save_catt_panels &lt;- function(all_catt, plot_titles, range = c(-8000, 8000), prefix = &quot;model_a&quot;, plots_per_page = 4) { dir.create(&quot;graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) catt_ldw &lt;- all_catt[[1]]$catt att_ldw &lt;- all_catt[[1]]$att[1] id_ldw &lt;- if (!is.null(all_catt[[1]]$id)) all_catt[[1]]$id else seq_along(catt_ldw) num_panels &lt;- length(all_catt) - 1 # skip experimental on page num_pages &lt;- ceiling(num_panels / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 2 # always skip all_catt[[1]] end_idx &lt;- min(page * plots_per_page + 1, length(all_catt)) plots_this_page &lt;- end_idx - start_idx + 1 file_name &lt;- sprintf(&quot;graphs/lalonde/%s_catt_estimates_%d.pdf&quot;, prefix, page) pdf(file = file_name, width = 10, height = 12) par(mfrow = c(2, 2), mar = c(4, 4, 2, 2)) for (i in start_idx:end_idx) { other &lt;- all_catt[[i]] main_label &lt;- plot_titles[i] catt2 &lt;- other$catt att2 &lt;- other$att[1] id2 &lt;- if (!is.null(other$id)) other$id else seq_along(catt2) common_ids &lt;- intersect(id_ldw, id2) idx_ldw &lt;- match(common_ids, id_ldw) idx_other &lt;- match(common_ids, id2) catt1_plot &lt;- catt_ldw[idx_ldw] catt2_plot &lt;- catt2[idx_other] plot_catt( catt1 = catt1_plot, catt2 = catt2_plot, att1 = att_ldw, att2 = att2, xlab = &quot;CATT (Experimental)&quot;, ylab = main_label, main = main_label, axes.range = range ) } # blanks if fewer than 4 plots on last page if (plots_this_page &lt; plots_per_page) { for (k in seq_len(plots_per_page - plots_this_page)) plot.new() } dev.off() } } Arguments all_catt: A list of objects containing conditional average treatment effect on treated (CATT) estimates. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_catt. range: A numeric vector of axis limits for plots (default c(-8000, 8000)). prefix: A string prefix for saved PDF filenames. plots_per_page: The number of plots to display per page / panel (default 4). eval_catt() computes summary statistics of CATT vectors for each method, returning the minimum, maximum, mean, and range (difference) of the CATT estimates. eval_catt &lt;- function(all_catt, plot_titles) { do.call(rbind, lapply(seq_along(all_catt), function(i) { catt_vec &lt;- all_catt[[i]]$catt data.frame( Method = plot_titles[i], Min_Catt = min(catt_vec, na.rm = TRUE), Max_Catt = max(catt_vec, na.rm = TRUE), Mean_Catt = mean(catt_vec, na.rm = TRUE), Diff_Catt = max(catt_vec, na.rm = TRUE) - min(catt_vec, na.rm = TRUE), stringsAsFactors = FALSE ) })) } Arguments all_catt: A list of objects containing conditional average treatment effect on treated (CATT) estimates. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_catt. 1.2.5.3 Quantile treatment effect on treated (QTET) plot_qte_top() plots QTET of top-ranked samples for comparison against an experimental benchmark. plot_qte_top &lt;- function(qtet_top, qtet_top0, bm, plot_titles, main_start = 1, ylim = NULL, col = NULL) { n &lt;- length(qtet_top) for (i in 1:n) { main_title &lt;- plot_titles[main_start + i - 1] mod &lt;- qtet_top[[i]] mod2 &lt;- qtet_top0[[i]] plot_qte(mod, mod2, bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) } } Arguments qtet_top: A list of objects containing QTET estimates for top-ranked samples. qtet_top0: A list of objects containing unadjusted QTET estimates. bm: Experimental benchmark. plot_titles: A character vector of titles for each plot, matching the order of elements in qtet_top. main_start: Numeric value index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots. col: Color specification. save_qtet() generates and saves quantile treatment effect on the treated (QTET) plots for a given list of estimates. save_qtet &lt;- function(plots, plot_titles = NULL, main_start = 1, ylim = NULL, col = NULL, prefix = &quot;model_a&quot;) { dir.create(&quot;graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) n &lt;- length(plots) for (i in seq_len(n)) { p &lt;- plots[[i]] main_title &lt;- if (is.null(plot_titles)) p$main else plot_titles[main_start + i - 1] clean_title &lt;- gsub(&quot;[^a-zA-Z0-9]&quot;, &quot;_&quot;, main_title) file_name &lt;- sprintf(&quot;graphs/lalonde/%s_qtet_estimates_%s.pdf&quot;, prefix, clean_title) pdf(file = file_name, width = 7, height = 5) plot_qte(p$mod, p$mod0, p$bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) dev.off() } } Arguments plots: A list of objects containing QTET estimates and corresponding unadjusted estimates. plot_titles: A character vector of titles for each plot, matching the order of elements in plots. main_start: Numeric value index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots. col: Color specification. prefix: A string prefix for saved PDF filenames. save_qte_top() generates and saves quantile treatment effect on the treated (QTET) plots for a given list of estimates of top-ranked samples. save_qte_top &lt;- function(qtet_top, qtet_top0, bm, plot_titles, main_start = 1, ylim = NULL, col = NULL, prefix = &quot;model_a_top&quot;) { n &lt;- length(qtet_top) dir.create(&quot;graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) for (i in seq_len(n)) { mod &lt;- qtet_top[[i]] mod2 &lt;- qtet_top0[[i]] main_title &lt;- plot_titles[main_start + i - 1] clean_title &lt;- gsub(&quot;[^a-zA-Z0-9]&quot;, &quot;_&quot;, main_title) file_name &lt;- sprintf(&quot;graphs/lalonde/%s_qte_estimates_%s.pdf&quot;, prefix, clean_title) pdf(file = file_name, width = 7, height = 5) plot_qte(mod, mod2, bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) dev.off() } } Arguments qtet_top: A list of objects containing QTET estimates for top-ranked samples. qtet_top0: A list of objects containing unadjusted QTET estimates. plot_titles: A character vector of titles for each plot, matching the order of elements in qtet_top. main_start: Numeric value index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots. col: Color specification. prefix: A string prefix for saved PDF filenames. 1.2.6 Outcome weights analysis get_res_att() estimates average treatment effects on the treated (ATT) using augmented inverse probability weighting with cross-fitting on a list of datasets. get_res_att &lt;- function(dataset_list, Y, treat, covar, estimators = &quot;AIPW_ATT&quot;, smoother = &quot;honest_forest&quot;, n_cf_folds = 5, n_reps = 1) { lapply(dataset_list, function(data) { dml_with_smoother( Y = data[[Y]], D = data[[treat]], X = data[, covar, drop = FALSE], estimators = estimators, smoother = smoother, n_cf_folds = n_cf_folds, n_reps = n_reps ) } ) } Arguments dataset_list: A list of datasets. Y: String specifying the name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. estimators: String specifying the estimator to use (default is “AIPW_ATT”). smoother: String specifying the smoothing method (default is “honest_forest”). n_cf_folds: Numeric value specifying the number of cross-fitting folds (default is 5). n_reps: Numeric value specifying the number of repetitions for robustness (default is 1). derive_ow() extracts outcome weights from a list of estimation results. derive_ow &lt;- function(results_list) { lapply(results_list, function(res) get_outcome_weights(res)) } Argument results_list: A list of objects obtained from get_res_att(). plot_ow() plots the distribution of the outcome weights. plot_ow &lt;- function(outcome_weights, plot_titles = NULL, breaks = 50, col = &quot;#ff000080&quot;, xlab = &quot;Outcome Weight&quot;, estimator = &quot;AIPW-ATT&quot;) { N &lt;- length(outcome_weights) for (i in seq_len(N)) { weights &lt;- outcome_weights[[i]]$omega[estimator, ] main_title &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Dataset&quot;, i) hist(weights, breaks = breaks, main = main_title, xlab = xlab, col = col) mtext(paste(&quot;N =&quot;, length(weights)), side = 3, line = -1.5, cex = 0.8) } par(mfrow = c(1, 1)) } Arguments outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. breaks: Numeric value specifying the number of bins for the histogram plots (default is 50). col: Color specification (default is “#ff000080”). xlab: String specifying the label for the x-axis (default is “Outcome Weight”) estimator: String specifying the estimator to use (default is “AIPW-ATT”). eval_ow() computes summary statistics of outcome weights by treatment group for a list of datasets and returns a data frame for comparison. eval_ow &lt;- function(outcome_weights, dataset_list, plot_titles = NULL, treat = &quot;treat&quot;, estimator = &quot;AIPW-ATT&quot;) { results &lt;- lapply(seq_along(outcome_weights), function(i) { ow &lt;- outcome_weights[[i]]$omega[estimator, ] treat &lt;- dataset_list[[i]][[treat]] method &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Dataset&quot;, i) sum_treated &lt;- sum(ow[treat == 1]) sum_untreated &lt;- sum(ow[treat == 0]) data.frame( Method = method, Sum_Treated = sum_treated, Sum_Untreated = sum_untreated, stringsAsFactors = FALSE ) }) do.call(rbind, results) } **Arguments* outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. treat_var: String specifying the treatment variable in each dataset (default is “treat”). estimator: String specifying the estimator to use (default is “AIPW-ATT”). save_ow() saves the outcome weight histograms as PDF files, one per dataset, with optional custom titles and formatting. save_ow &lt;- function(outcome_weights, plot_titles = NULL, breaks = 50, col = &quot;#ff000080&quot;, xlab = &quot;Outcome Weight&quot;, prefix = &quot;model_a&quot;, estimand = &quot;AIPW-ATT&quot;) { dir.create(&quot;graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) N &lt;- length(outcome_weights) for (i in seq_len(N)) { file_name &lt;- sprintf(&quot;graphs/lalonde/%s_outcomewt_%d.pdf&quot;, prefix, i) pdf(file = file_name, width = 8, height = 6) weights &lt;- outcome_weights[[i]]$omega[estimand, ] main_title &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Dataset&quot;, i) hist(weights, breaks = breaks, main = main_title, xlab = xlab, col = col) mtext(paste(&quot;N =&quot;, length(weights)), side = 3, line = -1.5, cex = 0.8) dev.off() } } Argument outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. breaks: Numeric value specifying the number of bins for the histogram plots (default is 50). col: Color specification (default is “#ff000080”). xlab: String specifying the label for the x-axis (default is “Outcome Weight”) prefix: A string prefix for saved PDF filenames. estimator: String specifying the estimator to use (default is “AIPW-ATT”). 1.2.7 Sensitivity analysis check_filter_datasets() filters a list of datasets to retain only those with all required variables, no missing data, binary treatment, and sufficient baseline/covariate variation. check_filter_datasets &lt;- function(datasets, Y, treat, covar, bm) { valid_datasets &lt;- list() for (i in seq_along(datasets)) { data &lt;- datasets[[i]] name &lt;- names(datasets)[i] if (is.null(name) || name == &quot;&quot;) name &lt;- paste0(&quot;dataset_&quot;, i) # provide a name if missing vars_needed &lt;- c(Y, treat, covar, bm) if (!all(vars_needed %in% names(data))) { # check all variables exist message(&quot;Removed &quot;, name, &quot;: missing required variables&quot;) next } sub &lt;- data[, vars_needed, drop = FALSE] if (any(is.na(sub))) { # check no missing values message(&quot;Removed &quot;, name, &quot;: contains missing values&quot;) next } tvals &lt;- unique(sub[[treat]]) # check treatment binary if (!all(tvals %in% c(0, 1)) &amp;&amp; !all(tvals %in% c(TRUE, FALSE))) { message(&quot;Removed &quot;, name, &quot;: treatment variable not binary&quot;) next } if (any(sapply(sub[bm], function(x) length(unique(x)) &lt;= 1))) { # check baseline variables have variation message(&quot;Removed &quot;, name, &quot;: baseline variable(s) lack variation&quot;) next } if (any(sapply(sub[covar], function(x) length(unique(x)) &lt;= 1))) { # check covariates have variation message(&quot;Removed &quot;, name, &quot;: covariate variable(s) lack variation&quot;) next } valid_datasets[[name]] &lt;- data # if all passed dataset is kept } return(valid_datasets) } Arguments datasets: A list of data frames containing data to be filtered. Y: The name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. bm: A vector of baseline variable names. save_sensitivity_plots() generates sensitivity analysis plots for a series of filtered datasets, saving each as a pdf file. save_sensitivity_plots &lt;- function(filtered_datasets, Y, treat, covar, bm, plot_titles, prefix) { folder &lt;- &quot;graphs/lalonde&quot; if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) for (i in seq_along(filtered_datasets)) { idx &lt;- i file_name &lt;- file.path(folder, paste0(prefix, &quot;_sensitivity_&quot;, idx, &quot;.pdf&quot;)) pdf(file_name, width = 8, height = 8) sens_ana(filtered_datasets[[i]], Y, treat, covar, bm, kd = 1:3) if (!missing(plot_titles) &amp;&amp; length(plot_titles) &gt;= idx) { title(main = plot_titles[idx]) } dev.off() } } Arguments filtered_datasets: A list of filtered datasets. Y: The name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. bm: A vector of baseline variable names. plot_titles: A vector of titles for plots corresponding to datasets. prefix: A string prefix for saving output PDF files. Please refer to the accompanying paper for a detailed explanation of the metrics used in the analysis, including absolute standardized mean differences (SMDs), effective sample sizes (ESS), and the composite scoring approach employed to evaluate covariate balance and overlap across multiple methods. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["lalonde-dehejia-wahba-ldw-data.html", "Chapter 2 LaLonde-Dehejia-Wahba (LDW) Data 2.1 Set up 2.2 Model A 2.3 Improving primarily covariate balance 2.4 Improving primarily overlap 2.5 Integrated methods 2.6 Reassessing methods 2.7 Integrated methods 2.8 Identifying best methods 2.9 Estimating 2.10 Validation through placebo analyses 2.11 Validation through sensitivity analyses 2.12 Summary", " Chapter 2 LaLonde-Dehejia-Wahba (LDW) Data LaLonde (1986) evaluated the effect of the National Supported Work Demonstration (NSW) program on both female and male participants. While the female participants were drawn from the Aid to Families with Dependent Children (AFDC) program, the male participants were drawn from three other groups: former drug addicts, ex-criminal offenders, and high-school dropouts. LaLonde relied on two main data sources: (1) CPS-SSA-1, based on Westat’s Matched Current Population Survey–Social Security Administration File for individuals under 55 matching specific criteria; (2) PSID-1, based on Panel Study of Income Dynamics for household heads under 55 from specific years who were not retired in 1975, adjusted for factors like employment status and poverty level, resulting in four additional comparison groups. Dehejia and Wahba (1999) constructed a subset of LaLonde’s original data, retaining 62% of observations and restricting the focus to male participants based on their 1974 earnings. As the dataset was formed entirely on pretreatment information like employment records or month of assignment, treatment allocation was effectively independent of all pre-treatment variables. Thus, they concluded that this subset, known as the LaLonde-Dehejia-Wahba (LDW) data, constitutes a valid experimental sample. The analysis in section 2 and 3 builds on the LDW data and considers in total three samples: (1) LDW-Experimental, consisting of 185 treated individuals and 280 controls from the experimental data; (2) LDW-CPS1, which pairs the same treated sample with 15,992 controls from CPS-SSA-1; (3) LDW-PSID1, featuring the same treated sample with 2,490 controls from PSID-1; In section 4, the analysis applies the same set of statistical tools to analyze a fourth sample as an additional demonstration: (4) LaLonde male samples (1986). In the last section, the analysis applies a reduced set of statistical tools to analyze a fifth sample again as an additional demonstration: (5) LaLonde female samples (2017). This section (2) covers model A, which includes the outcome variable 1978 earnings (re78) and adjusts for a set of covariates: age, education, race (black, hispanic), marital status, lack of high school degree, 1974 and 1975 earnings (re74, re75), and unemployment status in 1974 and 1975 (u74, u75). The model is defined by a regression formula for treatment assignment using these covariates. To improve covariate balance and overlap between treated and control groups, various methods are applied and are structured into five parts (matching, weighting, truncation, trimming and integrated methods). From these methods, the five best methods are determined based on a score defined by absolute standardized mean differences (SMD) and the effective sample size (ESS). The corresponding datasets are used to estimate the average treatment effect on the treated (ATT). Notably, the estimation incorporates the recently introduced augmented inverse probability weighting (AIPW) estimator, implemented via the OutcomeWeights R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify potential patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (re75) as an outcome to assess potential biases and the validity of unconfoundedness assumptions. Finally, sensitivity analyses are performed to evaluate the robustness of treatment effect estimates to violations of these assumptions. 2.1 Set up 2.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 2.1.2 Inspect data We begin the analysis with an overview of each dataset, where the dataset name, number of observations (rows), number of treated and control units, number of variables (columns), and variable names are reviewed. # collect datasets in a list data &lt;- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 2.1: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars lalonde 2675 0 0 13 nsw, age, educ, black, hisp, married, re74, re75, re78, u74, u75, u78, nodegr ldw_tr 185 185 0 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_co 260 0 260 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_cps 16177 185 15992 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid 2675 185 2490 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 2.1.3 Load and preprocess data Next, we augment the control groups in LDW-CPS1 and LDW-PSID1 by merging them with the experimental controls from LDW-Experimental. This approach follows the methodology laid out by Imbens and Xu (2024). # assigns 1 to the experimental controls ldw_co$treat &lt;- 1 # merge experimental data with CPS1 data ldw_cps_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_cps # CPS1 data (16177 observations) ) # merge experimental data with PSID1 data ldw_psid_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_psid # PSID1 data (2675 observations) ) datasets &lt;- list(ldw_cps_plus = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus) # inspect each dataset summary_stats_plus &lt;- inspect_data(datasets) knitr::kable(summary_stats_plus, caption = &quot;Summary Statistics&quot;) Table 2.2: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars ldw_cps_plus 16437 445 15992 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid_plus 2935 445 2490 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 2.2 Model A # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) #re74 included 2.2.1 Assessing overlap and covariate balance 2.2.1.1 Overlap To identify the average causal effect under unconfoundedness (that asserts that the treatment assignment is independent of the potential outcomes), it must be ensured that one can estimate the average effect at every value for the covariates. Thus, overlaps between the treated and untreated units (meaning that for every combination of covariates, there are both treated and untreated units in the dataset) are required. To assess overlap in the propensity scores and visualize the results using histograms of their log-odds, we use the assess_overlap() function of Imbens and Xu (2024). In a properly balanced experimental design, the distributions of the treatment group (red) and the control group (gray) would show considerable coverage. # assess overlap ldw.ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar) ## -1.310867 0.7158619 Figure 2.1: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_cps.ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar) ## -16.1181 1.787343 Figure 2.2: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_psid.ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar) ## -16.1181 3.752723 Figure 2.3: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. As anticipated, LDW-Experimental exhibits an almost perfect overlap. In contrast, the observational datasets LDW-CPS1 and LDW-PSID1 show weak overlap. In particular, many treated units have propensity scores outside the range of the controls, while a large share of control units have propensity scores concentrated at very low log-odds. Next, the overlap of the expanded observational datasets is examined. ldw_cps_plus.ps &lt;- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) ## -16.1181 3.63151 Figure 2.4: FIGUREA1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. ldw_psid_plus.ps &lt;- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) ## -16.1181 7.271394 Figure 2.5: FIGUREA1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. As expected, the datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS show an improved overlap compared to their non-plus states. For the following analysis, we set up a model formula. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 2.2.1.2 Covariate balance Initial covariate balance checks reveal the degree to which treatment and control groups differ on observed characteristics. We employ visual summaries using love.plot(), which depicts standardized mean differences across covariates before and after adjustment. # plot balance love.plot(ldw, ldw_cps, treat, covar = covar, title = &quot;LDW-CPS1&quot;) Figure 2.6: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = &quot;LDW-CPS1-PLUS&quot;) Figure 2.7: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid, treat, covar = covar, title = &quot;LDW-PSID1&quot;) Figure 2.8: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = &quot;LDW-PSID1-PLUS&quot;) Figure 2.9: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. Neither LDW-CPS1-PLUS nor LDW-PSID1-PLUS shows consistently improved covariate balance compared with their non-plus counterparts based on raw standardized mean differences. Although some specific covariates improve slightly, most show increased imbalance. For the subsequent analysis aimed at enhancing covariate balance and overlap, only the two datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS are used. The LDW-Experimental dataset is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 2.3 Improving primarily covariate balance 2.3.1 Matching The purpose of matching is to create comparable treated and control groups by pairing units with similar covariate profiles, thereby reducing covariate imbalance and confounding bias. We apply several matching methods as outlined by Greifer (2025) in the following. 2.3.1.1 Distance Matching 2.3.1.1.1 1:1 Nearest neighbor matching # perform nearest neighbor matching with k=1, logistic propensity score and replacement m.out.cps.nearest &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) m.out.psid.nearest &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) 2.3.1.1.2 k:1 matching (k=2) k&lt;-2 # perform nearest neighbor matching with k=2, logistic propensity score and replacement m.out.cps.k2 &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k2 &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 2.3.1.1.3 k:1 matching (k=3) k&lt;-3 # perform nearest neighbor matching with k=3, logistic propensity score and replacement m.out.cps.k3 &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k3 &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 2.3.1.1.4 Caliper matching # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score m.out.cps.caliper &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) m.out.psid.caliper &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) 2.3.1.1.5 Common support restriction matching # perform nearest neighbor matching with exclusion of units outside common support m.out.cps.cs &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) m.out.psid.cs &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) 2.3.1.1.6 Mahalanobis distance matching (mahvars) # perform nearest neighbor matching using mahalanobis distance on selected covariates m.out.cps.mahvars &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) m.out.psid.mahvars &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) 2.3.1.1.7 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.cps.optimal_pair &lt;- matchit(model, data = ldw_cps, method = &quot;optimal&quot;, distance = &quot;logit&quot;) m.out.psid.optimal_pair &lt;- matchit(model, data = ldw_psid, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 2.3.1.1.8 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.cps.optimal_full &lt;- matchit(model, data = ldw_cps, method = &quot;full&quot;, distance = &quot;logit&quot;) m.out.psid.optimal_full &lt;- matchit(model, data = ldw_psid, method = &quot;full&quot;, distance = &quot;logit&quot;) 2.3.1.1.9 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.cps.general_full &lt;- matchit(model, data = ldw_cps, method = &quot;quick&quot;, distance = &quot;logit&quot;) m.out.psid.general_full &lt;- matchit(model, data = ldw_psid, method = &quot;quick&quot;, distance = &quot;logit&quot;) 2.3.1.1.10 Genetic matching # perform genetic matching m.out.cps.genetic &lt;- matchit(model, data = ldw_cps, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) m.out.psid.genetic &lt;- matchit(model, data = ldw_psid, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) 2.3.1.2 Stratum matching 2.3.1.2.1 Exact matching (exact) Strata = unique covariate profiles (raw covariates) # match units exactly by raw covariate profiles m.out.cps.exact &lt;- matchit(model, data = ldw_cps, method = &quot;exact&quot;) m.out.psid.exact &lt;- matchit(model, data = ldw_psid, method = &quot;exact&quot;) 2.3.1.2.2 Coarsened matching (cem) Strata = coarsened versions of covariates # match units exactly within coarse strata m.out.cps.cem &lt;- matchit(model, data = ldw_cps, method = &quot;cem&quot;) m.out.psid.cem &lt;- matchit(model, data = ldw_psid, method = &quot;cem&quot;) 2.3.1.2.3 Subclassification Strata = bins of the propensity score # partition sample into fixed number of bins based on propensity score m.out.cps.subcl &lt;- matchit(model, data = ldw_cps, method = &quot;subclass&quot;, subclass = 5) m.out.psid.subcl &lt;- matchit(model, data = ldw_psid, method = &quot;subclass&quot;, subclass = 5) 2.3.1.3 Pure subset selection 2.3.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units m.out.cps.card &lt;- matchit(model, data = ldw_cps, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) m.out.psid.card &lt;- matchit(model, data = ldw_psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) 2.3.1.3.2 Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact m.out.cps.profile &lt;- matchit(model, data = ldw_cps, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, solver = &quot;highs&quot;, time = 1200) m.out.psid.profile &lt;- matchit(model, data = ldw_psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, solver = &quot;highs&quot;, time = 1200) 2.3.2 Weighting The purpose of weighting is to reweight the units in order to create a synthetic population in which the distributions of covariates is balanced between treatment and control groups. In the following, several weighting methods as outlined by Stürmer et al. (2021) are applied. 2.3.2.1 Inverse probability weights (IPW) # w.out.cps.ipw &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) ldw_cps$ipw_weight &lt;- w.out.cps.ipw$weights w.out.psid.ipw &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) ldw_psid$ipw_weight &lt;- w.out.psid.ipw$weights 2.3.2.2 Stable balancing weights # w.out.cps.opt &lt;- optweight::optweight(model, data = ldw_cps, estimand = &quot;ATT&quot;) ldw_cps$opt_weight &lt;- w.out.cps.opt$weights w.out.psid.opt &lt;- optweight::optweight(model, data = ldw_psid, estimand = &quot;ATT&quot;) ldw_psid$opt_weight &lt;- w.out.psid.opt$weights 2.3.2.3 Propensity score weights # w.out.cps.cbps &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) ldw_cps$cbps_weight &lt;- w.out.cps.cbps$weights w.out.psid.cbps &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) ldw_psid$cbps_weight &lt;- w.out.psid.cbps$weights 2.3.2.4 Entropy balancing weights # w.out.cps.ebal &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) ldw_cps$ebal_weight &lt;- w.out.cps.ebal$weights w.out.psid.ebal &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) ldw_psid$ebal_weight &lt;- w.out.psid.ebal$weights 2.4 Improving primarily overlap Truncation aims at limiting the influence of extreme weights by capping them at a specified threshold. This helps to reduce variance and improve the stability of causal effect estimates. In the following, several truncation methods are applied, following similar approaches outlined by Matsouaka and Zhou (2023) and Ju, Schwab, and Laan (2013). 2.4.1 Truncation # list weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;opt_weight&quot;, &quot;cbps_weight&quot;, &quot;ebal_weight&quot;) 2.4.1.1 Fixed maximum value truncation # truncate weights by imposing a minimum and maximum threshold ldw_cps.fixed &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(ldw_cps.fixed)) { ldw_cps.fixed &lt;- truncate_weights_fixed(ldw_cps.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) } } ldw_psid.fixed &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(ldw_psid.fixed)) { ldw_psid.fixed &lt;- truncate_weights_fixed(ldw_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) } } 2.4.1.2 At percentile truncation # truncate weights such that values below the 5th percentile and above the 95th percentile are capped ldw_cps.percent &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(ldw_cps.percent)) { ldw_cps.percent &lt;- truncate_weights_percentile(ldw_cps.percent, weight_col = wcol, lower = 0.01, upper = 0.99) } } ldw_psid.percent &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(ldw_psid.percent)) { ldw_psid.percent &lt;- truncate_weights_percentile(ldw_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99) } } 2.4.1.3 Adaptive weight truncation We first inspect the variance of the weights. If variance is zero, adaptive weight truncation is not meaningful. # inspect variance of weights cps_results &lt;- list() psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(ldw_cps)) { cps_results[[paste0(&quot;cps_&quot;, wcol)]] &lt;- check_weights(ldw_cps, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in LDW-CPS1&quot;)) } } for (wcol in weight_columns) { if (wcol %in% names(ldw_psid)) { psid_results[[paste0(&quot;psid_&quot;, wcol)]] &lt;- check_weights(ldw_psid, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in LDW-PSID1&quot;)) } } var_cps_table &lt;- bind_rows(cps_results) var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_cps_table, caption = &quot;Variance of Weights (LDW-CPS1)&quot;) Table 2.3: Variance of Weights (LDW-CPS1) Weight_Column Variance ipw_weight 1.937790e-02 opt_weight 5.193582e+16 cbps_weight 1.877850e-02 ebal_weight 5.781854e+01 knitr::kable(var_psid_table, caption = &quot;Variance of Weights (LDW-PSID1)&quot;) Table 2.3: Variance of Weights (LDW-PSID1) Weight_Column Variance ipw_weight 2.9199073 opt_weight 64.5538174 cbps_weight 0.5926188 ebal_weight 98.2566241 Regarding above results, we apply adaptive weight truncation to all weights, where it may help mitigate the influence of extreme weights. # truncate adaptively at mean + 3 standard deviations ldw_cps.adapt &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(ldw_cps.adapt)) { ldw_cps.adapt &lt;- truncate_weights_adaptive(ldw_cps.adapt, weight_col = wcol, c = 3) } } ldw_psid.adapt &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(ldw_psid.adapt)) { ldw_psid.adapt &lt;- truncate_weights_adaptive(ldw_psid.adapt, weight_col = wcol, c = 3) } } 2.4.2 Trimming The purpose of trimming is to remove units whose propensity scores are too dissimilar from the opposite group, thereby improving covariate balance between treated and control groups. Below, we employ several trimming methods in line with the approaches proposed by Stürmer et al. (2021) and Imbens and Xu (2024). 2.4.2.1 Propensity score threshold trimming (Similar to tutorial by Imbens and Xu (2024)) # apply trimming with thresholds 0.9 and 0.8 ldw_cps_plus.trim &lt;- ps_trim(ldw_cps_plus.ps, threshold = 0.9) ldw_psid_plus.trim &lt;- ps_trim(ldw_psid_plus.ps, threshold = 0.8) # exclude experimental controls, subset trimmed data appropriately ldw_cps_plus.trim.match &lt;- subset(ldw_cps_plus.trim, sample %in% c(1,3) &amp; ps_assoverlap) ldw_psid_plus.trim.match &lt;- subset(ldw_psid_plus.trim, sample %in% c(1,4) &amp; ps_assoverlap) # re-assign treat variable for controls in sample 3 or 4 (non-treated group) ldw_cps_plus.trim.match$treat[ldw_cps_plus.trim.match$sample == 3] &lt;- 0 ldw_psid_plus.trim.match$treat[ldw_psid_plus.trim.match$sample == 4] &lt;- 0 # re-estimate propensity scores on trimmed data and perform 1:1 matching ldw_cps_plus.trim.match &lt;- psmatch(data = ldw_cps_plus.trim.match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid_plus.trim.match &lt;- psmatch(data = ldw_psid_plus.trim.match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 2.4.2.2 Propensity score threshold trimming # apply trimming with threshold 0.9 ldw_cps.trim &lt;- ps_trim(ldw_cps.ps, threshold = 0.9) ldw_psid.trim &lt;- ps_trim(ldw_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.trim &lt;- ps_estimate(data = ldw_cps.trim, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.trim &lt;- ps_estimate(data = ldw_psid.trim, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 2.4.2.3 Common range trimming # trim observations outside the common support region of propensity scores ldw_cps.common &lt;- common_range_trim(ldw_cps.ps) ldw_psid.common &lt;- common_range_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.common &lt;- ps_estimate(data = ldw_cps.common, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.common &lt;- ps_estimate(data = ldw_psid.common, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 2.4.2.4 Crump trimming # trim observations with propensity scores outside [0.1, 0.9] interval ldw_cps.crump &lt;- crump_trim(ldw_cps.ps, lower = 0.1, upper = 0.9) ldw_psid.crump &lt;- crump_trim(ldw_psid.ps, lower = 0.1, upper = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.crump &lt;- ps_estimate(data = ldw_cps.crump, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.crump &lt;- ps_estimate(data = ldw_psid.crump, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 2.4.2.5 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control ldw_cps.stuermer &lt;- stuermer_trim(ldw_cps.ps) ldw_psid.stuermer &lt;- stuermer_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.stuermer &lt;- ps_estimate(data = ldw_cps.stuermer, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.stuermer &lt;- ps_estimate(data = ldw_psid.stuermer, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 2.4.2.6 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations ldw_cps.walker &lt;- walker_trim(ldw_cps.ps) ldw_psid.walker &lt;- walker_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.walker &lt;- ps_estimate(data = ldw_cps.walker, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.walker &lt;- ps_estimate(data = ldw_psid.walker, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 2.5 Integrated methods The purpose of combining trimming and weighting methods is to leverage the strengths of both approaches for causal effect estimation. Trimming enhances overlap and reduces the influence of outliers by excluding units with extreme or non-comparable propensity scores, while weighting further adjusts for remaining covariate imbalance among the retained units. A similar approach to that presented by Stürmer et al. (2021) is employed. # list trimming methods all_trim.cps &lt;- list(ps_threshold = ldw_cps.trim, common_range = ldw_cps.common, stuermer = ldw_cps.stuermer, walker = ldw_cps.walker, crump = ldw_cps.crump) all_trim.psid &lt;- list(ps_threshold = ldw_psid.trim, common_range = ldw_psid.common, stuermer = ldw_psid.stuermer, walker = ldw_psid.walker, crump = ldw_psid.crump) 2.5.0.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;ipw_weight&quot;) ipw_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ipw_weight&quot;) 2.5.0.2 Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply stable balancing with trimming and attach stable balance weights opt_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;opt_weight&quot;) opt_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;opt_weight&quot;) 2.5.0.3 Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply propensity score weighting with trimming and attach propensity score weights cbps_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;cbps_weight&quot;) cbps_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;cbps_weight&quot;) 2.5.0.4 Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights ebal_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;ebal_weight&quot;) ebal_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ebal_weight&quot;) 2.6 Reassessing methods We now systematically reassess all methods described above by evaluating covariate balance and sample representativeness. Specifically, we examine the SMD and ESS for each approach and use visual diagnostics—such as love plots and histograms—to assess covariate balance and overlap between treated and control groups. 2.6.1 Matching # list all matching objects all_match.cps &lt;- list( nn = m.out.cps.nearest, k2 = m.out.cps.k2, k3 = m.out.cps.k3, caliper = m.out.cps.caliper, cS = m.out.cps.cs, mahvars = m.out.cps.mahvars, optimal_pair = m.out.cps.optimal_pair, optimal_full = m.out.cps.optimal_full, gen_full = m.out.cps.general_full, genetic = m.out.cps.genetic, exact = m.out.cps.exact, cem = m.out.cps.cem, card = m.out.cps.card, profile = m.out.cps.profile, subcl = m.out.cps.subcl ) all_match.psid &lt;- list( nn = m.out.psid.nearest, k2 = m.out.psid.k2, k3 = m.out.psid.k3, caliper = m.out.psid.caliper, cs = m.out.psid.cs, mahvars = m.out.psid.mahvars, optimal_pair = m.out.psid.optimal_pair, optimal_full = m.out.psid.optimal_full, gen_full = m.out.psid.general_full, genetic = m.out.psid.genetic, exact = m.out.psid.exact, cem = m.out.psid.cem, card = m.out.psid.card, profile = m.out.psid.profile, subcl = m.out.psid.subcl ) 2.6.1.1 SMD # compute SMD smd_matchit.cps &lt;- compute_abs_smd_matchit(all_match.cps) smd_matchit.psid &lt;- compute_abs_smd_matchit(all_match.psid) 2.6.1.2 ESS # calculate balance statistics bal.cps &lt;- cobalt::bal.tab(model, data = ldw_cps, un = TRUE, weights = all_match.cps, s.d.denom = &quot;treated&quot;) bal.psid &lt;- cobalt::bal.tab(model, data = ldw_psid, un = TRUE, weights = all_match.psid, s.d.denom = &quot;treated&quot;) # compute ESS ess_matchit.cps &lt;- compute_ess_matchit(bal.cps) ess_matchit.psid &lt;- compute_ess_matchit(bal.psid) 2.6.1.3 Visuals # visualize covariate balance plot_matching_balance(all_match.cps, title = &quot;LDW-CPS1&quot;) ## $nn Figure 2.10: FIGUREA3. ## ## $k2 Figure 2.11: FIGUREA3. ## ## $k3 Figure 2.12: FIGUREA3. ## ## $caliper Figure 2.13: FIGUREA3. ## ## $cS Figure 2.14: FIGUREA3. ## ## $mahvars Figure 2.15: FIGUREA3. ## ## $optimal_pair Figure 2.16: FIGUREA3. ## ## $optimal_full Figure 2.17: FIGUREA3. ## ## $gen_full Figure 2.18: FIGUREA3. ## ## $genetic Figure 2.19: FIGUREA3. ## ## $exact Figure 2.20: FIGUREA3. ## ## $cem Figure 2.21: FIGUREA3. ## ## $card Figure 2.22: FIGUREA3. ## ## $profile Figure 2.23: FIGUREA3. ## ## $subcl Figure 2.24: FIGUREA3. plot_matching_balance(all_match.psid, title = &quot;LDW-PSID1&quot;) ## $nn Figure 2.25: FIGUREA3. ## ## $k2 Figure 2.26: FIGUREA3. ## ## $k3 Figure 2.27: FIGUREA3. ## ## $caliper Figure 2.28: FIGUREA3. ## ## $cs Figure 2.29: FIGUREA3. ## ## $mahvars Figure 2.30: FIGUREA3. ## ## $optimal_pair Figure 2.31: FIGUREA3. ## ## $optimal_full Figure 2.32: FIGUREA3. ## ## $gen_full Figure 2.33: FIGUREA3. ## ## $genetic Figure 2.34: FIGUREA3. ## ## $exact Figure 2.35: FIGUREA3. ## ## $cem Figure 2.36: FIGUREA3. ## ## $card Figure 2.37: FIGUREA3. ## ## $profile Figure 2.38: FIGUREA3. ## ## $subcl Figure 2.39: FIGUREA3. 2.6.2 Weighting # list all weights all_weight.cps &lt;- list( ipw_weight = ldw_cps$ipw_weight, opt_weight = ldw_cps$opt_weight, cbps_weight = ldw_cps$cbps_weight, ebal_weight = ldw_cps$ebal_weight ) all_weight.psid &lt;- list( ipw_weight = ldw_psid$ipw_weight, opt_weight = ldw_psid$opt_weight, cbps_weight = ldw_psid$cbps_weight, ebal_weight = ldw_psid$ebal_weight ) 2.6.2.1 SMD # compute SMD smd_weight.cps &lt;- compute_abs_smd_weight(ldw_cps, treat, covar, all_weight.cps) smd_weight.psid &lt;- compute_abs_smd_weight(ldw_psid, treat, covar, all_weight.psid) 2.6.2.2 ESS # compute ESS ess_weight.cps &lt;- compute_ess_weight(ldw_cps, treat, covar, all_weight.cps) ess_weight.psid &lt;- compute_ess_weight(ldw_psid, treat, covar, all_weight.psid) 2.6.2.3 Visuals # visualize covariate balance plot_weighting_balance(ldw_cps, treat, covar, all_weight.cps, &quot;LDW-CPS1&quot;) ## $ipw_weight Figure 2.40: FIGUREA4. ## ## $opt_weight Figure 2.41: FIGUREA4. ## ## $cbps_weight Figure 2.42: FIGUREA4. ## ## $ebal_weight Figure 2.43: FIGUREA4. plot_weighting_balance(ldw_psid, treat, covar, all_weight.psid, &quot;LDW-PSID1&quot;) ## $ipw_weight Figure 2.44: FIGUREA4. ## ## $opt_weight Figure 2.45: FIGUREA4. ## ## $cbps_weight Figure 2.46: FIGUREA4. ## ## $ebal_weight Figure 2.47: FIGUREA4. 2.6.3 Truncation # list truncation methods all_trunc.cps &lt;- list( fix_max_value = ldw_cps.fixed, at_perc = ldw_cps.percent, adap_weight = ldw_cps.adapt ) all_trunc.psid &lt;- list( fix_max_value = ldw_psid.fixed, at_perc = ldw_psid.percent, adap_weight = ldw_psid.adapt ) 2.6.3.1 SMD # compute SMD smd_trunc.cps &lt;- compute_abs_smd_trunc(all_trunc.cps, &quot;treat&quot;, covar, weight_columns) smd_trunc.psid &lt;- compute_abs_smd_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 2.6.3.2 ESS # compute ESS ess_trunc.cps &lt;- compute_ess_trunc(all_trunc.cps, &quot;treat&quot;, covar, weight_columns) ess_trunc.psid &lt;- compute_ess_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 2.6.3.3 Visuals # visualize covariate balance plot_trunc_balance(all_trunc.cps, &quot;treat&quot;, covar, weight_columns, &quot;LDW-CPS1&quot;) ## $fix_max_value_ipw_weight Figure 2.48: FIGUREA5. ## ## $fix_max_value_opt_weight Figure 2.49: FIGUREA5. ## ## $fix_max_value_cbps_weight Figure 2.50: FIGUREA5. ## ## $fix_max_value_ebal_weight Figure 2.51: FIGUREA5. ## ## $at_perc_ipw_weight Figure 2.52: FIGUREA5. ## ## $at_perc_opt_weight Figure 2.53: FIGUREA5. ## ## $at_perc_cbps_weight Figure 2.54: FIGUREA5. ## ## $at_perc_ebal_weight Figure 2.55: FIGUREA5. ## ## $adap_weight_ipw_weight Figure 2.56: FIGUREA5. ## ## $adap_weight_opt_weight Figure 2.57: FIGUREA5. ## ## $adap_weight_cbps_weight Figure 2.58: FIGUREA5. ## ## $adap_weight_ebal_weight Figure 2.59: FIGUREA5. plot_trunc_balance(all_trunc.psid, &quot;treat&quot;, covar, weight_columns, &quot;LDW-PSID1&quot;) ## $fix_max_value_ipw_weight Figure 2.60: FIGUREA5. ## ## $fix_max_value_opt_weight Figure 2.61: FIGUREA5. ## ## $fix_max_value_cbps_weight Figure 2.62: FIGUREA5. ## ## $fix_max_value_ebal_weight Figure 2.63: FIGUREA5. ## ## $at_perc_ipw_weight Figure 2.64: FIGUREA5. ## ## $at_perc_opt_weight Figure 2.65: FIGUREA5. ## ## $at_perc_cbps_weight Figure 2.66: FIGUREA5. ## ## $at_perc_ebal_weight Figure 2.67: FIGUREA5. ## ## $adap_weight_ipw_weight Figure 2.68: FIGUREA5. ## ## $adap_weight_opt_weight Figure 2.69: FIGUREA5. ## ## $adap_weight_cbps_weight Figure 2.70: FIGUREA5. ## ## $adap_weight_ebal_weight Figure 2.71: FIGUREA5. 2.6.4 Trimming # list trimming objects plus original all_trim.cps &lt;- list( original = ldw_cps, ps_threshold = ldw_cps.trim, common_range = ldw_cps.common, crump = ldw_cps.crump, stuermer = ldw_cps.stuermer, walker = ldw_cps.walker ) all_trim.psid &lt;- list( original = ldw_psid, ps_threshold = ldw_psid.trim, common_range = ldw_psid.common, crump = ldw_psid.crump, stuermer = ldw_psid.stuermer, walker = ldw_psid.walker ) 2.6.4.1 SMD # compute SMDs smd_trim.cps &lt;- compute_abs_smd_trim(all_trim.cps, &quot;treat&quot;, covar) smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 2.6.4.2 ESS # compute ESS ess_trim.cps &lt;- compute_ess_trim(all_trim.cps, &quot;treat&quot;, covar) ess_trim.psid &lt;- compute_ess_trim(all_trim.psid, &quot;treat&quot;, covar) 2.6.4.3 Visuals # visualize overlap plot_trim_overlap(all_trim.cps, treat, covar, prefix = &quot;LDW-CPS1&quot;) ## -16.1181 1.787343 ## -16.1181 1.787343 ## -16.1181 2.267617 ## -2.050139 1.563952 ## -16.1181 -1.500729 ## -16.1181 -1.547533 Figure 2.72: FIGUREA6. plot_trim_overlap(all_trim.psid, treat, covar, prefix = &quot;LDW-PSID1&quot;) ## -16.1181 3.752723 ## -16.1181 2.365266 ## -7.117438 2.571188 ## -1.969023 2.449887 ## -8.326673 -2.127801 ## -8.405169 -1.926528 Figure 2.73: FIGUREA6. 2.7 Integrated methods # list all combined results comb.cps &lt;- list( ipw = ipw_comb.cps, opt = opt_comb.cps, cbps = cbps_comb.cps, ebal = ebal_comb.cps ) comb.psid &lt;- list( ipw = ipw_comb.psid, opt = opt_comb.psid, cbps = cbps_comb.psid, ebal = ebal_comb.psid ) 2.7.0.1 SMD # compute SMD smd_all_comb_meth.cps &lt;- compute_abs_smd_comb(comb.cps, &quot;treat&quot;, covar) smd_all_comb_meth.psid &lt;- compute_abs_smd_comb(comb.psid, &quot;treat&quot;, covar) 2.7.0.2 ESS # compute ESS ess_all_comb_meth.cps &lt;- compute_ess_comb(comb.cps, &quot;treat&quot;, covar) ess_all_comb_meth.psid &lt;- compute_ess_comb(comb.psid, &quot;treat&quot;, covar) 2.7.0.3 Visuals # visualize overlap #plot_comb_overlap(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) # visualize covariate balance #plot_comb_balance(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, orig_cps = ldw_cps, orig_psid = ldw_psid, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) # save results #save_comb_hist(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;model_a&quot;, prefix_cps = &quot;ldw_cps1&quot;, prefix_psid = &quot;ldw_psid1&quot;) #save_comb_loveplots(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;model_a&quot;, prefix_cps = &quot;ldw_cps1&quot;, prefix_psid = &quot;ldw_psid1&quot;) 2.8 Identifying best methods To identify the top five methods for each observational dataset, we first combine for each dataset all results of the SMD and ESS into a single data frame. This allows for a comprehensive comparison across all methods. # combine all results all_cps &lt;- combine_results(&quot;cps&quot;) all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_cps, &quot;ldw_model_a_cps1_all_results&quot;) save_csv(all_psid, &quot;ldw_model_a_psid1_all_results&quot;) Next, we evaluate each method by constructing a composite score that is build on two separate scores equally weighted: - smd_score rescales the SMD to a 0-1 range, where a lower value leads to a higher score - ess_score measures sample size effectiveness by combining ESS of treated and control groups and normalizing between 0 and 1. ranked_cps &lt;- assess_methods(all_cps) ranked_psid &lt;- assess_methods(all_psid) Based on the composite scores, we rank all methods and select the top five for each dataset. # get top 5 methods top5_methods.cps &lt;- get_top_methods(ranked_cps, top_n = 5) top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # print results top5_methods_df.cps &lt;- ranked_cps %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps, caption = &quot;Top 5 Methods for CPS1&quot;, booktabs = TRUE) Table 2.4: Top 5 Methods for CPS1 Method Score optimal_pair 0.7363112 card 0.7312287 mahvars 0.7306192 exact 0.7058145 ebal_weight 0.6773939 knitr::kable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID1&quot;, booktabs = TRUE) Table 2.4: Top 5 Methods for PSID1 Method Score card 0.7511588 mahvars 0.7250326 at_perc_ebal_weight 0.6911909 optimal_pair 0.6805432 at_perc_cbps_weight 0.6786009 # save results save_csv(top5_methods.cps, &quot;ldw_model_a_cps1_top5_methods&quot;) save_csv(top5_methods.psid, &quot;ldw_model_a_psid1_top5_methods&quot;) For estimation, we match the selected top method names back to their corresponding datasets, objects or vectors and construct corresponding datasets. dataset_list_cps &lt;- list( &quot;All&quot; = ldw_cps, &quot;original&quot; = ldw_cps, &quot;nn&quot; = m.out.cps.nearest, &quot;caliper&quot; = m.out.cps.caliper, &quot;card&quot; = m.out.cps.card, &quot;cem&quot; = m.out.cps.cem, &quot;cS&quot; = m.out.cps.cs, &quot;k2&quot; = m.out.cps.k2, &quot;k3&quot; = m.out.cps.k3, &quot;mahvars&quot; = m.out.cps.mahvars, &quot;optimal_full&quot; = m.out.cps.optimal_full, &quot;optimal_pair&quot; = m.out.cps.optimal_pair, &quot;gen_full&quot; = m.out.cps.general_full, &quot;genetic&quot; = m.out.cps.genetic, &quot;exact&quot; = m.out.cps.exact, &quot;subcl&quot; = m.out.cps.subcl, &quot;profile&quot; = m.out.cps.profile, &quot;ipw_weight&quot; = ldw_cps$ipw_weight, &quot;opt_weight&quot; = ldw_cps$opt_weight, &quot;cbps_weight&quot; = ldw_cps$cbps_weight, &quot;ebal_weight&quot; = ldw_cps$ebal_weight, &quot;fix_max_value_ipw_weight&quot; = ldw_cps.fixed$ipw_weight, &quot;fix_max_value_opt_weight&quot; = ldw_cps.fixed$opt_weight, &quot;fix_max_value_cbps_weight&quot; = ldw_cps.fixed$cbps_weight, &quot;fix_max_value_ebal_weight&quot; = ldw_cps.fixed$ebal_weight, &quot;at_perc_ipw_weight&quot; = ldw_cps.percent$ipw_weight, &quot;at_perc_opt_weight&quot; = ldw_cps.percent$opt_weight, &quot;at_perc_cbps_weight&quot; = ldw_cps.percent$cbps_weight, &quot;at_perc_ebal_weight&quot; = ldw_cps.percent$ebal_weight, &quot;adap_weight_ipw_weight&quot; = ldw_cps.adapt$ipw_weight, &quot;adap_weight_opt_weight&quot; = ldw_cps.adapt$opt_weight, &quot;adap_weight_cbps_weight&quot; = ldw_cps.adapt$cbps_weight, &quot;adap_weight_ebal_weight&quot; = ldw_cps.adapt$ebal_weight, &quot;ps_threshold&quot; = ldw_cps.trim, &quot;common_range&quot; = ldw_cps.common, &quot;stuermer&quot; = ldw_cps.stuermer, &quot;walker&quot; = ldw_cps.walker, &quot;crump&quot; = ldw_cps.crump, &quot;ipw_common_range&quot; = ipw_comb.cps[[1]], &quot;ipw_crump&quot;= ipw_comb.cps[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.cps[[3]], &quot;ipw_stuermer&quot;= ipw_comb.cps[[4]], &quot;ipw_walker&quot; = ipw_comb.cps[[5]], &quot;opt_common_range&quot; = opt_comb.cps[[1]], &quot;opt_crump&quot; = opt_comb.cps[[2]], &quot;opt_ps_threshold&quot; = opt_comb.cps[[3]], &quot;opt_stuermer&quot; = opt_comb.cps[[4]], &quot;opt_walker&quot; = opt_comb.cps[[5]], &quot;cbps_common_range&quot; = cbps_comb.cps[[1]], &quot;cbps_crump&quot; = cbps_comb.cps[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.cps[[3]], &quot;cbps_stuermer&quot; = cbps_comb.cps[[4]], &quot;cbps_walker&quot;= cbps_comb.cps[[5]], &quot;ebal_common_range&quot; = ebal_comb.cps[[1]], &quot;ebal_crump&quot; = ebal_comb.cps[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.cps[[3]], &quot;ebal_stuermer&quot; = ebal_comb.cps[[4]], &quot;ebal_walker&quot; = ebal_comb.cps[[5]]) dataset_list_psid &lt;- list( &quot;All&quot; = ldw_psid, &quot;original&quot; = ldw_psid, &quot;nn&quot; = m.out.psid.nearest, &quot;caliper&quot; = m.out.psid.caliper, &quot;card&quot; = m.out.psid.card, &quot;cem&quot; = m.out.psid.cem, &quot;cS&quot; = m.out.psid.cs, &quot;k2&quot; = m.out.psid.k2, &quot;k3&quot; = m.out.psid.k3, &quot;mahvars&quot; = m.out.psid.mahvars, &quot;optimal_full&quot; = m.out.psid.optimal_full, &quot;optimal_pair&quot; = m.out.psid.optimal_pair, &quot;gen_full&quot; = m.out.psid.general_full, &quot;genetic&quot; = m.out.psid.genetic, &quot;exact&quot; = m.out.psid.exact, &quot;subcl&quot; = m.out.psid.subcl, &quot;profile&quot; = m.out.psid.profile, &quot;ipw_weight&quot; = ldw_psid$ipw_weight, &quot;opt_weight&quot; = ldw_psid$opt_weight, &quot;cbps_weight&quot; = ldw_psid$cbps_weight, &quot;ebal_weight&quot; = ldw_psid$ebal_weight, &quot;fix_max_value_ipw_weight&quot; = ldw_psid.fixed$ipw_weight, &quot;fix_max_value_opt_weight&quot; = ldw_psid.fixed$opt_weight, &quot;fix_max_value_cbps_weight&quot; = ldw_psid.fixed$cbps_weight, &quot;fix_max_value_ebal_weight&quot; = ldw_psid.fixed$ebal_weight, &quot;at_perc_ipw_weight&quot; = ldw_psid.percent$ipw_weight, &quot;at_perc_opt_weight&quot; = ldw_psid.percent$opt_weight, &quot;at_perc_cbps_weight&quot; = ldw_psid.percent$cbps_weight, &quot;at_perc_ebal_weight&quot; = ldw_psid.percent$ebal_weight, &quot;adap_weight_ipw_weight&quot; = ldw_psid.adapt$ipw_weight, &quot;adap_weight_opt_weight&quot; = ldw_psid.adapt$opt_weight, &quot;adap_weight_cbps_weight&quot; = ldw_psid.adapt$cbps_weight, &quot;adap_weight_ebal_weight&quot; = ldw_psid.adapt$ebal_weight, &quot;ps_threshold&quot; = ldw_psid.trim, &quot;common_range&quot; = ldw_psid.common, &quot;stuermer&quot; = ldw_psid.stuermer, &quot;walker&quot; = ldw_psid.walker, &quot;crump&quot; = ldw_psid.crump, &quot;ipw_common_range&quot; = ipw_comb.psid[[1]], &quot;ipw_crump&quot;= ipw_comb.psid[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid[[4]], &quot;ipw_walker&quot; = ipw_comb.psid[[5]], &quot;opt_common_range&quot; = opt_comb.psid[[1]], &quot;opt_crump&quot; = opt_comb.psid[[2]], &quot;opt_ps_threshold&quot; = opt_comb.psid[[3]], &quot;opt_stuermer&quot; = opt_comb.psid[[4]], &quot;opt_walker&quot; = opt_comb.psid[[5]], &quot;cbps_common_range&quot; = cbps_comb.psid[[1]], &quot;cbps_crump&quot; = cbps_comb.psid[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.psid[[3]], &quot;cbps_stuermer&quot; = cbps_comb.psid[[4]], &quot;cbps_walker&quot;= cbps_comb.psid[[5]], &quot;ebal_common_range&quot; = ebal_comb.psid[[1]], &quot;ebal_crump&quot; = ebal_comb.psid[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.psid[[3]], &quot;ebal_stuermer&quot; = ebal_comb.psid[[4]], &quot;ebal_walker&quot; = ebal_comb.psid[[5]]) # create datasets corresponding to the top 5 methods for each dataset top5_datasets.cps &lt;- create_top5_datasets(dataset_list_cps, top5_methods.cps) top5_datasets.psid &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid) # save datasets into .RData files save_top5_datasets(dataset_list_cps, top5_methods.cps, prefix = &quot;ldw_model_b_cps1&quot;) save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = &quot;ldw_model_b_psid1&quot;) 2.9 Estimating 2.9.1 Average treatment effect on the treated (ATT) Next, we estimate the average treatment effect on the treated (ATT) using both the LDW-Experimental sample, the non-plus observational datasets and the newly constructed top five ranked samples for each observational dataset, LDW-CPS1 and LDW-PSID1, that achieved highest composite score results. We employ a broad set of estimators, including difference-in-means, regression, the Oaxaca-Blinder estimator, generalized random forests (GRF) as an outcome model, 1:5 nearest neighbor matching with bias correction, inverse probability weighting (IPW) with GRF-based propensity scores, covariate balancing propensity score (CBPS), entropy balancing, double/debiased machine learning using elastic net, and augmented inverse probability weighting (AIPW) via GRF. We also incorporate the recently introduced estimand-specific AIPW estimator implemented through an expansion of the OutcomeWeights R package by Knaus and Pfleiderer (2024). We utilize the estimate_all() and plot_coef() functions as defined by Imbens and Xu (2024). # estimate ATT library(hbal) out1 &lt;- estimate_all(ldw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(ldw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(ldw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out4 &lt;- estimate_all(ldw_cps_plus.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(ldw_psid_plus.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out6 &lt;- estimate_all(ldw_cps.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out7 &lt;- estimate_all(ldw_psid.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps &lt;- lapply(top5_datasets.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out8 &lt;- out.cps[[1]] out9 &lt;- out.cps[[2]] out10 &lt;- out.cps[[3]] out11 &lt;- out.cps[[4]] out12 &lt;- out.cps[[5]] out13 &lt;- out.psid[[1]] out14 &lt;- out.psid[[2]] out15 &lt;- out.psid[[3]] out16 &lt;- out.psid[[4]] out17 &lt;- out.psid[[5]] # build plot titles base_titles &lt;- c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS1&quot; , &quot;(C) LDW-PSID1&quot;, &quot;(D) Trimmed LDW-CPS1 &quot;, &quot;(E) Trimmed LDW-PSID1&quot;, &quot;(F) Trimmed LDW-CPS1-PLUS &quot;, &quot;(G) Trimmed LDW-PSID1-PLUS&quot;) top_start &lt;- 8 # H is 8th letter num_cps &lt;- length(top5_methods.cps) num_psid &lt;- length(top5_methods.psid) top_letters_cps &lt;- LETTERS[top_start:(top_start + num_cps - 1)] top_letters_psid &lt;- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)] top5_titles.cps &lt;- paste0(&quot;(&quot;, top_letters_cps, &quot;) Top CPS1: &quot;, top5_methods.cps) top5_titles.psid &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid) plot_titles &lt;- c(base_titles, top5_titles.cps, top5_titles.psid) # combine all results all_outs &lt;- c(list(out1, out2, out3, out4, out5, out6, out7), out.cps, out.psid) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 2.74: FIGUREA9. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.75: FIGUREA9. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.76: FIGUREA9. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.77: FIGUREA9. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.78: FIGUREA9. ATT Estimates Model A Given Unconfoundedness using LDW Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;ldw_model_a&quot;) The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, trimmed versions of the LDW-CPS1 and LDW-PSID1 samples (similar to Imbens and Xu (2024)) and a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria. Figure (A) presents the benchmark from the experimental sample (LDW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the observational samples, LDW-CPS1 and LDW-PSID1, while figures (D) and (E) present those for the trimmed versions, replicating the tutorial results of Imbens &amp; Xu (2024). Figures (F) through (J) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-based subsamples under parallel rules. Across the LDW-CPS1 dataset and its top-ranked subsamples, all estimators generally produce ATT estimates that closely cluster around the experimental benchmark. However, the adap_weight_trunc_smr_weight sample exhibit somewhat larger deviations. While most estimates are positive, the overlap_crump and optimal_pair subsample results include a few negative ATT estimates, and all ATT estimates for the mahvars subsample are consistently negative. In contrast, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors compared to LDW-CPS1 samples. Most ATT estimates are negatively aligned, indicating increased methodological uncertainty in these samples. Positive ATT estimates emerge only for the subsample based on overlap_crump. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 2.5: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) LDW-Experimental 676.0457 1670.7088 1960.9893 290.2805 (B) LDW-CPS1 670.2431 -8497.5161 1729.1183 10226.6344 (C) LDW-PSID1 829.1860 -15204.7774 3093.0153 18297.7928 (D) Trimmed LDW-CPS1 466.2262 -9239.5208 694.6026 9934.1234 (E) Trimmed LDW-PSID1 773.5220 -15869.5446 -1506.4339 14363.1107 (F) Trimmed LDW-CPS1-PLUS 671.0302 -8497.5161 1729.1183 10226.6344 (G) Trimmed LDW-PSID1-PLUS 883.2269 -14876.1225 2462.3215 17338.4440 (H) Top CPS1: optimal_pair 714.1254 1798.3715 2437.5903 639.2188 (I) Top CPS1: card 743.9572 1120.3711 2037.5080 917.1369 (J) Top CPS1: mahvars 696.1840 1259.1632 2026.7637 767.6005 (K) Top CPS1: exact 1543.5600 1850.0940 3406.3193 1556.2253 (L) Top CPS1: ebal_weight 667.7695 -8497.5161 1729.1183 10226.6344 (M) Top PSID1: card 941.1423 -862.3562 1732.6812 2595.0374 (N) Top PSID1: mahvars 1179.1251 -1561.3903 420.1772 1981.5675 (O) Top PSID1: at_perc_ebal_weight 821.8683 -15204.7774 2890.6547 18095.4321 (P) Top PSID1: optimal_pair 890.2079 -799.8420 2580.0545 3379.8966 (Q) Top PSID1: at_perc_cbps_weight 820.3766 -15204.7774 3098.9742 18303.7516 The ATT results are presented in the table below: # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) %&gt;% kable_styling(full_width = TRUE) Table 2.6: Table 2.7: ATT Estimates and SEs LDW-Experimental LDW-CPS1 LDW-PSID1 Trimmed LDW-CPS1 Trimmed LDW-PSID1 Trimmed LDW-CPS1-PLUS Trimmed LDW-PSID1-PLUS Top CPS1: optimal_pair Top CPS1: card Top CPS1: mahvars Top CPS1: exact Top CPS1: ebal_weight Top PSID1: card Top PSID1: mahvars Top PSID1: at_perc_ebal_weight Top PSID1: optimal_pair Top PSID1: at_perc_cbps_weight Experimental Benchmark 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) -9239.52 (354.42) -15869.54 (580.40) -8497.52 (581.92) -14876.12 (710.82) 2019.31 (703.83) 1398.28 (753.37) 1442.99 (706.97) 2356.55 (1610.09) -8497.52 (581.92) 1201.02 (940.46) -1561.39 (1287.97) -15204.78 (655.91) -799.84 (995.75) -15204.78 (655.91) diff 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) -9239.52 (354.42) -15869.54 (580.40) -8497.52 (581.92) -14876.12 (710.82) 2019.31 (703.83) 1398.28 (753.37) 1442.99 (706.97) 2356.55 (1610.09) -8497.52 (581.92) 1201.02 (940.46) -1561.39 (1287.97) -15204.78 (655.91) -799.84 (995.75) -15204.78 (655.91) reg 1670.71 (680.20) 1066.38 (626.85) 4.16 (854.15) 123.70 (413.56) -2475.11 (746.10) 1066.38 (626.85) 42.10 (869.76) 2006.88 (719.74) 1525.36 (712.33) 1334.81 (671.00) 2499.17 (1527.94) 1066.38 (626.85) 1130.40 (900.93) -677.61 (1132.14) 4.16 (854.15) 236.51 (914.30) 4.16 (854.15) om.reg 1706.20 (587.94) 1133.28 (624.26) 687.82 (635.26) 213.19 (387.53) -2303.97 (605.53) 1133.28 (624.26) 708.75 (704.38) 1798.37 (611.00) 1576.15 (615.38) 1465.81 (597.06) 2322.40 (1319.64) 1133.28 (624.26) 1462.48 (799.83) 3.86 (1098.60) 687.82 (635.26) 1781.94 (656.95) 687.82 (635.26) om.grf 1764.61 (582.34) 1098.04 (629.63) 744.36 (634.10) 69.09 (388.78) -2397.03 (608.27) 1098.87 (630.68) 806.68 (705.79) 2072.58 (594.54) 1613.92 (589.54) 1450.19 (564.68) 2173.41 (1278.48) 1090.38 (629.72) 1351.63 (726.00) -486.46 (919.05) 766.88 (635.29) 765.80 (607.05) 756.12 (634.93) matching 1757.17 (764.06) 1729.12 (815.38) 2255.47 (1403.83) 694.60 (591.89) -1634.69 (881.64) 1729.12 (815.38) 2415.12 (1320.78) 1836.40 (893.51) 1120.37 (926.15) 1403.21 (816.34) 2817.29 (1700.42) 1729.12 (815.38) 1732.68 (1177.52) 420.18 (1318.64) 2255.47 (1403.83) 2580.05 (1320.90) 2255.47 (1403.83) psm 1861.46 (694.65) 1191.09 (739.06) 3093.02 (718.06) 438.19 (467.93) -1506.43 (847.06) 997.00 (747.46) 2462.32 (895.42) 2437.59 (706.30) 1982.59 (740.46) 2026.76 (710.79) 2624.07 (1622.04) 1191.09 (739.06) -862.36 (1027.25) -1504.21 (1242.87) 2890.65 (748.82) 2568.00 (775.61) 3098.97 (717.56) ipw 1790.66 (679.48) 1223.33 (684.66) 685.05 (899.39) 142.67 (533.24) -2322.37 (816.38) 1223.33 (684.66) 876.49 (966.34) 2019.31 (703.83) 1398.28 (753.37) 1442.99 (706.97) 3057.52 (1554.07) 1406.35 (654.92) 1201.02 (940.46) -1561.39 (1287.97) -458.07 (828.71) -799.84 (995.75) -308.12 (835.57) cbps 1709.55 (699.04) 1408.01 (654.96) 2437.70 (877.80) 402.23 (473.48) -1709.60 (963.61) 1408.01 (654.96) 2401.25 (950.12) 2019.31 (703.83) 1398.28 (753.37) 1442.99 (706.97) 3057.52 (1554.07) 1406.35 (654.92) 1201.02 (940.46) -1561.39 (1287.97) -458.07 (828.71) -799.84 (995.75) -308.12 (835.57) ebal 1712.12 (699.26) 1406.27 (654.93) 2420.49 (876.85) 399.96 (473.60) -1554.92 (989.77) 1406.27 (654.93) 2436.68 (953.13) 1805.45 (724.48) 1568.50 (745.57) 1447.73 (746.99) 2313.13 (1573.09) 1406.27 (654.93) 1486.83 (954.64) 38.50 (1165.36) 2420.49 (876.85) 2345.80 (908.88) 2420.49 (876.85) dml 1960.99 (682.98) 1068.62 (627.81) 91.01 (861.30) 107.75 (413.81) -2578.17 (747.16) 1068.62 (627.81) -34.23 (882.81) 2046.96 (717.36) 1432.75 (721.74) 1259.16 (661.07) 3406.32 (1451.01) 1068.62 (627.81) 964.93 (902.21) -563.51 (1055.05) 91.01 (861.30) 801.61 (845.61) 91.01 (861.30) aipw_grf 1718.35 (690.60) 1546.90 (713.24) 1387.93 (773.40) 522.47 (573.77) -1753.70 (779.79) 1546.90 (713.24) 1340.59 (858.17) 2241.72 (755.25) 2037.51 (813.72) 1494.33 (723.94) 2360.18 (1613.05) 1546.90 (713.24) 955.14 (1009.14) -234.77 (1156.80) 1387.93 (773.40) 1276.99 (881.66) 1387.93 (773.40) aipw_ow 1831.33 (681.18) 1412.96 (690.23) 1324.99 (760.19) 337.77 (522.69) -1896.12 (716.56) 1412.96 (690.23) 1379.65 (781.21) 2245.94 (735.83) 1619.43 (802.50) 1432.63 (741.42) 1850.09 (1718.82) 1412.96 (690.23) 1265.27 (974.80) -177.48 (1197.07) 1324.99 (760.19) 1411.76 (784.30) 1324.99 (760.19) The first value in each cell represents the point estimate from the respective estimator and sample. The number in brackets directly following it is the robust standard error (SE) associated with that estimate, indicating the uncertainty or variability around the point estimate. The tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. For most LDW-CPS1-based samples, estimates remain not only positive but also comparatively close to the experimental benchmark, with modest variance inflation. In contrast, the LDW-PSID1-based estimates exhibit greater variability, more frequently negative values, and larger standard errors, reflecting an increased challenge of achieving balance and overlap in this observational dataset. Overall, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;ldw_att_estimates_model_a&quot;) Improved overlap and covariate balance generally leads to estimates closer to the experimental benchmark, but often at the cost of increased standard errors. This trade-off highlights the need to carefully balance bias reduction against precision when selecting methods for robust causal inference. Next, we explore alternative estimands such as heterogeneous treatment effects and quantile treatment effects, which may provide deeper insights into the validity of the unconfoundedness assumption. 2.9.2 Conditional average treatment effect on the treated (CATT) CATT enables analysis of treatment effect heterogeneity across covariate-defined subpopulations. We estimate the CATT for the same samples previously considered in the ATT estimation by applying the Augmented Inverse Probability Weighting Generalized Random Forest (AIPW-GRF) method via the catt() function from Imbens and Xu (2024). # estimate CATT catt.ldw &lt;- catt(ldw, Y, treat, covar) catt.cps &lt;- catt(ldw_cps, Y, treat, covar) catt.psid &lt;- catt(ldw_psid, Y, treat, covar) catt.cps.trim &lt;- catt(ldw_cps.trim, Y, treat, covar) catt.psid.trim &lt;- catt(ldw_psid.trim, Y, treat, covar) catt.cps_plus.trim &lt;- catt(ldw_cps_plus.trim, Y, treat, covar) # similar to Imbens &amp; Xu (2024) catt.psid_plus.trim &lt;- catt(ldw_psid_plus.trim, Y, treat, covar) # similar to Imbens &amp; Xu (2024) catt.top5_cps &lt;- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid &lt;- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar)) Then, we employ a modified version of the function plot_catt() from Imbens and Xu (2024) to visualize the results by plotting the estimated CATTs for all samples at the covariate values of each treated unit against their corresponding experimental benchmarks. Gray dots represent pairs of CATT estimates at covariate values of treated units, while the red crosses indicate pairs of estimated ATTs. # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim, catt.cps_plus.trim, catt.psid_plus.trim), catt.top5_cps, catt.top5_psid) # plot results par(mfrow = c(2,2)) par(cex.main = 0.9) plot_catt_panels(all_catt, plot_titles) Figure 2.79: FIGUREA10. CATT Estimates Model A using LDW Data Figure 2.80: FIGUREA10. CATT Estimates Model A using LDW Data Figure 2.81: FIGUREA10. CATT Estimates Model A using LDW Data Figure 2.82: FIGUREA10. CATT Estimates Model A using LDW Data Although the AIPW estimator can produce ATT estimates closely aligned with the experimental benchmark using LDW data, its performance for revealing the true CATT is considerably worse. all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 2.8: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) LDW-Experimental -148.845 3847.576 1781.8163 3996.421 (B) LDW-CPS1 -5113.357 7104.830 1994.9072 12218.187 (C) LDW-PSID1 -8027.850 4649.666 777.1562 12677.515 (D) Trimmed LDW-CPS1 -5880.843 7319.475 2059.5148 13200.318 (E) Trimmed LDW-PSID1 -8425.960 4736.539 685.6976 13162.498 (F) Trimmed LDW-CPS1-PLUS -7095.935 5606.071 787.3596 12702.006 (G) Trimmed LDW-PSID1-PLUS -10807.615 3027.968 -1777.5392 13835.583 (H) Top CPS1: optimal_pair -1235.530 6155.085 2280.9149 7390.615 (I) Top CPS1: card -1017.160 4816.883 1436.1808 5834.043 (J) Top CPS1: mahvars -2452.687 4823.015 1542.0369 7275.702 (K) Top CPS1: exact 1971.381 2987.374 2685.9439 1015.994 (L) Top CPS1: ebal_weight -5443.503 7299.079 2053.2340 12742.582 (M) Top PSID1: card -3231.863 3825.987 885.4359 7057.851 (N) Top PSID1: mahvars -6108.199 3810.232 -431.5045 9918.432 (O) Top PSID1: at_perc_ebal_weight -8408.411 4558.570 716.3808 12966.982 (P) Top PSID1: optimal_pair -5676.637 3111.795 407.0160 8788.432 (Q) Top PSID1: at_perc_cbps_weight -8330.860 4646.723 766.7725 12977.583 Specifically, with LDW-CPS1, CATT estimates span from $-4,979.99 to $7,201.81, contrasting with the CATT estimated from experimental data which ranges from $-189.40 to $3,835.95, with a mean CATT estimate of $1,713.26. The LDW-PSID1 data shows an even broader CATT estimate range, spanning from $-8,643.02 to $4,903.22, and a notably lower mean of approximately $820.77. Among the trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary substantially. Specific samples such as card or overlap_crump subsamples produce minimum CATTs that are considerably negative, but produce positive mean estimates. Subsamples like ps_threshold, and optimal_pair also deliver positive mean CATT estimates, though with smaller negative minimums, while mahvars is the only method among these to produce a negative mean CATT. Importantly, across all methods, the mean CATT estimates are far away from experimental mean estimate. The CATT estimates for the LDW-PSID1 trimmed and top-ranked subsamples reveal substantially decreased mean values and wider extremes compared to their CPS1 counterparts, reflecting greater difficulties in producing reliable treatment effect estimates. This variation in range and means across methods and samples reflects substantial heterogeneity in treatment effect estimation, indicating that while some criteria improve alignment with experimental benchmarks, others introduce considerable discrepancies and variability in estimated heterogeneous effects. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;model_a&quot;) 2.9.3 Quantile treatment effect on the treated (QTET) QTET provides a robust way to analyze treatment effect heterogeneity while being less impacted by outliers compared to average treatment effect measures. The QTET estimates are obtained using the propensity score re-weighting method introduced by Firpo (2007). Implementation leverages the qte() function from Imbens and Xu (2024), while visualization employs a modified version of their plot_qte() function. qte.ldw &lt;- est_qte(Y, treat, covar, data = ldw, cores = 4) qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) qte.ldw_cps_plus &lt;- est_qte(Y, treat, covar, data = ldw_cps_plus) qte.ldw_psid_plus &lt;- est_qte(Y, treat, covar, data = ldw_psid_plus) qte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps.trim) qte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid.trim) qte.ldw_cps_plus.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps_plus.trim) qte.ldw_psid_plus.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid_plus.trim) qte.top5_cps &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.ldw0 &lt;- est_qte(Y, treat, NULL, data = ldw) qte.ldw.cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) qte.ldw.psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) qte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps.trim) qte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid.trim) qte.ldw_cps_plus.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps_plus.trim) qte.ldw_psid_plus.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid_plus.trim) qte.top5_cps0 &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid0 &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d)) Each plot displays three distinct series for every dataset analyzed: (1) The blue line with diamond-shaped points represents QTET estimates derived from the experimental sample, serving as the benchmark. (2) The red line with triangles shows QTET estimates from the observational data before any adjustment. (3) The black line with circles presents QTET estimates for the observational data after applying covariate adjustment. par(mfrow = c(2,2)) par(cex.main = 0.8) # CPS1 plot_qte(qte.ldw_cps, qte.ldw.cps0, qte.ldw, main = &quot;(B) LDW-CPS1&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 plot_qte(qte.ldw_psid, qte.ldw.psid0, qte.ldw, main = &quot;(C) LDW-PSID1&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) ## CPS1 trimmed plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.ldw_cps, main = &quot;(D) LDW-CPS1 (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 trimmed plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.ldw_psid, main = &quot;(E) LDW-PSID1 (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 2.83: FIGUREA11. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental ## CPS1-PLUS trimmed plot_qte(qte.ldw_cps_plus.trim, qte.ldw_cps_plus.trim0, qte.ldw_cps_plus, main = &quot;(F) LDW-CPS1-PLUS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1-PLUS trimmed plot_qte(qte.ldw_psid_plus.trim, qte.ldw_psid_plus.trim0, qte.ldw_psid_plus, main = &quot;(G) LDW-PSID1-PLUS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # CPS1 top methods plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000)) Figure 2.84: FIGUREA11. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental # PSID1 top methods plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000)) Figure 2.85: FIGUREA11. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 2.86: FIGUREA11. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the experimental and various observational samples. The QTETs estimated from the original and trimmed LDW-CPS1 sample (B and D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original and trimmed LDW-PSID1 subsample (C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked LDW-CPS1-based subsamples, QTETs (F - J) continue to track the true experimental effect well, whereas LDW-PSID1-based subsamples produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty. # list results plots_ldw &lt;- list( list(mod = qte.ldw_cps, mod0 = qte.ldw.cps0, bm = qte.ldw, main = &quot;(B) LDW CPS1&quot;), list(mod = qte.ldw_psid, mod0 = qte.ldw.psid0, bm = qte.ldw, main = &quot;(C) LDW PSID1&quot;), list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.ldw_cps, main = &quot;(D) LDW CPS1 (Trimmed)&quot;), list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.ldw_psid, main = &quot;(E) LDW PSID1 (Trimmed)&quot;), list(mod = qte.ldw_cps_plus.trim, mod0 = qte.ldw_cps_plus.trim0, bm = qte.ldw_cps_plus, main = &quot;(F) LDW CPS1-PLUS (Trimmed)&quot;), list(mod = qte.ldw_psid_plus.trim, mod0 = qte.ldw_psid_plus.trim0, bm = qte.ldw_psid_plus, main = &quot;(G) LDW PSID1-PLUS (Trimmed)&quot;) ) # save results save_qtet(plots_ldw, prefix = &quot;ldw_model_a&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000), prefix = &quot;ldw_model_a_top&quot;) save_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000), prefix = &quot;ldw_model_a_top&quot;) 2.9.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c(list(ldw, ldw_cps, ldw_psid, ldw_cps.trim, ldw_psid.trim, ldw_cps_plus.trim.match, ldw_psid_plus.trim.match), top5_datasets.cps, top5_datasets.psid) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 2.87: FIGUREB12. Outcome Weights Model B using LDW Data Figure 2.88: FIGUREB12. Outcome Weights Model B using LDW Data Figure 2.89: FIGUREB12. Outcome Weights Model B using LDW Data Figure 2.90: FIGUREB12. Outcome Weights Model B using LDW Data Figure 2.91: FIGUREB12. Outcome Weights Model B using LDW Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat, &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 2.9: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) LDW-Experimental 1 -1 (B) LDW-CPS1 1 -1 (C) LDW-PSID1 1 -1 (D) Trimmed LDW-CPS1 1 -1 (E) Trimmed LDW-PSID1 1 -1 (F) Trimmed LDW-CPS1-PLUS 1 -1 (G) Trimmed LDW-PSID1-PLUS 1 -1 (H) Top CPS1: optimal_pair 1 -1 (I) Top CPS1: card 1 -1 (J) Top CPS1: mahvars 1 -1 (K) Top CPS1: exact 1 -1 (L) Top CPS1: ebal_weight 1 -1 (M) Top PSID1: card 1 -1 (N) Top PSID1: mahvars 1 -1 (O) Top PSID1: at_perc_ebal_weight 1 -1 (P) Top PSID1: optimal_pair 1 -1 (Q) Top PSID1: at_perc_cbps_weight 1 -1 The outcome weights are not obtained directly from the ATT point estimates due to computational design of other methods. Instead, the ATT is separately estimated for each dataset following the approach developed by Knaus and Pfleiderer (2024). The evaluation reveals that across each sample the estimated outcome weights sum to one within the treated group and minus one within the untreated group, resulting in an overall sum of zero. #save results save_ow(ow_att, plot_titles, prefix = &quot;model_a&quot;) 2.10 Validation through placebo analyses To further evaluate the credibility of the unconfoundedness assumption, a placebo analysis is performed by designating 1975 earnings (re75) as the outcome variable and omitting both re75 and u75 from the list of covariates. The analysis utilizes all previously considered samples and recomputes the ATT via the function estimate_all, conditioning only on the remaining set of covariates. # define variables Y_pl &lt;- &quot;re75&quot; treat &lt;- &quot;treat&quot; covar_pl &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;u74&quot;) # estimate placebo ATT on original and observational datasets out1_pl &lt;- estimate_all(ldw, Y_pl, &quot;treat&quot;, covar_pl) out2_pl &lt;- estimate_all(ldw_cps, Y_pl, &quot;treat&quot;, covar_pl) out3_pl &lt;- estimate_all(ldw_psid, Y_pl, &quot;treat&quot;, covar_pl) out4_pl &lt;- estimate_all(ldw_cps_plus.trim, Y_pl, &quot;treat&quot;, covar_pl) out5_pl &lt;- estimate_all(ldw_psid_plus.trim, Y_pl, &quot;treat&quot;, covar_pl) out6_pl &lt;- estimate_all(ldw_cps.trim, Y_pl, &quot;treat&quot;, covar_pl) out7_pl &lt;- estimate_all(ldw_psid.trim, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on top ranked datasets out.cps_pl &lt;- lapply(top5_datasets.cps, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out.psid_pl &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out8 &lt;- out.cps_pl[[1]] out9 &lt;- out.cps_pl[[2]] out10 &lt;- out.cps_pl[[3]] out11 &lt;- out.cps_pl[[4]] out12 &lt;- out.cps_pl[[5]] out13 &lt;- out.psid_pl[[1]] out14 &lt;- out.psid_pl[[2]] out15 &lt;- out.psid_pl[[3]] out16 &lt;- out.psid_pl[[4]] out17 &lt;- out.psid_pl[[5]] # collect all placebo results all_outs.pl &lt;- c(list(out1_pl, out2_pl, out3_pl, out4_pl, out5_pl, out6_pl, out7_pl), out.cps_pl, out.psid_pl) # plot placebo results band_pl &lt;- out1_pl[1, 3:4] est_pl &lt;- out1_pl[1, 1] ylim_pl = c(-15500, 5500) plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.7) Figure 2.92: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 2.93: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 2.94: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 2.95: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 2.96: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome # save results save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, &quot;ldw_model_a_placebo&quot;) The placebo ATT results are presented in the table below: # print placebo results result_mat_pl &lt;- create_matrix_results(all_outs.pl, plot_titles) knitr::kable(result_mat_pl, booktabs = TRUE, caption = &quot;Placebo ATT Estimates and SEs&quot;) %&gt;% kable_styling(full_width = TRUE) Table 2.10: Table 2.11: Placebo ATT Estimates and SEs LDW-Experimental LDW-CPS1 LDW-PSID1 Trimmed LDW-CPS1 Trimmed LDW-PSID1 Trimmed LDW-CPS1-PLUS Trimmed LDW-PSID1-PLUS Top CPS1: optimal_pair Top CPS1: card Top CPS1: mahvars Top CPS1: exact Top CPS1: ebal_weight Top PSID1: card Top PSID1: mahvars Top PSID1: at_perc_ebal_weight Top PSID1: optimal_pair Top PSID1: at_perc_cbps_weight Experimental Benchmark 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -12074.77 (183.95) -15746.50 (433.53) -12118.75 (247.18) -17310.56 (381.31) 58.85 (337.62) -321.71 (327.30) 181.42 (392.79) 0.00 (0.00) -12118.75 (247.18) -316.46 (482.91) -620.37 (756.62) -17531.28 (360.60) -1710.77 (357.12) -17531.28 (360.60) diff 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -12074.77 (183.95) -15746.50 (433.53) -12118.75 (247.18) -17310.56 (381.31) 58.85 (337.62) -321.71 (327.30) 181.42 (392.79) 0.00 (0.00) -12118.75 (247.18) -316.46 (482.91) -620.37 (756.62) -17531.28 (360.60) -1710.77 (357.12) -17531.28 (360.60) reg 224.34 (218.33) -1134.82 (272.44) -2757.40 (589.02) -1395.81 (216.87) -3331.37 (539.11) -1134.82 (272.44) -2791.14 (586.16) 26.23 (233.27) -164.01 (261.86) 122.91 (304.54) 0.00 (0.00) -1134.82 (272.44) -239.97 (438.64) 103.01 (566.52) -2757.40 (589.02) -450.75 (481.81) -2757.40 (589.02) om.reg 165.70 (284.98) -1096.70 (395.18) -2640.76 (367.46) -1327.06 (299.84) -3245.87 (571.43) -1096.70 (395.18) -2693.20 (415.11) 56.09 (315.39) -163.96 (268.84) 154.22 (341.02) 0.00 (0.00) -1096.70 (395.18) -364.83 (391.80) 263.10 (606.27) -2640.76 (367.46) -1197.66 (261.10) -2640.76 (367.46) om.grf 109.73 (284.03) -1590.61 (373.01) -4290.47 (343.87) -1796.03 (278.27) -4883.92 (523.53) -1577.24 (373.93) -4314.19 (388.10) 174.93 (279.67) -166.78 (267.38) 257.51 (305.15) 0.00 (0.00) -1586.62 (372.99) -52.15 (391.33) -46.24 (560.76) -4277.81 (344.64) -859.18 (262.53) -4296.75 (343.76) matching 148.67 (227.58) -1465.93 (351.78) -1913.65 (805.37) -1698.99 (299.92) -3372.05 (580.70) -1465.93 (351.78) -2212.50 (773.97) 81.70 (282.50) -362.21 (313.69) 339.84 (283.87) 0.00 (0.00) -1465.93 (351.78) -23.88 (494.96) 226.18 (589.67) -1913.65 (805.37) -598.67 (529.25) -1913.65 (805.37) psm 277.10 (299.90) -1423.50 (416.96) -2688.25 (503.26) -1450.09 (286.85) -3681.53 (609.49) -1352.83 (399.06) -2846.27 (573.23) -75.70 (371.48) -314.09 (315.22) 449.11 (345.60) 0.00 (0.00) -1423.50 (416.96) 49.80 (448.74) 80.93 (657.97) -2814.88 (470.32) -829.84 (317.64) -2788.08 (486.24) ipw 180.76 (309.68) -1552.48 (335.84) -3224.79 (738.21) -1665.18 (315.82) -4355.58 (551.46) -1552.48 (335.84) -3465.02 (708.20) 58.85 (337.62) -321.71 (327.30) 181.42 (392.79) 0.00 (0.00) 0.05 (254.74) -316.46 (482.91) -620.37 (756.62) -1474.17 (318.63) -1710.77 (357.12) -1416.18 (326.00) cbps 188.34 (304.79) -1227.83 (297.89) -2282.31 (834.92) -1487.19 (256.67) -4107.03 (643.70) -1227.83 (297.89) -2537.31 (836.47) 58.85 (337.62) -321.71 (327.30) 181.42 (392.79) 0.00 (0.00) 0.05 (254.74) -316.46 (482.91) -620.37 (756.62) -1474.17 (318.63) -1710.77 (357.12) -1416.18 (326.00) ebal 189.20 (304.71) -1228.49 (297.88) -2250.80 (842.15) -1477.27 (256.56) -4080.14 (652.32) -1228.49 (297.88) -2473.43 (840.37) 55.40 (339.02) -152.62 (318.19) 139.64 (457.50) 0.00 (0.00) -1228.49 (297.88) -324.36 (512.68) 205.50 (711.78) -2250.80 (842.15) -946.32 (687.61) -2250.80 (842.15) dml 275.69 (231.57) -1152.96 (271.75) -2725.28 (591.57) -1401.28 (217.10) -3412.13 (539.38) -1152.96 (271.75) -2787.00 (585.61) -71.76 (235.66) -49.66 (270.04) 136.72 (317.05) 0.00 (0.00) -1152.96 (271.75) -35.83 (467.61) -26.10 (548.60) -2725.28 (591.57) -418.86 (483.43) -2725.28 (591.57) aipw_grf 82.43 (231.26) -1285.84 (267.60) -2408.26 (616.07) -1515.79 (250.69) -4246.59 (503.91) -1285.84 (267.60) -2872.04 (608.79) 202.03 (263.11) -357.28 (296.49) 307.22 (297.23) 0.00 (0.00) -1285.84 (267.60) -4.97 (431.67) 156.20 (554.54) -2408.26 (616.07) -446.85 (431.41) -2408.26 (616.07) aipw_ow 108.01 (233.22) -1318.36 (276.40) -2904.04 (648.78) -1515.34 (243.49) -4454.43 (474.65) -1318.36 (276.40) -3509.84 (457.13) 100.29 (308.64) -325.51 (294.36) 161.64 (355.48) 0.00 (0.00) -1318.36 (276.40) 141.95 (430.86) 156.19 (651.92) -2904.04 (648.78) -581.33 (333.46) -2904.04 (648.78) The placebo analysis reveals that the experimental benchmarks are positive, near zero and statistically insignificant, while all estimators applied to the observational datasets, LDW-CPS1 and LDW-PSID1, yield by majority large, negative ATT estimates. For LDW-CPS1, most ATT estimates are negative. The overlap_crump subsample shows a modest improvement toward the experimental benchmark compared to LDW-CPS1 (B) results, but also produces notably poorer estimates for certain estimators. The trimmed subsamples (D) and (I), which use similar approaches, further improve upon the LDW-CPS1 (B) results. The optimal_pair and card subsamples provide even greater improvement. The mahvars (G) subsample delivers ATT estimates closest to the experimental benchmark and is the only case to yield positive ATT estimates across the LDW-CPS1 samples. For LDW-PSID1, the subsample (O) applying the overlap_common_range method shows no improvement compared to the LDW-PSID1 sample (C) except for the Diff-in-Means estimator. The overlap_crump subsample generally delivers ATT estimates closer to the experimental benchmark, while the card and mahvars subsamples producing estimates even closer to the experimental benchmark. The trimmed subsamples (E) and (N), which use similar approaches, achieve the closest alignment with the benchmark. Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis reveals substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underlines the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings. # save results save_csv(result_mat_pl, &quot;ldw_att_estimates_pl_model_a&quot;) 2.11 Validation through sensitivity analyses Finally, a sensitivity analyses using the LDW data is conducted and results are depicted in contour plots using the function sens_ana of Imbens &amp; Xu (2024). # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets filtered_datasets_sens &lt;- check_filter_datasets(all_datasets, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx]) } Figure 2.97: FIGUREB14. Sensitivity Analyses Model B Figure 2.98: FIGUREB14. Sensitivity Analyses Model B Figure 2.99: FIGUREB14. Sensitivity Analyses Model B Figure 2.100: FIGUREB14. Sensitivity Analyses Model B # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;ldw_model_b&quot;) The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of re75. Notably, some samples such as LDW-PSID1 exhibit a greater sensitivity with more pronounced swings including negative estimates at higher confounder strengths, contrasting with consistent positive effects in LDW-CPS1 variants. This highlights sample-specific differences in robustness against potential unobserved confounding. The analyses suggest that some samples maintain stable treatment effect estimates despite increasing confounder strength, while others show greater sensitivity. This highlights the importance of assessing robustness across different samples (respectively methods used to derive specific samples) to account for potential unobserved bias. 2.12 Summary After reexamining model A, that is based on the LaLonde-Dehejia-Wahba (LDW) data and its augmented versions with control groups from CPS-1 and PSID-1, several insights into causal inference challenges emerge. First, we confirm that ensuring overlap between treated and control groups remains crucial for credible causal estimation. The LDW-Experimental data exhibit excellent overlap, while the observational datasets (LDW-CPS1 and LDW-PSID1) show weaker overlap, with many treated units outside the control range. Augmenting these datasets with experimental controls improves overlap but does not consistently improve covariate balance. Second, controlling for covariates such as age, education, race, and prior earnings, and using various methods including matching, weighting, truncation, trimming, and combined approaches, largely yields consistent effects. The propensity score plays an important role in assessing overlap and balancing covariates across groups. Third, the LDW dataset is somewhat unique in that most methods approximate the experimental benchmark well for average treatment effects on the treated (ATT), an achievement not fully replicated in the original LaLonde samples. However, placebo tests using pre-treatment earnings and sensitivity analyses reveal lingering concerns about the unconfoundedness assumption and robustness of some estimators. Overall, this chapter highlights the importance of overlap and covariate balance, the utility of propensity scores, and the need for rigorous validation of treatment assignment assumptions to produce credible causal estimates. Despite improvements in data and methods, tests of unconfoundedness via placebo outcomes suggest caution in interpreting causal effects. References Greifer, Noah. 2025. “Matching Methods.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Ju, Cheng, Joshua Schwab, and Mark J. van der Laan. 2013. “On Adaptive Propensity Score Truncation in Causal Inference.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” Matsouaka, Roland A., and Yunji Zhou. 2023. “Causal Inference in the Absence of Positivity: The Role of Overlap Weights.” Biometrical Journal. Stürmer, Til, Michael Webster-Clark, Jennifer L. Lund, Richard Wyss, Alan R. Ellis, Mark Lunt, Kenneth J. Rothman, and Robert J. Glynn. 2021. “Propensity Score Weighting and Trimming Strategies for Reducing Variance and Bias of Treatment Effect Estimates: A Simulation Study.” American Journal of Epidemiology. "],["lalonde-dehejia-wahba-ldw-data-1.html", "Chapter 3 LaLonde-Dehejia-Wahba (LDW) Data 3.1 Set up 3.2 Model B 3.3 Improving primarily covariate balance 3.4 Improving primarily overlap 3.5 Reassessing methods 3.6 Integrated methods 3.7 Identifying best methods 3.8 Estimating 3.9 Validation through placebo analyses 3.10 Validation through sensitivity analyses 3.11 Summary", " Chapter 3 LaLonde-Dehejia-Wahba (LDW) Data This section (3) covers model B, which, similar to model A, uses 1978 earnings (re78) as the outcome variable but adjusts for a slightly different set of covariates: age, education, race indicators (black, hispanic), marital status, lack of a high school degree, 1975 earnings (re75), and unemployment status in 1974 and 1975 (u74, u75), explicitly excluding 1974 earnings (re74) to test the model’s robustness. The model is specified via a regression formula based on these covariates. To enhance covariate balance between treated and untreated groups, the same comprehensive suite of methods is employed as in model A, organized into five categories. From these approaches, the best five methods are selected based on a score defined by absolute standardized mean differences (SMD) and the effective sample size (ESS), and their resulting datasets are used to estimate the average treatment effect on the treated (ATT). This estimation process also incorporates the augmented inverse probability weighting (AIPW) estimator from the OutcomeWeights R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (re75) as the outcome variable to assess potential biases and the validity of the unconfoundedness assumption. Finally, sensitivity analyses are performed to evaluate the robustness of the treatment effect estimates to violations of these assumptions. For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the model B–specific results. 3.1 Set up 3.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 3.1.2 Inspect data # collect datasets in a list data &lt;- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 3.1: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars lalonde 2675 0 0 13 nsw, age, educ, black, hisp, married, re74, re75, re78, u74, u75, u78, nodegr ldw_tr 185 185 0 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_co 260 0 260 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_cps 16177 185 15992 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid 2675 185 2490 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 3.1.3 Load and preprocess data # assigns 1 to the experimental controls ldw_co$treat &lt;- 1 # merge experimental data with CPS1 data ldw_cps_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_cps # CPS1 data (16177 observations) ) # merge experimental data with PSID1 data ldw_psid_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_psid # PSID1 data (2675 observations) ) datasets &lt;- list(ldw_cps_plus = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus) # inspect each dataset summary_stats_plus &lt;- inspect_data(datasets) knitr::kable(summary_stats_plus, caption = &quot;Summary Statistics&quot;) Table 3.2: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars ldw_cps_plus 16437 445 15992 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid_plus 2935 445 2490 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 3.2 Model B # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) #re74 excluded 3.2.1 Assessing overlap and covariate balance 3.2.1.1 Overlap # assess overlap ldw.ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar) ## -1.26191 0.7410732 Figure 3.1: FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_cps.ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar) ## -16.1181 1.813362 Figure 3.2: FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_psid.ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar) ## -11.47475 3.722802 Figure 3.3: FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. # assess overlap ldw_cps_plus.ps &lt;- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) ## -16.1181 3.425533 Figure 3.4: FIGUREB1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. ldw_psid_plus.ps &lt;- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) ## -11.65343 7.149751 Figure 3.5: FIGUREB1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 3.2.1.2 Covariate balance love.plot(ldw, ldw_cps, treat, covar = covar, title = &quot;LDW-CPS1&quot;) Figure 3.6: FIGUREB2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = &quot;LDW-CPS1-PLUS&quot;) Figure 3.7: FIGUREB2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid, treat, covar = covar, title = &quot;LDW-PSID1&quot;) Figure 3.8: FIGUREB2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = &quot;LDW-PSID1-PLUS&quot;) Figure 3.9: FIGUREB2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. 3.3 Improving primarily covariate balance 3.3.1 Matching 3.3.1.1 Distance Matching 3.3.1.1.1 1:1 Nearest neighbor matching # perform nearest neighbor matching with k=1, logistic propensity score and replacement m.out.cps.nearest &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) m.out.psid.nearest &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) 3.3.1.1.2 k:1 matching (k=2) k&lt;-2 # perform nearest neighbor matching with k=2, logistic propensity score and replacement m.out.cps.k2 &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k2 &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 3.3.1.1.3 k:1 matching (k=3) k&lt;-3 # perform nearest neighbor matching with k=3, logistic propensity score and replacement m.out.cps.k3 &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k3 &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 3.3.1.1.4 Caliper matching # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score m.out.cps.caliper &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) m.out.psid.caliper &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) 3.3.1.1.5 Common support restriction matching # perform nearest neighbor matching with exclusion of units outside common support m.out.cps.cs &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) m.out.psid.cs &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) 3.3.1.1.6 Mahalanobis distance matching (mahvars) # perform nearest neighbor matching using mahalanobis distance on selected covariates m.out.cps.mahvars &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) m.out.psid.mahvars &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) 3.3.1.1.7 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.cps.optimal_pair &lt;- matchit(model, data = ldw_cps, method = &quot;optimal&quot;, distance = &quot;logit&quot;) m.out.psid.optimal_pair &lt;- matchit(model, data = ldw_psid, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 3.3.1.1.8 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.cps.optimal_full &lt;- matchit(model, data = ldw_cps, method = &quot;full&quot;, distance = &quot;logit&quot;) m.out.psid.optimal_full &lt;- matchit(model, data = ldw_psid, method = &quot;full&quot;, distance = &quot;logit&quot;) 3.3.1.1.9 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.cps.general_full &lt;- matchit(model, data = ldw_cps, method = &quot;quick&quot;, distance = &quot;logit&quot;) m.out.psid.general_full &lt;- matchit(model, data = ldw_psid, method = &quot;quick&quot;, distance = &quot;logit&quot;) 3.3.1.1.10 Genetic matching # perform genetic matching m.out.cps.genetic &lt;- matchit(model, data = ldw_cps, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) m.out.psid.genetic &lt;- matchit(model, data = ldw_psid, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) 3.3.1.2 Stratum matching 3.3.1.2.1 Exact matching (exact) # match units exactly by raw covariate profiles m.out.cps.exact &lt;- matchit(model, data = ldw_cps, method = &quot;exact&quot;) m.out.psid.exact &lt;- matchit(model, data = ldw_psid, method = &quot;exact&quot;) 3.3.1.2.2 Coarsened matching (cem) # match units exactly within coarse strata m.out.cps.cem &lt;- matchit(model, data = ldw_cps, method = &quot;cem&quot;) m.out.psid.cem &lt;- matchit(model, data = ldw_psid, method = &quot;cem&quot;) 3.3.1.2.3 Subclassification # partition sample into fixed number of bins based on propensity score m.out.cps.subcl &lt;- matchit(model, data = ldw_cps, method = &quot;subclass&quot;, subclass = 5) m.out.psid.subcl &lt;- matchit(model, data = ldw_psid, method = &quot;subclass&quot;, subclass = 5) 3.3.1.3 Pure subset selection 3.3.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units m.out.cps.card &lt;- matchit(model, data = ldw_cps, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) m.out.psid.card &lt;- matchit(model, data = ldw_psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) 3.3.1.3.2 Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact m.out.cps.profile &lt;- matchit(model, data = ldw_cps, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, solver = &quot;highs&quot;, time = 1200) m.out.psid.profile &lt;- matchit(model, data = ldw_psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, solver = &quot;highs&quot;, time = 1200) 3.3.2 Weighting 3.3.2.1 Inverse probability weights (IPW) # w.out.cps.ipw &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) ldw_cps$ipw_weight &lt;- w.out.cps.ipw$weights w.out.psid.ipw &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) ldw_psid$ipw_weight &lt;- w.out.psid.ipw$weights 3.3.2.2 Stable balancing weights # w.out.cps.opt &lt;- optweight::optweight(model, data = ldw_cps, estimand = &quot;ATT&quot;) ldw_cps$opt_weight &lt;- w.out.cps.opt$weights w.out.psid.opt &lt;- optweight::optweight(model, data = ldw_psid, estimand = &quot;ATT&quot;) ldw_psid$opt_weight &lt;- w.out.psid.opt$weights 3.3.2.3 Propensity score weights w.out.cps.cbps &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) ldw_cps$cbps_weight &lt;- w.out.cps.cbps$weights w.out.psid.cbps &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) ldw_psid$cbps_weight &lt;- w.out.psid.cbps$weights 3.3.2.4 Entropy balancing weights # w.out.cps.ebal &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) ldw_cps$ebal_weight &lt;- w.out.cps.ebal$weights w.out.psid.ebal &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) ldw_psid$ebal_weight &lt;- w.out.psid.ebal$weights 3.4 Improving primarily overlap 3.4.1 Truncation # list weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;opt_weight&quot;, &quot;cbps_weight&quot;, &quot;ebal_weight&quot;) 3.4.1.1 Fixed maximum value truncation # truncate weights by imposing a minimum and maximum threshold ldw_cps.fixed &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(ldw_cps.fixed)) { ldw_cps.fixed &lt;- truncate_weights_fixed(ldw_cps.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) } } ldw_psid.fixed &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(ldw_psid.fixed)) { ldw_psid.fixed &lt;- truncate_weights_fixed(ldw_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) } } 3.4.1.2 At percentile truncation # truncate weights such that values below the 5th percentile and above the 95th percentile are capped ldw_cps.percent &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(ldw_cps.percent)) { ldw_cps.percent &lt;- truncate_weights_percentile(ldw_cps.percent, weight_col = wcol, lower = 0.01, upper = 0.99) } } ldw_psid.percent &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(ldw_psid.percent)) { ldw_psid.percent &lt;- truncate_weights_percentile(ldw_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99) } } 3.4.1.3 Adaptive weight truncation # inspect variance of weights cps_results &lt;- list() psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(ldw_cps)) { cps_results[[paste0(&quot;cps_&quot;, wcol)]] &lt;- check_weights(ldw_cps, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in LDW-CPS1&quot;)) } } for (wcol in weight_columns) { if (wcol %in% names(ldw_psid)) { psid_results[[paste0(&quot;psid_&quot;, wcol)]] &lt;- check_weights(ldw_psid, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in LDW-PSID1&quot;)) } } var_cps_table &lt;- bind_rows(cps_results) var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_cps_table, caption = &quot;Variance of Weights (LDW-CPS1)&quot;) Table 3.3: Variance of Weights (LDW-CPS1) Weight_Column Variance ipw_weight 1.884430e-02 opt_weight 5.193582e+16 cbps_weight 1.861220e-02 ebal_weight 5.657937e+01 knitr::kable(var_psid_table, caption = &quot;Variance of Weights (LDW-PSID1)&quot;) Table 3.3: Variance of Weights (LDW-PSID1) Weight_Column Variance ipw_weight 2.5849861 opt_weight 64.1858073 cbps_weight 0.5926453 ebal_weight 98.2229728 Regarding these results we can apply adaptive weight truncation to all considered weights, where it may help mitigate the influence of extreme weights. # truncate adaptively at mean + 3 standard deviations ldw_cps.adapt &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(ldw_cps.adapt)) { ldw_cps.adapt &lt;- truncate_weights_adaptive(ldw_cps.adapt, weight_col = wcol, c = 3) } } ldw_psid.adapt &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(ldw_psid.adapt)) { ldw_psid.adapt &lt;- truncate_weights_adaptive(ldw_psid.adapt, weight_col = wcol, c = 3) } } 3.4.2 Trimming 3.4.2.1 Propensity score threshold trimming and nn matching (Similar to tutorial of Imbens and Xu (2024)) # apply trimming with thresholds 0.9 and 0.8 ldw_cps_plus.trim &lt;- ps_trim(ldw_cps_plus.ps, threshold = 0.9) ldw_psid_plus.trim &lt;- ps_trim(ldw_psid_plus.ps, threshold = 0.8) # exclude experimental controls, subset trimmed data appropriately ldw_cps_plus.trim.match &lt;- subset(ldw_cps_plus.trim, sample %in% c(1,3) &amp; ps_assoverlap) ldw_psid_plus.trim.match &lt;- subset(ldw_psid_plus.trim, sample %in% c(1,4) &amp; ps_assoverlap) # re-assign treat variable for controls in sample 3 or 4 (non-treated group) ldw_cps_plus.trim.match$treat[ldw_cps_plus.trim.match$sample == 3] &lt;- 0 ldw_psid_plus.trim.match$treat[ldw_psid_plus.trim.match$sample == 4] &lt;- 0 # re-estimate propensity scores on trimmed data and perform 1:1 matching ldw_cps_plus.trim.match &lt;- psmatch(data = ldw_cps_plus.trim.match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid_plus.trim.match &lt;- psmatch(data = ldw_psid_plus.trim.match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 3.4.2.2 Propensity score threshold trimming # apply trimming with threshold 0.9 ldw_cps.trim &lt;- ps_trim(ldw_cps.ps, threshold = 0.9) ldw_psid.trim &lt;- ps_trim(ldw_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.trim &lt;- ps_estimate(data = ldw_cps.trim, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.trim &lt;- ps_estimate(data = ldw_psid.trim, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 3.4.2.3 Common range trimming # trim observations outside the common support region of propensity scores ldw_cps.common &lt;- common_range_trim(ldw_cps.ps) ldw_psid.common &lt;- common_range_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.common &lt;- ps_estimate(data = ldw_cps.common, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.common &lt;- ps_estimate(data = ldw_psid.common, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 3.4.2.4 Crump trimming # trim observations with propensity scores outside [0.1, 0.9] interval ldw_cps.crump &lt;- crump_trim(ldw_cps.ps, lower = 0.1, upper = 0.9) ldw_psid.crump &lt;- crump_trim(ldw_psid.ps, lower = 0.1, upper = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.crump &lt;- ps_estimate(data = ldw_cps.crump, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.crump &lt;- ps_estimate(data = ldw_psid.crump, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 3.4.2.5 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control ldw_cps.stuermer &lt;- stuermer_trim(ldw_cps.ps) ldw_psid.stuermer &lt;- stuermer_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.stuermer &lt;- ps_estimate(data = ldw_cps.stuermer, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.stuermer &lt;- ps_estimate(data = ldw_psid.stuermer, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 3.4.2.6 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations ldw_cps.walker &lt;- walker_trim(ldw_cps.ps) ldw_psid.walker &lt;- walker_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.walker &lt;- ps_estimate(data = ldw_cps.walker, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.walker &lt;- ps_estimate(data = ldw_psid.walker, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 3.4.3 Integrated methods # list trimming methods all_trim.cps &lt;- list(ps_threshold = ldw_cps.trim, common_range = ldw_cps.common, stuermer = ldw_cps.stuermer, walker = ldw_cps.walker, crump = ldw_cps.crump) all_trim.psid &lt;- list(ps_threshold = ldw_psid.trim, common_range = ldw_psid.common, stuermer = ldw_psid.stuermer, walker = ldw_psid.walker, crump = ldw_psid.crump) 3.4.3.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;ipw_weight&quot;) ipw_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ipw_weight&quot;) 3.4.3.2 Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply stable balancing with trimming and attach stable balance weights opt_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;opt_weight&quot;) opt_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;opt_weight&quot;) 3.4.3.3 Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply propensity score weighting with trimming and attach propensity score weights cbps_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;cbps_weight&quot;) cbps_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;cbps_weight&quot;) 3.4.3.4 Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights ebal_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;ebal_weight&quot;) ebal_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ebal_weight&quot;) 3.5 Reassessing methods 3.5.1 Matching # list all matching objects all_match.cps &lt;- list( nn = m.out.cps.nearest, k2 = m.out.cps.k2, k3 = m.out.cps.k3, caliper = m.out.cps.caliper, cS = m.out.cps.cs, mahvars = m.out.cps.mahvars, optimal_pair = m.out.cps.optimal_pair, optimal_full = m.out.cps.optimal_full, gen_full = m.out.cps.general_full, genetic = m.out.cps.genetic, exact = m.out.cps.exact, cem = m.out.cps.cem, card = m.out.cps.card, profile = m.out.cps.profile, subcl = m.out.cps.subcl ) all_match.psid &lt;- list( nn = m.out.psid.nearest, k2 = m.out.psid.k2, k3 = m.out.psid.k3, caliper = m.out.psid.caliper, cs = m.out.psid.cs, mahvars = m.out.psid.mahvars, optimal_pair = m.out.psid.optimal_pair, optimal_full = m.out.psid.optimal_full, gen_full = m.out.psid.general_full, genetic = m.out.psid.genetic, exact = m.out.psid.exact, cem = m.out.psid.cem, card = m.out.psid.card, profile = m.out.psid.profile, subcl = m.out.psid.subcl ) 3.5.1.1 SMD # compute SMD smd_matchit.cps &lt;- compute_abs_smd_matchit(all_match.cps) smd_matchit.psid &lt;- compute_abs_smd_matchit(all_match.psid) 3.5.1.2 ESS # calculate balance statistics bal.cps &lt;- cobalt::bal.tab(model, data = ldw_cps, un = TRUE, weights = all_match.cps, s.d.denom = &quot;treated&quot;) bal.psid &lt;- cobalt::bal.tab(model, data = ldw_psid, un = TRUE, weights = all_match.psid, s.d.denom = &quot;treated&quot;) # compute ESS ess_matchit.cps &lt;- compute_ess_matchit(bal.cps) ess_matchit.psid &lt;- compute_ess_matchit(bal.psid) 3.5.1.3 Visuals # visualize covariate balance plot_matching_balance(all_match.cps, title = &quot;LDW-CPS1&quot;) ## $nn Figure 3.10: FIGUREB3. ## ## $k2 Figure 3.11: FIGUREB3. ## ## $k3 Figure 3.12: FIGUREB3. ## ## $caliper Figure 3.13: FIGUREB3. ## ## $cS Figure 3.14: FIGUREB3. ## ## $mahvars Figure 3.15: FIGUREB3. ## ## $optimal_pair Figure 3.16: FIGUREB3. ## ## $optimal_full Figure 3.17: FIGUREB3. ## ## $gen_full Figure 3.18: FIGUREB3. ## ## $genetic Figure 3.19: FIGUREB3. ## ## $exact Figure 3.20: FIGUREB3. ## ## $cem Figure 3.21: FIGUREB3. ## ## $card Figure 3.22: FIGUREB3. ## ## $profile Figure 3.23: FIGUREB3. ## ## $subcl Figure 3.24: FIGUREB3. plot_matching_balance(all_match.psid, title = &quot;LDW-PSID1&quot;) ## $nn Figure 3.25: FIGUREB3. ## ## $k2 Figure 3.26: FIGUREB3. ## ## $k3 Figure 3.27: FIGUREB3. ## ## $caliper Figure 3.28: FIGUREB3. ## ## $cs Figure 3.29: FIGUREB3. ## ## $mahvars Figure 3.30: FIGUREB3. ## ## $optimal_pair Figure 3.31: FIGUREB3. ## ## $optimal_full Figure 3.32: FIGUREB3. ## ## $gen_full Figure 3.33: FIGUREB3. ## ## $genetic Figure 3.34: FIGUREB3. ## ## $exact Figure 3.35: FIGUREB3. ## ## $cem Figure 3.36: FIGUREB3. ## ## $card Figure 3.37: FIGUREB3. ## ## $profile Figure 3.38: FIGUREB3. ## ## $subcl Figure 3.39: FIGUREB3. 3.5.2 Weighting # list all weights all_weight.cps &lt;- list( ipw_weight = ldw_cps$ipw_weight, opt_weight = ldw_cps$opt_weight, cbps_weight = ldw_cps$cbps_weight, ebal_weight = ldw_cps$ebal_weight ) all_weight.psid &lt;- list( ipw_weight = ldw_psid$ipw_weight, opt_weight = ldw_psid$opt_weight, cbps_weight = ldw_psid$cbps_weight, ebal_weight = ldw_psid$ebal_weight ) 3.5.2.1 SMD # compute SMD smd_weight.cps &lt;- compute_abs_smd_weight(ldw_cps, treat, covar, all_weight.cps) smd_weight.psid &lt;- compute_abs_smd_weight(ldw_psid, treat, covar, all_weight.psid) 3.5.2.2 ESS # compute ESS ess_weight.cps &lt;- compute_ess_weight(ldw_cps, treat, covar, all_weight.cps) ess_weight.psid &lt;- compute_ess_weight(ldw_psid, treat, covar, all_weight.psid) 3.5.2.3 Visuals # visualize covariate balance plot_weighting_balance(ldw_cps, treat, covar, all_weight.cps, &quot;LDW-CPS1&quot;) ## $ipw_weight Figure 3.40: FIGUREB4. ## ## $opt_weight Figure 3.41: FIGUREB4. ## ## $cbps_weight Figure 3.42: FIGUREB4. ## ## $ebal_weight Figure 3.43: FIGUREB4. plot_weighting_balance(ldw_psid, treat, covar, all_weight.psid, &quot;LDW-PSID1&quot;) ## $ipw_weight Figure 3.44: FIGUREB4. ## ## $opt_weight Figure 3.45: FIGUREB4. ## ## $cbps_weight Figure 3.46: FIGUREB4. ## ## $ebal_weight Figure 3.47: FIGUREB4. 3.5.3 Truncation # list truncation methods all_trunc.cps &lt;- list( fix_max_value = ldw_cps.fixed, at_perc = ldw_cps.percent, adap_weight = ldw_cps.adapt ) all_trunc.psid &lt;- list( fix_max_value = ldw_psid.fixed, at_perc = ldw_psid.percent, adap_weight = ldw_psid.adapt ) 3.5.3.1 SMD # compute SMD smd_trunc.cps &lt;- compute_abs_smd_trunc(all_trunc.cps, &quot;treat&quot;, covar, weight_columns) smd_trunc.psid &lt;- compute_abs_smd_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 3.5.3.2 ESS # compute ESS ess_trunc.cps &lt;- compute_ess_trunc(all_trunc.cps, &quot;treat&quot;, covar, weight_columns) ess_trunc.psid &lt;- compute_ess_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 3.5.3.3 Visuals # visualize covariate balance plot_trunc_balance(all_trunc.cps, &quot;treat&quot;, covar, weight_columns, &quot;LDW-CPS1&quot;) ## $fix_max_value_ipw_weight Figure 3.48: FIGUREB5. ## ## $fix_max_value_opt_weight Figure 3.49: FIGUREB5. ## ## $fix_max_value_cbps_weight Figure 3.50: FIGUREB5. ## ## $fix_max_value_ebal_weight Figure 3.51: FIGUREB5. ## ## $at_perc_ipw_weight Figure 3.52: FIGUREB5. ## ## $at_perc_opt_weight Figure 3.53: FIGUREB5. ## ## $at_perc_cbps_weight Figure 3.54: FIGUREB5. ## ## $at_perc_ebal_weight Figure 3.55: FIGUREB5. ## ## $adap_weight_ipw_weight Figure 3.56: FIGUREB5. ## ## $adap_weight_opt_weight Figure 3.57: FIGUREB5. ## ## $adap_weight_cbps_weight Figure 3.58: FIGUREB5. ## ## $adap_weight_ebal_weight Figure 3.59: FIGUREB5. plot_trunc_balance(all_trunc.psid, &quot;treat&quot;, covar, weight_columns, &quot;LDW-PSID1&quot;) ## $fix_max_value_ipw_weight Figure 3.60: FIGUREB5. ## ## $fix_max_value_opt_weight Figure 3.61: FIGUREB5. ## ## $fix_max_value_cbps_weight Figure 3.62: FIGUREB5. ## ## $fix_max_value_ebal_weight Figure 3.63: FIGUREB5. ## ## $at_perc_ipw_weight Figure 3.64: FIGUREB5. ## ## $at_perc_opt_weight Figure 3.65: FIGUREB5. ## ## $at_perc_cbps_weight Figure 3.66: FIGUREB5. ## ## $at_perc_ebal_weight Figure 3.67: FIGUREB5. ## ## $adap_weight_ipw_weight Figure 3.68: FIGUREB5. ## ## $adap_weight_opt_weight Figure 3.69: FIGUREB5. ## ## $adap_weight_cbps_weight Figure 3.70: FIGUREB5. ## ## $adap_weight_ebal_weight Figure 3.71: FIGUREB5. 3.5.4 Trimming # list trimming objects plus original all_trim.cps &lt;- list( original = ldw_cps, ps_threshold = ldw_cps.trim, common_range = ldw_cps.common, crump = ldw_cps.crump, stuermer = ldw_cps.stuermer, walker = ldw_cps.walker ) all_trim.psid &lt;- list( original = ldw_psid, ps_threshold = ldw_psid.trim, common_range = ldw_psid.common, crump = ldw_psid.crump, stuermer = ldw_psid.stuermer, walker = ldw_psid.walker ) 3.5.4.1 SMD # compute SMDs smd_trim.cps &lt;- compute_abs_smd_trim(all_trim.cps, &quot;treat&quot;, covar) smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 3.5.4.2 ESS # compute ESS ess_trim.cps &lt;- compute_ess_trim(all_trim.cps, &quot;treat&quot;, covar) ess_trim.psid &lt;- compute_ess_trim(all_trim.psid, &quot;treat&quot;, covar) 3.5.4.3 Visuals # visualize overlap plot_trim_overlap(all_trim.cps, treat, covar, prefix = &quot;LDW-CPS1&quot;) ## -16.1181 1.813362 ## -16.1181 1.813362 ## -16.1181 2.15634 ## -2.343659 1.583009 ## -16.1181 -1.53596 ## -16.1181 -1.674165 Figure 3.72: FIGUREB6. plot_trim_overlap(all_trim.psid, treat, covar, prefix = &quot;LDW-PSID1&quot;) ## -11.47475 3.722802 ## -11.79877 2.234331 ## -5.979529 2.661789 ## -2.198028 2.22155 ## -7.047886 -2.164173 ## -16.1181 -2.091567 Figure 3.73: FIGUREB6. 3.6 Integrated methods # list all combined results comb.cps &lt;- list( ipw = ipw_comb.cps, opt = opt_comb.cps, cbps = cbps_comb.cps, ebal = ebal_comb.cps ) comb.psid &lt;- list( ipw = ipw_comb.psid, opt = opt_comb.psid, cbps = cbps_comb.psid, ebal = ebal_comb.psid ) 3.6.0.1 SMD # compute SMD smd_all_comb_meth.cps &lt;- compute_abs_smd_comb(comb.cps, &quot;treat&quot;, covar) smd_all_comb_meth.psid &lt;- compute_abs_smd_comb(comb.psid, &quot;treat&quot;, covar) 3.6.0.2 ESS # compute ESS ess_all_comb_meth.cps &lt;- compute_ess_comb(comb.cps, &quot;treat&quot;, covar) ess_all_comb_meth.psid &lt;- compute_ess_comb(comb.psid, &quot;treat&quot;, covar) 3.6.0.3 Visuals # visualize overlap #plot_comb_overlap(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) # visualize covariate balance #plot_comb_balance(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, orig_cps = ldw_cps, orig_psid = ldw_psid, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) # save results #save_comb_hist(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;model_b&quot;, prefix_cps = &quot;ldw_cps1&quot;, prefix_psid = &quot;ldw_psid1&quot;) #save_comb_loveplots(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;model_b&quot;, prefix_cps = &quot;ldw_cps1&quot;, prefix_psid = &quot;ldw_psid1&quot;) 3.7 Identifying best methods # combine all results all_cps &lt;- combine_results(&quot;cps&quot;) all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_cps, &quot;ldw_model_b_cps1_all_results&quot;) save_csv(all_psid, &quot;ldw_model_b_psid1_all_results&quot;) # rank methods ranked_cps &lt;- assess_methods(all_cps) ranked_psid &lt;- assess_methods(all_psid) # get top 5 methods top5_methods.cps &lt;- get_top_methods(ranked_cps, top_n = 5) top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # print results top5_methods_df.cps &lt;- ranked_cps %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps, caption = &quot;Top 5 Methods for CPS1&quot;, booktabs = TRUE) Table 3.4: Top 5 Methods for CPS1 Method Score card 0.7274242 optimal_pair 0.7259802 mahvars 0.7207269 exact 0.7059085 cem 0.6795290 knitr::kable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID1&quot;, booktabs = TRUE) Table 3.4: Top 5 Methods for PSID1 Method Score card 0.7452164 mahvars 0.7307163 cem 0.6863268 at_perc_ebal_weight 0.6850651 optimal_pair 0.6751945 # save results save_csv(top5_methods.cps, &quot;ldw_model_b_cps1_top5_methods&quot;) save_csv(top5_methods.psid, &quot;ldw_model_b_psid1_top5_methods&quot;) dataset_list_cps &lt;- list( &quot;All&quot; = ldw_cps, &quot;original&quot; = ldw_cps, &quot;nn&quot; = m.out.cps.nearest, &quot;caliper&quot; = m.out.cps.caliper, &quot;card&quot; = m.out.cps.card, &quot;cem&quot; = m.out.cps.cem, &quot;cS&quot; = m.out.cps.cs, &quot;k2&quot; = m.out.cps.k2, &quot;k3&quot; = m.out.cps.k3, &quot;mahvars&quot; = m.out.cps.mahvars, &quot;optimal_full&quot; = m.out.cps.optimal_full, &quot;optimal_pair&quot; = m.out.cps.optimal_pair, &quot;gen_full&quot; = m.out.cps.general_full, &quot;genetic&quot; = m.out.cps.genetic, &quot;exact&quot; = m.out.cps.exact, &quot;subcl&quot; = m.out.cps.subcl, &quot;profile&quot; = m.out.cps.profile, &quot;ipw_weight&quot; = ldw_cps$ipw_weight, &quot;opt_weight&quot; = ldw_cps$opt_weight, &quot;cbps_weight&quot; = ldw_cps$cbps_weight, &quot;ebal_weight&quot; = ldw_cps$ebal_weight, &quot;fix_max_value_ipw_weight&quot; = ldw_cps.fixed$ipw_weight, &quot;fix_max_value_opt_weight&quot; = ldw_cps.fixed$opt_weight, &quot;fix_max_value_cbps_weight&quot; = ldw_cps.fixed$cbps_weight, &quot;fix_max_value_ebal_weight&quot; = ldw_cps.fixed$ebal_weight, &quot;at_perc_ipw_weight&quot; = ldw_cps.percent$ipw_weight, &quot;at_perc_opt_weight&quot; = ldw_cps.percent$opt_weight, &quot;at_perc_cbps_weight&quot; = ldw_cps.percent$cbps_weight, &quot;at_perc_ebal_weight&quot; = ldw_cps.percent$ebal_weight, &quot;adap_weight_ipw_weight&quot; = ldw_cps.adapt$ipw_weight, &quot;adap_weight_opt_weight&quot; = ldw_cps.adapt$opt_weight, &quot;adap_weight_cbps_weight&quot; = ldw_cps.adapt$cbps_weight, &quot;adap_weight_ebal_weight&quot; = ldw_cps.adapt$ebal_weight, &quot;ps_threshold&quot; = ldw_cps.trim, &quot;common_range&quot; = ldw_cps.common, &quot;stuermer&quot; = ldw_cps.stuermer, &quot;walker&quot; = ldw_cps.walker, &quot;crump&quot; = ldw_cps.crump, &quot;ipw_common_range&quot; = ipw_comb.cps[[1]], &quot;ipw_crump&quot;= ipw_comb.cps[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.cps[[3]], &quot;ipw_stuermer&quot;= ipw_comb.cps[[4]], &quot;ipw_walker&quot; = ipw_comb.cps[[5]], &quot;opt_common_range&quot; = opt_comb.cps[[1]], &quot;opt_crump&quot; = opt_comb.cps[[2]], &quot;opt_ps_threshold&quot; = opt_comb.cps[[3]], &quot;opt_stuermer&quot; = opt_comb.cps[[4]], &quot;opt_walker&quot; = opt_comb.cps[[5]], &quot;cbps_common_range&quot; = cbps_comb.cps[[1]], &quot;cbps_crump&quot; = cbps_comb.cps[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.cps[[3]], &quot;cbps_stuermer&quot; = cbps_comb.cps[[4]], &quot;cbps_walker&quot;= cbps_comb.cps[[5]], &quot;ebal_common_range&quot; = ebal_comb.cps[[1]], &quot;ebal_crump&quot; = ebal_comb.cps[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.cps[[3]], &quot;ebal_stuermer&quot; = ebal_comb.cps[[4]], &quot;ebal_walker&quot; = ebal_comb.cps[[5]]) dataset_list_psid &lt;- list( &quot;All&quot; = ldw_psid, &quot;original&quot; = ldw_psid, &quot;nn&quot; = m.out.psid.nearest, &quot;caliper&quot; = m.out.psid.caliper, &quot;card&quot; = m.out.psid.card, &quot;cem&quot; = m.out.psid.cem, &quot;cS&quot; = m.out.psid.cs, &quot;k2&quot; = m.out.psid.k2, &quot;k3&quot; = m.out.psid.k3, &quot;mahvars&quot; = m.out.psid.mahvars, &quot;optimal_full&quot; = m.out.psid.optimal_full, &quot;optimal_pair&quot; = m.out.psid.optimal_pair, &quot;gen_full&quot; = m.out.psid.general_full, &quot;genetic&quot; = m.out.psid.genetic, &quot;exact&quot; = m.out.psid.exact, &quot;subcl&quot; = m.out.psid.subcl, &quot;profile&quot; = m.out.psid.profile, &quot;ipw_weight&quot; = ldw_psid$ipw_weight, &quot;opt_weight&quot; = ldw_psid$opt_weight, &quot;cbps_weight&quot; = ldw_psid$cbps_weight, &quot;ebal_weight&quot; = ldw_psid$ebal_weight, &quot;fix_max_value_ipw_weight&quot; = ldw_psid.fixed$ipw_weight, &quot;fix_max_value_opt_weight&quot; = ldw_psid.fixed$opt_weight, &quot;fix_max_value_cbps_weight&quot; = ldw_psid.fixed$cbps_weight, &quot;fix_max_value_ebal_weight&quot; = ldw_psid.fixed$ebal_weight, &quot;at_perc_ipw_weight&quot; = ldw_psid.percent$ipw_weight, &quot;at_perc_opt_weight&quot; = ldw_psid.percent$opt_weight, &quot;at_perc_cbps_weight&quot; = ldw_psid.percent$cbps_weight, &quot;at_perc_ebal_weight&quot; = ldw_psid.percent$ebal_weight, &quot;adap_weight_ipw_weight&quot; = ldw_psid.adapt$ipw_weight, &quot;adap_weight_opt_weight&quot; = ldw_psid.adapt$opt_weight, &quot;adap_weight_cbps_weight&quot; = ldw_psid.adapt$cbps_weight, &quot;adap_weight_ebal_weight&quot; = ldw_psid.adapt$ebal_weight, &quot;ps_threshold&quot; = ldw_psid.trim, &quot;common_range&quot; = ldw_psid.common, &quot;stuermer&quot; = ldw_psid.stuermer, &quot;walker&quot; = ldw_psid.walker, &quot;crump&quot; = ldw_psid.crump, &quot;ipw_common_range&quot; = ipw_comb.psid[[1]], &quot;ipw_crump&quot;= ipw_comb.psid[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid[[4]], &quot;ipw_walker&quot; = ipw_comb.psid[[5]], &quot;opt_common_range&quot; = opt_comb.psid[[1]], &quot;opt_crump&quot; = opt_comb.psid[[2]], &quot;opt_ps_threshold&quot; = opt_comb.psid[[3]], &quot;opt_stuermer&quot; = opt_comb.psid[[4]], &quot;opt_walker&quot; = opt_comb.psid[[5]], &quot;cbps_common_range&quot; = cbps_comb.psid[[1]], &quot;cbps_crump&quot; = cbps_comb.psid[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.psid[[3]], &quot;cbps_stuermer&quot; = cbps_comb.psid[[4]], &quot;cbps_walker&quot;= cbps_comb.psid[[5]], &quot;ebal_common_range&quot; = ebal_comb.psid[[1]], &quot;ebal_crump&quot; = ebal_comb.psid[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.psid[[3]], &quot;ebal_stuermer&quot; = ebal_comb.psid[[4]], &quot;ebal_walker&quot; = ebal_comb.psid[[5]]) # create datasets corresponding to the top 5 methods for each dataset top5_datasets.cps &lt;- create_top5_datasets(dataset_list_cps, top5_methods.cps) top5_datasets.psid &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid) # save datasets into .RData files save_top5_datasets(dataset_list_cps, top5_methods.cps, prefix = &quot;ldw_model_b_cps1&quot;) save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = &quot;ldw_model_b_psid1&quot;) 3.8 Estimating 3.8.1 Average treatment effect on the treated (ATT) # estimate ATT out1 &lt;- estimate_all(ldw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(ldw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(ldw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out4 &lt;- estimate_all(ldw_cps_plus.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(ldw_psid_plus.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out6 &lt;- estimate_all(ldw_cps.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out7 &lt;- estimate_all(ldw_psid.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps &lt;- lapply(top5_datasets.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out8 &lt;- out.cps[[1]] out9 &lt;- out.cps[[2]] out10 &lt;- out.cps[[3]] out11 &lt;- out.cps[[4]] out12 &lt;- out.cps[[5]] out13 &lt;- out.psid[[1]] out14 &lt;- out.psid[[2]] out15 &lt;- out.psid[[3]] out16 &lt;- out.psid[[4]] out17 &lt;- out.psid[[5]] # build plot titles base_titles &lt;- c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS1&quot; , &quot;(C) LDW-PSID1&quot;, &quot;(D) Trimmed LDW-CPS1 &quot;, &quot;(E) Trimmed LDW-PSID1&quot;, &quot;(F) Trimmed LDW-CPS1-PLUS &quot;, &quot;(G) Trimmed LDW-PSID1-PLUS&quot;) top_start &lt;- 8 # H is 8th letter num_cps &lt;- length(top5_methods.cps) num_psid &lt;- length(top5_methods.psid) top_letters_cps &lt;- LETTERS[top_start:(top_start + num_cps - 1)] top_letters_psid &lt;- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)] top5_titles.cps &lt;- paste0(&quot;(&quot;, top_letters_cps, &quot;) Top CPS1: &quot;, top5_methods.cps) top5_titles.psid &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid) plot_titles &lt;- c(base_titles, top5_titles.cps, top5_titles.psid) # combine all results all_outs &lt;- c(list(out1, out2, out3, out4, out5, out6, out7), out.cps, out.psid) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 3.74: FIGUREB9. ATT Estimates Model B Given Unconfoundedness using LDW Samples Figure 3.75: FIGUREB9. ATT Estimates Model B Given Unconfoundedness using LDW Samples Figure 3.76: FIGUREB9. ATT Estimates Model B Given Unconfoundedness using LDW Samples Figure 3.77: FIGUREB9. ATT Estimates Model B Given Unconfoundedness using LDW Samples Figure 3.78: FIGUREB9. ATT Estimates Model B Given Unconfoundedness using LDW Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;ldw_model_b&quot;) As in model A, the above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, trimmed versions of the LDW-CPS1 and LDW-PSID1 samples (analogous to Imbens and Xu (2024)) and a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria. Again, figure (A) presents the benchmark, serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the LDW-CPS1 and LDW-PSID1y, while figures (D) and (E) present those for the trimmed versions. Figures (F) through (J) display results for CPS1-derived subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-derived subsamples under parallel rules. For LDW-CPS1, the top-ranked subsamples are derived with the same methods as in model A, though they appear in a slightly different order. However, for the LDW-PSID1, the top-ranked subsamples are based on two different methods, fix_max_value_trunc_overlap_weight and overlap_weight. Across the LDW-CPS1 and its top-ranked samples, all estimators generally yield ATT estimates that cluster near the experimental benchmark, overall slightly closer than in model A but with greater standard errors. Notable deviations from the experimental benchmark remain for the optimal_pair and overlap_crump subsamples. For LDW-PSID1 and its subsamples, the ATT estimates continue to exhibit greater dispersion and considerably larger standard errors compared to LDW-CPS1 counterpart samples, yet they lie closer to the benchmark than in model A. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 3.5: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) LDW-Experimental 674.4860 1583.5544 1991.09517 407.5408 (B) LDW-CPS1 671.9799 -8497.5161 1682.91470 10180.4309 (C) LDW-PSID1 884.4407 -15204.7774 2424.45272 17629.2301 (D) Trimmed LDW-CPS1 459.8358 -9276.6106 728.03107 10004.6417 (E) Trimmed LDW-PSID1 753.7550 -15968.1825 -1115.15131 14853.0312 (F) Trimmed LDW-CPS1-PLUS 672.4870 -8497.5161 1682.91470 10180.4309 (G) Trimmed LDW-PSID1-PLUS 936.3756 -14800.1765 2388.46042 17188.6369 (H) Top CPS1: card 761.7291 715.7223 1268.05556 552.3332 (I) Top CPS1: optimal_pair 756.1530 1116.6548 1979.65310 862.9983 (J) Top CPS1: mahvars 807.3279 1401.5121 1669.51241 268.0003 (K) Top CPS1: exact 1555.5071 1834.3116 3406.31933 1572.0078 (L) Top CPS1: cem 935.0239 1122.1416 2351.94474 1229.8032 (M) Top PSID1: card 950.7980 683.1109 1815.37965 1132.2688 (N) Top PSID1: mahvars 1178.3073 -1976.9692 44.09807 2021.0673 (O) Top PSID1: cem 1319.4678 -4388.8247 -1237.32723 3151.4975 (P) Top PSID1: at_perc_ebal_weight 870.2131 -15204.7774 2424.45272 17629.2301 (Q) Top PSID1: optimal_pair 948.2072 -942.7821 3274.21317 4216.9953 # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) %&gt;% kable_styling(full_width = TRUE) Table 3.6: Table 3.7: ATT Estimates and SEs LDW-Experimental LDW-CPS1 LDW-PSID1 Trimmed LDW-CPS1 Trimmed LDW-PSID1 Trimmed LDW-CPS1-PLUS Trimmed LDW-PSID1-PLUS Top CPS1: card Top CPS1: optimal_pair Top CPS1: mahvars Top CPS1: exact Top CPS1: cem Top PSID1: card Top PSID1: mahvars Top PSID1: cem Top PSID1: at_perc_ebal_weight Top PSID1: optimal_pair Experimental Benchmark 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) -9276.61 (353.32) -15968.18 (578.35) -8497.52 (581.92) -14800.18 (719.40) 715.72 (762.26) 1236.76 (761.74) 1465.01 (820.32) 2356.55 (1610.09) 1122.14 (855.77) 1475.56 (941.87) -1370.28 (1242.93) -4388.82 (1188.45) -15204.78 (655.91) -942.78 (1011.91) diff 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) -9276.61 (353.32) -15968.18 (578.35) -8497.52 (581.92) -14800.18 (719.40) 715.72 (762.26) 1236.76 (761.74) 1465.01 (820.32) 2356.55 (1610.09) 1122.14 (855.77) 1475.56 (941.87) -1370.28 (1242.93) -4388.82 (1188.45) -15204.78 (655.91) -942.78 (1011.91) reg 1605.52 (665.93) 1484.61 (631.51) 1227.70 (892.77) 588.26 (409.69) -1763.18 (748.14) 1484.61 (631.51) 1264.59 (913.94) 1027.75 (715.45) 1273.64 (748.88) 1560.88 (790.08) 2499.17 (1527.94) 1962.92 (868.22) 1445.19 (932.38) -1017.97 (1130.03) -1256.63 (1323.68) 1227.70 (892.77) 627.46 (934.98) om.reg 1709.79 (587.92) 1553.68 (621.16) 2052.84 (644.01) 684.88 (380.32) -1506.33 (614.24) 1553.68 (621.16) 2052.69 (724.20) 1248.70 (634.67) 1322.62 (628.61) 1602.70 (696.29) 2322.40 (1319.64) 2230.29 (832.03) 1710.32 (778.55) -349.89 (1030.44) -1237.33 (1120.27) 2052.84 (644.01) 3274.21 (667.60) om.grf 1771.26 (581.97) 1164.55 (625.47) 449.34 (636.41) 136.49 (381.65) -2872.46 (585.32) 1137.41 (624.90) 365.30 (714.25) 1027.62 (614.27) 1247.37 (603.36) 1436.18 (671.25) 2036.83 (1278.95) 2272.99 (799.29) 1471.03 (723.97) -1085.85 (844.53) -2470.15 (1015.46) 427.46 (634.93) 316.73 (600.24) matching 1583.55 (785.15) 1591.49 (832.21) 2174.97 (1575.49) 728.03 (592.65) -1376.72 (861.40) 1591.49 (832.21) 2276.73 (1463.93) 832.57 (947.23) 1209.91 (946.76) 1516.95 (949.99) 2817.29 (1700.42) 2008.37 (995.34) 1815.38 (1138.42) 44.10 (1285.84) -1890.11 (1353.72) 2174.97 (1575.49) 2564.23 (1767.05) psm 1991.10 (697.13) 1162.74 (739.79) 1154.56 (944.07) 278.35 (479.74) -1623.97 (845.81) 1172.80 (746.45) 624.17 (990.49) 1204.76 (744.83) 1979.65 (724.83) 1451.08 (835.15) 2114.08 (1748.37) 1880.74 (984.74) 683.11 (967.18) -1976.97 (1385.84) -2921.86 (1449.32) 1209.90 (923.77) 1369.54 (877.63) ipw 1808.52 (681.51) 1149.70 (684.62) 729.65 (931.05) 343.78 (513.20) -2733.35 (852.83) 1149.70 (684.62) 898.97 (1032.10) 715.72 (762.26) 1236.76 (761.74) 1465.01 (820.32) 3057.52 (1554.07) 2080.40 (1057.49) 1475.56 (941.87) -1370.28 (1242.93) -2321.96 (1325.20) -450.71 (827.64) -942.78 (1011.91) cbps 1699.09 (699.19) 1493.80 (652.71) 2359.12 (873.16) 549.59 (466.05) -1192.80 (791.64) 1493.80 (652.71) 2375.13 (957.83) 715.72 (762.26) 1236.76 (761.74) 1465.01 (820.32) 3057.52 (1554.07) 2080.40 (1057.49) 1475.56 (941.87) -1370.28 (1242.93) -2321.96 (1325.20) -450.71 (827.64) -942.78 (1011.91) ebal 1701.38 (699.39) 1492.13 (652.66) 2424.45 (875.94) 542.39 (465.92) -1115.15 (799.75) 1492.13 (652.66) 2388.46 (967.43) 1226.86 (733.34) 1305.66 (775.59) 1582.75 (828.58) 2313.13 (1573.09) 1861.26 (1041.37) 1772.73 (940.62) -494.01 (1140.12) -2464.25 (1580.68) 2424.45 (875.94) 2493.02 (863.41) dml 1831.36 (653.57) 1497.70 (632.53) 1286.02 (897.44) 608.11 (410.86) -1853.26 (755.86) 1497.70 (632.53) 1334.33 (911.57) 817.59 (716.54) 1116.65 (734.41) 1669.51 (789.14) 3406.32 (1451.01) 2351.94 (828.42) 1225.06 (949.61) -1203.91 (1143.87) -1750.84 (1321.73) 1286.02 (897.44) 987.19 (907.30) aipw_grf 1791.51 (689.14) 1682.91 (721.78) 1367.67 (886.34) 611.33 (539.94) -2003.78 (848.42) 1682.91 (721.78) 1154.71 (928.21) 1268.06 (883.21) 1356.03 (815.85) 1401.51 (827.80) 2315.89 (1619.15) 2227.37 (934.62) 967.59 (1071.10) -886.83 (1252.83) -2058.62 (1443.18) 1367.67 (886.34) 1011.53 (915.83) aipw_ow 1848.58 (682.11) 1471.91 (687.41) 1234.26 (800.69) 518.16 (524.70) -2101.53 (763.30) 1471.91 (687.41) 1549.76 (913.16) 1082.17 (864.45) 1223.97 (810.32) 1429.15 (838.70) 1834.31 (1729.28) 2346.67 (965.50) 1271.25 (1082.14) -774.18 (1197.39) -1928.81 (1386.74) 1234.26 (800.69) 1102.91 (808.71) As in model A, the tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. In model B, most LDW-CPS1-based samples yield ATT estimates that are closer to the experimental benchmark than in model A, with still modest variance. By contrast, the LDW-PSID1-based estimates, while somewhat closer to the experimental benchmark than in model A, continue to exhibit substantially larger standard errors compared to LDW-CPS1 samples. This again reflects the greater challenge of obtaining reliable estimates from the observational dataset LDW-PSID1. Overall, figures and table jointly demonstrate again that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;ldw_att_estimates_model_b&quot;) 3.8.2 Conditional average treatment effect on the treated (CATT) # estimate CATT catt.ldw &lt;- catt(ldw, Y, treat, covar) catt.cps &lt;- catt(ldw_cps, Y, treat, covar) catt.psid &lt;- catt(ldw_psid, Y, treat, covar) catt.cps.trim &lt;- catt(ldw_cps.trim, Y, treat, covar) catt.psid.trim &lt;- catt(ldw_psid.trim, Y, treat, covar) catt.cps_plus.trim &lt;- catt(ldw_cps_plus.trim, Y, treat, covar) # similar to Imbens &amp; Xu (2024) catt.psid_plus.trim &lt;- catt(ldw_psid_plus.trim, Y, treat, covar) # similar to Imbens &amp; Xu (2024) catt.top5_cps &lt;- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid &lt;- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar)) # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim, catt.cps_plus.trim, catt.psid_plus.trim), catt.top5_cps, catt.top5_psid) # plot results par(mfrow = c(2,2)) par(cex.main = 0.9) plot_catt_panels(all_catt, plot_titles) Figure 3.79: FIGUREB10. CATT Estimates Model B using LDW Data Figure 3.80: FIGUREB10. CATT Estimates Model B using LDW Data Figure 3.81: FIGUREB10. CATT Estimates Model B using LDW Data Figure 3.82: FIGUREB10. CATT Estimates Model B using LDW Data all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 3.8: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) LDW-Experimental -221.9683 3854.784 1750.54800 4076.753 (B) LDW-CPS1 -3307.2869 7084.117 2108.48636 10391.404 (C) LDW-PSID1 -6811.9970 4489.936 577.15727 11301.933 (D) Trimmed LDW-CPS1 -3857.8146 7067.844 2137.50396 10925.659 (E) Trimmed LDW-PSID1 -7594.7296 4423.158 308.31124 12017.887 (F) Trimmed LDW-CPS1-PLUS -6248.8815 5545.287 794.85593 11794.169 (G) Trimmed LDW-PSID1-PLUS -7386.5822 2311.574 -2130.91494 9698.156 (H) Top CPS1: card -4011.8749 5529.439 878.53945 9541.314 (I) Top CPS1: optimal_pair -2796.3727 5548.332 1363.03164 8344.705 (J) Top CPS1: mahvars -1723.4598 5328.496 1513.10609 7051.956 (K) Top CPS1: exact 1992.5483 3003.103 2654.20443 1010.554 (L) Top CPS1: cem -31.1243 5412.574 2228.92976 5443.699 (M) Top PSID1: card -2143.3132 3876.711 1070.60784 6020.024 (N) Top PSID1: mahvars -4876.6348 2486.306 -933.19022 7362.941 (O) Top PSID1: cem -3281.7664 -1040.171 -1819.04251 2241.596 (P) Top PSID1: at_perc_ebal_weight -6988.2668 4516.139 558.94617 11504.406 (Q) Top PSID1: optimal_pair -4440.8057 2668.283 -49.90918 7109.088 In model B, using LDW-CPS1, the CATT estimates range from $-3,868.54 to $7,128.42. This span is considerably narrower than in model A, but still performs worse when contrasted with the experimental benchmark, where CATT estimates range from $-213.93 to $3,858.52 with a mean of $1,720.13. The experimental mean CATT estimate remains closer to its corresponding ATT estimate than in model A. Further, LDW-PSID1 shows a narrower CATT estimate range, from $-6,772.16 to $5,032.31, compared to LDW-CPS1 and model A, with a mean CATT estimate of about $557.39, which deviates further from the experimental benchmark, indicating poorer performance. For trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary considerably, yet the mean estimates are generally closer to the experimental benchmark, as in model A. Moreover, the minimum CATT estimates are less negative, which reduces the spread between minimum and maximum estimates. Top-ranked LDW-PSID1 subsamples, on the other hand, again yield more negative mean CATT estimates and wider ranges compared to their LDW-CPS1 counterparts, signaling persistent difficulties in generating reliable effect estimates. Still, compared to model A, the minimum CATT estimates are less strongly negative, though the mean CATTs only improve marginally in their proximity to the experimental benchmark. Hence, alike model A, these results show that the variation in ranges and means across methods and samples reflects substantial heterogeneity in treatment effect estimation. While certain criteria may improve consistency with experimental benchmarks, they may also introduce notable discrepancies and variability in estimated heterogeneous effects. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;model_b&quot;) 3.8.3 Quantile treatment effect on the treated (QTET) qte.ldw &lt;- est_qte(Y, treat, covar, data = ldw, cores = 4) qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) qte.ldw_cps_plus &lt;- est_qte(Y, treat, covar, data = ldw_cps_plus) qte.ldw_psid_plus &lt;- est_qte(Y, treat, covar, data = ldw_psid_plus) qte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps.trim) qte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid.trim) qte.ldw_cps_plus.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps_plus.trim) qte.ldw_psid_plus.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid_plus.trim) qte.top5_cps &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.ldw0 &lt;- est_qte(Y, treat, NULL, data = ldw) qte.ldw.cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) qte.ldw.psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) qte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps.trim) qte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid.trim) qte.ldw_cps_plus.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps_plus.trim) qte.ldw_psid_plus.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid_plus.trim) qte.top5_cps0 &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid0 &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d)) par(mfrow = c(2,2)) par(cex.main = 0.8) # CPS1 plot_qte(qte.ldw_cps, qte.ldw.cps0, qte.ldw, main = &quot;(B) LDW-CPS1&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 plot_qte(qte.ldw_psid, qte.ldw.psid0, qte.ldw, main = &quot;(C) LDW-PSID1&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) ## CPS1 trimmed plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.ldw_cps, main = &quot;(D) LDW-CPS1 (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 trimmed plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.ldw_psid, main = &quot;(E) LDW-PSID1 (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 3.83: FIGUREB11. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental ## CPS1-PLUS trimmed plot_qte(qte.ldw_cps_plus.trim, qte.ldw_cps_plus.trim0, qte.ldw_cps_plus, main = &quot;(F) LDW-CPS1-PLUS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1-PLUS trimmed plot_qte(qte.ldw_psid_plus.trim, qte.ldw_psid_plus.trim0, qte.ldw_psid_plus, main = &quot;(G) LDW-PSID1-PLUS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # CPS1 top methods plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000)) Figure 3.84: FIGUREB11. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental # PSID1 top methods plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000)) Figure 3.85: FIGUREB11. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental Figure 3.86: FIGUREB11. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the experimental and various non-experimental samples. Compared to model A, the QTET results of all samples closely resemble those of their respective counterparts. The QTETs estimated from the original and trimmed LDW-CPS1 sample continue to correspond well with the true QTET, although the estimates often suffer from low power. The QTET estimates from the original and trimmed LDW-PSID1 subsample show clear biases when compared to the experimental benchmark, which clusters near zero. The QTET estimates derived from the top-ranked subsamples of LDW-CPS1 (F - J) track the true experimental effect well. In contrast, the top-ranked subsamples of LDW-PSID1-based produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty. # list results plots_ldw &lt;- list( list(mod = qte.ldw_cps, mod0 = qte.ldw.cps0, bm = qte.ldw, main = &quot;(B) LDW CPS1&quot;), list(mod = qte.ldw_psid, mod0 = qte.ldw.psid0, bm = qte.ldw, main = &quot;(C) LDW PSID1&quot;), list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.ldw_cps, main = &quot;(D) LDW CPS1 (Trimmed)&quot;), list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.ldw_psid, main = &quot;(E) LDW PSID1 (Trimmed)&quot;), list(mod = qte.ldw_cps_plus.trim, mod0 = qte.ldw_cps_plus.trim0, bm = qte.ldw_cps_plus, main = &quot;(F) LDW CPS1-PLUS (Trimmed)&quot;), list(mod = qte.ldw_psid_plus.trim, mod0 = qte.ldw_psid_plus.trim0, bm = qte.ldw_psid_plus, main = &quot;(G) LDW PSID1-PLUS (Trimmed)&quot;) ) # save results save_qtet(plots_ldw, prefix = &quot;ldw_model_b&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000), prefix = &quot;ldw_model_b_top&quot;) save_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000), prefix = &quot;ldw_model_b_top&quot;) 3.8.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c(list(ldw, ldw_cps, ldw_psid, ldw_cps.trim, ldw_psid.trim, ldw_cps_plus.trim.match, ldw_psid_plus.trim.match), top5_datasets.cps, top5_datasets.psid) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 3.87: FIGUREB12. Outcome Weights Model B using LDW Data Figure 3.88: FIGUREB12. Outcome Weights Model B using LDW Data Figure 3.89: FIGUREB12. Outcome Weights Model B using LDW Data Figure 3.90: FIGUREB12. Outcome Weights Model B using LDW Data Figure 3.91: FIGUREB12. Outcome Weights Model B using LDW Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat, &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 3.9: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) LDW-Experimental 1 -1 (B) LDW-CPS1 1 -1 (C) LDW-PSID1 1 -1 (D) Trimmed LDW-CPS1 1 -1 (E) Trimmed LDW-PSID1 1 -1 (F) Trimmed LDW-CPS1-PLUS 1 -1 (G) Trimmed LDW-PSID1-PLUS 1 -1 (H) Top CPS1: card 1 -1 (I) Top CPS1: optimal_pair 1 -1 (J) Top CPS1: mahvars 1 -1 (K) Top CPS1: exact 1 -1 (L) Top CPS1: cem 1 -1 (M) Top PSID1: card 1 -1 (N) Top PSID1: mahvars 1 -1 (O) Top PSID1: cem 1 -1 (P) Top PSID1: at_perc_ebal_weight 1 -1 (Q) Top PSID1: optimal_pair 1 -1 #save results save_ow(ow_att, plot_titles, prefix = &quot;model_b&quot;) In model B, the evaluation once again confirms that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. 3.9 Validation through placebo analyses # define variables Y_pl &lt;- &quot;re75&quot; treat &lt;- &quot;treat&quot; covar_pl &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;u74&quot;) # estimate placebo ATT on original and observational datasets out1_pl &lt;- estimate_all(ldw, Y_pl, &quot;treat&quot;, covar_pl) out2_pl &lt;- estimate_all(ldw_cps, Y_pl, &quot;treat&quot;, covar_pl) out3_pl &lt;- estimate_all(ldw_psid, Y_pl, &quot;treat&quot;, covar_pl) out4_pl &lt;- estimate_all(ldw_cps_plus.trim, Y_pl, &quot;treat&quot;, covar_pl) out5_pl &lt;- estimate_all(ldw_psid_plus.trim, Y_pl, &quot;treat&quot;, covar_pl) out6_pl &lt;- estimate_all(ldw_cps.trim, Y_pl, &quot;treat&quot;, covar_pl) out7_pl &lt;- estimate_all(ldw_psid.trim, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on top ranked datasets out.cps_pl &lt;- lapply(top5_datasets.cps, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out.psid_pl &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out8 &lt;- out.cps_pl[[1]] out9 &lt;- out.cps_pl[[2]] out10 &lt;- out.cps_pl[[3]] out11 &lt;- out.cps_pl[[4]] out12 &lt;- out.cps_pl[[5]] out13 &lt;- out.psid_pl[[1]] out14 &lt;- out.psid_pl[[2]] out15 &lt;- out.psid_pl[[3]] out16 &lt;- out.psid_pl[[4]] out17 &lt;- out.psid_pl[[5]] # collect all placebo results all_outs.pl &lt;- c(list(out1_pl, out2_pl, out3_pl, out4_pl, out5_pl, out6_pl, out7_pl), out.cps_pl, out.psid_pl) # plot placebo results band_pl &lt;- out1_pl[1, 3:4] est_pl &lt;- out1_pl[1, 1] ylim_pl = c(-15500, 5500) plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.7) Figure 3.92: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.93: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.94: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.95: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.96: FIGUREB13. Placebo Test Model B: ’75 Earnings as the Outcome # save results save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, &quot;ldw_model_b_placebo&quot;) # print placebo results result_mat_pl &lt;- create_matrix_results(all_outs.pl, plot_titles) knitr::kable(result_mat_pl, booktabs = TRUE, caption = &quot;Placebo ATT Estimates and SEs&quot;) %&gt;% kable_styling(full_width = TRUE) Table 3.10: Table 3.11: Placebo ATT Estimates and SEs LDW-Experimental LDW-CPS1 LDW-PSID1 Trimmed LDW-CPS1 Trimmed LDW-PSID1 Trimmed LDW-CPS1-PLUS Trimmed LDW-PSID1-PLUS Top CPS1: card Top CPS1: optimal_pair Top CPS1: mahvars Top CPS1: exact Top CPS1: cem Top PSID1: card Top PSID1: mahvars Top PSID1: cem Top PSID1: at_perc_ebal_weight Top PSID1: optimal_pair Experimental Benchmark 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -12082.01 (183.24) -15598.17 (453.34) -12118.75 (247.18) -17277.13 (384.37) -315.95 (360.93) 199.82 (315.38) 138.41 (402.35) 0.00 (0.00) 254.32 (403.24) -288.80 (484.76) -525.35 (751.12) -3300.94 (661.68) -17531.28 (360.60) -1723.62 (369.06) diff 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -12082.01 (183.24) -15598.17 (453.34) -12118.75 (247.18) -17277.13 (384.37) -315.95 (360.93) 199.82 (315.38) 138.41 (402.35) 0.00 (0.00) 254.32 (403.24) -288.80 (484.76) -525.35 (751.12) -3300.94 (661.68) -17531.28 (360.60) -1723.62 (369.06) reg 224.34 (218.33) -1134.82 (272.44) -2757.40 (589.02) -1394.11 (216.12) -3316.46 (555.59) -1134.82 (272.44) -2785.38 (585.73) -199.08 (258.55) 203.59 (233.79) -50.37 (295.67) 0.00 (0.00) -165.84 (370.67) -227.83 (434.70) -329.64 (577.87) -1662.69 (519.67) -2757.40 (589.02) -684.25 (490.54) om.reg 165.70 (284.98) -1096.70 (395.18) -2640.76 (367.46) -1325.05 (298.43) -3245.05 (611.21) -1096.70 (395.18) -2686.64 (422.27) -196.63 (322.74) 180.91 (282.31) -73.00 (371.72) 0.00 (0.00) -284.09 (467.39) -326.76 (393.16) -265.01 (626.56) -1507.59 (696.04) -2640.76 (367.46) -1673.78 (259.54) om.grf 108.32 (283.15) -1590.61 (373.01) -4290.47 (343.87) -1768.18 (277.28) -4796.42 (562.20) -1584.37 (373.06) -4294.36 (394.91) -259.02 (300.08) 268.86 (267.52) 69.40 (328.39) 0.00 (0.00) 204.48 (420.11) 26.07 (395.94) -256.98 (573.63) -1663.86 (635.46) -4251.21 (345.86) -958.83 (264.19) matching 148.67 (227.58) -1465.93 (351.78) -1913.65 (805.37) -1689.11 (299.78) -3384.86 (585.81) -1465.93 (351.78) -2214.44 (763.26) -299.45 (288.76) 39.89 (283.34) 422.17 (288.96) 0.00 (0.00) -164.78 (333.05) 22.16 (495.33) -257.79 (584.36) -1875.54 (543.95) -1913.65 (805.37) -647.74 (534.00) psm 277.10 (299.90) -1423.50 (416.96) -2688.25 (503.26) -1532.38 (290.84) -3026.78 (614.96) -1530.20 (421.97) -3106.67 (594.94) -459.50 (349.70) 183.58 (323.11) 277.03 (387.83) 0.00 (0.00) 308.38 (439.62) -334.86 (488.26) -1141.20 (750.33) -2557.57 (679.15) -2809.48 (470.01) -741.57 (347.50) ipw 180.76 (309.68) -1552.48 (335.84) -3224.79 (738.21) -1618.85 (299.57) -4296.48 (561.35) -1552.48 (335.84) -3481.48 (710.20) -315.95 (360.93) 199.82 (315.38) 138.41 (402.35) 0.00 (0.00) -28.32 (536.73) -288.80 (484.76) -525.35 (751.12) -1873.76 (831.99) -1472.53 (318.65) -1723.62 (369.06) cbps 188.34 (304.79) -1227.83 (297.89) -2282.31 (834.92) -1473.64 (254.98) -4092.52 (646.95) -1227.83 (297.89) -2484.03 (824.94) -315.95 (360.93) 199.82 (315.38) 138.41 (402.35) 0.00 (0.00) -28.32 (536.73) -288.80 (484.76) -525.35 (751.12) -1873.76 (831.99) -1472.53 (318.65) -1723.62 (369.06) ebal 189.20 (304.71) -1228.49 (297.88) -2250.80 (842.15) -1470.31 (254.92) -4072.33 (654.91) -1228.49 (297.88) -2484.11 (830.58) -193.01 (353.75) 190.56 (327.59) -90.70 (520.11) 0.00 (0.00) -407.07 (1003.41) -284.71 (513.61) -290.32 (798.42) -1556.91 (716.26) -2250.80 (842.15) -1042.28 (692.79) dml 275.69 (231.57) -1152.96 (271.75) -2725.28 (591.57) -1397.56 (215.92) -3327.50 (557.95) -1152.96 (271.75) -2734.90 (584.14) -323.77 (258.28) 168.20 (231.93) -74.08 (307.79) 0.00 (0.00) -137.48 (450.46) -82.46 (448.39) -23.82 (610.38) -1431.56 (497.36) -2725.28 (591.57) -714.91 (486.45) aipw_grf 82.43 (231.26) -1285.84 (267.60) -2408.26 (616.07) -1469.36 (225.57) -4198.50 (513.28) -1285.84 (267.60) -2797.18 (634.53) -481.95 (290.30) 303.21 (271.08) 28.40 (311.97) 0.00 (0.00) -97.57 (417.61) -28.06 (428.33) -93.13 (585.17) -1506.38 (461.17) -2408.26 (616.07) -491.16 (426.35) aipw_ow 108.01 (233.22) -1318.36 (276.40) -2904.04 (648.78) -1560.74 (236.40) -4387.15 (485.69) -1318.36 (276.40) -3154.41 (574.22) -248.33 (285.46) 249.89 (280.00) 142.10 (339.19) 0.00 (0.00) 46.71 (399.35) 119.53 (438.00) -136.60 (679.05) -1433.29 (498.69) -2904.04 (648.78) -750.14 (337.70) The placebo analysis shows that the experimental benchmarks remain close to zero and statistically insignificant, closely mirroring the results in model A. The results for LDW-CPS1 and LDW-PSID1 are identical to those observed in model A. For LDW-CPS1 samples (B and F through J), ATT estimates remain consistently negative. The overlap_crump estimates show modest improvement toward the benchmark compared to LDW-CPS1 (B) results, but also yields notably worse estimates for certain estimators. Further gains are observed with the trimmed sample (D), ps_threshold (I), card (G) and optimal_pair. The mahvars (G) sample performs best, producing ATT estimates closest to the experimental results. However, compared to model A, no clear pattern emerges: some methods perform better, while others produce poorer estimates. For LDW-PSID1, the sample (O) applying fix_max_value_truncation_overlap_weight shows some improvement relative to the PSID1 sample (C), though it also produces worse results for certain estimators. A similar pattern holds for the overlap_weight sample. The card (K), mahvars (L), trimmed sample (E) and theps_threshold (M) further reduce discrepancies, drawing estimates closer to the experimental benchmark results. Still, their performance not markedly surpass that of model A. Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis continues to reveal substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underscores the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings. # save results save_csv(result_mat_pl, &quot;ldw_att_estimates_pl_model_b&quot;) 3.10 Validation through sensitivity analyses # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets filtered_datasets_sens &lt;- check_filter_datasets(all_datasets, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx]) } Figure 3.97: FIGUREB14. Sensitivity Analyses Model B Figure 3.98: FIGUREB14. Sensitivity Analyses Model B Figure 3.99: FIGUREB14. Sensitivity Analyses Model B Figure 3.100: FIGUREB14. Sensitivity Analyses Model B # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;ldw_model_b&quot;) The sensitivity analysis demonstrates identical results for LDW-Experimental, LDW-CPS1 and LDW-PSID1 as in model A and indicates once again that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of re75. However, compared to Model A, these estimates tend to shift upwards, exhibiting somewhat more positive values across variants. 3.11 Summary After reexamining model B, which uses the LaLonde-Dehejia-Wahba (LDW) data with a revised set of covariates, we find that changing the covariate set leads to noticeable shifts in effect estimates. For CPS-1, estimates are generally more consistent and remain close to the experimental benchmark, though standard errors are somewhat larger than in model A. In contrast, PSID-1 continues to show greater dispersion and substantially larger standard errors, highlighting persistent challenges with this observational sample. Conditional and quantile treatment effect analyses confirm that, while some methods bring estimates closer to the experimental benchmark, considerable heterogeneity and estimator-dependent variability remain. Placebo tests using pre-treatment earnings as the outcome reveal that, despite some improvements, bias and deviation from the true effect persist. Sensitivity analyses indicate that most treatment effect estimates are fairly robust to increasing confounder strength, but some upward shifts are observed compared to model A. Overall, these results reinforce the importance of overlap, covariate balance, and careful method selection, while underscoring the ongoing difficulty of recovering unbiased causal effects from observational data. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["lalonde-nsw-data.html", "Chapter 4 LaLonde (NSW) Data 4.1 Set up 4.2 NSW 4.3 Improving primarily covariate balance 4.4 Improving primarily overlap 4.5 Reassessing methods 4.6 Integrated methods 4.7 Identifying best methods 4.8 Estimating 4.9 Validation through sensitivity analyses 4.10 Summary", " Chapter 4 LaLonde (NSW) Data This section (4) examines the effect of the treatment (participation in the job training program) on the participants’ earnings in 1978 (re78) in the original LaLonde dataset (loaded as nsw, similar to Imbens &amp; Xu). For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the nsw–specific results. 4.1 Set up 4.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 4.1.2 Load and preprocess data treat &lt;- &quot;treat&quot; nsw_co$treat &lt;- 1 # drop re74, u74, tau from CPS1 and PSID1 and merge data cps1a &lt;- subset(cps1, select = -c(re74, u74)) nsw_cps &lt;- rbind.data.frame(nsw_tr, cps1a) psid1a &lt;- subset(psid1, select = -c(re74, u74)) nsw_psid &lt;- rbind.data.frame(nsw_tr, psid1a) nsw_cps_plus &lt;- rbind.data.frame(nsw_cps, nsw_co) nsw_psid_plus &lt;- rbind.data.frame(nsw_psid, nsw_co) 4.1.3 Inspect data # collect datasets in a list data &lt;- list(nsw = nsw, nsw_cps = nsw_cps, nsw_psid = nsw_psid, nsw_cps_plus = nsw_cps_plus, nsw_psid_plus = nsw_psid_plus) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 4.1: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars nsw 722 297 425 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_cps 16289 297 15992 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_psid 2787 297 2490 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_cps_plus 16714 722 15992 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_psid_plus 3212 722 2490 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample 4.2 NSW # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u75&quot;) 4.2.1 Assessing overlap and covariate balance 4.2.1.1 Overlap # assess overlap nsw.ps &lt;- assess_overlap(data = nsw, treat = treat, cov = covar) ## -1.375215 0.6394217 Figure 4.1: FIGUREC1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. nsw_cps.ps &lt;- assess_overlap(data = nsw_cps, treat = treat, cov = covar) ## -12.49703 1.660349 Figure 4.2: FIGUREC1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. nsw_psid.ps &lt;- assess_overlap(data = nsw_psid, treat = treat, cov = covar) ## -10.70941 3.573044 Figure 4.3: FIGUREC1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. As anticipated, the NSW-Experimental data exhibit an almost perfect overlap. In contrast, the observational datasets NSW-CPS1 and NSW-PSID1 display weak overlap. # assess overlap nsw_cps_plus.ps &lt;- assess_overlap(data = nsw_cps_plus, treat = treat, cov = covar) ## -11.56837 2.929738 Figure 4.4: FIGUREC1. SubfigureD:NSW-CPS1-PLUS. SubfigureE:NSW-PSID1-PLUS. nsw_psid_plus.ps &lt;- assess_overlap(data = nsw_psid_plus, treat = treat, cov = covar) ## -9.367327 6.41566 Figure 4.5: FIGUREC1. SubfigureD:NSW-CPS1-PLUS. SubfigureE:NSW-PSID1-PLUS. With the expanded datasets NSW-CPS1-PLUS and NSW-PSID1-PLUS, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater coverage of log-odds densities across both samples. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 4.2.1.2 Covariate balance love.plot(nsw, nsw_cps, treat, covar = covar, title = &quot;NSW-CPS1&quot;) Figure 4.6: FIGUREC2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. love.plot(nsw, nsw_cps_plus, treat, covar = covar, title = &quot;NSW-CPS1-PLUS&quot;) Figure 4.7: FIGUREC2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. love.plot(nsw, nsw_psid, treat, covar = covar, title = &quot;NSW-PSID1&quot;) Figure 4.8: FIGUREC2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. love.plot(nsw, nsw_psid_plus, treat, covar = covar, title = &quot;NSW-PSID1-PLUS&quot;) Figure 4.9: FIGUREC2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. Neither NSW-CPS1-PLUS nor NSW-PSID1-PLUS shows consistently improved covariate balance compared with their non-plus counterparts based on raw standardized differences. Although some specific covariates improve slightly, most show the same or increased imbalance. In the subsequent analysis, that is focused on improving covariate balance and overlap, only the two datasets NSW-CPS1-PLUS and NSW-PSID1-PLUS are considered. The NSW-Experimental data is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 4.3 Improving primarily covariate balance 4.3.1 Matching 4.3.1.1 Distance Matching 4.3.1.1.1 1:1 Nearest neighbor matching # perform nearest neighbor matching with k=1, logistic propensity score and replacement m.out.cps.nearest &lt;- matchit(model, data = nsw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) m.out.psid.nearest &lt;- matchit(model, data = nsw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) 4.3.1.1.2 k:1 matching (k=2) k&lt;-2 # perform nearest neighbor matching with k=2, logistic propensity score and replacement m.out.cps.k2 &lt;- matchit(model, data = nsw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k2 &lt;- matchit(model, data = nsw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 4.3.1.1.3 k:1 matching (k=3) k&lt;-3 # perform nearest neighbor matching with k=3, logistic propensity score and replacement m.out.cps.k3 &lt;- matchit(model, data = nsw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k3 &lt;- matchit(model, data = nsw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 4.3.1.1.4 Caliper matching # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score m.out.cps.caliper &lt;- matchit(model, data = nsw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) m.out.psid.caliper &lt;- matchit(model, data = nsw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) 4.3.1.1.5 Common support restriction matching # perform nearest neighbor matching with exclusion of units outside common support m.out.cps.cs &lt;- matchit(model, data = nsw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) m.out.psid.cs &lt;- matchit(model, data = nsw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) 4.3.1.1.6 Mahalanobis distance matching (mahvars) # perform nearest neighbor matching using mahalanobis distance on selected covariates m.out.cps.mahvars &lt;- matchit(model, data = nsw_cps, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) m.out.psid.mahvars &lt;- matchit(model, data = nsw_psid, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) 4.3.1.1.7 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.cps.optimal_pair &lt;- matchit(model, data = nsw_cps, method = &quot;optimal&quot;, distance = &quot;logit&quot;) m.out.psid.optimal_pair &lt;- matchit(model, data = nsw_psid, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 4.3.1.1.8 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.cps.optimal_full &lt;- matchit(model, data = nsw_cps, method = &quot;full&quot;, distance = &quot;logit&quot;) m.out.psid.optimal_full &lt;- matchit(model, data = nsw_psid, method = &quot;full&quot;, distance = &quot;logit&quot;) 4.3.1.1.9 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.cps.general_full &lt;- matchit(model, data = nsw_cps, method = &quot;quick&quot;, distance = &quot;logit&quot;) m.out.psid.general_full &lt;- matchit(model, data = nsw_psid, method = &quot;quick&quot;, distance = &quot;logit&quot;) 4.3.1.1.10 Genetic matching # perform genetic matching m.out.cps.genetic &lt;- matchit(model, data = nsw_cps, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) m.out.psid.genetic &lt;- matchit(model, data = nsw_psid, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) 4.3.1.2 Stratum matching 4.3.1.2.1 Exact matching (exact) Strata = unique covariate profiles (raw covariates) # match units exactly by raw covariate profiles m.out.cps.exact &lt;- matchit(model, data = nsw_cps, method = &quot;exact&quot;) m.out.psid.exact &lt;- matchit(model, data = nsw_psid, method = &quot;exact&quot;) 4.3.1.2.2 Coarsened matching (cem) Strata = coarsened versions of covariates # match units exactly within coarse strata m.out.cps.cem &lt;- matchit(model, data = nsw_cps, method = &quot;cem&quot;) m.out.psid.cem &lt;- matchit(model, data = nsw_psid, method = &quot;cem&quot;) 4.3.1.2.3 Subclassification Strata = bins of the propensity score # partition sample into fixed number of bins based on propensity score m.out.cps.subcl &lt;- matchit(model, data = nsw_cps, method = &quot;subclass&quot;, subclass = 5) m.out.psid.subcl &lt;- matchit(model, data = nsw_psid, method = &quot;subclass&quot;, subclass = 5) 4.3.1.3 Pure subset selection 4.3.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units m.out.cps.card &lt;- matchit(model, data = nsw_cps, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) m.out.psid.card &lt;- matchit(model, data = nsw_psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) 4.3.1.3.2 Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact m.out.cps.profile &lt;- matchit(model, data = nsw_cps, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, solver = &quot;highs&quot;, time = 1200) m.out.psid.profile &lt;- matchit(model, data = nsw_psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, solver = &quot;highs&quot;, time = 1200) 4.3.2 Weighting 4.3.2.1 Inverse probability weights (IPW) # w.out.cps.ipw &lt;- WeightIt::weightit(model, data = nsw_cps, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) nsw_cps$ipw_weight &lt;- w.out.cps.ipw$weights w.out.psid.ipw &lt;- WeightIt::weightit(model, data = nsw_psid, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) nsw_psid$ipw_weight &lt;- w.out.psid.ipw$weights 4.3.2.2 Stable balancing weights # w.out.cps.opt &lt;- optweight::optweight(model, data = nsw_cps, estimand = &quot;ATT&quot;) nsw_cps$opt_weight &lt;- w.out.cps.opt$weights w.out.psid.opt &lt;- optweight::optweight(model, data = nsw_psid, estimand = &quot;ATT&quot;) nsw_psid$opt_weight &lt;- w.out.psid.opt$weights 4.3.2.3 Propensity score weights w.out.cps.cbps &lt;- WeightIt::weightit(model, data = nsw_cps, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) nsw_cps$cbps_weight &lt;- w.out.cps.cbps$weights w.out.psid.cbps &lt;- WeightIt::weightit(model, data = nsw_psid, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) nsw_psid$cbps_weight &lt;- w.out.psid.cbps$weights 4.3.2.4 Entropy balancing weights # w.out.cps.ebal &lt;- WeightIt::weightit(model, data = nsw_cps, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) nsw_cps$ebal_weight &lt;- w.out.cps.ebal$weights w.out.psid.ebal &lt;- WeightIt::weightit(model, data = nsw_psid, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) nsw_psid$ebal_weight &lt;- w.out.psid.ebal$weights 4.4 Improving primarily overlap 4.4.1 Truncation # list weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;opt_weight&quot;, &quot;cbps_weight&quot;, &quot;ebal_weight&quot;) 4.4.1.1 Fixed maximum value truncation # truncate weights by imposing a minimum and maximum threshold nsw_cps.fixed &lt;- nsw_cps for (wcol in weight_columns) { if (wcol %in% names(nsw_cps.fixed)) { nsw_cps.fixed &lt;- truncate_weights_fixed(nsw_cps.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) } } nsw_psid.fixed &lt;- nsw_psid for (wcol in weight_columns) { if (wcol %in% names(nsw_psid.fixed)) { nsw_psid.fixed &lt;- truncate_weights_fixed(nsw_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) } } 4.4.1.2 At percentile truncation # truncate weights such that values below the 5th percentile and above the 95th percentile are capped nsw_cps.percent &lt;- nsw_cps for (wcol in weight_columns) { if (wcol %in% names(nsw_cps.percent)) { nsw_cps.percent &lt;- truncate_weights_percentile(nsw_cps.percent, weight_col = wcol, lower = 0.01, upper = 0.99) } } nsw_psid.percent &lt;- nsw_psid for (wcol in weight_columns) { if (wcol %in% names(nsw_psid.percent)) { nsw_psid.percent &lt;- truncate_weights_percentile(nsw_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99) } } 4.4.1.3 Adaptive weight truncation # inspect variance of weights cps_results &lt;- list() psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(nsw_cps)) { cps_results[[paste0(&quot;cps_&quot;, wcol)]] &lt;- check_weights(nsw_cps, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in NSW-CPS1&quot;)) } } for (wcol in weight_columns) { if (wcol %in% names(nsw_psid)) { psid_results[[paste0(&quot;psid_&quot;, wcol)]] &lt;- check_weights(nsw_psid, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in NSW-PSID1&quot;)) } } var_cps_table &lt;- bind_rows(cps_results) var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_cps_table, caption = &quot;Variance of Weights (NSW-CPS1)&quot;) Table 4.2: Variance of Weights (NSW-CPS1) Weight_Column Variance ipw_weight 2.896830e-02 opt_weight 8.223537e+16 cbps_weight 2.764510e-02 ebal_weight 3.016606e+01 knitr::kable(var_psid_table, caption = &quot;Variance of Weights (NSW-PSID1)&quot;) Table 4.2: Variance of Weights (NSW-PSID1) Weight_Column Variance ipw_weight 0.6650298 opt_weight 23.2087737 cbps_weight 0.5383566 ebal_weight 32.8004541 Regarding these results we apply adaptive weight truncation to all considered weights. # truncate adaptively at mean + 3 standard deviations nsw_cps.adapt &lt;- nsw_cps for (wcol in weight_columns) { if (wcol %in% names(nsw_cps.adapt)) { nsw_cps.adapt &lt;- truncate_weights_adaptive(nsw_cps.adapt, weight_col = wcol, c = 3) } } nsw_psid.adapt &lt;- nsw_psid for (wcol in weight_columns) { if (wcol %in% names(nsw_psid.adapt)) { nsw_psid.adapt &lt;- truncate_weights_adaptive(nsw_psid.adapt, weight_col = wcol, c = 3) } } 4.4.2 Trimming 4.4.2.1 Propensity score threshold trimming (Similar to Imbens &amp; Xu (2024)) # apply trimming with thresholds 0.85 nsw_cps_plus.trim &lt;- ps_trim(nsw_cps_plus.ps, threshold = 0.85) nsw_psid_plus.trim &lt;- ps_trim(nsw_psid_plus.ps, threshold = 0.85) # exclude experimental controls, subset trimmed data appropriately nsw_cps_plus.trim.match &lt;- subset(nsw_cps_plus.trim, sample %in% c(0,3) &amp; ps_assoverlap) nsw_psid_plus.trim.match &lt;- subset(nsw_psid_plus.trim, sample %in% c(0,4) &amp; ps_assoverlap) # re-assign treat variable for controls in sample 3 or 4 (non-treated group) nsw_cps_plus.trim.match$treat[nsw_cps_plus.trim.match$sample == 0.5] &lt;- 0 nsw_psid_plus.trim.match$treat[nsw_psid_plus.trim.match$sample == 0.5] &lt;- 0 # re-estimate propensity scores on trimmed data and perform 1:1 matching nsw_cps_plus.trim.match &lt;- psmatch(data = nsw_cps_plus.trim.match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid_plus.trim.match &lt;- psmatch(data = nsw_psid_plus.trim.match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 4.4.2.2 Propensity score threshold trimming # apply trimming with threshold 0.9 nsw_cps.trim &lt;- ps_trim(nsw_cps.ps, threshold = 0.9) nsw_psid.trim &lt;- ps_trim(nsw_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data nsw_cps.trim &lt;- ps_estimate(data = nsw_cps.trim, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid.trim &lt;- ps_estimate(data = nsw_psid.trim, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 4.4.2.3 Common range trimming # trim observations outside the common support region of propensity scores nsw_cps.common &lt;- common_range_trim(nsw_cps.ps) nsw_psid.common &lt;- common_range_trim(nsw_psid.ps) # re-estimate propensity scores on trimmed data nsw_cps.common &lt;- ps_estimate(data = nsw_cps.common, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid.common &lt;- ps_estimate(data = nsw_psid.common, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 4.4.2.4 Crump trimming # trim observations with propensity scores outside [0.1, 0.9] interval nsw_cps.crump &lt;- crump_trim(nsw_cps.ps, lower = 0.1, upper = 0.9) nsw_psid.crump &lt;- crump_trim(nsw_psid.ps, lower = 0.1, upper = 0.9) # re-estimate propensity scores on trimmed data nsw_cps.crump &lt;- ps_estimate(data = nsw_cps.crump, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid.crump &lt;- ps_estimate(data = nsw_psid.crump, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 4.4.2.5 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control nsw_cps.stuermer &lt;- stuermer_trim(nsw_cps.ps) nsw_psid.stuermer &lt;- stuermer_trim(nsw_psid.ps) # re-estimate propensity scores on trimmed data nsw_cps.stuermer &lt;- ps_estimate(data = nsw_cps.stuermer, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid.stuermer &lt;- ps_estimate(data = nsw_psid.stuermer, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 4.4.2.6 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations nsw_cps.walker &lt;- walker_trim(nsw_cps.ps) nsw_psid.walker &lt;- walker_trim(nsw_psid.ps) # re-estimate propensity scores on trimmed data nsw_cps.walker &lt;- ps_estimate(data = nsw_cps.walker, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid.walker &lt;- ps_estimate(data = nsw_psid.walker, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 4.4.3 Integrated methods # list trimming methods all_trim.cps &lt;- list(ps_threshold = nsw_cps.trim, common_range = nsw_cps.common, stuermer = nsw_cps.stuermer, walker = nsw_cps.walker, crump = nsw_cps.crump) all_trim.psid &lt;- list(ps_threshold = nsw_psid.trim, common_range = nsw_psid.common, stuermer = nsw_psid.stuermer, walker = nsw_psid.walker, crump = nsw_psid.crump) 4.4.3.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;ipw_weight&quot;) ipw_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ipw_weight&quot;) 4.4.3.2 Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply stable balancing with trimming and attach stable balance weights opt_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;opt_weight&quot;) opt_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;opt_weight&quot;) 4.4.3.3 Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply propensity score weighting with trimming and attach propensity score weights cbps_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;cbps_weight&quot;) cbps_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;cbps_weight&quot;) 4.4.3.4 Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights ebal_comb.cps &lt;- trim_attach_weights(all_trim.cps, model, &quot;ebal_weight&quot;) ebal_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ebal_weight&quot;) 4.5 Reassessing methods 4.5.1 Matching # list all matching objects all_match.cps &lt;- list( nn = m.out.cps.nearest, k2 = m.out.cps.k2, k3 = m.out.cps.k3, caliper = m.out.cps.caliper, cS = m.out.cps.cs, mahvars = m.out.cps.mahvars, optimal_pair = m.out.cps.optimal_pair, optimal_full = m.out.cps.optimal_full, gen_full = m.out.cps.general_full, genetic = m.out.cps.genetic, exact = m.out.cps.exact, cem = m.out.cps.cem, card = m.out.cps.card, profile = m.out.cps.profile, subcl = m.out.cps.subcl ) all_match.psid &lt;- list( nn = m.out.psid.nearest, k2 = m.out.psid.k2, k3 = m.out.psid.k3, caliper = m.out.psid.caliper, cs = m.out.psid.cs, mahvars = m.out.psid.mahvars, optimal_pair = m.out.psid.optimal_pair, optimal_full = m.out.psid.optimal_full, gen_full = m.out.psid.general_full, genetic = m.out.psid.genetic, exact = m.out.psid.exact, cem = m.out.psid.cem, card = m.out.psid.card, profile = m.out.psid.profile, subcl = m.out.psid.subcl ) 4.5.1.1 SMD # compute SMD smd_matchit.cps &lt;- compute_abs_smd_matchit(all_match.cps) smd_matchit.psid &lt;- compute_abs_smd_matchit(all_match.psid) 4.5.1.2 ESS # calculate balance statistics bal.cps &lt;- cobalt::bal.tab(model, data = nsw_cps, un = TRUE, weights = all_match.cps, s.d.denom = &quot;treated&quot;) bal.psid &lt;- cobalt::bal.tab(model, data = nsw_psid, un = TRUE, weights = all_match.psid, s.d.denom = &quot;treated&quot;) # compute ESS ess_matchit.cps &lt;- compute_ess_matchit(bal.cps) ess_matchit.psid &lt;- compute_ess_matchit(bal.psid) 4.5.1.3 Visuals # visualize covariate balance plot_matching_balance(all_match.cps, title = &quot;NSW-CPS1&quot;) ## $nn Figure 4.10: FIGUREC3. ## ## $k2 Figure 4.11: FIGUREC3. ## ## $k3 Figure 4.12: FIGUREC3. ## ## $caliper Figure 4.13: FIGUREC3. ## ## $cS Figure 4.14: FIGUREC3. ## ## $mahvars Figure 4.15: FIGUREC3. ## ## $optimal_pair Figure 4.16: FIGUREC3. ## ## $optimal_full Figure 4.17: FIGUREC3. ## ## $gen_full Figure 4.18: FIGUREC3. ## ## $genetic Figure 4.19: FIGUREC3. ## ## $exact Figure 4.20: FIGUREC3. ## ## $cem Figure 4.21: FIGUREC3. ## ## $card Figure 4.22: FIGUREC3. ## ## $profile Figure 4.23: FIGUREC3. ## ## $subcl Figure 4.24: FIGUREC3. plot_matching_balance(all_match.psid, title = &quot;NSW-PSID1&quot;) ## $nn Figure 4.25: FIGUREC3. ## ## $k2 Figure 4.26: FIGUREC3. ## ## $k3 Figure 4.27: FIGUREC3. ## ## $caliper Figure 4.28: FIGUREC3. ## ## $cs Figure 4.29: FIGUREC3. ## ## $mahvars Figure 4.30: FIGUREC3. ## ## $optimal_pair Figure 4.31: FIGUREC3. ## ## $optimal_full Figure 4.32: FIGUREC3. ## ## $gen_full Figure 4.33: FIGUREC3. ## ## $genetic Figure 4.34: FIGUREC3. ## ## $exact Figure 4.35: FIGUREC3. ## ## $cem Figure 4.36: FIGUREC3. ## ## $card Figure 4.37: FIGUREC3. ## ## $profile Figure 4.38: FIGUREC3. ## ## $subcl Figure 4.39: FIGUREC3. 4.5.2 Weighting # list all weights all_weight.cps &lt;- list( ipw_weight = nsw_cps$ipw_weight, opt_weight = nsw_cps$opt_weight, cbps_weight = nsw_cps$cbps_weight, ebal_weight = nsw_cps$ebal_weight ) all_weight.psid &lt;- list( ipw_weight = nsw_psid$ipw_weight, opt_weight = nsw_psid$opt_weight, cbps_weight = nsw_psid$cbps_weight, ebal_weight = nsw_psid$ebal_weight ) 4.5.2.1 SMD # compute SMD smd_weight.cps &lt;- compute_abs_smd_weight(nsw_cps, treat, covar, all_weight.cps) smd_weight.psid &lt;- compute_abs_smd_weight(nsw_psid, treat, covar, all_weight.psid) 4.5.2.2 ESS # compute ESS ess_weight.cps &lt;- compute_ess_weight(nsw_cps, treat, covar, all_weight.cps) ess_weight.psid &lt;- compute_ess_weight(nsw_psid, treat, covar, all_weight.psid) 4.5.2.3 Visuals # visualize covariate balance plot_weighting_balance(nsw_cps, treat, covar, all_weight.cps, &quot;NSW-CPS1&quot;) ## $ipw_weight Figure 4.40: FIGUREC4. ## ## $opt_weight Figure 4.41: FIGUREC4. ## ## $cbps_weight Figure 4.42: FIGUREC4. ## ## $ebal_weight Figure 4.43: FIGUREC4. plot_weighting_balance(nsw_psid, treat, covar, all_weight.psid, &quot;NSW-PSID1&quot;) ## $ipw_weight Figure 4.44: FIGUREC4. ## ## $opt_weight Figure 4.45: FIGUREC4. ## ## $cbps_weight Figure 4.46: FIGUREC4. ## ## $ebal_weight Figure 4.47: FIGUREC4. 4.5.3 Truncation # list truncation methods all_trunc.cps &lt;- list( fix_max_value = nsw_cps.fixed, at_perc = nsw_cps.percent, adap_weight = nsw_cps.adapt ) all_trunc.psid &lt;- list( fix_max_value = nsw_psid.fixed, at_perc = nsw_psid.percent, adap_weight = nsw_psid.adapt ) 4.5.3.1 SMD # compute SMD smd_trunc.cps &lt;- compute_abs_smd_trunc(all_trunc.cps, &quot;treat&quot;, covar, weight_columns) smd_trunc.psid &lt;- compute_abs_smd_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 4.5.3.2 ESS # compute ESS ess_trunc.cps &lt;- compute_ess_trunc(all_trunc.cps, &quot;treat&quot;, covar, weight_columns) ess_trunc.psid &lt;- compute_ess_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 4.5.3.3 Visuals # visualize covariate balance plot_trunc_balance(all_trunc.cps, &quot;treat&quot;, covar, weight_columns, &quot;NSW-CPS1&quot;) ## $fix_max_value_ipw_weight Figure 4.48: FIGUREC5. ## ## $fix_max_value_opt_weight Figure 4.49: FIGUREC5. ## ## $fix_max_value_cbps_weight Figure 4.50: FIGUREC5. ## ## $fix_max_value_ebal_weight Figure 4.51: FIGUREC5. ## ## $at_perc_ipw_weight Figure 4.52: FIGUREC5. ## ## $at_perc_opt_weight Figure 4.53: FIGUREC5. ## ## $at_perc_cbps_weight Figure 4.54: FIGUREC5. ## ## $at_perc_ebal_weight Figure 4.55: FIGUREC5. ## ## $adap_weight_ipw_weight Figure 4.56: FIGUREC5. ## ## $adap_weight_opt_weight Figure 4.57: FIGUREC5. ## ## $adap_weight_cbps_weight Figure 4.58: FIGUREC5. ## ## $adap_weight_ebal_weight Figure 4.59: FIGUREC5. plot_trunc_balance(all_trunc.psid, &quot;treat&quot;, covar, weight_columns, &quot;NSW-PSID1&quot;) ## $fix_max_value_ipw_weight Figure 4.60: FIGUREC5. ## ## $fix_max_value_opt_weight Figure 4.61: FIGUREC5. ## ## $fix_max_value_cbps_weight Figure 4.62: FIGUREC5. ## ## $fix_max_value_ebal_weight Figure 4.63: FIGUREC5. ## ## $at_perc_ipw_weight Figure 4.64: FIGUREC5. ## ## $at_perc_opt_weight Figure 4.65: FIGUREC5. ## ## $at_perc_cbps_weight Figure 4.66: FIGUREC5. ## ## $at_perc_ebal_weight Figure 4.67: FIGUREC5. ## ## $adap_weight_ipw_weight Figure 4.68: FIGUREC5. ## ## $adap_weight_opt_weight Figure 4.69: FIGUREC5. ## ## $adap_weight_cbps_weight Figure 4.70: FIGUREC5. ## ## $adap_weight_ebal_weight Figure 4.71: FIGUREC5. 4.5.4 Trimming # list trimming objects plus original all_trim.cps &lt;- list( original = nsw_cps, ps_threshold = nsw_cps.trim, common_range = nsw_cps.common, crump = nsw_cps.crump, stuermer = nsw_cps.stuermer, walker = nsw_cps.walker ) all_trim.psid &lt;- list( original = nsw_psid, ps_threshold = nsw_psid.trim, common_range = nsw_psid.common, crump = nsw_psid.crump, stuermer = nsw_psid.stuermer, walker = nsw_psid.walker ) 4.5.4.1 SMD # compute SMDs smd_trim.cps &lt;- compute_abs_smd_trim(all_trim.cps, &quot;treat&quot;, covar) smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 4.5.4.2 ESS # compute ESS ess_trim.cps &lt;- compute_ess_trim(all_trim.cps, &quot;treat&quot;, covar) ess_trim.psid &lt;- compute_ess_trim(all_trim.psid, &quot;treat&quot;, covar) 4.5.4.3 Visuals # visualize overlap plot_trim_overlap(all_trim.cps, treat, covar, prefix = &quot;NSW-CPS1&quot;) ## -12.49703 1.660349 ## -12.49703 1.660349 ## -12.35664 1.724553 ## -2.283175 1.503162 ## -16.1181 -2.253741 ## -10.96064 -2.254369 Figure 4.72: FIGUREC6. plot_trim_overlap(all_trim.psid, treat, covar, prefix = &quot;NSW-PSID1&quot;) ## -10.70941 3.573044 ## -9.836359 2.234878 ## -6.531578 2.333365 ## -2.058494 2.301793 ## -3.214249 -1.209959 ## -4.090612 -1.553181 Figure 4.73: FIGUREC6. 4.6 Integrated methods # list all combined results comb.cps &lt;- list( ipw = ipw_comb.cps, opt = opt_comb.cps, cbps = cbps_comb.cps, ebal = ebal_comb.cps ) comb.psid &lt;- list( ipw = ipw_comb.psid, opt = opt_comb.psid, cbps = cbps_comb.psid, ebal = ebal_comb.psid ) 4.6.0.1 SMD # compute SMD smd_all_comb_meth.cps &lt;- compute_abs_smd_comb(comb.cps, &quot;treat&quot;, covar) smd_all_comb_meth.psid &lt;- compute_abs_smd_comb(comb.psid, &quot;treat&quot;, covar) 4.6.0.2 ESS # compute ESS ess_all_comb_meth.cps &lt;- compute_ess_comb(comb.cps, &quot;treat&quot;, covar) ess_all_comb_meth.psid &lt;- compute_ess_comb(comb.psid, &quot;treat&quot;, covar) 4.6.0.3 Visuals # visualize overlap #plot_comb_overlap(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix_cps = &quot;NSW-CPS1&quot;, prefix_psid = &quot;NSW-PSID1&quot;) # visualize covariate balance #plot_comb_balance(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, orig_cps = nsw_cps, orig_psid = nsw_psid, prefix_cps = &quot;NSW-CPS1&quot;, prefix_psid = &quot;NSW-PSID1&quot;) # save results #save_comb_hist(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;nsw&quot;, prefix_cps = &quot;nsw_cps1&quot;, prefix_psid = &quot;nsw_psid1&quot;) #save_comb_loveplots(comb_meth_cps = comb.cps, comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;nsw&quot;, prefix_cps = &quot;nsw_cps1&quot;, prefix_psid = &quot;nsw_psid1&quot;) 4.7 Identifying best methods # combine all results all_cps &lt;- combine_results(&quot;cps&quot;) all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_cps, &quot;nsw_cps1_all_results&quot;) save_csv(all_psid, &quot;nsw_psid1_all_results&quot;) # rank methods ranked_cps &lt;- assess_methods(all_cps) ranked_psid &lt;- assess_methods(all_psid) # get top 5 methods top5_methods.cps &lt;- get_top_methods(ranked_cps, top_n = 5) top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # print results top5_methods_df.cps &lt;- ranked_cps %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps, caption = &quot;Top 5 Methods for CPS1&quot;, booktabs = TRUE) Table 4.3: Top 5 Methods for CPS1 Method Score mahvars 0.7357153 k3 0.7291071 exact 0.7290518 cem 0.7265186 card 0.7233095 knitr::kable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID1&quot;, booktabs = TRUE) Table 4.3: Top 5 Methods for PSID1 Method Score card 0.7547055 mahvars 0.7478798 optimal_pair 0.6751910 fix_max_value_opt_weight 0.6125277 exact 0.6029221 # save results save_csv(top5_methods.cps, &quot;nsw_cps1_top5_methods&quot;) save_csv(top5_methods.psid, &quot;nsw_psid1_top5_methods&quot;) The table shows that CPS1 and PSID1 share the same top five methods, with the exception of one differing method and a variation in their ordering for PSID1. dataset_list_cps &lt;- list( &quot;All&quot; = nsw_cps, &quot;original&quot; = nsw_cps, &quot;nn&quot; = m.out.cps.nearest, &quot;caliper&quot; = m.out.cps.caliper, &quot;card&quot; = m.out.cps.card, &quot;cem&quot; = m.out.cps.cem, &quot;cS&quot; = m.out.cps.cs, &quot;k2&quot; = m.out.cps.k2, &quot;k3&quot; = m.out.cps.k3, &quot;mahvars&quot; = m.out.cps.mahvars, &quot;optimal_full&quot; = m.out.cps.optimal_full, &quot;optimal_pair&quot; = m.out.cps.optimal_pair, &quot;gen_full&quot; = m.out.cps.general_full, &quot;genetic&quot; = m.out.cps.genetic, &quot;exact&quot; = m.out.cps.exact, &quot;subcl&quot; = m.out.cps.subcl, &quot;profile&quot; = m.out.cps.profile, &quot;ipw_weight&quot; = nsw_cps$ipw_weight, &quot;opt_weight&quot; = nsw_cps$opt_weight, &quot;cbps_weight&quot; = nsw_cps$cbps_weight, &quot;ebal_weight&quot; = nsw_cps$ebal_weight, &quot;fix_max_value_ipw_weight&quot; = nsw_cps.fixed$ipw_weight, &quot;fix_max_value_opt_weight&quot; = nsw_cps.fixed$opt_weight, &quot;fix_max_value_cbps_weight&quot; = nsw_cps.fixed$cbps_weight, &quot;fix_max_value_ebal_weight&quot; = nsw_cps.fixed$ebal_weight, &quot;at_perc_ipw_weight&quot; = nsw_cps.percent$ipw_weight, &quot;at_perc_opt_weight&quot; = nsw_cps.percent$opt_weight, &quot;at_perc_cbps_weight&quot; = nsw_cps.percent$cbps_weight, &quot;at_perc_ebal_weight&quot; = nsw_cps.percent$ebal_weight, &quot;adap_weight_ipw_weight&quot; = nsw_cps.adapt$ipw_weight, &quot;adap_weight_opt_weight&quot; = nsw_cps.adapt$opt_weight, &quot;adap_weight_cbps_weight&quot; = nsw_cps.adapt$cbps_weight, &quot;adap_weight_ebal_weight&quot; = nsw_cps.adapt$ebal_weight, &quot;ps_threshold&quot; = nsw_cps.trim, &quot;common_range&quot; = nsw_cps.common, &quot;stuermer&quot; = nsw_cps.stuermer, &quot;walker&quot; = nsw_cps.walker, &quot;crump&quot; = nsw_cps.crump, &quot;ipw_common_range&quot; = ipw_comb.cps[[1]], &quot;ipw_crump&quot;= ipw_comb.cps[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.cps[[3]], &quot;ipw_stuermer&quot;= ipw_comb.cps[[4]], &quot;ipw_walker&quot; = ipw_comb.cps[[5]], &quot;opt_common_range&quot; = opt_comb.cps[[1]], &quot;opt_crump&quot; = opt_comb.cps[[2]], &quot;opt_ps_threshold&quot; = opt_comb.cps[[3]], &quot;opt_stuermer&quot; = opt_comb.cps[[4]], &quot;opt_walker&quot; = opt_comb.cps[[5]], &quot;cbps_common_range&quot; = cbps_comb.cps[[1]], &quot;cbps_crump&quot; = cbps_comb.cps[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.cps[[3]], &quot;cbps_stuermer&quot; = cbps_comb.cps[[4]], &quot;cbps_walker&quot;= cbps_comb.cps[[5]], &quot;ebal_common_range&quot; = ebal_comb.cps[[1]], &quot;ebal_crump&quot; = ebal_comb.cps[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.cps[[3]], &quot;ebal_stuermer&quot; = ebal_comb.cps[[4]], &quot;ebal_walker&quot; = ebal_comb.cps[[5]]) dataset_list_psid &lt;- list( &quot;All&quot; = nsw_psid, &quot;original&quot; = nsw_psid, &quot;nn&quot; = m.out.psid.nearest, &quot;caliper&quot; = m.out.psid.caliper, &quot;card&quot; = m.out.psid.card, &quot;cem&quot; = m.out.psid.cem, &quot;cS&quot; = m.out.psid.cs, &quot;k2&quot; = m.out.psid.k2, &quot;k3&quot; = m.out.psid.k3, &quot;mahvars&quot; = m.out.psid.mahvars, &quot;optimal_full&quot; = m.out.psid.optimal_full, &quot;optimal_pair&quot; = m.out.psid.optimal_pair, &quot;gen_full&quot; = m.out.psid.general_full, &quot;genetic&quot; = m.out.psid.genetic, &quot;exact&quot; = m.out.psid.exact, &quot;subcl&quot; = m.out.psid.subcl, &quot;profile&quot; = m.out.psid.profile, &quot;ipw_weight&quot; = nsw_psid$ipw_weight, &quot;opt_weight&quot; = nsw_psid$opt_weight, &quot;cbps_weight&quot; = nsw_psid$cbps_weight, &quot;ebal_weight&quot; = nsw_psid$ebal_weight, &quot;fix_max_value_ipw_weight&quot; = nsw_psid.fixed$ipw_weight, &quot;fix_max_value_opt_weight&quot; = nsw_psid.fixed$opt_weight, &quot;fix_max_value_cbps_weight&quot; = nsw_psid.fixed$cbps_weight, &quot;fix_max_value_ebal_weight&quot; = nsw_psid.fixed$ebal_weight, &quot;at_perc_ipw_weight&quot; = nsw_psid.percent$ipw_weight, &quot;at_perc_opt_weight&quot; = nsw_psid.percent$opt_weight, &quot;at_perc_cbps_weight&quot; = nsw_psid.percent$cbps_weight, &quot;at_perc_ebal_weight&quot; = nsw_psid.percent$ebal_weight, &quot;adap_weight_ipw_weight&quot; = nsw_psid.adapt$ipw_weight, &quot;adap_weight_opt_weight&quot; = nsw_psid.adapt$opt_weight, &quot;adap_weight_cbps_weight&quot; = nsw_psid.adapt$cbps_weight, &quot;adap_weight_ebal_weight&quot; = nsw_psid.adapt$ebal_weight, &quot;ps_threshold&quot; = nsw_psid.trim, &quot;common_range&quot; = nsw_psid.common, &quot;stuermer&quot; = nsw_psid.stuermer, &quot;walker&quot; = nsw_psid.walker, &quot;crump&quot; = nsw_psid.crump, &quot;ipw_common_range&quot; = ipw_comb.psid[[1]], &quot;ipw_crump&quot;= ipw_comb.psid[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid[[4]], &quot;ipw_walker&quot; = ipw_comb.psid[[5]], &quot;opt_common_range&quot; = opt_comb.psid[[1]], &quot;opt_crump&quot; = opt_comb.psid[[2]], &quot;opt_ps_threshold&quot; = opt_comb.psid[[3]], &quot;opt_stuermer&quot; = opt_comb.psid[[4]], &quot;opt_walker&quot; = opt_comb.psid[[5]], &quot;cbps_common_range&quot; = cbps_comb.psid[[1]], &quot;cbps_crump&quot; = cbps_comb.psid[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.psid[[3]], &quot;cbps_stuermer&quot; = cbps_comb.psid[[4]], &quot;cbps_walker&quot;= cbps_comb.psid[[5]], &quot;ebal_common_range&quot; = ebal_comb.psid[[1]], &quot;ebal_crump&quot; = ebal_comb.psid[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.psid[[3]], &quot;ebal_stuermer&quot; = ebal_comb.psid[[4]], &quot;ebal_walker&quot; = ebal_comb.psid[[5]]) # create datasets corresponding to the top 5 methods for each dataset top5_datasets.cps &lt;- create_top5_datasets(dataset_list_cps, top5_methods.cps) top5_datasets.psid &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid) # save datasets into .RData files save_top5_datasets(dataset_list_cps, top5_methods.cps, prefix = &quot;nsw_cps1&quot;) save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = &quot;nsw_psid1&quot;) 4.8 Estimating 4.8.1 Average treatment effect on the treated (ATT) # estimate ATT out1 &lt;- estimate_all(nsw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(nsw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(nsw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out4 &lt;- estimate_all(nsw_cps_plus.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(nsw_psid_plus.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out6 &lt;- estimate_all(nsw_cps.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out7 &lt;- estimate_all(nsw_psid.trim, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps &lt;- lapply(top5_datasets.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out8 &lt;- out.cps[[1]] out9 &lt;- out.cps[[2]] out10 &lt;- out.cps[[3]] out11 &lt;- out.cps[[4]] out12 &lt;- out.cps[[5]] out13 &lt;- out.psid[[1]] out14 &lt;- out.psid[[2]] out15 &lt;- out.psid[[3]] out16 &lt;- out.psid[[4]] out17 &lt;- out.psid[[5]] # build plot titles base_titles &lt;- c(&quot;(A) NSW-Experimental&quot;, &quot;(B) NSW-CPS1&quot; , &quot;(C) NSW-PSID1&quot;, &quot;(D) Trimmed NSW-CPS1 &quot;, &quot;(E) Trimmed NSW-PSID1&quot;, &quot;(F) Trimmed NSW-CPS1-PLUS &quot;, &quot;(G) Trimmed NSW-PSID1-PLUS&quot;) top_start &lt;- 8 # H is 8th letter num_cps &lt;- length(top5_methods.cps) num_psid &lt;- length(top5_methods.psid) top_letters_cps &lt;- LETTERS[top_start:(top_start + num_cps - 1)] top_letters_psid &lt;- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)] top5_titles.cps &lt;- paste0(&quot;(&quot;, top_letters_cps, &quot;) Top CPS1: &quot;, top5_methods.cps) top5_titles.psid &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid) plot_titles &lt;- c(base_titles, top5_titles.cps, top5_titles.psid) # combine all results all_outs &lt;- c(list(out1, out2, out3, out4, out5, out6, out7), out.cps, out.psid) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 4.74: FIGUREC9. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.75: FIGUREC9. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.76: FIGUREC9. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.77: FIGUREC9. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.78: FIGUREC9. ATT Estimates Given Unconfoundedness using NSW Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;nsw&quot;) The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: NSW-Experimental, NSW-CPS1, NSW-PSID1, trimmed versions of the NSW-CPS1 and NSW-PSID1 samples (analogous to Imbens &amp; Xu (2024)) and a series of top-ranked subsamples of both NSW-CPS1 and NSW-PSID1 based on various matching, weighting, truncation and trimming criteria. Figure (A) presents the benchmark from the experimental sample (NSW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the observational samples, NSW-CPS1 and NSW-PSID1, while figures (D) and (E) present those for the trimmed versions, replicating the tutorial results of Imbens &amp; Xu (2024). Figures (F) through (J) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-based subsamples under parallel rules. Across the NSW-CPS1 and its top-ranked subsamples, all estimators produce ATT estimates that closely align with the experimental benchmark, though all estimates are negative. Some larger deviations occur for the Diff-in-Means estimator within the overlap_crump and adapt_weight_trunc_ipw_weight subsamples. Nevertheless, these ATT estimates deviate more from the benchmark than those obtained under models A and B in previous sections using LDW data. In comparison, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors than NSW-CPS1 samples, consistent with previous observations from LDW data. All ATT estimates remain negatively aligned, reflecting heightened methodological uncertainty within these samples. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 4.4: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) NSW-Experimental 488.1798 497.1128 886.3037 389.1909 (B) NSW-CPS1 488.8617 -8870.3076 -266.3443 8603.9633 (C) NSW-PSID1 768.9609 -15577.5689 -691.8459 14885.7230 (D) Trimmed NSW-CPS1 332.6410 -9264.8225 -809.8590 8454.9635 (E) Trimmed NSW-PSID1 767.4047 -15660.8694 -3648.2250 12012.6444 (F) Trimmed NSW-CPS1-PLUS 489.4265 -8870.3076 -266.3443 8603.9633 (G) Trimmed NSW-PSID1-PLUS 789.0188 -15434.2131 -906.2396 14527.9735 (H) Top CPS1: mahvars 568.1113 -582.0667 -178.5012 403.5655 (I) Top CPS1: k3 530.8020 -1603.2376 -406.2001 1197.0375 (J) Top CPS1: exact 1301.1756 2485.4287 3478.2148 992.7862 (K) Top CPS1: cem 636.0979 -1021.7289 1122.7161 2144.4450 (L) Top CPS1: card 571.4871 -936.6956 -436.0583 500.6374 (M) Top PSID1: card 942.2279 -3024.0022 -1850.5626 1173.4396 (N) Top PSID1: mahvars 1241.4677 -3218.4670 -2303.7144 914.7526 (O) Top PSID1: optimal_pair 764.6943 -3813.6263 -737.9041 3075.7222 (P) Top PSID1: fix_max_value_opt_weight 752.4069 -15577.5689 -691.8459 14885.7230 (Q) Top PSID1: exact 2076.6338 -1302.5949 3409.0870 4711.6819 # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) %&gt;% kable_styling(full_width = TRUE) Table 4.5: Table 4.6: ATT Estimates and SEs NSW-Experimental NSW-CPS1 NSW-PSID1 Trimmed NSW-CPS1 Trimmed NSW-PSID1 Trimmed NSW-CPS1-PLUS Trimmed NSW-PSID1-PLUS Top CPS1: mahvars Top CPS1: k3 Top CPS1: exact Top CPS1: cem Top CPS1: card Top PSID1: card Top PSID1: mahvars Top PSID1: optimal_pair Top PSID1: fix_max_value_opt_weight Top PSID1: exact Experimental Benchmark 886.30 (488.14) -8870.31 (408.30) -15577.57 (508.12) -9264.82 (249.65) -15660.87 (459.23) -8870.31 (408.30) -15434.21 (534.10) -568.04 (584.68) -1603.24 (528.91) 2623.42 (1303.73) -1021.73 (549.96) -916.37 (579.97) -2401.30 (968.20) -2642.24 (1245.17) -3813.63 (728.73) -15577.57 (508.12) 786.34 (2224.74) diff 886.30 (488.14) -8870.31 (408.30) -15577.57 (508.12) -9264.82 (249.65) -15660.87 (459.23) -8870.31 (408.30) -15434.21 (534.10) -568.04 (584.68) -1603.24 (528.91) 2623.42 (1303.73) -1021.73 (549.96) -916.37 (579.97) -2401.30 (968.20) -2642.24 (1245.17) -3813.63 (728.73) -15577.57 (508.12) 786.34 (2224.74) reg 812.52 (485.60) -792.15 (479.67) -1581.11 (718.80) -1442.58 (309.96) -3926.39 (627.34) -792.15 (479.67) -1691.16 (732.34) -523.41 (565.88) -731.67 (521.04) 2981.41 (1297.81) 545.00 (609.84) -604.75 (547.13) -2202.91 (978.79) -2553.39 (1276.61) -2447.03 (843.28) -1581.11 (718.80) 1724.03 (1835.50) om.reg 854.16 (413.47) -726.42 (462.50) -1215.01 (481.08) -1374.87 (289.62) -3715.30 (448.65) -726.42 (462.50) -1374.31 (520.95) -467.22 (468.17) -475.38 (475.20) 2789.82 (1132.46) 727.76 (548.31) -436.06 (471.60) -1891.67 (602.27) -2336.30 (754.13) -1605.93 (446.01) -1215.01 (481.08) 1795.84 (1697.40) om.grf 834.99 (408.15) -969.43 (451.72) -2823.28 (454.43) -1645.28 (279.69) -4798.67 (420.85) -962.18 (451.84) -2939.23 (491.62) -426.40 (450.59) -582.58 (453.50) 2659.52 (1115.82) 154.55 (535.11) -560.11 (446.60) -2278.12 (557.19) -2604.73 (687.72) -2405.30 (426.25) -2837.70 (455.59) 775.55 (1123.43) matching 776.30 (553.82) -290.38 (585.14) -1122.98 (1210.25) -1084.89 (420.38) -5508.67 (1133.93) -290.38 (585.14) -1523.97 (1188.33) -178.50 (633.02) -443.32 (629.06) 3028.28 (1470.66) 961.13 (684.62) -596.16 (710.71) -3024.00 (1215.38) -2753.52 (1413.36) -1346.35 (1196.22) -1122.98 (1210.25) 1217.47 (2246.68) psm 497.11 (533.70) -374.13 (545.22) -1832.89 (734.81) -943.15 (361.09) -4212.13 (729.88) -324.75 (551.88) -2259.64 (905.18) -575.30 (586.56) -812.40 (554.27) 3140.12 (1380.51) 1122.72 (704.84) -936.70 (572.79) -2549.87 (940.33) -2616.73 (1361.63) -737.90 (688.90) -1832.34 (738.73) -1302.59 (2453.53) ipw 816.41 (500.17) -552.85 (485.11) -2027.40 (973.28) -1162.67 (369.71) -4450.38 (974.41) -552.85 (485.11) -1944.31 (945.75) -568.04 (584.68) -487.52 (546.78) 3076.24 (1303.65) 492.19 (712.89) -916.37 (579.97) -2401.30 (968.20) -2642.24 (1245.17) -3813.63 (728.73) -6347.85 (828.84) 1165.25 (2039.41) cbps 852.06 (495.44) -566.41 (476.37) -718.81 (888.13) -1198.96 (349.84) -3701.63 (960.85) -566.41 (476.37) -939.58 (859.22) -568.04 (584.68) -487.52 (546.78) 3076.24 (1303.65) 492.19 (712.89) -916.37 (579.97) -2401.30 (968.20) -2642.24 (1245.17) -3813.63 (728.73) -6347.85 (828.84) 1165.25 (2039.41) ebal 850.96 (495.52) -566.82 (476.39) -691.85 (889.21) -1192.64 (350.35) -3648.22 (951.80) -566.82 (476.39) -906.24 (862.48) -464.34 (595.88) -506.31 (515.49) 2800.18 (1291.86) 630.59 (670.08) -461.96 (571.99) -1850.56 (991.98) -2355.32 (1434.58) -826.46 (895.86) -691.85 (889.21) 1703.25 (1790.73) dml 748.59 (482.57) -787.03 (479.32) -1673.83 (722.32) -1469.24 (309.83) -3932.83 (631.32) -787.03 (479.32) -1665.23 (736.30) -582.07 (564.07) -641.55 (520.45) 3478.21 (1353.79) 549.58 (605.42) -522.49 (544.46) -2276.35 (962.93) -2303.71 (1242.69) -2482.89 (824.44) -1673.83 (722.32) 3409.09 (2507.84) aipw_grf 855.58 (499.08) -266.34 (512.48) -1799.75 (873.71) -809.86 (357.73) -4393.13 (958.79) -266.34 (512.48) -2238.24 (905.57) -375.44 (591.58) -406.20 (541.80) 2765.38 (1309.56) 714.08 (645.94) -712.32 (646.37) -2860.00 (1124.56) -3218.47 (1516.64) -1729.74 (862.36) -1799.75 (873.71) 944.63 (2288.86) aipw_ow 877.36 (502.50) -374.41 (504.11) -1691.75 (773.39) -1030.44 (343.84) -4717.31 (911.80) -374.41 (504.11) -1764.17 (786.39) -390.09 (607.56) -452.44 (536.33) 2485.43 (1350.61) 829.36 (653.28) -597.06 (606.26) -2318.34 (1028.71) -2685.77 (1474.72) -1526.82 (806.84) -1691.75 (773.39) 737.81 (2672.08) The tabulated results confirm visual patterns: Column (A) reports the estimates for the NSW-Experimental sample, column (B) for the NSW-CPS1 sample, and column (C) for the NSW-PSID1 sample. Columns (D)-(O) summarize results for the trimmed and top-ranked samples for both NSW-CPS1 and NSW-PSID1. For all CPS1-based samples, ATT estimates remain negative, but are relatively close to the experimental benchmark. In contrast, the PSID1-based estimates exhibit larger negative magnitudes, and increased standard errors, underscoring the heightened difficulty of achieving covariate balance and overlap in this observational dataset. Overall, consistent with findings from models A and B, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain methods can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;nsw_att_estimates&quot;) 4.8.2 Conditional average treatment effect on the treated (CATT) # estimate CATT catt.ldw &lt;- catt(nsw, Y, treat, covar) catt.cps &lt;- catt(nsw_cps, Y, treat, covar) catt.psid &lt;- catt(nsw_psid, Y, treat, covar) catt.cps.trim &lt;- catt(nsw_cps.trim, Y, treat, covar) catt.psid.trim &lt;- catt(nsw_psid.trim, Y, treat, covar) catt.cps_plus.trim &lt;- catt(nsw_cps_plus.trim, Y, treat, covar) # similar to Imbens &amp; Xu (2024) catt.psid_plus.trim &lt;- catt(nsw_psid_plus.trim, Y, treat, covar) # similar to Imbens &amp; Xu (2024) catt.top5_cps &lt;- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid &lt;- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar)) # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim, catt.cps_plus.trim, catt.psid_plus.trim), catt.top5_cps, catt.top5_psid) # plot results par(mfrow = c(2,2)) par(cex.main = 0.9) plot_catt_panels(all_catt, plot_titles) Figure 4.79: FIGUREC10. CATT Estimates using NSW Data Figure 4.80: FIGUREC10. CATT Estimates using NSW Data Figure 4.81: FIGUREC10. CATT Estimates using NSW Data Figure 4.82: FIGUREC10. CATT Estimates using NSW Data all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 4.7: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) NSW-Experimental -1326.0686 3408.1467 803.08307 4734.2153 (B) NSW-CPS1 -8923.7481 6475.0515 -99.80603 15398.7996 (C) NSW-PSID1 -8456.6752 880.2746 -2294.65082 9336.9498 (D) Trimmed NSW-CPS1 -9228.0154 6462.9462 -128.49109 15690.9616 (E) Trimmed NSW-PSID1 -8144.9670 719.7532 -2389.43765 8864.7202 (F) Trimmed NSW-CPS1-PLUS -10451.3178 5106.9934 -899.26760 15558.3112 (G) Trimmed NSW-PSID1-PLUS -12155.0748 628.5303 -4550.45977 12783.6050 (H) Top CPS1: mahvars -5871.8447 4497.1872 -403.46896 10369.0319 (I) Top CPS1: k3 -6433.6618 5758.7425 -310.44164 12192.4042 (J) Top CPS1: exact 2107.5114 4004.1513 2987.72886 1896.6399 (K) Top CPS1: cem -2171.4373 4696.2185 732.85922 6867.6558 (L) Top CPS1: card -6580.1000 3282.7761 -667.44247 9862.8762 (M) Top PSID1: card -4940.7926 -246.1088 -2625.22319 4694.6838 (N) Top PSID1: mahvars -5399.1537 -466.6551 -2910.40388 4932.4986 (O) Top PSID1: optimal_pair -6393.1324 509.6989 -2317.97639 6902.8314 (P) Top PSID1: fix_max_value_opt_weight -8113.0122 1033.6624 -2305.33884 9146.6745 (Q) Top PSID1: exact 712.3349 1654.1756 1137.51262 941.8407 With NSW-CPS1, the CATT estimates range from $-8,652.64 to $6,452.97, contrasting with the benchmark where CATT estimates span from $-1,179.03 to $3,339.96, with a mean CATT estimate of $812.17. Alike in the previous sections, the NSW-PSID1 data exhibits a narrower CATT estimates range compared to NSW-CPS1, spanning from $-8,591.86 to $1,170.55. Yet its mean CATT estimate remains substantially negative, at approximately $-2,321.86, contrary to the positive mean CATT estimates observed in models A and B. Among the trimmed and top-ranked NSW-CPS1 subsamples, CATT estimates exhibit substantial variability. Subsamples such as overlap_crump or adap_weight_trunc_ipw_weight yield notably negative minimum CATT values alongside moderately negative mean CATT estimates. Similarly, card and mahvars subsamples produce consistently negative mean CATT estimates, although weaker alignment with the experimental benchmark. The ps_threshold subsample yields improved estimates with highest min CATT and mean CATTs estimates closest to the experimental benchmark, while still negative. The NSW-PSID1 trimmed and top-ranked subsamples deliver substantially decreased mean CATT estimates and wider extremes compared to their NSW-CPS1 counterparts, reflecting greater difficulties in producing reliable effect estimates. This variation in range and means across samples, as observed in previous sections, reflects substantial heterogeneity in treatment effect estimation but also indicates that while certain criteria improve alignment with the experimental benchmark, others introduce considerable discrepancies and spread in estimated heterogeneous effects. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;nsw&quot;) 4.8.3 Quantile treatment effect on the treated (QTET) qte.nsw &lt;- est_qte(Y, treat, covar, data = nsw, cores = 4) qte.nsw_cps &lt;- est_qte(Y, treat, covar, data = nsw_cps) qte.nsw_psid &lt;- est_qte(Y, treat, covar, data = nsw_psid) qte.nsw_cps_plus &lt;- est_qte(Y, treat, covar, data = nsw_cps_plus) qte.nsw_psid_plus &lt;- est_qte(Y, treat, covar, data = nsw_psid_plus) qte.nsw_cps.trim &lt;- est_qte(Y, treat, covar, data = nsw_cps.trim) qte.nsw_psid.trim &lt;- est_qte(Y, treat, covar, data = nsw_psid.trim) qte.nsw_cps_plus.trim &lt;- est_qte(Y, treat, covar, data = nsw_cps_plus.trim) qte.nsw_psid_plus.trim &lt;- est_qte(Y, treat, covar, data = nsw_psid_plus.trim) qte.top5_cps &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.nsw0 &lt;- est_qte(Y, treat, NULL, data = nsw) qte.nsw.cps0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps) qte.nsw.psid0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid) qte.nsw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps.trim) qte.nsw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid.trim) qte.nsw_cps_plus.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps_plus.trim) qte.nsw_psid_plus.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid_plus.trim) qte.top5_cps0 &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid0 &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d)) par(mfrow = c(2,2)) par(cex.main = 0.8) # CPS1 plot_qte(qte.nsw_cps, qte.nsw.cps0, qte.nsw, main = &quot;(B) NSW-CPS1&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 plot_qte(qte.nsw_psid, qte.nsw.psid0, qte.nsw, main = &quot;(C) NSW-PSID1&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) ## CPS1 trimmed plot_qte(qte.nsw_cps.trim, qte.nsw_cps.trim0, qte.nsw_cps, main = &quot;(D) NSW-CPS1 (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 trimmed plot_qte(qte.nsw_psid.trim, qte.nsw_psid.trim0, qte.nsw_psid, main = &quot;(E) NSW-PSID1 (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 4.83: FIGUREC11. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental ## CPS1-PLUS trimmed plot_qte(qte.nsw_cps_plus.trim, qte.nsw_cps_plus.trim0, qte.nsw_cps_plus, main = &quot;(F) NSW-CPS1-PLUS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1-PLUS trimmed plot_qte(qte.nsw_psid_plus.trim, qte.nsw_psid_plus.trim0, qte.nsw_psid_plus, main = &quot;(G) NSW-PSID1-PLUS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # CPS1 top methods plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.nsw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000)) Figure 4.84: FIGUREC11. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental # PSID1 top methods plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.nsw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000)) Figure 4.85: FIGUREC11. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental Figure 4.86: FIGUREC11. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the NSW experimental and various observational samples. The QTETs estimated from trimmed NSW-CPS1 sample (D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original NSW-CPS1, the original NSW-PSID1 and its trimmed subsample (B, C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked subsamples, CPS1-based QTETs (F–J) consistently track the true QTET closely. In contrast, PSID1-based QTETs (K–O) generally perform well, aligning closely with the true QTET, except for subsamples mahvars and card, which exhibit increased bias and noticeably wider confidence intervals, reflecting greater estimation uncertainty. # list results plots_nsw &lt;- list( list(mod = qte.nsw_cps, mod0 = qte.nsw.cps0, bm = qte.nsw, main = &quot;(B) NSW CPS1&quot;), list(mod = qte.nsw_psid, mod0 = qte.nsw.psid0, bm = qte.nsw, main = &quot;(C) NSW PSID1&quot;), list(mod = qte.nsw_cps.trim, mod0 = qte.nsw_cps.trim0, bm = qte.nsw_cps, main = &quot;(D) NSW CPS1 (Trimmed)&quot;), list(mod = qte.nsw_psid.trim, mod0 = qte.nsw_psid.trim0, bm = qte.nsw_psid, main = &quot;(E) NSW PSID1 (Trimmed)&quot;), list(mod = qte.nsw_cps_plus.trim, mod0 = qte.nsw_cps_plus.trim0, bm = qte.nsw_cps_plus, main = &quot;(F) NSW CPS1-PLUS (Trimmed)&quot;), list(mod = qte.nsw_psid_plus.trim, mod0 = qte.nsw_psid_plus.trim0, bm = qte.nsw_psid_plus, main = &quot;(G) NSW PSID1-PLUS (Trimmed)&quot;) ) # save results save_qtet(plots_nsw, prefix = &quot;nsw&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_cps, qte.top5_cps0, qte.nsw_cps, plot_titles, main_start = 8, ylim = c(-25000, 15000), prefix = &quot;nsw_top&quot;) save_qte_top(qte.top5_psid, qte.top5_psid0, qte.nsw_psid, plot_titles, main_start = 13, ylim = c(-25000, 15000), prefix = &quot;nsw_top&quot;) 4.8.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c(list(nsw, nsw_cps, nsw_psid, nsw_cps.trim, nsw_psid.trim, nsw_cps_plus.trim.match, nsw_psid_plus.trim.match), top5_datasets.cps, top5_datasets.psid) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 4.87: FIGUREC12. Outcome Weights using NSW Data Figure 4.88: FIGUREC12. Outcome Weights using NSW Data Figure 4.89: FIGUREC12. Outcome Weights using NSW Data Figure 4.90: FIGUREC12. Outcome Weights using NSW Data Figure 4.91: FIGUREC12. Outcome Weights using NSW Data #evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat, &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 4.8: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) NSW-Experimental 1 -1 (B) NSW-CPS1 1 -1 (C) NSW-PSID1 1 -1 (D) Trimmed NSW-CPS1 1 -1 (E) Trimmed NSW-PSID1 1 -1 (F) Trimmed NSW-CPS1-PLUS 1 -1 (G) Trimmed NSW-PSID1-PLUS 1 -1 (H) Top CPS1: mahvars 1 -1 (I) Top CPS1: k3 1 -1 (J) Top CPS1: exact 1 -1 (K) Top CPS1: cem 1 -1 (L) Top CPS1: card 1 -1 (M) Top PSID1: card 1 -1 (N) Top PSID1: mahvars 1 -1 (O) Top PSID1: optimal_pair 1 -1 (P) Top PSID1: fix_max_value_opt_weight 1 -1 (Q) Top PSID1: exact 1 -1 #save results save_ow(ow_att, plot_titles, prefix = &quot;nsw&quot;) Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. A placebo test is not performed as the NSW data comes from a randomized controlled trial (RCT), which ensures internal validity and unbiased treatment effect estimates, without confounding. 4.9 Validation through sensitivity analyses # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets filtered_datasets_sens &lt;- check_filter_datasets(all_datasets, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx]) } Figure 4.92: FIGUREC13. Sensitivity Analyses NSW Figure 4.93: FIGUREC13. Sensitivity Analyses NSW Figure 4.94: FIGUREC13. Sensitivity Analyses NSW Figure 4.95: FIGUREC13. Sensitivity Analyses NSW # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;nsw&quot;) The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of re78. 4.10 Summary After reexamining the original LaLonde (NSW) dataset, the results confirm that the NSW-Experimental data shows nearly perfect overlap between treated and control groups, while the observational datasets (NSW-CPS1 and NSW-PSID1) display weak overlap, with many treated units outside the control range. Expanding these datasets with experimental controls improves overlap but does not consistently enhance covariate balance. These findings reinforce the lessons from previous LDW analyses: even with improved overlap and some gains in covariate balance, achieving consistent and reliable effect estimation remains difficult, especially with non-experimental data. The results highlight the persistent limitations of observational samples in replicating experimental benchmarks. "],["lalonde-calónico-smith-lcs-data.html", "Chapter 5 LaLonde-Calónico-Smith (LCS) Data 5.1 Set up 5.2 Improving primarily covariate balance 5.3 Improving primarily overlap 5.4 Integrated methods 5.5 Reassessing methods 5.6 Integrated methods 5.7 Identifying best methods 5.8 Estimating 5.9 Validation through placebo analyses 5.10 Validation through sensitivity analyses 5.11 Summary", " Chapter 5 LaLonde-Calónico-Smith (LCS) Data This section (5) examines the LaLonde female samples reconstructed by Calónico and Smith (2017), referred to as the LaLonde-Calónico-Smith (LCS) sample (loaded as lcs below, similar to Imbens and Xu (2024)). For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only present and explain the LCS–specific results. 5.1 Set up 5.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lcs.RData&quot;) # set seed set.seed(42) 5.1.2 Load and preprocess data # expc = 0: experimental treated; # expc = 1: experimental control; # expc = 2: psid control; lcs_psid$expc &lt;- 0 lcs_psid[lcs_psid$treat==0, ]$expc &lt;- 2 lcs_tr &lt;- lcs[lcs$treat==1, ] lcs_co &lt;- lcs[lcs$treat==0, ] lcs_co$treat &lt;- 1 lcs_co$expc &lt;- 1 lcs_psid_plus &lt;- rbind.data.frame(lcs_psid, lcs_co) 5.1.3 Inspect data # collect datasets in a list data &lt;- list(lcs = lcs, lcs_psid = lcs_psid, lcs_psid_plus = lcs_psid_plus) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 5.1: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars lcs 1185 600 585 11 re79, treat, age, educ, nodegree, married, black, hisp, nchildren75, re75, u75 lcs_psid 1248 600 648 12 re79, treat, age, educ, nodegree, married, black, hisp, nchildren75, re75, u75, expc lcs_psid_plus 1833 1185 648 12 re79, treat, age, educ, nodegree, married, black, hisp, nchildren75, re75, u75, expc # define variables Y &lt;- &quot;re79&quot; treat &lt;- &quot;treat&quot; # redefine covariates: removing &quot;nchildren75&quot; to be used as placebo outcome covar &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) In the following analysis, only PSID1 data is used as the original LaLonde study and its reconstruction by Calónico and Smith (2017) designate PSID1 as the appropriate nonexperimental control group for women, providing a comparable observational dataset that aligns with the experimental sample’s characteristics. 5.1.4 Assessing overlap and covariate balance 5.1.4.1 Overlap # assess overlap lcs.ps &lt;- assess_overlap(data = lcs, treat = treat, cov = covar, xlim = c(-1.5, 1.5), breaks = 40) Figure 5.1: FIGURED1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1. lcs_psid.ps &lt;- assess_overlap(data = lcs_psid, treat = treat, cov = covar, xlim = c(-11, 7), breaks = 40) Figure 5.2: FIGURED1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1. As anticipated, the LCS-Experimental data exhibit an almost perfect overlap. In contrast, the observational dataset LCS-PSID1 displays weak overlap. # assess overlap lcs_psid_plus.ps &lt;- assess_overlap(data = lcs_psid_plus, treat = treat, cov = covar, xlim = c(-15, 5)) Figure 5.3: FIGURED2. SubfigureC:LCS-PSID1-PLUS. With the expanded dataset LCS-PSID1, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater spread of log-odds densities across both samples. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 5.1.4.2 Covariate balance love.plot(lcs, lcs_psid, treat, covar = covar, title = &quot;LCS-PSID1&quot;) love.plot(lcs, lcs_psid_plus, treat, covar = covar, title = &quot;LCS-PSID1-PLUS&quot;) Due to computational constraints, we use a reduced set of matching methods, consistent with previous sections. 5.2 Improving primarily covariate balance 5.2.1 Matching 5.2.1.1 Distance Matching 5.2.1.1.1 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.psid.optimal_pair &lt;- matchit(model, data = lcs_psid, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 5.2.1.1.2 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.psid.optimal_full &lt;- matchit(model, data = lcs_psid, method = &quot;full&quot;, distance = &quot;logit&quot;) 5.2.1.1.3 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.psid.general_full &lt;- matchit(model, data = lcs_psid, method = &quot;quick&quot;, distance = &quot;logit&quot;) 5.2.1.2 Stratum matching 5.2.1.2.1 Coarsened matching (cem) Strata = coarsened versions of covariates # match units exactly within coarse strata m.out.psid.cem &lt;- matchit(model, data = lcs_psid, method = &quot;cem&quot;) 5.2.1.2.2 Subclassification Strata = bins of the propensity score # partition sample into fixed number of bins based on propensity score m.out.psid.subcl &lt;- matchit(model, data = lcs_psid, method = &quot;subclass&quot;, subclass = 5) 5.2.1.3 Pure subset selection 5.2.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units m.out.psid.card &lt;- matchit(model, data = lcs_psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) 5.2.1.3.2 Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact m.out.psid.profile &lt;- matchit(model, data = lcs_psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, solver = &quot;highs&quot;) 5.2.2 Weighting 5.2.2.1 Inverse probability weights (IPW) w.out.ipw &lt;- WeightIt::weightit(model, data = lcs_psid, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) lcs_psid$ipw_weight &lt;- w.out.ipw$weights 5.2.2.2 Stable balancing weights w.out.opt &lt;- optweight::optweight(model, data = lcs_psid, estimand = &quot;ATT&quot;) lcs_psid$opt_weight &lt;- w.out.opt$weights 5.2.2.3 Propensity score weights w.out.cbps &lt;- WeightIt::weightit(model, data = lcs_psid, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) lcs_psid$cbps_weight &lt;- w.out.cbps$weights 5.2.2.4 Entropy balancing weights w.out.ebal &lt;- WeightIt::weightit(model, data = lcs_psid, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) lcs_psid$ebal_weight &lt;- w.out.ebal$weights 5.3 Improving primarily overlap 5.3.1 Truncation # list of weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;opt_weight&quot;, &quot;cbps_weight&quot;, &quot;ebal_weight&quot;) 5.3.1.1 Fixed maximum value truncation # truncate weights by imposing a minimum and maximum threshold lcs_psid.fixed &lt;- lcs_psid for (wcol in weight_columns) { if (wcol %in% names(lcs_psid.fixed)) { lcs_psid.fixed &lt;- truncate_weights_fixed(lcs_psid.fixed, weight_col = wcol, lower = 0.025, upper = 0.975) } } 5.3.1.2 At percentile truncation # truncate weights such that values below the 5th percentile and above the 95th percentile are capped lcs_psid.percent &lt;- lcs_psid for (wcol in weight_columns) { if (wcol %in% names(lcs_psid.percent)) { lcs_psid.percent &lt;- truncate_weights_percentile(lcs_psid.percent, weight_col = wcol, lower = 0.01, upper = 0.99) } } 5.3.1.3 Adaptive weight truncation psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(lcs_psid)) { psid_results[[wcol]] &lt;- check_weights(lcs_psid, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in LCS-PSID1&quot;)) } } var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_psid_table, caption = &quot;Variance of Weights&quot;) Table 5.2: Variance of Weights Weight_Column Variance ipw_weight 1.830457 opt_weight 1.186013 cbps_weight 1.202438 ebal_weight 1.401061 Regarding these results we can apply adaptive weight truncation to all considered weights. # truncate adaptively at mean + 3 standard deviations lcs_psid.adapt &lt;- lcs_psid for (wcol in weight_columns) { if (wcol %in% names(lcs_psid.adapt)) { lcs_psid.adapt &lt;- truncate_weights_adaptive(lcs_psid.adapt, weight_col = wcol, c = 3) } } 5.3.2 Trimming 5.3.2.1 Propensity score threshold trimming and nn matching (Similar to tutorial of Imbens and Xu (2024)) # apply trimming with threshold 0.9 lcs_psid_plus.trim &lt;- ps_trim(lcs_psid_plus.ps, threshold = 0.9) # exclude experimental controls, subset trimmed data appropriately lcs_psid_plus.trim.match &lt;- subset(lcs_psid_plus.trim, expc %in% c(0,2) &amp; ps_assoverlap) # re-estimate propensity scores on trimmed data and perform 1:1 matching lcs_psid_plus.trim.match &lt;- psmatch(data = lcs_psid_plus.trim.match, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) # trim experimental data and re-assign treat variable for controls in sample 3 or 4 (non-treated group) #lcs_trim_psid &lt;- subset(lcs_psid_trim, expc %in% c(0, 1)) #lcs_trim_psid$treat[lcs_trim_psid$expc == 1] &lt;- 0 5.3.2.2 Propensity score threshold trimming # apply trimming with threshold 0.9 lcs_psid.trim &lt;- ps_trim(lcs_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data lcs_psid.trim &lt;- ps_estimate(data = lcs_psid.trim, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) 5.3.2.3 Common range trimming # trim observations outside the common support region of propensity scores lcs_psid.common &lt;- common_range_trim(lcs_psid.ps) # re-estimate propensity scores on trimmed data lcs_psid.common &lt;- ps_estimate(data = lcs_psid.common, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) 5.3.2.4 Crump trimming # trim observations with propensity scores outside [0.1, 0.9] interval lcs_psid.crump &lt;- crump_trim(lcs_psid.ps, lower = 0.1, upper = 0.9) # re-estimate propensity scores on trimmed data lcs_psid.crump &lt;- ps_estimate(data = lcs_psid.crump, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) 5.3.2.5 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control lcs_psid.stuermer &lt;- stuermer_trim(lcs_psid.ps) # re-estimate propensity scores on trimmed data lcs_psid.stuermer &lt;- ps_estimate(data = lcs_psid.stuermer, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) 5.3.2.6 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations lcs_psid.walker &lt;- walker_trim(lcs_psid.ps) # re-estimate propensity scores on trimmed data lcs_psid.walker &lt;- ps_estimate(data = lcs_psid.walker, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) 5.4 Integrated methods # list trimming objects all_trim.psid &lt;- list(ps_threshold = lcs_psid.trim, common_range = lcs_psid.common, stuermer = lcs_psid.stuermer, walker = lcs_psid.walker, crump = lcs_psid.crump) 5.4.0.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ipw_weight&quot;) 5.4.0.2 Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply stable balancing with trimming and attach stable balance weights opt_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;opt_weight&quot;) 5.4.0.3 Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply propensity score weighting with trimming and attach propensity score weights cbps_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;cbps_weight&quot;) 5.4.0.4 Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights ebal_comb.psid &lt;- trim_attach_weights(all_trim.psid, model, &quot;ebal_weight&quot;) 5.5 Reassessing methods 5.5.1 Matching # list all matching objects all_match.psid &lt;- list( optimal_pair = m.out.psid.optimal_pair, optimal_full = m.out.psid.optimal_full, gen_full = m.out.psid.general_full, cem = m.out.psid.cem, card = m.out.psid.card, profile = m.out.psid.profile, subcl = m.out.psid.subcl ) 5.5.1.1 SMD # compute SMD smd_matchit.psid &lt;- compute_abs_smd_matchit(all_match.psid) 5.5.1.2 ESS # calculate balance statistics bal.psid &lt;- cobalt::bal.tab(model, data = lcs_psid, un = TRUE, weights = all_match.psid, s.d.denom = &quot;treated&quot;) # compute effective sample sizes (ESS) ess_matchit.psid &lt;- compute_ess_matchit(bal.psid) 5.5.1.3 Visuals # visualize covariate balance plot_matching_balance(all_match.psid, title = &quot;LCS-PSID1&quot;) ## $optimal_pair Figure 5.4: FIGURED3. ## ## $optimal_full Figure 5.5: FIGURED3. ## ## $gen_full Figure 5.6: FIGURED3. ## ## $cem Figure 5.7: FIGURED3. ## ## $card Figure 5.8: FIGURED3. ## ## $profile Figure 5.9: FIGURED3. ## ## $subcl Figure 5.10: FIGURED3. 5.5.2 Weighting # list all weights all_weight.psid &lt;- list( ipw_weight = lcs_psid$ipw_weight, opt_weight = lcs_psid$opt_weight, cbps_weight = lcs_psid$cbps_weight, ebal_weight = lcs_psid$ebal_weight ) 5.5.2.1 SMD # compute SMD smd_weight.psid &lt;- compute_abs_smd_weight(lcs_psid, treat, covar, all_weight.psid) 5.5.2.2 ESS # compute ESS ess_weight.psid &lt;- compute_ess_weight(lcs_psid, treat, covar, all_weight.psid) 5.5.2.3 Visuals # visualize covariate balance plot_weighting_balance(lcs_psid, treat, covar, all_weight.psid, &quot;LCS-PSID1&quot;) ## $ipw_weight Figure 5.11: FIGURED4. ## ## $opt_weight Figure 5.12: FIGURED4. ## ## $cbps_weight Figure 5.13: FIGURED4. ## ## $ebal_weight Figure 5.14: FIGURED4. 5.5.3 Truncation # list truncation methods all_trunc.psid &lt;- list( fix_max_value = lcs_psid.fixed, at_perc = lcs_psid.percent, adap_weight = lcs_psid.adapt ) 5.5.3.1 SMD # compute SMD smd_trunc.psid &lt;- compute_abs_smd_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 5.5.3.2 ESS # compute ESS ess_trunc.psid &lt;- compute_ess_trunc(all_trunc.psid, &quot;treat&quot;, covar, weight_columns) 5.5.3.3 Visuals # visualize covariate balance plot_trunc_balance(all_trunc.psid, &quot;treat&quot;, covar, weight_columns, &quot;LCS-PSID1&quot;) ## $fix_max_value_ipw_weight Figure 5.15: FIGURED5. ## ## $fix_max_value_opt_weight Figure 5.16: FIGURED5. ## ## $fix_max_value_cbps_weight Figure 5.17: FIGURED5. ## ## $fix_max_value_ebal_weight Figure 5.18: FIGURED5. ## ## $at_perc_ipw_weight Figure 5.19: FIGURED5. ## ## $at_perc_opt_weight Figure 5.20: FIGURED5. ## ## $at_perc_cbps_weight Figure 5.21: FIGURED5. ## ## $at_perc_ebal_weight Figure 5.22: FIGURED5. ## ## $adap_weight_ipw_weight Figure 5.23: FIGURED5. ## ## $adap_weight_opt_weight Figure 5.24: FIGURED5. ## ## $adap_weight_cbps_weight Figure 5.25: FIGURED5. ## ## $adap_weight_ebal_weight Figure 5.26: FIGURED5. 5.5.4 Trimming # list trimming object plus original all_trim.psid &lt;- list( original = lcs_psid, ps_threshold = lcs_psid.trim, common_range = lcs_psid.common, crump = lcs_psid.crump, stuermer = lcs_psid.stuermer, walker = lcs_psid.walker ) 5.5.4.1 SMD # compute SMD smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 5.5.4.2 ESS # compute ESS ess_trim.psid &lt;- compute_ess_trim(all_trim.psid, &quot;treat&quot;, covar) 5.5.4.3 Visuals # visualize overlap plot_trim_overlap(all_trim.psid, treat, covar, prefix = &quot;LDW-PSID1&quot;) ## -7.208955 2.596894 ## -7.002306 2.620523 ## -3.118168 2.71402 ## -2.571072 2.659878 ## -1.157976 2.166121 ## -0.7934438 1.341572 Figure 5.27: FIGURED6. 5.6 Integrated methods # list all combined results comb.psid &lt;- list( ipw = ipw_comb.psid, opt = opt_comb.psid, cbps = cbps_comb.psid, ebal = ebal_comb.psid ) 5.6.0.1 SMD # compute SMD smd_all_comb_meth.psid &lt;- compute_abs_smd_comb(comb.psid, &quot;treat&quot;, covar) 5.6.0.2 ESS # compute ESS ess_all_comb_meth.psid &lt;- compute_ess_comb(comb.psid, &quot;treat&quot;, covar) 5.6.0.3 Visuals # visualize overlap #plot_comb_overlap(comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix_psid = &quot;LCS-PSID1&quot;) # visualize covariate balance #plot_comb_balance(comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, orig_psid = lcs_psid, prefix_psid = &quot;LCS-PSID1&quot;) # save results #save_comb_hist(comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;lcs&quot;, prefix_psid = &quot;lcs_psid1&quot;) #save_comb_loveplots(comb_meth_psid = comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;lcs&quot;, prefix_psid = &quot;lcs_psid1&quot;) 5.7 Identifying best methods # combine all results all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_psid, &quot;ldw_psid1_all_results&quot;) # assess and rank methods ranked_psid &lt;- assess_methods(all_psid) # get top 5 methods top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # print results top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.psid, caption = &quot;Top 5 Methods&quot;, booktabs = TRUE) Table 5.3: Top 5 Methods Method Score card 0.7964751 cbps_walker 0.6893253 ebal_walker 0.6893253 ipw_walker 0.6893253 opt_walker 0.6893253 # save results save_csv(top5_methods.psid, &quot;PSID1_top5_methods_lcs&quot;) The table shows that CPS1 and PSID1 share the same top five methods, with the exception of one differing method and a variation in their ordering for PSID1. dataset_list_psid &lt;- list( &quot;All&quot; = lcs_psid, &quot;original&quot; = lcs_psid, &quot;card&quot; = m.out.psid.card, &quot;optimal_full&quot; = m.out.psid.optimal_full, &quot;optimal_pair&quot; = m.out.psid.optimal_pair, &quot;gen_full&quot; = m.out.psid.general_full, &quot;subcl&quot; = m.out.psid.subcl, &quot;profile&quot; = m.out.psid.profile, &quot;ipw_weight&quot; = lcs_psid$ipw_weight, &quot;opt_weight&quot; = lcs_psid$opt_weight, &quot;cbps_weight&quot; = lcs_psid$cbps_weight, &quot;ebal_weight&quot; = lcs_psid$ebal_weight, &quot;fix_max_value_ipw_weight&quot; = lcs_psid.fixed$ipw_weight, &quot;fix_max_value_opt_weight&quot; = lcs_psid.fixed$opt_weight, &quot;fix_max_value_cbps_weight&quot; = lcs_psid.fixed$cbps_weight, &quot;fix_max_value_ebal_weight&quot; = lcs_psid.fixed$ebal_weight, &quot;at_perc_ipw_weight&quot; = lcs_psid.percent$ipw_weight, &quot;at_perc_opt_weight&quot; = lcs_psid.percent$opt_weight, &quot;at_perc_cbps_weight&quot; = lcs_psid.percent$cbps_weight, &quot;at_perc_ebal_weight&quot; = lcs_psid.percent$ebal_weight, &quot;adap_weight_ipw_weight&quot; = lcs_psid.adapt$ipw_weight, &quot;adap_weight_opt_weight&quot; = lcs_psid.adapt$opt_weight, &quot;adap_weight_cbps_weight&quot; = lcs_psid.adapt$cbps_weight, &quot;adap_weight_ebal_weight&quot; = lcs_psid.adapt$ebal_weight, &quot;ps_threshold&quot; = lcs_psid.trim, &quot;common_range&quot; = lcs_psid.common, &quot;stuermer&quot; = lcs_psid.stuermer, &quot;walker&quot; = lcs_psid.walker, &quot;crump&quot; = lcs_psid.crump, &quot;ipw_common_range&quot; = ipw_comb.psid[[1]], &quot;ipw_crump&quot;= ipw_comb.psid[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid[[4]], &quot;ipw_walker&quot; = ipw_comb.psid[[5]], &quot;opt_common_range&quot; = opt_comb.psid[[1]], &quot;opt_crump&quot; = opt_comb.psid[[2]], &quot;opt_ps_threshold&quot; = opt_comb.psid[[3]], &quot;opt_stuermer&quot; = opt_comb.psid[[4]], &quot;opt_walker&quot; = opt_comb.psid[[5]], &quot;cbps_common_range&quot; = cbps_comb.psid[[1]], &quot;cbps_crump&quot; = cbps_comb.psid[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.psid[[3]], &quot;cbps_stuermer&quot; = cbps_comb.psid[[4]], &quot;cbps_walker&quot;= cbps_comb.psid[[5]], &quot;ebal_common_range&quot; = ebal_comb.psid[[1]], &quot;ebal_crump&quot; = ebal_comb.psid[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.psid[[3]], &quot;ebal_stuermer&quot; = ebal_comb.psid[[4]], &quot;ebal_walker&quot; = ebal_comb.psid[[5]]) # create the datasets from combined lists for your top 5 methods: top5_datasets.psid &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid) # save them into .RData files save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = &quot;lcs_psid1&quot;) 5.8 Estimating 5.8.1 Average treatment effect on the treated (ATT) # get estimates out1 &lt;- estimate_all(lcs, &quot;re79&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(lcs_psid, &quot;re79&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(lcs_psid_plus.trim, &quot;re79&quot;, &quot;treat&quot;, covar) # similar to Imbens &amp; Xu (2024) out4 &lt;- estimate_all(lcs_psid.trim, &quot;re79&quot;, &quot;treat&quot;, covar) out.psid &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, &quot;re79&quot;, &quot;treat&quot;, covar)) out5 &lt;- out.psid[[1]] out6 &lt;- out.psid[[2]] out7 &lt;- out.psid[[3]] out8 &lt;- out.psid[[4]] out9 &lt;- out.psid[[5]] # build plot titles base_titles &lt;- c(&quot;(A) LCS-Experimental&quot;, &quot;(B) LCS-PSID1&quot; , &quot;(C) Trimmed LCS-PSID1-PLUS&quot;, &quot;(D) Trimmed LCS-PSID1&quot;) top_start &lt;- 5 # E is 5th letter num_psid &lt;- length(top5_methods.psid) top_letters_psid &lt;- LETTERS[top_start:(top_start + num_psid - 1)] top5_titles.psid &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid) plot_titles &lt;- c(base_titles, top5_titles.psid) # combine all results all_outs &lt;- c(list(out1, out2, out3, out4), out.psid) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 5.28: FIGURED10. ATT Estimates Given Unconfoundedness using LCS Samples Figure 5.29: FIGURED10. ATT Estimates Given Unconfoundedness using LCS Samples Figure 5.30: FIGURED10. ATT Estimates Given Unconfoundedness using LCS Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;lcs&quot;) The above figures show the ATT estimates and their 95% confidence intervals for eight samples: LCS-Experimental, LCS-PSID1, a trimmed version of the LCS-PSID1 sample (analogous to Imbens and Xu (2024)) and a series of top-ranked subsamples of LCS-PSID1 based on various matching, weighting, truncation and trimming criteria. Figure (A) presents the benchmark from the experimental sample (LCS-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) shows results for the observational sample LCS-PSID1 and figure (C) for its trimmed version, replicating the tutorial results of Imbens &amp; Xu (2024). Figures (D) through (H) display results for PSID1-based subsamples. Across the LCS-PSID1 dataset and its top-ranked subsamples, all estimators yield ATT estimates that largely cluster around the experimental benchmark except Diff-in-Means, which tends to produce estimates that deviate more noticeably from the benchmark. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 5.4: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) LCS-Experimental 296.2628 787.7793 1059.0663 271.2870 (B) LCS-PSID1 405.1061 -4172.1762 1228.6598 5400.8360 (C) Trimmed LCS-PSID1-PLUS 352.8986 -4996.0797 397.0030 5393.0827 (D) Trimmed LCS-PSID1 417.4413 -4229.6610 1100.6995 5330.3605 (E) Top PSID1: card 438.7622 72.3074 553.5347 481.2273 (F) Top PSID1: cbps_walker 416.3379 -483.7775 1117.9513 1601.7288 (G) Top PSID1: ebal_walker 416.2621 -483.7775 1117.9513 1601.7288 (H) Top PSID1: ipw_walker 416.2621 -483.7775 1117.9513 1601.7288 (I) Top PSID1: opt_walker 416.2621 -483.7775 1117.9513 1601.7288 # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) %&gt;% kable_styling(full_width = TRUE) Table 5.5: Table 5.6: ATT Estimates and SEs LCS-Experimental LCS-PSID1 Trimmed LCS-PSID1-PLUS Trimmed LCS-PSID1 Top PSID1: card Top PSID1: cbps_walker Top PSID1: ebal_walker Top PSID1: ipw_walker Top PSID1: opt_walker Experimental Benchmark 821.49 (307.89) -4172.18 (412.18) -4996.08 (401.18) -4229.66 (416.23) 370.73 (454.27) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) diff 821.49 (307.89) -4172.18 (412.18) -4996.08 (401.18) -4229.66 (416.23) 370.73 (454.27) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) reg 848.63 (303.41) 808.44 (389.48) -5.68 (356.33) 749.65 (394.53) 438.30 (430.71) 615.23 (406.17) 615.23 (406.17) 615.23 (406.17) 615.23 (406.17) om.reg 895.65 (230.21) 1128.29 (239.37) 379.18 (207.39) 1047.62 (244.65) 520.87 (315.39) 1033.02 (243.64) 1033.02 (243.64) 1033.02 (243.64) 1033.02 (243.64) om.grf 902.37 (229.95) 937.89 (238.14) 28.53 (207.74) 813.35 (243.03) 368.37 (308.46) 818.67 (242.65) 760.65 (242.46) 760.65 (242.46) 760.65 (242.46) matching 1059.07 (320.55) 1036.86 (531.41) 33.14 (457.30) 806.02 (533.60) 72.31 (560.99) 874.17 (533.88) 874.17 (533.88) 874.17 (533.88) 874.17 (533.88) psm 812.29 (304.99) 1021.17 (330.85) 397.00 (286.78) 568.51 (348.71) 291.17 (449.67) 603.18 (359.61) 613.47 (358.89) 613.47 (358.89) 613.47 (358.89) ipw 906.05 (313.86) 994.63 (478.86) 199.30 (414.39) 786.68 (515.60) 370.73 (454.27) 785.57 (516.01) 785.57 (516.01) 785.57 (516.01) 785.57 (516.01) cbps 896.05 (304.69) 1216.52 (429.26) 265.57 (389.61) 1080.15 (433.57) 370.73 (454.27) 1117.95 (435.45) 1117.95 (435.45) 1117.95 (435.45) 1117.95 (435.45) ebal 896.09 (304.69) 1228.66 (429.73) 276.21 (390.37) 1100.70 (434.80) 553.53 (440.43) 1115.46 (436.50) 1115.46 (436.50) 1115.46 (436.50) 1115.46 (436.50) dml 787.78 (300.62) 813.84 (387.60) -23.21 (354.69) 840.99 (392.41) 398.62 (430.28) 575.46 (405.55) 575.46 (405.55) 575.46 (405.55) 575.46 (405.55) aipw_grf 914.66 (316.70) 1058.28 (508.02) 181.82 (392.67) 819.64 (565.76) 271.48 (497.23) 871.54 (518.56) 871.54 (518.56) 871.54 (518.56) 871.54 (518.56) aipw_ow 833.45 (317.61) 1127.15 (486.38) 28.00 (376.34) 854.13 (486.40) 443.16 (469.16) 857.20 (505.80) 857.20 (505.80) 857.20 (505.80) 857.20 (505.80) The tabulated results confirm visual patterns: Column (A) reports the estimates for the LCS-Experimental sample, column (B) for the LCS-PSID1 sample, and column (C) for its trimmed version. Columns (D)-(H) show results of the top-ranked subsample of LCS-PSID1. For all PSID1-based samples, the ATT estimates remain overly positive. However, the estimates obtained with the Diff-in-Means estimator are consistently negative. Likewise, for the sample constructed with the card method, the estimates remain negative across all estimators. # save results save_csv(result_mat, &quot;LCS_att_estimates&quot;) 5.8.2 Conditional average treatment effect on the treated (CATT) catt.lcs &lt;- catt(lcs, Y, treat, covar) catt.psid &lt;- catt(lcs_psid, Y, treat, covar) catt.psid.trim &lt;- catt(lcs_psid.trim, Y, treat, covar) catt.psid_plus.trim &lt;- catt(lcs_psid_plus.trim, Y, treat, covar) # similar to Imbens &amp; Xu (2024) catt.top5_psid &lt;- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar)) # combine all catt objects all_catt &lt;- c(list(catt.lcs, catt.psid, catt.psid.trim, catt.psid_plus.trim), catt.top5_psid) # plot results par(mfrow = c(2,2)) par(cex.main = 0.8) plot_catt_panels(all_catt, plot_titles) Figure 5.31: FIGURED11. CATT Estimates using LCS Data Figure 5.32: FIGURED11. CATT Estimates using LCS Data all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 5.7: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) LCS-Experimental -426.8372 2899.667 883.36978 3326.504 (B) LCS-PSID1 -3060.3753 2394.791 761.60140 5455.167 (C) Trimmed LCS-PSID1-PLUS -3248.0881 2290.514 619.81287 5538.602 (D) Trimmed LCS-PSID1 -3937.7820 2539.888 46.70449 6477.670 (E) Top PSID1: card -2789.9685 2305.005 297.58193 5094.973 (F) Top PSID1: cbps_walker -3370.2312 2290.075 524.07036 5660.306 (G) Top PSID1: ebal_walker -3227.1412 2364.397 569.28749 5591.538 (H) Top PSID1: ipw_walker -3291.0553 2347.947 530.11096 5639.002 (I) Top PSID1: opt_walker -3210.2430 2292.276 522.64714 5502.519 With LCS-PSID1, CATT estimates span from $-3,357.48 to $2,404.33, contrasting with the CATT estimated from experimental data which ranges from $-359.43 to $2,719.14, with a mean CATT estimate of $863.51. In contract, across the LCS-PSID1-based subsamples, the ranges of CATT estimates are relatively similar. Importantly, the mean CATT estimates remain positive in all cases, except for card subsample, that produces a mean CATT estimate of $-415.71. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;lcs&quot;) 5.8.3 Quantile treatment effect on the treated (QTET) qte.lcs &lt;- est_qte(Y, treat, covar, data = lcs, cores = 4) qte.lcs_psid &lt;- est_qte(Y, treat, covar, data = lcs_psid) qte.lcs_psid_plus &lt;- est_qte(Y, treat, covar, data = lcs_psid_plus) qte.lcs_psid.trim &lt;- est_qte(Y, treat, covar, data = lcs_psid.trim) qte.lcs_psid_plus.trim &lt;- est_qte(Y, treat, covar, data = lcs_psid_plus.trim) # similar to Imbens &amp; Xu (2024) qte.top5_psid &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.lcs0 &lt;- est_qte(Y, treat, NULL, data = lcs) qte.lcs_psid0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid) qte.lcs_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid.trim) qte.lcs_psid_plus.trim0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid_plus.trim) qte.top5_psid0 &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d)) par(mfrow = c(2,2)) par(cex.main = 0.8) # PSID1 plot_qte(qte.lcs_psid, qte.lcs_psid0, qte.lcs, main = &quot;(B) LCS-PSID1&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 trimmed plot_qte(qte.lcs_psid.trim, qte.lcs_psid.trim0, qte.lcs_psid, main = &quot;(C) LCS-PSID1 (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1-PLUS trimmed plot_qte(qte.lcs_psid_plus.trim, qte.lcs_psid_plus.trim0, qte.lcs_psid_plus, main = &quot;(D) LCS-PSID1-PLUS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # similar to Imbens &amp; Xu (2024) # PSID1 top methods plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.lcs_psid, plot_titles, main_start = 5, ylim = c(-25000, 15000)) Figure 5.33: FIGURED12. QTET Estimates Model A using LCS Data: Experimental vs. Nonexperimental Figure 5.34: FIGURED12. QTET Estimates Model A using LCS Data: Experimental vs. Nonexperimental These figures present QTET estimates obtained from LCS-Experimental sample and several observational samples. The QTETs estimated from both the original and trimmed LCS-PSID1 samples (B and C), as well as from the top-ranked subsamples (E through H), align comparatively close with the true QTET. However, the QTETs from subsample (F) exhibit a stronger bias, suggesting greater estimation uncertainty. plots_lcs &lt;- list( list(mod = qte.lcs_psid, mod0 = qte.lcs_psid0, bm = qte.lcs, main = &quot;(B) LCS PSID1&quot;), list(mod = qte.lcs_psid.trim, mod0 = qte.lcs_psid.trim0, bm = qte.lcs_psid, main = &quot;(D) LCS PSID1 (Trimmed)&quot;), list(mod = qte.lcs_psid_plus.trim, mod0 = qte.lcs_psid_plus.trim0, bm = qte.lcs_psid_plus, main = &quot;(C) LCS PSID1-PLUS (Trimmed)&quot;) # similar to Imbens &amp; Xu (2024) ) save_qtet(plots_lcs, prefix = &quot;lcs&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_psid, qte.top5_psid0, qte.lcs_psid, plot_titles, main_start = 5, ylim = c(-25000, 15000), prefix = &quot;lcs_top&quot;) 5.8.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c(list(lcs, lcs_psid, lcs_psid.trim, lcs_psid_plus.trim), top5_datasets.psid) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 5.35: FIGURED14. Outcome Weights using LCS Data Figure 5.36: FIGURED14. Outcome Weights using LCS Data Figure 5.37: FIGURED14. Outcome Weights using LCS Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat, &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 5.8: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) LCS-Experimental 1 -1 (B) LCS-PSID1 1 -1 (C) Trimmed LCS-PSID1-PLUS 1 -1 (D) Trimmed LCS-PSID1 1 -1 (E) Top PSID1: card 1 -1 (F) Top PSID1: cbps_walker 1 -1 (G) Top PSID1: ebal_walker 1 -1 (H) Top PSID1: ipw_walker 1 -1 (I) Top PSID1: opt_walker 1 -1 Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. # save results save_ow(ow_att, plot_titles, prefix = &quot;lcs&quot;) 5.9 Validation through placebo analyses # define variables Y_pl &lt;- &quot;nchildren75&quot; treat &lt;- &quot;treat&quot; covar_pl &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) # estimate placebo ATT on original and observational datasets out1_pl &lt;- estimate_all(lcs, Y_pl, &quot;treat&quot;, covar_pl) out2_pl &lt;- estimate_all(lcs_psid, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on trimmed datasets out3_pl &lt;- estimate_all(lcs_psid_plus.trim, Y_pl, &quot;treat&quot;, covar_pl) # similar to Imbens &amp; Xu (2024) out4_pl &lt;- estimate_all(lcs_psid.trim, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on top ranked datasets out.psid_pl &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out5_pl &lt;- out.psid_pl[[1]] out6_pl &lt;- out.psid_pl[[2]] out7_pl &lt;- out.psid_pl[[3]] out8_pl &lt;- out.psid_pl[[4]] out9_pl &lt;- out.psid_pl[[5]] # collect all placebo results all_outs.pl &lt;- c(list(out1_pl, out2_pl, out3_pl, out4_pl), out.psid_pl) # plot placebo results band_pl &lt;- out1_pl[1, 3:4] est_pl &lt;- out1_pl[1, 1] ylim_pl = c(-1.5, 1) plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.8) Figure 5.38: FIGURED16. Placebo Test LCS: Number of Children in 1975 as the Outcome Figure 5.39: FIGURED16. Placebo Test LCS: Number of Children in 1975 as the Outcome Figure 5.40: FIGURED16. Placebo Test LCS: Number of Children in 1975 as the Outcome # save results save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, &quot;lcs_placebo&quot;) result_mat_pl &lt;- create_matrix_results(all_outs.pl, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;Placebo ATT Estimates and SEs&quot;) %&gt;% kable_styling(full_width = TRUE) Table 5.9: Table 5.10: Placebo ATT Estimates and SEs LCS-Experimental LCS-PSID1 Trimmed LCS-PSID1-PLUS Trimmed LCS-PSID1 Top PSID1: card Top PSID1: cbps_walker Top PSID1: ebal_walker Top PSID1: ipw_walker Top PSID1: opt_walker Experimental Benchmark 821.49 (307.89) -4172.18 (412.18) -4996.08 (401.18) -4229.66 (416.23) 370.73 (454.27) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) diff 821.49 (307.89) -4172.18 (412.18) -4996.08 (401.18) -4229.66 (416.23) 370.73 (454.27) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) -483.78 (392.24) reg 848.63 (303.41) 808.44 (389.48) -5.68 (356.33) 749.65 (394.53) 438.30 (430.71) 615.23 (406.17) 615.23 (406.17) 615.23 (406.17) 615.23 (406.17) om.reg 895.65 (230.21) 1128.29 (239.37) 379.18 (207.39) 1047.62 (244.65) 520.87 (315.39) 1033.02 (243.64) 1033.02 (243.64) 1033.02 (243.64) 1033.02 (243.64) om.grf 902.37 (229.95) 937.89 (238.14) 28.53 (207.74) 813.35 (243.03) 368.37 (308.46) 818.67 (242.65) 760.65 (242.46) 760.65 (242.46) 760.65 (242.46) matching 1059.07 (320.55) 1036.86 (531.41) 33.14 (457.30) 806.02 (533.60) 72.31 (560.99) 874.17 (533.88) 874.17 (533.88) 874.17 (533.88) 874.17 (533.88) psm 812.29 (304.99) 1021.17 (330.85) 397.00 (286.78) 568.51 (348.71) 291.17 (449.67) 603.18 (359.61) 613.47 (358.89) 613.47 (358.89) 613.47 (358.89) ipw 906.05 (313.86) 994.63 (478.86) 199.30 (414.39) 786.68 (515.60) 370.73 (454.27) 785.57 (516.01) 785.57 (516.01) 785.57 (516.01) 785.57 (516.01) cbps 896.05 (304.69) 1216.52 (429.26) 265.57 (389.61) 1080.15 (433.57) 370.73 (454.27) 1117.95 (435.45) 1117.95 (435.45) 1117.95 (435.45) 1117.95 (435.45) ebal 896.09 (304.69) 1228.66 (429.73) 276.21 (390.37) 1100.70 (434.80) 553.53 (440.43) 1115.46 (436.50) 1115.46 (436.50) 1115.46 (436.50) 1115.46 (436.50) dml 787.78 (300.62) 813.84 (387.60) -23.21 (354.69) 840.99 (392.41) 398.62 (430.28) 575.46 (405.55) 575.46 (405.55) 575.46 (405.55) 575.46 (405.55) aipw_grf 914.66 (316.70) 1058.28 (508.02) 181.82 (392.67) 819.64 (565.76) 271.48 (497.23) 871.54 (518.56) 871.54 (518.56) 871.54 (518.56) 871.54 (518.56) aipw_ow 833.45 (317.61) 1127.15 (486.38) 28.00 (376.34) 854.13 (486.40) 443.16 (469.16) 857.20 (505.80) 857.20 (505.80) 857.20 (505.80) 857.20 (505.80) The placebo analysis shows that the experimental benchmark is close to zero and statistically insignificant, while all estimators applied to the observational datasets produce comparable results. # save results save_csv(result_mat_pl, &quot;LCS_att_estimates_pl&quot;) 5.10 Validation through sensitivity analyses # define variables Y &lt;- &quot;re79&quot; treat &lt;- &quot;treat&quot; # redefine covariates covar &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets datasets_sens &lt;- c(list(lcs, lcs_psid, lcs_psid_plus), top5_datasets.psid) filtered_datasets_sens &lt;- check_filter_datasets(datasets_sens, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx+1]) } Figure 5.41: FIGURED17. Sensitivity Analyses LCS Figure 5.42: FIGURED17. Sensitivity Analyses LCS # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;lcs&quot;) The sensitivity analysis shows that treatment effect estimates in LCS-Experimental (A) are robust to unmeasured confounding, as expected. Observational samples instead show varying degrees of sensitivity, with the full observational sample (B) being more sensitive than the trimmed version (C). The top-ranked PSID1 subsamples (D-H) show that despite employing advanced criteria to improve balance and overlap, treatment effect estimates can exhibit increasing bias under plausible stronger confounding scenarios based on the reference confounder strength. 5.11 Summary After reexamining the LaLonde-Calónico-Smith (LCS) data, the results confirm that, as with the NSW and LDW datasets, overlap between treated and control groups is generally stronger in the experimental sample than in the observational (PSID-1) controls. Augmenting the sample with experimental controls improves overlap but does not consistently resolve covariate imbalance. The findings for the LCS sample closely mirror those from the LDW and NSW analyses: while certain methods can bring effect estimates closer to experimental benchmarks, substantial estimator-dependent variability and sensitivity to sample construction persist. Placebo and sensitivity analyses again show that unconfoundedness is difficult to verify, and that treatment effect estimates from observational data remain fragile. This underscores the ongoing challenge of obtaining reliable causal estimates for the LCS data. References Calónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["references.html", "References", " References Calónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Greifer, Noah. 2025. “Matching Methods.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Ju, Cheng, Joshua Schwab, and Mark J. van der Laan. 2013. “On Adaptive Propensity Score Truncation in Causal Inference.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” Matsouaka, Roland A., and Yunji Zhou. 2023. “Causal Inference in the Absence of Positivity: The Role of Overlap Weights.” Biometrical Journal. Stürmer, Til, Michael Webster-Clark, Jennifer L. Lund, Richard Wyss, Alan R. Ellis, Mark Lunt, Kenneth J. Rothman, and Robert J. Glynn. 2021. “Propensity Score Weighting and Trimming Strategies for Reducing Variance and Bias of Treatment Effect Estimates: A Simulation Study.” American Journal of Epidemiology. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
