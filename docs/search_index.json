[["index.html", "Application of the Outcome Weights Framework for Double Machine Learning to the LaLonde Study Preface", " Application of the Outcome Weights Framework for Double Machine Learning to the LaLonde Study Laura Kreisel 2025-12-04 Preface This book replicates the LaLonde study by Imbens and Xu (2024) and extends it by comparing a full with a reduced covariate model to assess potential confounding. It evaluates various methods to improve overlap and covariate balance for robust treatment effect estimation and applies the outcome weights framework by Knaus and Pfleiderer (2024) to assess another estimator, while analysing the distributional properties of resulting outcome weights. It further applies placebo tests and sensitivity analysis to assess the robustness of the treatment effect estimates. The analysis draws on the original LaLonde data (NSW) as well as the LaLonde–Dehejia–Wahba (LDW) and LaLonde–Calónico–Smith (LCS) data. Figure 0.1: Conceptual illustration (AI-generated) Section 1 introduces required packages and wrapper functions used throughout the analysis. Section 2 replicates and extends the full covariate model from Imbens and Xu (2024) using the LDW sample. Section 3 applies a reduced covariate set to the same LDW sample. Section 4 analyzes the NSW sample following similar methods and section 5 explores the LCS sample, focusing on female samples. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” "],["getting-started.html", "Chapter 1 Getting started 1.1 Installation 1.2 Wrapper functions", " Chapter 1 Getting started The functions presented below constitute the core wrapper functions utilized throughout the analysis, including functions originally from the Imbens and Xu (2024) tutorial, that were modified to suit specific analytical purposes (highlighted by ***), as well as others that were integrated without modification. For the full collection of functions by Imbens and Xu (2024), please consult their official source code available on their GitHub repository. 1.1 Installation Several R packages are required for the data analysis and visualization. The code below checks for all required packages and installs those that are missing. Once installation is complete, the packages must be loaded. Since the analysis sources functions directly from the Imbens and Xu (2024) tutorial, the required packages are automatically installed and loaded as part of that process. Therefore, it is only necessary to install and load any additional packages as well as add custom functions that are required for the analysis. Packages: “CBPS”, “cobalt”, “data.table”, “dplyr”, “DT”, “DoubleML”, “ebal”, “estimatr”, “ggplot2”, “gridExtra”, “grf”, “hbal”, “highr”, “highs”, “kableExtra”, “MatchIt”, “Matching”, “mlr3”, “mlr3learners”, “OutcomeWeights”, “optmatch”, “optweight”, “quickmatch”, “readr”, “rgenoud”, “tidyr”, “tidyverse”, “patchwork”, “ppcor”, “WeightIt” # required packages packages &lt;- c(&quot;CBPS&quot;, &quot;cobalt&quot;, &quot;data.table&quot;, &quot;dplyr&quot;, &quot;DT&quot;, &quot;DoubleML&quot;, &quot;ebal&quot;, &quot;estimatr&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;grf&quot;, &quot;hbal&quot;, &quot;highr&quot;, &quot;highs&quot;, &quot;kableExtra&quot;, &quot;MatchIt&quot;, &quot;Matching&quot;, &quot;mlr3&quot;, &quot;mlr3learners&quot;, &quot;OutcomeWeights&quot;, &quot;optmatch&quot;, &quot;optweight&quot;, &quot;quickmatch&quot;, &quot;readr&quot;, &quot;rgenoud&quot;, &quot;tidyr&quot;, &quot;tidyverse&quot;, &quot;patchwork&quot;, &quot;ppcor&quot;, &quot;WeightIt&quot; ) # install packages install_all &lt;- function(packages) { installed_pkgs &lt;- installed.packages()[, &quot;Package&quot;] for (pkg in packages) { if (!pkg %in% installed_pkgs) { install.packages(pkg) } } } install_all(packages) # load packages library(CBPS) library(cobalt) library(data.table) library(dplyr) library(DT) library(DoubleML) library(ebal) library(ggplot2) library(gridExtra) library(grf) library(hbal) library(highr) library(highs) library(kableExtra) library(MatchIt) library(Matching) library(mlr3) library(mlr3learners) library(optmatch) library(optweight) library(quickmatch) library(readr) library(rgenoud) library(tidyr) library(tidyverse) library(ppcor) library(patchwork) library(WeightIt) library(OutcomeWeights) 1.2 Wrapper functions Next, the wrapper functions designed to manage the data, address overlap and covariate balance, estimate treatment effects and analyze outcome weights are presented. To use the wrapper functions, the simplest method is to source the R script with the following code. source(&quot;tutorial/functions.R&quot;) If RStudio is used, the functions should now appear in the environment section. 1.2.1 Overview Function Description Code inspect_data() , save_overlap_panels Inspects samples and save overlap visualizations. More ps_trim(), common_range_trim(), crump_trim(), stuermer_trim (), walker_trim(), ps_estimate(), attach_matchit() Implements methods to improve overlap, address covariate imbalance and reestimate propensity scores. More compute_abs_smd_trim(), compute_ovl_trim(), compute_abs_smd_matchit(), compute_ovl_matchit(), combine_results(), save_csv(), assess_methods(), get_top_methods(), wrap_match_entries(), create_top5_samples(), save_top5_samples() Evaluates performance of previous methods through comparative metrics (ASMD, OVL). More estimate_all(), plot_coef(), save_att_panels(), create_matrix_results(), eval_att(), plot_catt_panels(), save_catt_panels(), save_main_catt_panels(), save_plus_catt_panels(), eval_catt(), est_qte_safe(), plot_qte_top(), save_qtet(), save_qte_top() Computes and visualizes treatment effect estimands (ATT, CATT, QTET) using a number of estimators. More get_res_att(), derive_ow(), plot_ow(), eval_ow(), save_ow() Analyses outcome weights of samples. More check_filter_samples(), save_sensitivity_plots() Validates and filters samples. More save_balance() Saves results of balance check in covariates. More 1.2.2 Inspection inspect_data() provides a structured summary of one or multiple samples by returning a single data frame listing each dataset’s name, number of observations (rows), number of treated units, number of control units, number of variables (columns) and a concatenated string of variable names. inspect_data &lt;- function(data, treat = &quot;treat&quot;) { if (is.data.frame(data)) { data &lt;- list(sample = data) } data.frame( sample = names(data), num_obs = sapply(data, nrow), num_treated = sapply(data, function(df) sum(df[[treat]] == 1, na.rm = TRUE)), num_controls = sapply(data, function(df) sum(df[[treat]] == 0, na.rm = TRUE)), num_vars = sapply(data, ncol), name_vars = sapply(data, function(df) paste(names(df), collapse = &quot;, &quot;)), row.names = NULL ) } Argument data: A data frame or a list of data frames containing structured data. treat: A character string indicating the name of the (binary) treatment indicator (default is “treat”). save_overlap_panels()*** saves the histograms that visualize overlap between the treatment groups. save_overlap_panels &lt;- function( data_list, treat, covar, plot_titles = NULL, prefix = &quot;overlap_panels&quot;, folder = &quot;graphs/lalonde&quot;, plots_per_page = 1 ) { if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) n &lt;- length(data_list) pages &lt;- ceiling(n / plots_per_page) for (p in seq_len(pages)) { start &lt;- (p - 1) * plots_per_page + 1 end &lt;- min(p * plots_per_page, n) file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, p, &quot;.pdf&quot;)) pdf(file_name, width = 8, height = 2.75 * (end - start + 1)) par(mfrow = c(end - start + 1, 1), mar = c(4, 5, 3, 2)) for (i in start:end) { assess_overlap(data = data_list[[i]], treat = treat, cov = covar) if (!is.null(plot_titles) &amp;&amp; length(plot_titles) &gt;= i) { title(main = plot_titles[i]) } else { title(main = paste(&quot;Panel&quot;, i)) } } dev.off() } } Argument data_list: A data frame or a list of data frames containing structured data. treat: A character string indicating the name of the (binary) treatment indicator (default is “treat”). covar: A vector of covariate names. plot_titles: A character vector of titles for each plot. prefix: A string prefix used for saved file names to identify sample. folder: A string specifying the folder path where the PDF panels will be saved (default is “graphs/lalonde”). plots_per_page: The number of plots to display per page / panel (default 1). 1.2.3 Improving covariate balance and overlap 1.2.3.1 Trimming ps_trim() trims the sample based on a specified propensity score threshold, removing observations whose propensity scores exceed the given cutoff value.*** ps_trim &lt;- function(data, ps = &quot;ps_assoverlap&quot;, threshold = 0.9) { sub &lt;- data[which(data[, ps] &lt; threshold), ] return(sub) } Arguments data: The data frame containing structured data. ps: The name of the propensity score variable as string. threshold: The upper limit for propensity score inclusion as numeric value (default is 0.9). common_range_trim() trims the sample to observations with propensity scores within the common support range for treated and control groups. It takes as lower cutpoint the lowest observed propensity score in the treated group, and as upper cutpoint the highest observed propensity score in the control group. common_range_trim &lt;- function(data, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;) { lower_cut &lt;- min(data[[ps]][data[[treat]] == 1], na.rm = TRUE) upper_cut &lt;- max(data[[ps]][data[[treat]] == 0], na.rm = TRUE) sub &lt;- data[data[[ps]] &gt;= lower_cut &amp; data[[ps]] &lt;= upper_cut, ] return(sub) } Arguments data: The data frame containing structured data. ps: The column name of propensity scores as string (default is “ps_assoverlap”). treat: The column name of the (binary) treatment indicator as string (default is “treat”). crump_trim() trims the sample to observations with propensity scores outside specified lower and upper bounds (default 0.1 and 0.9). Only those observations are kept that are within the specified interval (default 0.1 &lt;= PS &lt;= 0.9). crump_trim &lt;- function(data, ps = &quot;ps_assoverlap&quot;, lower = 0.1, upper = 0.9) { sub &lt;- data[data[[ps]] &gt;= lower &amp; data[[ps]] &lt;= upper, ] return(sub) } Arguments data: The data frame containing structured data. ps: The column name of propensity scores as string (default is “ps_assoverlap”). lower: The lower bound for inclusion as numeric value (default is 0.1). upper: The upper bound for inclusion as numeric value (default is 0.9). stuermer_trim () trims the sample to observations based on propensity score quantiles separately for treated and control group. stuermer_trim &lt;- function(data, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, lower_percentile = 0.01, upper_percentile = 0.99) { treated_ps &lt;- data[[ps]][data[[treat]] == 1] untreated_ps &lt;- data[[ps]][data[[treat]] == 0] lower_cutoff &lt;- quantile(treated_ps, probs = lower_percentile, na.rm = TRUE) upper_cutoff &lt;- quantile(untreated_ps, probs = upper_percentile, na.rm = TRUE) sub &lt;- data[data[[ps]] &gt;= lower_cutoff &amp; data[[ps]] &lt;= upper_cutoff, ] return(sub) } Arguments data: The data frame containing structured data. treat: The column name of the (binary) treatment indicator as string (default is “treat”). ps: The column name of propensity scores as string (default is “ps_assoverlap”). lower_percentile: Numeric value between 0 and 1 specifying the lower quantile cutoff for propensity scores in the treated group (default is 0.01, i.e., 1st percentile). upper_percentile: Numeric value between 0 and 1 specifying the upper quantile cutoff for propensity scores in the untreated group (default is 0.99, i.e., 99th percentile). walker_trim() trims the sample to observations based on preference scores that adjust for treatment prevalence using logit transformations. walker_trim &lt;- function(data, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, lower_cutoff = 0.1, upper_cutoff = 0.9) { treat_prevalence &lt;- mean(data[[treat]], na.rm = TRUE) logit_ps &lt;- log(data[[ps]] / (1 - data[[ps]])) logit_prevalence &lt;- log(treat_prevalence / (1 - treat_prevalence)) preference_score &lt;- 1 / (1 + exp(-(logit_ps - logit_prevalence))) sub &lt;- data[preference_score &gt;= lower_cutoff &amp; preference_score &lt;= upper_cutoff, ] return(sub) } Arguments data: The data frame containing structured data. treat: The column name of the (binary) treatment indicator as string (default is “treat”). ps: The column name of propensity scores as string (default is “ps_assoverlap”). lower_cutoff: Numeric value between 0 and 1 specifying the lower cutoff for the preference score (default is 0.1). upper_cutoff: Numeric value between 0 and 1 specifying the upper cutoff for the preference score (default is 0.9). ps_estimate() reestimates the propensity scores by fitting a probability forest model to predict the treatment assignment based on the specified covariates. ps_estimate &lt;- function(data, treat, cov, num.trees = NULL, seed = 42) { if(is.null(num.trees)){ p.forest1 &lt;- probability_forest( X = data[, cov], Y = as.factor(data[,treat]), seed = seed) } else { p.forest1 &lt;- probability_forest( X = data[, cov], Y = as.factor(data[,treat]), seed = seed, num.trees = num.trees) } data$ps_assoverlap &lt;- p.forest1$predictions[,2] data$ps_assoverlap[which(abs(data$ps_assoverlap) &lt;= 1e-7)] &lt;- 1e-7 return(data) } Arguments data: The data frame containing structured data. treat: The column name of the (binary) treatment indicator as string. cov: A vector of covariate names. num.trees: Integer specifying the number of trees to grow in the random forest model for propensity score estimation. seed: Integer to ensure reproducibility (default is 42). 1.2.3.2 Integrated methods attach_matchit() attach_matchit &lt;- function(model, data_list, ..., verbose = FALSE) { if (!is.list(data_list) || length(data_list) == 0) { stop(&quot;attach_matchit(): &#39;data_list&#39; must be a non-empty list&quot;, call. = FALSE) } matchit_results &lt;- vector(&quot;list&quot;, length(data_list)) names(matchit_results) &lt;- names(data_list) dims_report &lt;- character(length(data_list)) for (i in seq_along(data_list)) { data_i &lt;- data_list[[i]] label_i &lt;- if (length(names(matchit_results))) names(matchit_results)[i] else i res &lt;- tryCatch( { obj &lt;- matchit(model, data = data_i, ...) attr(obj, &quot;match_source&quot;) &lt;- data_i obj }, error = function(e) { warning(sprintf(&quot;attach_matchit(): &#39;%s&#39; failed: %s&quot;, label_i, e$message), call. = FALSE) NULL } ) matchit_results[[i]] &lt;- res source_rows &lt;- tryCatch(nrow(data_i), error = function(e) NA_integer_) matched_rows &lt;- if (inherits(res, &quot;matchit&quot;)) { tryCatch(nrow(match.data(res, data = data_i)), error = function(e) NA_integer_) } else { NA_integer_ } dims_report[[i]] &lt;- sprintf(&quot;%s: source=%s matched=%s&quot;, label_i, source_rows, matched_rows) } if (isTRUE(verbose)) { message(&quot;attach_matchit(): &quot;, paste(dims_report, collapse = &quot;; &quot;)) } attr(matchit_results, &quot;match_dims&quot;) &lt;- dims_report # report summary null_count &lt;- sum(sapply(matchit_results, is.null)) success_count &lt;- length(matchit_results) - null_count if (null_count &gt; 0) { failed_names &lt;- names(matchit_results)[sapply(matchit_results, is.null)] cat(sprintf(&quot;MATCHING SUMMARY: %d succeeded, %d failed. Failed: %s\\n&quot;, success_count, null_count, paste(failed_names, collapse = &quot;, &quot;))) } return(matchit_results) } Arguments model: A model formula specifying the treatment and covariates to be used for calculating weights. data_list: A list of data frames containing the subsetted sample after trimming procedures. 1.2.4 Assessing methods 1.2.4.1 Trimming compute_abs_smd_trim() computes absolute SMDs for multiple samples. compute_abs_smd_trim &lt;- function(data_list, treat = &quot;treat&quot;, covar) { smd_list &lt;- lapply(names(data_list), function(name) { data &lt;- data_list[[name]] bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, un = TRUE, stats = &quot;mean.diffs&quot;, s.d.denom = &quot;treated&quot; ) smds &lt;- bal_obj$Balance$Diff.Un smd_vals &lt;- abs(smds) mean_smd &lt;- mean(smd_vals, na.rm = TRUE) max_smd &lt;- max(smd_vals, na.rm = TRUE) return(data.frame( Method = name, Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd )) }) smd_summary &lt;- do.call(rbind, smd_list) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments data_list: A list of data frames. treat: The name of the binary treatment indicator variable as string (default is “treat”). covar: A vector of covariate names. compute_ovl_trim() compute the overlapping coefficient (OVL) for multiple samples. compute_ovl_trim &lt;- function(data_list, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, n_points = 512) { ovl_res &lt;- lapply(names(data_list), function(meth) { dat &lt;- data_list[[meth]] ps &lt;- as.numeric(dat[[ps]]) treat &lt;- dat[[treat]] valid_idx &lt;- !is.na(ps) &amp; !is.na(treat) &amp; (ps &gt;= 0 &amp; ps &lt;= 1) ps &lt;- ps[valid_idx] treat &lt;- treat[valid_idx] treated_scores &lt;- ps[treat == 1] control_scores &lt;- ps[treat == 0] dens_treated &lt;- density(treated_scores, from = 0, to = 1, n = n_points) dens_control &lt;- density(control_scores, from = 0, to = 1, n = n_points) x_grid &lt;- dens_treated$x min_density &lt;- pmin(dens_treated$y, dens_control$y) bin_width &lt;- x_grid[2] - x_grid[1] ovl &lt;- sum(min_density) * bin_width data.frame(Method = meth, OVL = ovl) }) res &lt;- do.call(rbind, ovl_res) rownames(res) &lt;- NULL return(res) } Arguments data_list: A list of data frames, each a trimmed sample. ps: A vector containing propensity scores (default is “ps_assoverlap”). treat: The name of the binary treatment indicator variable as string (default is “treat”). n_points: The number of grid points to use for the kernel density estimation (default is 512). 1.2.4.2 Integrated methods compute_abs_smd_matchit() computes the mean absolute standardized difference (ASMD) for matchit objects. compute_abs_smd_matchit &lt;- function(match_list, data_list) { if (!is.list(match_list) || length(match_list) == 0) { stop(&quot;compute_abs_smd_matchit(): &#39;match_list&#39; must be a non-empty list&quot;, call. = FALSE) } if (!is.list(data_list) || length(data_list) == 0) { stop(&quot;compute_abs_smd_matchit(): &#39;data_list&#39; must be a non-empty list&quot;, call. = FALSE) } data_len &lt;- length(data_list) data_labels &lt;- if (length(names(data_list))) names(data_list) else seq_len(data_len) smd_results &lt;- list() for (method_name in names(match_list)) { method_sublist &lt;- match_list[[method_name]] if (!is.list(method_sublist)) { warning(sprintf(&quot;compute_abs_smd_matchit(): &#39;%s&#39; is not a list of matchit objects; skipping&quot;, method_name), call. = FALSE) next } method_len &lt;- length(method_sublist) if (method_len != data_len) { warning(sprintf( &quot;compute_abs_smd_matchit(): &#39;%s&#39; match list length (%d) differs from data_list length (%d); only the first %d elements are considered.&quot;, method_name, method_len, data_len, min(method_len, data_len) ), call. = FALSE) } max_idx &lt;- min(method_len, data_len) for (i in seq_len(max_idx)) { match_obj &lt;- method_sublist[[i]] data_i &lt;- data_list[[i]] label_i &lt;- if (i &lt;= length(data_labels)) data_labels[[i]] else i if (is.null(match_obj)) { warning(sprintf( &quot;compute_abs_smd_matchit(): skipping &#39;%s&#39; match object %d (%s) because it is NULL; check attach_matchit() failures.&quot;, method_name, i, label_i ), call. = FALSE) next } if (is.null(data_i)) { warning(sprintf( &quot;compute_abs_smd_matchit(): skipping &#39;%s&#39; source data %d (%s) because it is NULL; verify trimming outputs.&quot;, method_name, i, label_i ), call. = FALSE) next } bal &lt;- bal.tab( match_obj, data = data_i, stats = &quot;mean.diffs&quot;, un = TRUE, s.d.denom = &quot;treated&quot; ) smds &lt;- bal$Balance$Diff.Adj smd_vals &lt;- abs(smds) mean_smd &lt;- mean(smd_vals, na.rm = TRUE) max_smd &lt;- max(smd_vals, na.rm = TRUE) smd_results[[paste(method_name, label_i, sep = &quot;_&quot;)]] &lt;- data.frame( Method = method_name, MatchIndex = label_i, Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd ) } } if (length(smd_results) == 0) { return(data.frame( Method = character(0), MatchIndex = integer(0), Mean_Abs_SMD = numeric(0), Max_Abs_SMD = numeric(0) )) } smd_summary &lt;- do.call(rbind, smd_results) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments match_list: A named list of method-specific elements, where each itself is a list of matchit objects. data_list: A list of data frames, each a trimmed sample. compute_ovl_matchit() computes the OVL for matchit objects. compute_ovl_matchit &lt;- function(match_list, data_list, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = NULL, num.trees = NULL, seed = 42, n_points = 512) { if (!is.list(match_list) || length(match_list) == 0) { stop(&quot;compute_ovl_matchit(): &#39;match_list&#39; must be a non-empty list&quot;, call. = FALSE) } if (!is.list(data_list) || length(data_list) == 0) { stop(&quot;compute_ovl_matchit(): &#39;data_list&#39; must be a non-empty list&quot;, call. = FALSE) } data_len &lt;- length(data_list) data_labels &lt;- if (length(names(data_list))) names(data_list) else seq_len(data_len) ovl_results &lt;- list() for (method_name in names(match_list)) { method_sublist &lt;- match_list[[method_name]] if (!is.list(method_sublist)) { warning(sprintf(&quot;compute_ovl_matchit(): &#39;%s&#39; is not a list of matchit objects; skipping&quot;, method_name), call. = FALSE) next } method_len &lt;- length(method_sublist) if (method_len != data_len) { warning(sprintf( &quot;compute_ovl_matchit(): &#39;%s&#39; match list length (%d) differs from data_list length (%d); only the first %d elements are considered.&quot;, method_name, method_len, data_len, min(method_len, data_len) ), call. = FALSE) } max_idx &lt;- min(method_len, data_len) for (i in seq_len(max_idx)) { match_obj &lt;- method_sublist[[i]] data_i &lt;- data_list[[i]] label_i &lt;- if (i &lt;= length(data_labels)) data_labels[[i]] else i if (is.null(match_obj)) { warning(sprintf( &quot;compute_ovl_matchit(): skipping &#39;%s&#39; match object %d (%s) because it is NULL; check attach_matchit() failures.&quot;, method_name, i, label_i ), call. = FALSE) next } if (!inherits(match_obj, &quot;matchit&quot;)) { warning(sprintf( &quot;compute_ovl_matchit(): skipping &#39;%s&#39; match object %d (%s) because it is class &#39;%s&#39; not &#39;matchit&#39;&quot;, method_name, i, label_i, paste(class(match_obj), collapse = &quot;/&quot;) ), call. = FALSE) next } if (is.null(data_i)) { data_i &lt;- attr(match_obj, &quot;match_source&quot;) if (is.null(data_i)) { warning(sprintf( &quot;compute_ovl_matchit(): source data missing for method &#39;%s&#39; index %d (%s); cannot recover matched data.&quot;, method_name, i, label_i ), call. = FALSE) next } } if (!is.data.frame(data_i)) { warning(sprintf( &quot;compute_ovl_matchit(): data_list[[%d]] for method &#39;%s&#39; is type &#39;%s&#39; not data.frame&quot;, i, method_name, paste(class(data_i), collapse = &quot;/&quot;) ), call. = FALSE) next } if (!nrow(data_i)) { warning(sprintf( &quot;compute_ovl_matchit(): data_list[[%d]] for method &#39;%s&#39; has zero rows&quot;, i, method_name ), call. = FALSE) next } matched_data &lt;- match.data(match_obj, data = data_i) if (!is.data.frame(matched_data) || !nrow(matched_data)) { warning(sprintf( &quot;compute_ovl_matchit(): matched data empty for method &#39;%s&#39; index %d (%s)&quot;, method_name, i, label_i ), call. = FALSE) next } if (ps %in% names(matched_data)) { ps_vals &lt;- as.numeric(matched_data[[ps]]) } else { if (is.null(covar)) { stop(sprintf( &quot;compute_ovl_matchit(): propensity scores missing for &#39;%s&#39; index %d (%s) and &#39;covar&#39; not provided&quot;, method_name, i, label_i ), call. = FALSE) } X &lt;- matched_data[, covar, drop = FALSE] Y &lt;- as.factor(matched_data[[treat]]) if (is.null(num.trees)) { p.forest1 &lt;- probability_forest(X = X, Y = Y, seed = seed) } else { p.forest1 &lt;- probability_forest(X = X, Y = Y, seed = seed, num.trees = num.trees) } ps_vals &lt;- p.forest1$predictions[, 2] ps_vals[which(abs(ps_vals) &lt;= 1e-7)] &lt;- 1e-7 } treat_vals &lt;- matched_data[[treat]] valid_idx &lt;- !is.na(ps_vals) &amp; !is.na(treat_vals) &amp; (ps_vals &gt;= 0 &amp; ps_vals &lt;= 1) ps_vals &lt;- ps_vals[valid_idx] treat_vals &lt;- treat_vals[valid_idx] if (!length(ps_vals) || length(unique(treat_vals)) &lt; 2) { warning(sprintf( &quot;compute_ovl_matchit(): insufficient treated/control overlap after cleaning for method &#39;%s&#39; index %d (%s)&quot;, method_name, i, label_i ), call. = FALSE) next } treated_scores &lt;- ps_vals[treat_vals == 1] control_scores &lt;- ps_vals[treat_vals == 0] if (length(treated_scores) &lt; 2 || length(control_scores) &lt; 2) { warning(sprintf( &quot;compute_ovl_matchit(): Not enough treated/control units for density estimation in method &#39;%s&#39; index %d (%s)&quot;, method_name, i, label_i ), call. = FALSE) next } dens_treated &lt;- density(treated_scores, from = 0, to = 1, n = n_points) dens_control &lt;- density(control_scores, from = 0, to = 1, n = n_points) x_grid &lt;- dens_treated$x min_density &lt;- pmin(dens_treated$y, dens_control$y) bin_width &lt;- x_grid[2] - x_grid[1] ovl &lt;- sum(min_density) * bin_width ovl_results[[paste(method_name, label_i, sep = &quot;_&quot;)]] &lt;- data.frame( Method = paste(method_name, label_i, sep = &quot;_&quot;), OVL = ovl ) } } if (length(ovl_results) == 0) { return(data.frame(Method = character(0), OVL = numeric(0))) } final_df &lt;- do.call(rbind, ovl_results) rownames(final_df) &lt;- NULL return(final_df) } Arguments match_list: A named list of method-specific elements, where each itself is a list of matchit objects. data_list: A list of data frames, each a trimmed sample. ps: A vector containing propensity scores (default is “ps_assoverlap”). treat: The name of the binary treatment indicator variable as string (default is “treat”). covar: A vector of covariate names. num.trees: Integer specifying the number of trees to grow in the random forest model for propensity score estimation. seed: Integer to ensure reproducibility (default is 42). n_points: The number of grid points to use for the kernel density estimation. 1.2.5 Identifying best methods combine_results() merges and summarizes mean ASMD and OVL statistics from various analysis stages of non-plus-samples into a final comparison table. combine_results &lt;- function(data) { data_lower &lt;- tolower(data) # retrieve individual method results smd_trimming &lt;- get(paste0(&quot;smd_trim.&quot;, data_lower)) ovl_trimming &lt;- get(paste0(&quot;ovl_trim.&quot;, data_lower)) smd_trim_match_combined &lt;- get(paste0(&quot;smd_trim_match_comb.&quot;, data_lower)) ovl_trim_match_combined &lt;- get(paste0(&quot;ovl_trim_match_comb.&quot;, data_lower)) format_smd_results &lt;- function(df) { if (is.null(df) || !nrow(df)) { return(data.frame(Method = character(0), Mean_Abs_SMD = numeric(0), Max_Abs_SMD = numeric(0))) } out &lt;- df if (&quot;MatchIndex&quot; %in% names(out)) { out$Method &lt;- paste(out$Method, out$MatchIndex, sep = &quot;_&quot;) out$MatchIndex &lt;- NULL } out[, c(&quot;Method&quot;, &quot;Mean_Abs_SMD&quot;, &quot;Max_Abs_SMD&quot;), drop = FALSE] } format_ovl_results &lt;- function(df) { if (is.null(df) || !nrow(df)) { return(data.frame(Method = character(0), OVL = numeric(0))) } df[, c(&quot;Method&quot;, &quot;OVL&quot;), drop = FALSE] } smd_all &lt;- dplyr::bind_rows( format_smd_results(smd_trimming), format_smd_results(smd_trim_match_combined) ) ovl_all &lt;- dplyr::bind_rows( format_ovl_results(ovl_trimming), format_ovl_results(ovl_trim_match_combined) ) # merge absolute SMD and OVL results by method final_df &lt;- dplyr::full_join(smd_all, ovl_all, by = &quot;Method&quot;) if (!nrow(final_df)) { return(final_df) } final_df$Method &lt;- as.character(final_df$Method) # remove sample suffixes for clean labels final_df$Method &lt;- gsub(&quot;\\\\.psid&quot;, &quot;&quot;, final_df$Method, ignore.case = TRUE) final_df$Method &lt;- gsub(&quot;\\\\.cps&quot;, &quot;&quot;, final_df$Method, ignore.case = TRUE) # reset row names rownames(final_df) &lt;- NULL return(final_df) } Arguments data: The sample name for which to combine ASMD and OVL summaries. save_csv() saves the tables into a CSV file. save_csv &lt;- function(data, filename) { folder &lt;- &quot;tables&quot; if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) file_csv &lt;- file.path(folder, paste0(filename, &quot;.csv&quot;)) write.csv(data, file = file_csv, row.names = FALSE) } Arguments data: The data frame. filename: The name of the file that is to be saved as CSV. assess_methods() ranks methods based on the OVL. assess_methods &lt;- function(data) { data %&gt;% dplyr::select(Method, OVL, Mean_Abs_SMD) %&gt;% arrange(desc(OVL)) } Argument data: A data frame containing method performance metrics. get_top_methods() retrieves the top-performing methods based on the OVL. get_top_methods &lt;- function(data, top_n = 5, score_col = NULL) { if (!&quot;Method&quot; %in% names(data)) { stop(&quot;Data frame must contain column &#39;Method&#39;&quot;) } if (is.null(score_col)) { if (&quot;Score&quot; %in% names(data)) { score_col &lt;- &quot;Score&quot; } else if (&quot;OVL&quot; %in% names(data)) { score_col &lt;- &quot;OVL&quot; } else { stop(&quot;Data frame must contain a scoring column (&#39;Score&#39; or &#39;OVL&#39;), or specify &#39;score_col&#39;&quot;) } } if (!score_col %in% names(data)) { stop(sprintf(&quot;Column &#39;%s&#39; not found in data&quot;, score_col)) } data %&gt;% dplyr::filter(!is.na(.data[[score_col]])) %&gt;% arrange(dplyr::desc(.data[[score_col]])) %&gt;% head(top_n) %&gt;% dplyr::pull(Method) } Arguments data: A data frame including columns used for ranking. top_n: Integer specifying the number of top-performing methods to return (default 5). score_col: The name of the column to use for ranking methods. wrap_match_entries() wrap_match_entries &lt;- function(match_list, source_list, prefix) { if (!is.list(match_list)) { return(list()) } max_idx &lt;- min(length(match_list), length(source_list)) source_labels &lt;- if (length(names(source_list))) names(source_list) else seq_len(max_idx) entries &lt;- vector(&quot;list&quot;, max_idx) names(entries) &lt;- paste0(prefix, &quot;_&quot;, source_labels[seq_len(max_idx)]) for (i in seq_len(max_idx)) { match_obj &lt;- match_list[[i]] if (is.null(match_obj)) { next } entries[[i]] &lt;- list(matchit = match_obj, data = source_list[[i]]) } Filter(Negate(is.null), entries) } Arguments match_list: A named list of method-specific elements, where each itself is a list of matchit objects. source_list: A list of source data frames corresponding to each match object. prefix: A string prefix for defining the names of the returned list entries. create_top5_samples() creates samples corresponding to the top five ranked methods for further analysis or presentation. create_top5_samples &lt;- function(data_list, top_method_names) { if (!is.list(data_list) || length(data_list) == 0) { stop(&quot;create_top5_samples(): &#39;data_list&#39; must be a non-empty list&quot;, call. = FALSE) } if (length(top_method_names) == 0) { stop(&quot;create_top5_samples(): &#39;top_method_names&#39; must contain at least one method name&quot;, call. = FALSE) } missing_methods &lt;- setdiff(top_method_names, names(data_list)) if (length(missing_methods)) { stop(sprintf( &quot;create_top5_samples(): the following methods are missing from &#39;data_list&#39;: %s&quot;, paste(missing_methods, collapse = &quot;, &quot;) ), call. = FALSE) } out &lt;- lapply(top_method_names, function(method_name) { ds &lt;- data_list[[method_name]] if (is.null(ds)) { stop(sprintf(&quot;create_top5_samples(): sample for method &#39;%s&#39; is NULL&quot;, method_name), call. = FALSE) } if (inherits(ds, &quot;matchit&quot;)) { source_data &lt;- attr(ds, &quot;match_source&quot;) if (is.null(source_data)) { stop(sprintf( &quot;create_top5_samples(): matchit object &#39;%s&#39; is missing source data. Regenerate it with attach_matchit() so &#39;match_source&#39; attribute is available or provide a data.frame entry instead.&quot;, method_name ), call. = FALSE) } return(as.data.frame(match.data(ds, data = source_data))) } if (is.list(ds) &amp;&amp; inherits(ds$matchit, &quot;matchit&quot;) &amp;&amp; is.data.frame(ds$data)) { return(as.data.frame(match.data(ds$matchit, data = ds$data))) } if (is.data.frame(ds)) { return(ds) } stop(sprintf(&quot;create_top5_samples(): unsupported entry type for method &#39;%s&#39;&quot;, method_name), call. = FALSE) }) names(out) &lt;- top_method_names out } Arguments data_list: A list of samples or MatchIt objects containing processed results for different methods. top_method_names: A character vector of method names corresponding to the top-ranked samples. save_top5_samples() saves samples of the top five methods as individual files for reproducibility or sharing. save_top5_samples &lt;- function(combined_methods_list, top_method_names, prefix) { dir.create(&quot;tutorial/data&quot;, showWarnings = FALSE, recursive = TRUE) for (i in seq_along(top_method_names)) { method_name &lt;- top_method_names[i] if (!method_name %in% names(combined_methods_list)) { warning(paste0(&quot;Method &#39;&quot;, method_name, &quot;&#39; not found in combined methods list&quot;)) next } sample_to_save &lt;- combined_methods_list[[method_name]] file_name &lt;- sprintf(&quot;tutorial/data/top%d_%s_method_%s.RData&quot;, i, prefix, method_name) save(sample_to_save, file = file_name) } } Arguments combined_methods_list: A list of all combined method results. top_method_names: A character vector of method names corresponding to the top-ranked samples. prefix: A string prefix used for saved file names to identify sample. 1.2.6 Estimating 1.2.6.1 Average treatment effect of the treated (ATT) estimate_all()*** runs multiple treatment effect estimators on a sample and returns point estimates, standard errors and confidence intervals. #### quiet()*** quiet &lt;- function(x) { sink(tempfile()) on.exit(sink()) invisible(force(x)) } #### diff()*** diff &lt;- function(data, Y, treat) { fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) out &lt;- summary(lm_robust(fml, data = data, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] return(out) # extract coef, se, ci.lower, ci.upper } #### reg()*** reg &lt;- function(data, Y, treat, covar) { fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat, &quot;+&quot;, paste(covar, collapse = &quot; + &quot;))) out &lt;- summary(lm_robust(fml, data = data, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] # extract coef, se, ci.lower, ci.upper return(out) } # library(Matching) #### matching()*** matching &lt;- function(data, Y, treat, covar) { tryCatch({ m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = data[, covar], Z = data[, covar], estimand = &quot;ATT&quot;, M = 5, replace = TRUE, ties = TRUE, BiasAdjust = TRUE) out &lt;- c(m.out$est[1], m.out$se[1], m.out$est[1] - 1.96 * m.out$se[1], m.out$est[1] + 1.96 * m.out$se[1]) return(out) }, error = function(e) { cat(&quot;Warning in matching method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } #### psm()*** psm &lt;- function(data, Y, treat, covar) { ps &lt;- probability_forest(X = data[, covar], Y = as.factor(data[,treat]), seed = 42, num.trees = 4000)$predictions[,2] m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = matrix(ps, nrow(data), 1), estimand = &quot;ATT&quot;, M = 5, replace = TRUE, ties = FALSE, BiasAdjust = FALSE) if (is.null(m.out$se)==FALSE) { se &lt;- m.out$se[1] } else { se &lt;- m.out$se.standard[1] } out &lt;- c(m.out$est[1], se, m.out$est[1] - 1.96 * se, m.out$est[1] + 1.96 * se) return(out) } #### om.reg()*** om.reg &lt;- function(data, Y, treat, covar) { tr &lt;- which(data[, treat] == 1) co &lt;- which(data[, treat] == 0) fml &lt;- as.formula(paste(Y, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) out.co &lt;- lm(fml, data = data[co, ]) Y.tr.hat &lt;- predict(out.co, newdata = data[tr, covar, drop = FALSE]) newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr))) out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = &quot;stata&quot;))$coefficients[&quot;treat&quot;, c(1, 2, 5, 6)] return(out) } # library(grf) #### om.grf()*** om.grf &lt;- function(data, Y, treat, covar) { tr &lt;- which(data[, treat] == 1) co &lt;- which(data[, treat] == 0) out.co &lt;- regression_forest(X = data[co, covar, drop = FALSE], Y = as.vector(data[co, Y]) ) Y.tr.hat &lt;- as.vector(unlist(predict(out.co, newdata = data[tr, covar, drop = FALSE]))) newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr))) out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = &quot;stata&quot;))$coefficients[&quot;treat&quot;, c(1, 2, 5, 6)] return(out) } #### ipw()*** ipw &lt;- function(data, Y, treat, covar) { ps &lt;- probability_forest(X = data[, covar, drop = FALSE], Y = as.factor(data[, treat]), seed = 42)$predictions[,2] fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) weights &lt;- rep(1, nrow(data)) co &lt;- which(data[, treat] == 0) weights[co] &lt;- ps[co]/(1-ps[co]) out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] # extract coef, se, ci.lower, ci.upper return(out) } # library(&quot;CBPS&quot;) #### cbps()*** cbps &lt;- function(data, Y, treat, covar) { tryCatch({ fml &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) ps &lt;- quiet(CBPS(fml, data = data, standardize = TRUE)$fitted.values) fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) weights &lt;- rep(1, nrow(data)) co &lt;- which(data[, treat] == 0) weights[co] &lt;- ps[co]/(1-ps[co]) out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] return(out) }, error = function(e) { cat(&quot;Warning in cbps method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } # library(hbal) #### ebal()*** ebal &lt;- function(data, Y, treat, covar) { tryCatch({ ebal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar, data = data, expand.degree = 1) out &lt;- hbal::att(ebal.out, dr = FALSE)[1, c(1, 2, 5, 6)] return(out) }, error = function(e) { cat(&quot;Warning in ebal method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } #### hbal()*** # hbal &lt;- function(data, Y, treat, covar) { # hbal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar, data = data, expand.degree = 2, # cv = TRUE) # out &lt;- hbal::att(hbal.out, dr = FALSE)[1, c(1, 2, 5, 6)] # return(out) # } #### aipw_grf()*** aipw &lt;- function(data, Y, treat, covar) { tryCatch({ #library(&quot;grf&quot;) for (var in c(Y, treat, covar)) { data[, var] &lt;- as.vector(data[, var]) } c.forest &lt;- causal_forest(X = data[, covar, drop = FALSE], Y = data[, Y], W = data[, treat], seed = 42) att &lt;- average_treatment_effect(c.forest, target.sample = &quot;treated&quot;, method = &quot;AIPW&quot;) att &lt;- c(att, att[1] - 1.96 * att[2], att[1] + 1.96 * att[2]) return(att) }, error = function(e) { cat(&quot;Error in aipw_grf method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } #### aipw.match()*** aipw.match &lt;- function(data, Y, treat, covar) { # match on ps ps &lt;- probability_forest(X = data[, covar], Y = as.factor(data[, treat]), seed = 42)$predictions[,2] m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = ps, estimand = &quot;ATT&quot;, M = 1, replace = FALSE, ties = FALSE, BiasAdjust = FALSE) mb &lt;- quiet(MatchBalance(treat ~ ps, data = data, match.out = m.out, nboots= 0)) ks &lt;- mb$AfterMatching[[1]]$ks$ks$statistic s &lt;- data[c(m.out$index.treated, m.out$index.control), ] out &lt;- aipw(s, Y, treat, covar) # return(out) return(c(out, ks)) } #### aipw_ow() aipw_ow &lt;- function(data, Y, treat, covar) { tryCatch({ for (var in c(Y, treat, covar)) { data[, var] &lt;- as.vector(data[, var]) } X &lt;- data[, covar, drop = FALSE] Y &lt;- data[, Y] W &lt;- data[, treat] # run dml_with_smoother with AIPW_ATT dml_fit &lt;- dml_with_smoother( Y = Y, D = W, X = X, estimators = c(&quot;AIPW_ATT&quot;), smoother = &quot;honest_forest&quot;, n_cf_folds = 5, n_reps = 1) # extract estimate and SE from summary summ &lt;- summary(dml_fit, quiet = TRUE) est &lt;- summ[&quot;AIPW-ATT&quot;, &quot;Estimate&quot;] se &lt;- summ[&quot;AIPW-ATT&quot;, &quot;SE&quot;] ci_lower &lt;- est - 1.96 * se ci_upper &lt;- est + 1.96 * se return(c(est, se, ci_lower, ci_upper)) }, error = function(e) { cat(&quot;Error in aipw_ow method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } ### this script checks for robustness by estimating original model ### using double/debiased machine learning using DoubleML package #### dml()*** dml &lt;-function(data, Y = NULL, treat = NULL, covar = NULL, clust_var = NULL, ml_l = lrn(&quot;regr.cv_glmnet&quot;), ml_m = lrn(&quot;regr.cv_glmnet&quot;)){ tryCatch({ if(is.null(covar)){ stop(&quot;No controls in specification.&quot;) } #require(DoubleML) #require(mlr3learners) #require(fixest) #require(ggplot2) if(is.null(clust_var) == TRUE){ dat = data[,c(Y,treat,covar)] dat = na.omit(dat) dml_dat = DoubleMLData$new( dat, y_col = Y, d_cols = treat, use_other_treat_as_covariate = FALSE, x_cols = covar) }else{ dat = data[,c(Y, treat, covar, clust_var)] dat[,clust_var] = as.numeric(factor(dat[,clust_var])) dat = dat[is.na(dat[,Y]) == FALSE,] dat = dat[is.na(dat[,D]) == FALSE,] features = data.frame(model.matrix(formula(paste(c(&#39;~ 1&#39;,treat,covar), collapse=&quot;+&quot;)), dat)) dat = cbind(dat[,c(Y,clust_var)],features) dml_dat = DoubleMLClusterData$new( dat, y_col = Y, d_cols = treat, cluster_cols = clust_var, use_other_treat_as_covariate = FALSE, x_cols = covar) } # set active treatment treatment dml_dat$set_data_model(treat) # estimate with DML set.seed(pi) dml_mod = DoubleMLPLR$new(dml_dat, ml_l=ml_l, ml_m=ml_m) quiet(dml_mod$fit()) out = c(dml_mod$coef[treat], dml_mod$se[treat], dml_mod$confint()[treat,]) return(out) }, error = function(e) { cat(&quot;Error in dml method:&quot;, e$message, &quot;\\n&quot;) return(c(NA, NA, NA, NA)) }) } #### estimate_all*** estimate_all &lt;- function(data, Y, treat, covar, methods = c(&quot;diff&quot;, &quot;reg&quot;, &quot;om.reg&quot;, &quot;om.grf&quot;, &quot;matching&quot;, &quot;psm&quot;, &quot;ipw&quot;, &quot;cbps&quot;, &quot;ebal&quot;, &quot;dml&quot;, &quot;aipw_grf&quot;, &quot;aipw_ow&quot;)) { results &lt;- as.data.frame(matrix(NA, length(methods), 4)) rownames(results) &lt;- methods colnames(results) &lt;- c(&quot;Estimate&quot;, &quot;SE&quot;, &quot;CI_lower&quot;, &quot;CI_upper&quot;) m &lt;- 1 if (&quot;diff&quot; %in% methods) { results[m, ] &lt;- diff(data, Y, treat) m &lt;- m + 1 } if (&quot;reg&quot; %in% methods) { results[m, ] &lt;- reg(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;om.reg&quot; %in% methods) { results[m, ] &lt;- om.reg(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;om.grf&quot; %in% methods) { results[m, ] &lt;- om.grf(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;matching&quot; %in% methods) { results[m, ] &lt;- matching(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;psm&quot; %in% methods) { results[m, ] &lt;- psm(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;ipw&quot; %in% methods) { results[m, ] &lt;- ipw(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;cbps&quot; %in% methods) { results[m, ] &lt;- cbps(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;ebal&quot; %in% methods) { results[m, ] &lt;- quiet(ebal(data, Y, treat, covar)) m &lt;- m + 1 } # if (&quot;hbal&quot; %in% methods) { # results[m, ] &lt;- quiet(hbal(data, Y, treat, covar)) # m &lt;- m + 1 # } if (&quot;dml&quot; %in% methods) { results[m, ] &lt;-dml(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;aipw_grf&quot; %in% methods) { results[m, ] &lt;- aipw(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;aipw_ow&quot; %in% methods) { results[m, ] &lt;- aipw_ow(data, Y, treat, covar) m &lt;- m + 1 } return(results) } Function calls quiet: Suppresses output from a function call. diff: Difference in means estimator. It runs a linear regression adjusting for robust standard errors and returns the coefficient, standard error, and confidence interval for the treatment variable. reg: Regression adjustment. Similar to diff but includes additional covariates in the regression model. matching: Propensity score matching using the Matching package. It aligns treated units to control units based on covariates and returns the estimated ATT and its confidence interval. psm: Propensity score matching using a probability forest, followed by matching and estimation of the ATT. om.reg: Outcome modeling using regression. It predicts the outcome for the treated units based on the model fitted to the control units, and then estimates the ATT. om.grf: Outcome modeling using generalized random forests, noted as GRF. ipw: Inverse probability weighting,denoted as IPW. It weights observations by the inverse of their estimated propensity scores and calculates the treatment effect with a weighted regression. cbps: Covariate balancing propensity score, noted as CBPS. It estimates propensity scores to achieve balance on covariates across groups. ebal: Entropy balancing. It reweights the data to balance the covariate distributions. hbal: Hierarchical balancing. It is an extension of ebal with more complex balancing methods. aipw: Augmented inverse probability weighting, noted as AIPW. aipw.match: Combines matching on propensity scores with AIPW. aipw_ow: AIPW computed via outcome weights. dml: Double machine learning. It uses machine learning algorithms to control for confounders when estimating treatment effects. plot_coef()*** plots treatment effect point estimates and corresponding confidence intervals comparatively across various estimators. plot_coef &lt;- function(out, methods = c(&quot;diff&quot;, &quot;reg&quot;, &quot;om.reg&quot;, &quot;om.grf&quot;, &quot;matching&quot;, &quot;psm&quot;, &quot;ipw&quot;, &quot;cbps&quot;, &quot;ebal&quot;, &quot;dml&quot;, &quot;aipw_grf&quot;, &quot;aipw_ow&quot;), labels = c(&quot;Diff-in-Means&quot;, &quot;Reg&quot;, &quot;OM: Reg&quot;, &quot;OM: GRF&quot;, &quot;NN\\nMatching&quot;, &quot;PS\\nMatching&quot;, &quot;IPW&quot;, &quot;CBPS&quot;, &quot;Ebal&quot;, &quot;DML\\nElasnet&quot;, &quot;AIPW-GRF&quot;, &quot;AIPW-OW&quot;), main = NULL, ylab = &quot;Estimate&quot;, band = NULL, line = NULL, grid = TRUE, main.pos = 1, main.line = -2, ylim = NULL, textsize = 0.8 ) { if (is.null(methods) == TRUE) { methods &lt;- rownames(out) } if (is.null(labels) == TRUE) { labels &lt;- methods } # # check # if (is.null(out)==FALSE) { # if (inherits(out, &quot;ivDiag&quot;) == FALSE) {stop(&quot;\\&quot;out\\&quot; needs to be a \\&quot;ltz\\&quot; object.&quot;)} # } # # # title # if (is.null(main)==TRUE) { # main &lt;- &quot;Estimates with 95% CIs&quot; # } # data for the plot data &lt;- out rg &lt;- range(data[,c(3,4)], na.rm = TRUE) adj &lt;- rg[2] - rg[1] if (is.null(ylim) == TRUE) { ylim &lt;- c(min(0, rg[1] - 0.3*adj), max(0, rg[2] + 0.35*adj)) } adj2 &lt;- ylim[2] - ylim[1] # Set up the plot ncoefs &lt;- length(methods) par(mar = c(2.5, 4, 1, 2)) plot(1: ncoefs, data[, 1], xlim = c(0.5, ncoefs + 0.5), ylim = ylim, ylab = &quot;&quot;, xlab = &quot;&quot;, main = &quot;&quot;, axes = FALSE, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, type = &quot;n&quot;) axis(1, at = 1: ncoefs, labels = labels, las = 1, cex.axis = 0.8) axis(2, cex.axis = 0.7) mtext(main, main.pos, line = main.line, cex = textsize) mtext(ylab, 2, line = 2.5) if (is.null(band) == FALSE) { rect(-0.5, band[1], ncoefs + 1, band[2], col = &quot;#ff000030&quot;, border = &quot;white&quot;) # label at bottom } if (is.null(line) == FALSE) { abline(h = line, col = &quot;red&quot;, lty = 2) } if (grid == TRUE) { abline(h = axTicks(2), lty = &quot;dotted&quot;, col = &quot;gray50&quot;) abline(v = c(0.5, c(1: ncoefs) + 0.5), lty = &quot;dotted&quot;, col = &quot;gray50&quot;) # horizontal grid } abline(h = 0, col = &quot;red&quot;, lwd = 2, lty = &quot;solid&quot;) segments(y0 = data[, 3], x0 = c(1: ncoefs), y1 = data[, 4], x1 = c(1: ncoefs), lwd = 2) #CI points(1: ncoefs, data[, 1], pch = 16, col = 1, cex = 1.2) #point coefs box() } save_att_panels()*** generates and saves paginated pdf plots that display ATT estimates and their confidence bands from multiple methods. save_att_panels &lt;- function( out_list, plot_titles, band_list, est_list, prefix = &quot;ldw_model_a_plus&quot;, plots_per_page = 4, ylim = c(-15500, 5500), folder = &quot;graphs/lalonde&quot;) { if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) n &lt;- length(out_list) pages &lt;- ceiling(n / plots_per_page) for (p in seq_len(pages)) { start &lt;- (p - 1) * plots_per_page + 1 end &lt;- min(p * plots_per_page, n) file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, p, &quot;.pdf&quot;)) pdf(file_name, width = 8, height = 11) par(mfrow = c(plots_per_page, 1), mar = c(3, 4, 3, 2)) for (i in start:end) { plot_coef(out_list[[i]], band = band_list[[i]], line = est_list[[i]], ylim = ylim, main = plot_titles[i]) } dev.off() } } Arguments out_list: A list of output objects containing ATT estimates and confidence intervals for different methods. plot_titles: A character vector of titles for each plot. band_list: A list of numeric vectors specifying the confidence interval bounds for each plot. est_list: A list or numeric vector representing the point estimates (ATT values) for each plot. prefix: A string prefix used for saved file names to identify sample (default is “ldw_model_a_plus”). plots_per_page: The number of plots to display per page / panel (default 4). ylim: A numeric vector specifying the y-axis limits for the plots. folder: A string specifying the folder path where the PDF panels will be saved (default is “graphs/lalonde”). create_matrix_results() organizes estimation results into a formatted matrix suitable for reporting or tables. create_matrix_results &lt;- function(all_outs, all_out_mat, sample_names) { n_samples &lt;- length(sample_names) n_estimators &lt;- nrow(all_outs[[1]]) result_mat &lt;- matrix(&quot;&quot;, nrow = n_estimators + 1, ncol = n_samples * 2) cnames &lt;- character(n_samples * 2) for (j in seq_along(sample_names)) { cnames[(j - 1) * 2 + 1] &lt;- sample_names[j] cnames[(j - 1) * 2 + 2] &lt;- &quot;&quot; } colnames(result_mat) &lt;- cnames estimator_names &lt;- rownames(all_outs[[1]]) rownames(result_mat) &lt;- c(&quot;Experimental Benchmark&quot;, estimator_names) # all_out_mat contains 13 entries bench.exp &lt;- if(!is.null(all_out_mat[[1]])) all_out_mat[[1]][1, 1:2] else c(NA, NA) bench.cps &lt;- if(length(all_out_mat) &gt;= 6) lapply(all_out_mat[2:6], function(x) if(!is.null(x)) x[1, 1:2] else c(NA, NA)) else NULL bench.psid &lt;- if(length(all_out_mat) &gt;= 11) lapply(all_out_mat[7:11], function(x) if(!is.null(x)) x[1, 1:2] else c(NA, NA)) else NULL bench.cps_plus &lt;- if(length(all_out_mat) &gt;= 12 &amp;&amp; !is.null(all_out_mat[[12]])) all_out_mat[[12]][1, 1:2] else c(NA, NA) bench.psid_plus&lt;- if(length(all_out_mat) &gt;= 13 &amp;&amp; !is.null(all_out_mat[[13]])) all_out_mat[[13]][1, 1:2] else c(NA, NA) # all_outs contains 15 entries for (j in seq_along(all_outs)) { out &lt;- all_outs[[j]] # assign benchmark according to position # use bench.exp for the first 3 entries in all_outs if (j &lt;= 3 &amp;&amp; !any(is.na(bench.exp))) { result_mat[1, (j - 1) * 2 + 1] &lt;- sprintf(&quot;%.2f&quot;, bench.exp[1]) result_mat[1, (j - 1) * 2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, bench.exp[2]), &quot;)&quot;) } # use bench.cps for the next 5 entries in all_outs # use all entries in bench.cps one after another if (j &gt;= 4 &amp;&amp; j &lt;= 8 &amp;&amp; !is.null(bench.cps) &amp;&amp; length(bench.cps) &gt;= (j - 3)) { b &lt;- bench.cps[[j - 3]] result_mat[1, (j - 1) * 2 + 1] &lt;- sprintf(&quot;%.2f&quot;, b[1]) result_mat[1, (j - 1) * 2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, b[2]), &quot;)&quot;) } # use bench.psid for the next 5 entries in all_outs # use all entries in bench.psid one after another if (j &gt;= 9 &amp;&amp; j &lt;= 13 &amp;&amp; !is.null(bench.psid) &amp;&amp; length(bench.psid) &gt;= (j - 8)) { b &lt;- bench.psid[[j - 8]] result_mat[1, (j - 1) * 2 + 1] &lt;- sprintf(&quot;%.2f&quot;, b[1]) result_mat[1, (j - 1) * 2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, b[2]), &quot;)&quot;) } # use bench.cps_plus for the second last entry in all_outs if (j == n_samples - 1 &amp;&amp; !any(is.na(bench.cps_plus))) { result_mat[1, (j - 1) * 2 + 1] &lt;- sprintf(&quot;%.2f&quot;, bench.cps_plus[1]) result_mat[1, (j - 1) * 2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, bench.cps_plus[2]), &quot;)&quot;) } # use bench.psid_plus for the last entry in all_outs if (j == n_samples &amp;&amp; !any(is.na(bench.psid_plus))) { result_mat[1, (j - 1) * 2 + 1] &lt;- sprintf(&quot;%.2f&quot;, bench.psid_plus[1]) result_mat[1, (j - 1) * 2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, bench.psid_plus[2]), &quot;)&quot;) } # fill in estimates + SEs for (i in 2:(n_estimators + 1)) { if ((i-1) &lt;= nrow(out)) { result_mat[i, (j - 1) * 2 + 1] &lt;- sprintf(&quot;%.2f&quot;, out[i - 1, 1]) result_mat[i, (j - 1) * 2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, out[i - 1, 2]), &quot;)&quot;) } else { result_mat[i, (j - 1) * 2 + 1] &lt;- &quot;&quot; result_mat[i, (j - 1) * 2 + 2] &lt;- &quot;&quot; } } } return(result_mat) } Arguments all_outs: A list of output objects containing ATT estimates and confidence intervals for different methods. all_out_mat: A list of objects containing ATT estimates and confidence intervals for different methods used for benchmark construction. sample_names: A character vector of sample names corresponding to all_outs. eval_att() computes summary statistics of the treatment effect estimates. eval_att &lt;- function(data) { data.frame( Mean_SE = mean(data[, &quot;SE&quot;], na.rm = TRUE), # mean standard error Min_Estimate = min(data[, &quot;Estimate&quot;], na.rm = TRUE), # maximum estimate Max_Estimate = max(data[, &quot;Estimate&quot;], na.rm = TRUE), # minimum estimate Diff_Estimate = max(data[, &quot;Estimate&quot;], na.rm = TRUE) - min(data[, &quot;Estimate&quot;], na.rm = TRUE) ) } Argument data: A data frame containing treatment effect estimation results. 1.2.6.2 Conditional average treatment effect on the treated (CATT) plot_catt_panels()*** visualizes CATT comparing multiple methods. plot_catt_panels &lt;- function(exp_catt_list, catt_list, plot_titles, plots_per_page = 4, range = c(-8000, 8000)) { n &lt;- length(catt_list) num_pages &lt;- ceiling(n / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, n) par(mfrow = c(2, 2), mar = c(4.5, 5, 3, 2)) for (i in start_idx:end_idx) { catt_ldw &lt;- exp_catt_list[[i]]$catt att_ldw &lt;- exp_catt_list[[i]]$att[1] id_ldw &lt;- if (!is.null(exp_catt_list[[i]]$id)) exp_catt_list[[i]]$id else seq_along(catt_ldw) catt2 &lt;- catt_list[[i]]$catt att2 &lt;- catt_list[[i]]$att[1] id2 &lt;- if (!is.null(catt_list[[i]]$id)) catt_list[[i]]$id else seq_along(catt2) common_ids &lt;- intersect(id_ldw, id2) idx_ldw &lt;- match(common_ids, id_ldw) idx_other &lt;- match(common_ids, id2) catt1_plot &lt;- catt_ldw[idx_ldw] catt2_plot &lt;- catt2[idx_other] plot_catt( catt1 = catt1_plot, catt2 = catt2_plot, att1 = att_ldw, att2 = att2, xlab = &quot;CATT (Experimental)&quot;, ylab = plot_titles[i], main = plot_titles[i], axes.range = range ) } } } Arguments exp_catt_list: A list of objects containing CATT estimates used as experimental benchmark. catt_list: A list of objects containing CATT estimates from each comparison with the experimental benchmark. plot_titles: A character vector of titles for each plot. plots_per_page: The number of plots to display per page / panel (default 4). range: A numeric vector of axis limits for plots (default c(-8000, 8000)). save_catt_panels()*** generates and saves multi-page PDF plots comparing CATT estimates across different methods. save_catt_panels &lt;- function( exp_catt_list, catt_list, plot_titles, prefix = &quot;catt_top5&quot;, plots_per_page = 1, range = c(-8000, 8000), folder = &quot;graphs/lalonde&quot;) { if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) n &lt;- length(catt_list) num_pages &lt;- ceiling(n / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, n) file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, page, &quot;.pdf&quot;)) pdf(file = file_name, width = 10, height = 12) par(mfrow = c(plots_per_page, 1), mar = c(4.5, 5, 3, 2)) for (i in start_idx:end_idx) { # Use matching elements from both lists catt_ldw &lt;- exp_catt_list[[i]]$catt att_ldw &lt;- exp_catt_list[[i]]$att[1] id_ldw &lt;- if (!is.null(exp_catt_list[[i]]$id)) exp_catt_list[[i]]$id else seq_along(catt_ldw) catt2 &lt;- catt_list[[i]]$catt att2 &lt;- catt_list[[i]]$att[1] id2 &lt;- if (!is.null(catt_list[[i]]$id)) catt_list[[i]]$id else seq_along(catt2) common_ids &lt;- intersect(id_ldw, id2) idx_ldw &lt;- match(common_ids, id_ldw) idx_other &lt;- match(common_ids, id2) catt1_plot &lt;- catt_ldw[idx_ldw] catt2_plot &lt;- catt2[idx_other] plot_catt( catt1 = catt1_plot, catt2 = catt2_plot, att1 = att_ldw, att2 = att2, xlab = &quot;CATT (Experimental)&quot;, ylab = plot_titles[i], main = plot_titles[i], axes.range = range ) } # fill empty panels if last page is not full if ((end_idx - start_idx + 1) &lt; plots_per_page) { for (k in seq_len(plots_per_page - (end_idx - start_idx + 1))) plot.new() } dev.off() } } Arguments exp_catt_list: A list of objects containing CATT estimates used as experimental benchmark. catt_list: A list of objects containing CATT estimates from each comparison with the experimental benchmark. plot_titles: A character vector of titles for each plot. prefix: A string prefix for saved PDF filenames (default is “catt_top5”). plots_per_page: The number of plots to display per page / panel (default 1). range: A numeric vector of axis limits for plots (default c(-8000, 8000)). folder: A string specifying the folder path where the PDF panels will be saved (default is “graphs/lalonde”). save_main_catt_panels() save_main_catt_panels &lt;- function( catt_refs, catt_comps, ylabels, prefix = &quot;catt_main&quot;, plots_per_page = 1, main_titles = NULL, range = c(-8000, 8000), folder = &quot;graphs/lalonde&quot; ) { if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) n_panels &lt;- length(catt_comps) num_pages &lt;- ceiling(n_panels / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, n_panels) file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, page, &quot;.pdf&quot;)) pdf(file = file_name, width = 10, height = 12) par(mfrow = c(plots_per_page, 1), mar = c(4.5, 5, 3, 2)) for (i in start_idx:end_idx) { ref_idx &lt;- min(i, length(catt_refs)) catt1 &lt;- catt_refs[[ref_idx]]$catt catt2 &lt;- catt_comps[[i]]$catt att1 &lt;- catt_refs[[ref_idx]]$att[1] att2 &lt;- catt_comps[[i]]$att[1] plot_catt( catt1 = catt1, catt2 = catt2, att1 = att1, att2 = att2, xlab = &quot;CATT (Reference)&quot;, ylab = ylabels[i], main = if (is.null(main_titles)) paste(&quot;Comparison&quot;, i) else main_titles[i], axes.range = range ) } # fill empty panels if last page not full if ((end_idx - start_idx + 1) &lt; plots_per_page) { for (k in seq_len(plots_per_page - (end_idx - start_idx + 1))) plot.new() } dev.off() } } Arguments catt_refs: List of reference CATT objects used for x-axis values in each comparison plot. catt_comps: List of comparison CATT objects used for the y-axis in each plot. ylabels: Character vector of plot y-axis labels. prefix: A string prefix for saved PDF filenames (default is “catt_main”). plots_per_page: The number of plots to display per page / panel (default 1). main_titles: Character vector of main titles to appear at the top of each plot. range: A numeric vector of axis limits for plots (default c(-8000, 8000)). folder: A string specifying the folder path where the PDF panels will be saved (default is “graphs/lalonde”). save_plus_catt_panels() save_plus_catt_panels &lt;- function( catt1_list, catt2_list, ylabels, prefix = &quot;catt_plus&quot;, plots_per_page = 1, main_titles = NULL, range = c(-8000, 8000), folder = &quot;graphs/lalonde&quot; ) { if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) n_panels &lt;- min(length(catt1_list), length(catt2_list)) num_pages &lt;- ceiling(n_panels / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, n_panels) file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, page, &quot;.pdf&quot;)) pdf(file = file_name, width = 10, height = 12) par(mfrow = c(plots_per_page, 1), mar = c(4.5, 5, 3, 2)) for (i in start_idx:end_idx) { catt1 &lt;- catt1_list[[i]]$catt catt2 &lt;- catt2_list[[i]]$catt att1 &lt;- catt1_list[[i]]$att[1] att2 &lt;- catt2_list[[i]]$att[1] plot_catt( catt1 = catt1, catt2 = catt2, att1 = att1, att2 = att2, xlab = &quot;CATT (Reference/Trimmed)&quot;, ylab = ylabels[i], main = if (is.null(main_titles)) paste(&quot;Trimmed Panel&quot;, i) else main_titles[i], axes.range = range ) } # fill empty panels if last page not full if ((end_idx - start_idx + 1) &lt; plots_per_page) { for (k in seq_len(plots_per_page - (end_idx - start_idx + 1))) plot.new() } dev.off() } } Arguments catt1_list: List of CATT objects for x-axis values. catt2_list: List of CATT objects for y-axis values. ylabels: Character vector of plot y-axis labels. prefix: A string prefix for saved PDF filenames. plots_per_page: The number of plots to display per page / panel (default 1). main_titles: Character vector of main titles to appear at the top of each plot. range: A numeric vector of axis limits for plots (default c(-8000, 8000)). folder: A string specifying the folder path where the PDF panels will be saved (default is “graphs/lalonde”). eval_catt() computes summary statistics of CATT vectors for each method, returning the minimum, maximum, mean, and range (difference) of the CATT estimates. eval_catt &lt;- function(all_catt, plot_titles) { do.call(rbind, lapply(seq_along(all_catt), function(i) { catt_vec &lt;- all_catt[[i]]$catt data.frame( Method = plot_titles[i], Min_Catt = min(catt_vec, na.rm = TRUE), Max_Catt = max(catt_vec, na.rm = TRUE), Mean_Catt = mean(catt_vec, na.rm = TRUE), Diff_Catt = max(catt_vec, na.rm = TRUE) - min(catt_vec, na.rm = TRUE), stringsAsFactors = FALSE ) })) } Arguments all_catt: A list of objects containing conditional average treatment effect on treated (CATT) estimates. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_catt. 1.2.6.3 Quantile treatment effect on treated (QTET) est_qte_safe()*** computes QTET estimates while handling potential errors gracefully. est_qte_safe &lt;- function(Y, treat, covar, data, cores = 1) { tryCatch({ est_qte(Y, treat, covar, data = data, cores = cores) }, error = function(e) { cat(&quot;Warning in est_qte:&quot;, e$message, &quot;\\n&quot;) return(NULL) }) } Arguments Y: The name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. data: The data frame used for QTET estimation. cores: The number of CPU cores used for parallel computation (default is 1). plot_qte_top()*** plots QTET of top-ranked samples for comparison against an experimental benchmark. plot_qte_top &lt;- function(qtet_top, qtet_top0, bm_list, plot_titles, main_start = 1, ylim = c(-25000, 15000), col = NULL) { n &lt;- length(qtet_top) for (i in seq_len(n)) { main_title &lt;- plot_titles[main_start + i - 1] mod &lt;- qtet_top[[i]] mod2 &lt;- qtet_top0[[i]] bm &lt;- bm_list[[i]] plot_qte(mod, mod2, bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) } } Arguments qtet_top: A list of objects containing QTET estimates for top-ranked samples. qtet_top0: A list of objects containing unadjusted QTET estimates. bm_list: A list containing QTET estimates for experimental benchmark construction. plot_titles: A character vector of titles for each plot, matching the order of elements in qtet_top. main_start: Numeric value index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots (default is c(-25000, 15000)). col: Color specification. save_qtet()*** generates and saves quantile treatment effect on the treated (QTET) plots for a given list of estimates. save_qtet &lt;- function(plots, plot_titles = NULL, main_start = 1, ylim = c(-25000, 15000), col = NULL, prefix = &quot;ldw&quot;) { dir.create(&quot;graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) n &lt;- length(plots) for (i in seq_len(n)) { p &lt;- plots[[i]] main_title &lt;- if (is.null(plot_titles)) p$main else plot_titles[main_start + i - 1] clean_title &lt;- gsub(&quot;[^a-zA-Z0-9]&quot;, &quot;_&quot;, main_title) file_name &lt;- sprintf(&quot;graphs/lalonde/%s_qtet_estimates_%s.pdf&quot;, prefix, clean_title) pdf(file = file_name, width = 7, height = 5) plot_qte(p$mod, p$mod0, p$bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) dev.off() } } Arguments plots: A list of objects containing QTET estimates and corresponding unadjusted estimates. plot_titles: A character vector of titles for each plot, matching the order of elements in plots. main_start: Numeric value index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots (default is c(-25000, 15000)). col: Color specification. prefix: A string prefix for saved PDF filenames (default is “ldw”). save_qte_top()*** generates and saves quantile treatment effect on the treated (QTET) plots for a given list of estimates of top-ranked samples. save_qte_top &lt;- function(qtet_top, qtet_top0, bm_list, plot_titles, main_start = 1, ylim = c(-25000, 15000), col = NULL, prefix = &quot;ldw_top&quot;) { n &lt;- length(qtet_top) dir.create(&quot;graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) for (i in seq_len(n)) { mod &lt;- qtet_top[[i]] mod2 &lt;- qtet_top0[[i]] bm &lt;- bm_list[[i]] main_title &lt;- plot_titles[main_start + i - 1] clean_title &lt;- gsub(&quot;[^a-zA-Z0-9]&quot;, &quot;_&quot;, main_title) file_name &lt;- sprintf(&quot;graphs/lalonde/%s_qte_estimates_%s.pdf&quot;, prefix, clean_title) pdf(file = file_name, width = 7, height = 5) plot_qte(mod, mod2, bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) dev.off() } } Arguments qtet_top: A list of objects containing QTET estimates for top-ranked samples. qtet_top0: A list of objects containing unadjusted QTET estimates. bm_list: A list containing QTET estimates for experimental benchmark construction. plot_titles: A character vector of titles for each plot, matching the order of elements in qtet_top. main_start: Numeric value index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots (default is c(-25000, 15000)). col: Color specification. prefix: A string prefix for saved PDF filenames (default is “ldw_top”). 1.2.7 Outcome weights analysis get_res_att() estimates average treatment effects on the treated (ATT) using augmented inverse probability weighting with cross-fitting on a list of sample. get_res_att &lt;- function(data_list, Y, treat, covar, estimator = &quot;AIPW_ATT&quot;, smoother = &quot;honest_forest&quot;, n_cf_folds = 5, n_reps = 1) { results &lt;- lapply(seq_along(data_list), function(i) { data &lt;- data_list[[i]] n_obs &lt;- nrow(data) # adjust n_cf_folds for small samples folds &lt;- if (n_obs &lt; 100) { max(2, min(3, n_cf_folds)) } else if (n_obs &lt; 300) { max(3, min(4, n_cf_folds)) } else { n_cf_folds } tryCatch({ dml_with_smoother( Y = data[[Y]], D = data[[treat]], X = data[, covar, drop = FALSE], estimator = estimator, smoother = smoother, n_cf_folds = folds, n_reps = n_reps ) }, error = function(e) { cat(sprintf(&quot;WARNING: get_res_att failed for sample %d (n=%d): %s\\n&quot;, i, n_obs, e$message)) return(NULL) }) } ) # summary report null_count &lt;- sum(sapply(results, is.null)) success_count &lt;- length(results) - null_count cat(sprintf(&quot;OUTCOME WEIGHTS SUMMARY: %d succeeded, %d failed out of %d samples\\n&quot;, success_count, null_count, length(results))) return(results) } Arguments data_list: A list of samples containing data. Y: String specifying the name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. estimator: String specifying the estimator to use (default is “AIPW_ATT”). smoother: String specifying the smoothing method (default is “honest_forest”). n_cf_folds: Numeric value specifying the number of cross-fitting folds (default is 5). n_reps: Numeric value specifying the number of repetitions for robustness (default is 1). derive_ow() extracts outcome weights from a list of estimation results. derive_ow &lt;- function(results_list) { lapply(results_list, function(res) get_outcome_weights(res)) } Argument results_list: A list of objects obtained from get_res_att(). plot_ow() plots the distribution of the outcome weights. plot_ow &lt;- function(outcome_weights, plot_titles = NULL, breaks = 50, col = &quot;#ff000080&quot;, xlab = &quot;Outcome Weight&quot;, estimator = &quot;AIPW-ATT&quot;) { N &lt;- length(outcome_weights) for (i in seq_len(N)) { weights &lt;- outcome_weights[[i]]$omega[estimator, ] main_title &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Sample&quot;, i) hist(weights, breaks = breaks, main = main_title, xlab = xlab, col = col) mtext(paste(&quot;N =&quot;, length(weights)), side = 3, line = -1.5, cex = 0.8) } par(mfrow = c(1, 1)) } Arguments outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. breaks: Numeric value specifying the number of bins for the histogram plots (default is 50). col: Color specification (default is “#ff000080”). xlab: String specifying the label for the x-axis (default is “Outcome Weight”) estimator: String specifying the estimator to use (default is “AIPW-ATT”). eval_ow() computes summary statistics of outcome weights by treatment group for a list of samples and returns a data frame for comparison. eval_ow &lt;- function(outcome_weights, data_list, plot_titles = NULL, treat = &quot;treat&quot;, estimator = &quot;AIPW-ATT&quot;) { results &lt;- lapply(seq_along(outcome_weights), function(i) { ow &lt;- outcome_weights[[i]]$omega[estimator, ] treat &lt;- data_list[[i]][[treat]] method &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Sample&quot;, i) sum_treated &lt;- sum(ow[treat == 1]) sum_untreated &lt;- sum(ow[treat == 0]) data.frame( Method = method, Sum_Treated = sum_treated, Sum_Untreated = sum_untreated, Total_Sum = sum_treated + sum_untreated, stringsAsFactors = FALSE ) }) do.call(rbind, results) } **Arguments* outcome_weights: A list of outcome weight objects. data_list: A list of samples containing data. plot_titles: A character vector of titles for each plot. treat: String specifying the treatment variable in each sample (default is “treat”). estimator: String specifying the estimator to use (default is “AIPW-ATT”). save_ow() saves the outcome weight histograms as PDF files, one per sample, with optional custom titles and formatting. save_ow &lt;- function(outcome_weights, plot_titles = NULL, breaks = 50, col = &quot;#ff000080&quot;, xlab = &quot;Outcome Weight&quot;, prefix = &quot;model_a&quot;, estimator = &quot;AIPW-ATT&quot;) { dir.create(&quot;graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) N &lt;- length(outcome_weights) for (i in seq_len(N)) { file_name &lt;- sprintf(&quot;graphs/lalonde/%s_outcomewt_%d.pdf&quot;, prefix, i) pdf(file = file_name, width = 8, height = 6) weights &lt;- outcome_weights[[i]]$omega[estimator, ] main_title &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Sample&quot;, i) hist(weights, breaks = breaks, main = main_title, xlab = xlab, col = col) mtext(paste(&quot;N =&quot;, length(weights)), side = 3, line = -1.5, cex = 0.8) dev.off() } } Argument outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. breaks: Numeric value specifying the number of bins for the histogram plots (default is 50). col: Color specification (default is “#ff000080”). xlab: String specifying the label for the x-axis (default is “Outcome Weight”) prefix: A string prefix for saved PDF filenames. estimator: String specifying the estimator to use (default is “AIPW-ATT”). 1.2.8 Sensitivity analysis check_filter_samples() filters a list of samples to retain only those with all required variables, no missing data, binary treatment, and sufficient baseline/covariate variation. check_filter_samples &lt;- function(data_list, Y, treat, covar, bm) { valid_samples &lt;- list() for (i in seq_along(data_list)) { data &lt;- data_list[[i]] name &lt;- names(data_list)[i] if (is.null(name) || name == &quot;&quot;) name &lt;- paste0(&quot;data_&quot;, i) # provide a name if missing vars_needed &lt;- c(Y, treat, covar, bm) if (!all(vars_needed %in% names(data))) { # check all variables exist message(&quot;Removed &quot;, name, &quot;: missing required variables&quot;) next } sub &lt;- data[, vars_needed, drop = FALSE] if (any(is.na(sub))) { # check no missing values message(&quot;Removed &quot;, name, &quot;: contains missing values&quot;) next } tvals &lt;- unique(sub[[treat]]) # check treatment binary if (!all(tvals %in% c(0, 1)) &amp;&amp; !all(tvals %in% c(TRUE, FALSE))) { message(&quot;Removed &quot;, name, &quot;: treatment variable not binary&quot;) next } if (any(sapply(sub[bm], function(x) length(unique(x)) &lt;= 1))) { # check baseline variables have variation message(&quot;Removed &quot;, name, &quot;: baseline variable(s) lack variation&quot;) next } if (any(sapply(sub[covar], function(x) length(unique(x)) &lt;= 1))) { # check covariates have variation message(&quot;Removed &quot;, name, &quot;: covariate variable(s) lack variation&quot;) next } valid_samples[[name]] &lt;- data # if all passed sample is kept } return(valid_samples) } Arguments data_list: A list of data frames containing data to be filtered. Y: The name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. bm: A vector of baseline variable names. save_sensitivity_plots() generates sensitivity analysis plots for a series of filtered samples, saving each as a pdf file. save_sensitivity_plots &lt;- function(filtered_data_list, Y, treat, covar, bm, plot_titles, prefix) { folder &lt;- &quot;graphs/lalonde&quot; if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) success_count &lt;- 0 fail_count &lt;- 0 for (i in seq_along(filtered_data_list)) { idx &lt;- i file_name &lt;- file.path(folder, paste0(prefix, &quot;_sensitivity_&quot;, idx, &quot;.pdf&quot;)) pdf(file_name, width = 8, height = 8) tryCatch({ sens_ana(filtered_data_list[[i]], Y, treat, covar, bm, kd = 1:3) if (!is.null(plot_titles) &amp;&amp; length(plot_titles) &gt;= idx) { title(main = plot_titles[idx]) } success_count &lt;- success_count + 1 }, error = function(e) { plot.new() title_text &lt;- if (!is.null(plot_titles) &amp;&amp; length(plot_titles) &gt;= idx) plot_titles[idx] else paste(&quot;Sample&quot;, idx) text(0.5, 0.5, paste(&quot;ERROR:&quot;, title_text, &quot;\\n&quot;, e$message), cex = 0.8) cat(sprintf(&quot;WARNING: Sensitivity plot %d (%s) failed: %s\\n&quot;, idx, title_text, e$message)) fail_count &lt;- fail_count + 1 }) dev.off() } cat(sprintf(&quot;SUMMARY: Sensitivity plots - %d succeeded, %d failed out of %d total\\n&quot;, success_count, fail_count, length(filtered_data_list))) } Arguments filtered_data_list: A list of filtered samples containing data. Y: The name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. bm: A vector of baseline variable names. plot_titles: A vector of titles for plots corresponding to samples. prefix: A string prefix for saving output PDF files. 1.2.9 Balance analysis save_balance() generates balance plots that visualize the distribution of a specified covariate across treated and control groups for each sample and method. save_balance &lt;- function( data_list, method_names, balance_var = &quot;re75&quot;, prefix = &quot;balance_panels&quot;, plots_per_page = 4, folder = &quot;graphs/lalonde&quot; ) { if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) n &lt;- length(data_list) pages &lt;- ceiling(n / plots_per_page) for (p in seq_len(pages)) { start &lt;- (p - 1) * plots_per_page + 1 end &lt;- min(p * plots_per_page, n) file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, balance_var, &quot;_&quot;, p, &quot;.pdf&quot;)) plot_list &lt;- list() for (i in start:end) { plot_title &lt;- paste0(method_names[i]) pl &lt;- tryCatch({ form &lt;- as.formula(paste0(&quot;treat ~ &quot;, balance_var)) bal.plot(form, data = data_list[[i]], which = &quot;both&quot;) + ggtitle(plot_title) }, error = function(e) { message(sprintf(&quot;Could not plot %s: %s&quot;, method_names[i], e$message)) ggplot() + ggtitle(sprintf(&quot;Error: %s&quot;, method_names[i])) }) plot_list[[length(plot_list)+1]] &lt;- pl } pdf(file_name, width = 8, height = 11) print(wrap_plots(plotlist = plot_list, ncol = 1)) dev.off() } } Arguments data_list: A list of samples containing data. method_names: A list of methods names that were used to generate the samples. balance_var: The name of the covariate that shall be used for balance check. prefix: A string prefix for saving output PDF files. folder: A string specifying the folder path where the PDF panels will be saved (default is “graphs/lalonde”). plots_per_page: The number of plots to display per page / panel (default 4). References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["lalonde-dehejia-wahba-ldw-data.html", "Chapter 2 LaLonde-Dehejia-Wahba (LDW) Data 2.1 Set up 2.2 LDW-Model A 2.3 Pre-assessing methods 2.4 Improving overlap 2.5 Post-assessing methods 2.6 Identifying most efficient methods 2.7 Estimating 2.8 Validation through placebo analyses 2.9 Validation through sensitivity analyses 2.10 Inspection of re74 and re75 2.11 Summary", " Chapter 2 LaLonde-Dehejia-Wahba (LDW) Data LaLonde (1986) evaluated the effect of the National Supported Work Demonstration (NSW) program on both female and male participants. While the female participants were drawn from the Aid to Families with Dependent Children (AFDC) program, the male participants were drawn from three other groups: former drug addicts, ex-criminal offenders, and high-school dropouts. LaLonde relied on two main data sources: (1) CPS-SSA-1, based on Westat’s Matched Current Population Survey–Social Security Administration File for individuals under 55 matching specific criteria; (2) PSID-1, based on Panel Study of Income Dynamics for household heads under 55 from specific years who were not retired in 1975, adjusted for factors like employment status and poverty level. Dehejia and Wahba (1999) constructed a subset of LaLonde’s original data, retaining 62% of observations and restricting the focus to male participants based on their 1974 earnings. As the sample was formed entirely on pretreatment information like employment records or month of assignment, treatment allocation was effectively independent of all pretreatment variables. Thus, they concluded that this subset, known as the LaLonde-Dehejia-Wahba (LDW) data, constitutes a valid experimental sample. The analysis in section 2 and 3 builds on the LDW data and considers in total three samples: (1) LDW-Experimental, consisting of 185 treated individuals and 280 controls from the experimental data; (2) LDW-CPS-1, which pairs the same treated units with 15,992 controls from CPS-SSA-1; (3) LDW-PSID-1, featuring the same treated units with 2,490 controls from PSID-1. In section 4 and 5, the analysis applies the same set of statistical tools to analyze a fourth and fifth sample as additional demonstrations: (4) LaLonde male samples (1986); (5) LaLonde female samples (2017). This section (2) covers model A, which includes the outcome variable 1978 earnings (re78) and adjusts for a set of covariates: age, education, race (black, hispanic), marital status (married), high school dropouts (nodegree), 1974 and 1975 earnings (re74, re75), and unemployment status in 1974 and 1975 (u74, u75). The model is defined by a regression formula for treatment assignment using these covariates. To achieve adequate overlap between treated and control groups and covariate balance, various methods are applied and are structured into two parts (trimming and integrated methods). From these methods, the five most efficient methods are determined based on the overlapping coefficient and reranked by the mean absolute standardized mean difference. The corresponding samples are used to estimate to inform subsequent analysis. Notably, the estimation of the average treatment effect on the treated (ATT) incorporates the recently introduced augmented inverse probability weighting (AIPW) estimator, implemented via the OutcomeWeights R package (AIPW-OW). Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify potential patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (re75) as the outcome to assess potential biases and the validity of unconfoundedness assumptions. Finally, sensitivity analyses are performed to evaluate the robustness of treatment effect estimates to violations of these assumptions. 2.1 Set up 2.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 2.1.2 Inspect data We begin the analysis with an overview of each sample, where the sample name, number of observations (rows), number of treated and control units, number of variables (columns), and variable names are reviewed. # collect samples in a list data &lt;- list(ldw = ldw, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid) # print and inspect key metrics of each sample summary_stats &lt;- inspect_data(data) datatable(summary_stats, caption = &quot;Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) 2.1.3 Load and preprocess data Next, we augment the control groups in LDW-CPS-1 and LDW-PSID-1 by merging them with the experimental controls from LDW-Experimental. This approach follows the methodology laid out by Imbens and Xu (2024). These expanded samples are used solely for comparative purposes, while all primary analyses rely on the original LDW‑CPS-1 and LDW‑PSID-1 samples. # assigns 1 to the experimental controls ldw_co$treat &lt;- 1 # merge experimental data with CPS-1 data ldw_cps_plus &lt;- rbind.data.frame( ldw_co, # experimental controls ldw_cps # CPS-1 data ) # merge experimental data with PSID-1 data ldw_psid_plus &lt;- rbind.data.frame( ldw_co, # experimental controls ldw_psid # PSID-1 data ) samples &lt;- list(ldw_cps_plus = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus) # print and inspect each sample summary_stats_plus &lt;- inspect_data(samples) datatable(summary_stats_plus, caption = &quot;Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) 2.2 LDW-Model A Finally, we define model A as the baseline specification underlying the analysis before we proceed to analyze overlap. # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) #re74 included The model formula is as following. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 2.3 Pre-assessing methods 2.3.1 Overlap To identify the average causal effect under unconfoundedness (that asserts that the treatment assignment is independent of the potential outcomes), it must be ensured that one can estimate the average effect at every value for the covariates. Thus, overlap between the treated and untreated units (meaning that for every combination of covariates, there are both treated and untreated units in the sample) is required. To assess overlap in the propensity scores and visualize the results using histograms of their log-odds, we use the assess_overlap() function introduced by Imbens and Xu (2024). In a properly balanced experimental design, the distributions of the treatment group (red) and the control group (gray) would show considerable coverage. ldw.ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar) ## -1.310867 0.7158619 Figure 2.1: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. ldw_cps.ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar) ## -16.1181 1.787343 Figure 2.2: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. ldw_psid.ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar) ## -16.1181 3.752723 Figure 2.3: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. As anticipated, LDW-Experimental exhibits an almost perfect overlap. In contrast, the observational samples LDW-CPS-1 and LDW-PSID-1 show poor overlap. Notably, many treated units have propensity scores outside the range of the controls, while a large share of control units have propensity scores concentrated at very low log-odds. Next, the overlap of the expanded observational samples is examined. ldw_cps_plus.ps &lt;- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) ## -16.1181 3.63151 Figure 2.4: FIGUREA1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. ldw_psid_plus.ps &lt;- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) ## -16.1181 7.271394 Figure 2.5: FIGUREA1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. As expected, the samples LDW-CPS1-PLUS and LDW-PSID1-PLUS show an improved overlap compared to their non-plus states. However, they only serve as a reference for comparison. # combine results data_list &lt;- list(ldw, ldw_cps, ldw_psid, ldw_cps_plus, ldw_psid_plus) plot_titles &lt;- c(&quot;(A) LDW-Experimental&quot;,&quot;(B) LDW-CPS-1&quot;, &quot;(C) LDW-PSID-1&quot;, &quot;(D) LDW-CPS-1-PLUS&quot;, &quot;(E) LDW-PSID-1-PLUS&quot;) # save results save_overlap_panels( data_list = data_list, treat = treat, covar = covar, plot_titles = plot_titles, prefix = &quot;ldw_overlap_model_a_panels&quot; ) ## -1.310867 0.7158619 ## -16.1181 1.787343 ## -16.1181 3.752723 ## -16.1181 3.63151 ## -16.1181 7.271394 For the subsequent analysis aimed at achieving adequate overlap, only the two samples LDW-CPS-1 and LDW-PSID-1 are considered. However, since covariate imbalance can induce bias even in the presence of overlap, it remains crucial to also ensure sufficient balance on observed covariates in these samples. The LDW-Experimental sample is excluded from these steps, as randomization already ensures adequate overlap. 2.4 Improving overlap 2.4.1 Single methods 2.4.1.1 Trimming The purpose of trimming is to remove units whose propensity scores are too dissimilar from the counterfactual group, thereby improving overlap. Below, we employ several trimming methods in line with the approaches proposed by Stürmer et al. (2021) and Imbens and Xu (2024). Propensity score threshold trimming # apply trimming with a (maximum) threshold ldw_cps.ps_trim &lt;- ps_trim(ldw_cps.ps, threshold = 0.9) ldw_psid.ps_trim &lt;- ps_trim(ldw_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.ps_trim &lt;- ps_estimate(data = ldw_cps.ps_trim, treat = treat, cov = covar) ldw_psid.ps_trim &lt;- ps_estimate(data = ldw_psid.ps_trim, treat = treat, cov = covar) Common range trimming # trim observations outside the common support region of propensity scores ldw_cps.ps_common &lt;- common_range_trim(ldw_cps.ps) ldw_psid.ps_common &lt;- common_range_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.ps_common &lt;- ps_estimate(data = ldw_cps.ps_common, treat = treat, cov = covar) ldw_psid.ps_common &lt;- ps_estimate(data = ldw_psid.ps_common, treat = treat, cov = covar) Crump trimming # trim observations with propensity scores outside an interval ldw_cps.ps_crump &lt;- crump_trim(ldw_cps.ps) ldw_psid.ps_crump &lt;- crump_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.ps_crump &lt;- ps_estimate(data = ldw_cps.ps_crump, treat = treat, cov = covar) ldw_psid.ps_crump &lt;- ps_estimate(data = ldw_psid.ps_crump, treat = treat, cov = covar) Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control ldw_cps.ps_stuermer &lt;- stuermer_trim(ldw_cps.ps, lower_percentile = 0.01, upper_percentile = 0.99) ldw_psid.ps_stuermer &lt;- stuermer_trim(ldw_psid.ps, lower_percentile = 0.01, upper_percentile = 0.99) # re-estimate propensity scores on trimmed data ldw_cps.ps_stuermer &lt;- ps_estimate(data = ldw_cps.ps_stuermer, treat = treat, cov = covar) ldw_psid.ps_stuermer &lt;- ps_estimate(data = ldw_psid.ps_stuermer, treat = treat, cov = covar) Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations ldw_cps.ps_walker &lt;- walker_trim(ldw_cps.ps) ldw_psid.ps_walker &lt;- walker_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.ps_walker &lt;- ps_estimate(data = ldw_cps.ps_walker, treat = treat, cov = covar) ldw_psid.ps_walker &lt;- ps_estimate(data = ldw_psid.ps_walker, treat = treat, cov = covar) 2.4.2 Integrated methods 2.4.2.1 Trimming and matching The purpose of integrating trimming and matching is to address not only poor overlap, but also covariate imbalance. Matching creates comparable treated and control groups by pairing units with similar covariate profiles, thereby reducing covariate imbalance and confounding bias. We apply several matching methods as outlined by Greifer (2025) in the following. For comparison, an integrated method combining (maximum) threshold trimming and 1:1 matching is applied consistent with the procedure in the tutorial by Imbens and Xu (2024), before all combinations of proposed trimming and matching method are applied to the initial observational samples. 2.4.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # apply trimming with a (maximum) threshold ldw_cps_trim &lt;- ps_trim(ldw_cps_plus.ps, threshold = 0.9) ldw_psid_trim &lt;- ps_trim(ldw_psid_plus.ps, threshold = 0.8) # excluding the experimental controls ldw_cps.trim_match &lt;- subset(ldw_cps_trim, sample %in% c(1,3) &amp; ps_assoverlap) ldw_psid.trim_match &lt;- subset(ldw_psid_trim, sample %in% c(1,4) &amp; ps_assoverlap) # re-estimate propensity scores and employ 1:1 matching ldw_cps.trim_match &lt;- psmatch(data = ldw_cps.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.trim_match &lt;- psmatch(data = ldw_psid.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) # further subset data and re-assign treat variable ldw_trim_cps &lt;- subset(ldw_cps_trim, sample %in% c(1,2) &amp; ps_assoverlap &lt;= 0.9) ldw_trim_cps$treat[which(ldw_trim_cps$sample == 2)] &lt;- 0 ldw_trim_psid &lt;- subset(ldw_psid_trim, sample %in% c(1,2) &amp; ps_assoverlap &lt;= 0.8) ldw_trim_psid$treat[which(ldw_trim_psid$sample == 2)] &lt;- 0 2.4.2.1.2 Initial samples # combine trimmed samples all_trim.cps &lt;- list( ps_threshold = ldw_cps.ps_trim, common_range = ldw_cps.ps_common, stuermer = ldw_cps.ps_stuermer, walker = ldw_cps.ps_walker, crump = ldw_cps.ps_crump) all_trim.psid &lt;- list( ps_threshold = ldw_psid.ps_trim, common_range = ldw_psid.ps_common, stuermer = ldw_psid.ps_stuermer, walker = ldw_psid.ps_walker, crump = ldw_psid.ps_crump) 2.4.2.1.2.1 Distance matching 1:1 Nearest neighbor matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=1, logistic propensity score and replacement nn_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) nn_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) k:1 matching (k=2) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=2, logistic propensity score and replacement k&lt;-2 k2_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k2_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k:1 matching (k=3) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=3, logistic propensity score and replacement k&lt;-3 k3_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k3_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) Caliper matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score and replacement caliper_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) caliper_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) Common support restriction matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with exclusion of units outside common support and replacement cs_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) cs_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) Mahalanobis distance matching (mahvars) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching using mahalanobis distance without replacement mahvars_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) mahvars_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) Optimal pair matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal pair matching that minimizes total within-pair distance on propensity scores optimal_pair_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) optimal_pair_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Optimal full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion optimal_full_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) optimal_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Generalized full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios general_full_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) general_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Genetic matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform genetic matching genetic_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) genetic_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) 2.4.2.1.2.2 Stratum matching Exact matching (exact) # match units exactly by raw covariate profiles exact_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;exact&quot;) exact_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;exact&quot;) ## MATCHING SUMMARY: 3 succeeded, 2 failed. Failed: walker, Coarsened matching (cem) # match units exactly within coarse strata cem_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cem&quot;) cem_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cem&quot;) Subclassification # partition sample into fixed number of bins based on propensity score subcl_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;subclass&quot;, subclass = 3) subcl_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;subclass&quot;, subclass = 3) 2.4.2.1.2.3 Pure subset selection Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units card_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) card_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact profile_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) profile_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) 2.5 Post-assessing methods We now systematically reassess all methods described above by evaluating the overlapping coefficient (OVL) and the absolute standardized mean differences (ASMD). Specifically, we compute the ASMD and OVL for each approach to determine the most efficient methods for the observational samples. 2.5.1 Single methods 2.5.1.1 Trimming 2.5.1.1.1 SMD # compute absolute standardized mean differences smd_trim.cps &lt;- compute_abs_smd_trim(all_trim.cps, &quot;treat&quot;, covar) smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 2.5.1.1.2 OVL # compute overlap coefficients ovl_trim.cps &lt;- compute_ovl_trim(all_trim.cps, &quot;ps_assoverlap&quot;, &quot;treat&quot;) ovl_trim.psid &lt;- compute_ovl_trim(all_trim.psid, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 2.5.2 Integrated methods 2.5.2.1 Trimming and matching 2.5.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # list all trimmed and matched samples trim_match_comb.cps_plus &lt;- list(ps_threshold_match = ldw_cps.trim_match) trim_match_comb.psid_plus &lt;- list(ps_threshold_match = ldw_psid.trim_match) 2.5.2.1.1.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.cps_plus &lt;- compute_abs_smd_trim(trim_match_comb.cps_plus, &quot;treat&quot;, covar) smd_trim_match_comb.psid_plus &lt;- compute_abs_smd_trim(trim_match_comb.psid_plus, &quot;treat&quot;, covar) 2.5.2.1.1.2 OVL # compute overlap coefficients ovl_trim_match_comb.cps_plus &lt;- compute_ovl_trim(trim_match_comb.cps_plus, &quot;ps_assoverlap&quot;, &quot;treat&quot;) ovl_trim_match_comb.psid_plus &lt;- compute_ovl_trim(trim_match_comb.psid_plus, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 2.5.2.1.2 Initial samples # list all trimmed and matched samples trim_match_comb.cps &lt;- list( nn = nn_trim_comb.cps, k2 = k2_trim_comb.cps, k3 = k3_trim_comb.cps, caliper = caliper_trim_comb.cps, cs = cs_trim_comb.cps, mahvars = mahvars_trim_comb.cps, optimal_pair = optimal_pair_trim_comb.cps, optimal_full = optimal_full_trim_comb.cps, genetic = genetic_trim_comb.cps, exact = exact_trim_comb.cps, cem = cem_trim_comb.cps, subcl = subcl_trim_comb.cps ) trim_match_comb.psid &lt;- list( nn = nn_trim_comb.psid, k2 = k2_trim_comb.psid, k3 = k3_trim_comb.psid, caliper = caliper_trim_comb.psid, cs = cs_trim_comb.psid, mahvars = mahvars_trim_comb.psid, optimal_pair = optimal_pair_trim_comb.psid, optimal_full = optimal_full_trim_comb.psid, genetic = genetic_trim_comb.psid, exact = exact_trim_comb.psid, cem = cem_trim_comb.psid, subcl = subcl_trim_comb.psid ) 2.5.2.1.2.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.cps &lt;- compute_abs_smd_matchit(trim_match_comb.cps, all_trim.cps) smd_trim_match_comb.psid &lt;- compute_abs_smd_matchit(trim_match_comb.psid, all_trim.psid) 2.5.2.1.2.2 OVL # compute overlap coefficients ovl_trim_match_comb.cps &lt;- compute_ovl_matchit(trim_match_comb.cps, all_trim.cps, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = covar) ovl_trim_match_comb.psid &lt;- compute_ovl_matchit(trim_match_comb.psid, all_trim.psid, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = covar) 2.6 Identifying most efficient methods 2.6.1 Ranking To identify the top five methods for each observational sample, we first combine for each sample all results of the mean ASMD and OVL into a single data frame. This allows for a comprehensive comparison across all methods. Only results based on the non-plus samples are included in the identification of the most efficient methods, as the objective is to identify the overall top-performing methods for the original observational samples. # combine all results all_cps &lt;- combine_results(&quot;cps&quot;) all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_cps, &quot;ldw_model_a_cps1_all_results&quot;) save_csv(all_psid, &quot;ldw_model_a_psid1_all_results&quot;) Next, each method is evaluated according to its OVL and mean ASMD result. Specifically, the top five methods are selected based on the highest OVL value, as higher values indicate greater overlap between treated and control groups, before those are reranked based on the mean ASMD, where lower values indicate higher degrees of covariate balance. # rank comparatively ranked_cps &lt;- assess_methods(all_cps) ranked_psid &lt;- assess_methods(all_psid) # get top 5 methods top5_methods.cps &lt;- get_top_methods(ranked_cps, top_n = 5) top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # rerank top 5 methods top5_methods_df.cps &lt;- ranked_cps %&gt;% arrange(desc(OVL)) %&gt;% head(5) %&gt;% arrange(Mean_Abs_SMD) top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(OVL)) %&gt;% head(5) %&gt;% arrange(Mean_Abs_SMD) # get results top5_methods.cps &lt;- top5_methods_df.cps$Method top5_methods.psid &lt;- top5_methods_df.psid$Method # print table output datatable(top5_methods_df.cps, caption = &quot;Top 5 Methods for CPS-1&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) datatable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID-1&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) # save results save_csv(top5_methods.cps, &quot;ldw_model_a_cps1_top5_methods&quot;) save_csv(top5_methods.psid, &quot;ldw_model_a_psid1_top5_methods&quot;) 2.6.2 Sample construction For the subsequent estimation, we need to construct samples based on the top‑ranked methods. Therefore, we match all method names back to their corresponding data, or objects and construct corresponding samples. # create lookup lists match_lookup_cps &lt;- c( wrap_match_entries(nn_trim_comb.cps, all_trim.cps, &quot;nn&quot;), wrap_match_entries(k2_trim_comb.cps, all_trim.cps, &quot;k2&quot;), wrap_match_entries(k3_trim_comb.cps, all_trim.cps, &quot;k3&quot;), wrap_match_entries(caliper_trim_comb.cps, all_trim.cps, &quot;caliper&quot;), wrap_match_entries(cs_trim_comb.cps, all_trim.cps, &quot;cs&quot;), wrap_match_entries(mahvars_trim_comb.cps, all_trim.cps, &quot;mahvars&quot;), wrap_match_entries(optimal_pair_trim_comb.cps, all_trim.cps, &quot;optimal_pair&quot;), wrap_match_entries(optimal_full_trim_comb.cps, all_trim.cps, &quot;optimal_full&quot;), wrap_match_entries(genetic_trim_comb.cps, all_trim.cps, &quot;genetic&quot;), wrap_match_entries(exact_trim_comb.cps, all_trim.cps, &quot;exact&quot;), wrap_match_entries(cem_trim_comb.cps, all_trim.cps, &quot;cem&quot;), wrap_match_entries(subcl_trim_comb.cps, all_trim.cps, &quot;subcl&quot;) ) match_lookup_psid &lt;- c( wrap_match_entries(nn_trim_comb.psid, all_trim.psid, &quot;nn&quot;), wrap_match_entries(k2_trim_comb.psid, all_trim.psid, &quot;k2&quot;), wrap_match_entries(k3_trim_comb.psid, all_trim.psid, &quot;k3&quot;), wrap_match_entries(caliper_trim_comb.psid, all_trim.psid, &quot;caliper&quot;), wrap_match_entries(cs_trim_comb.psid, all_trim.psid, &quot;cs&quot;), wrap_match_entries(mahvars_trim_comb.psid, all_trim.psid, &quot;mahvars&quot;), wrap_match_entries(optimal_pair_trim_comb.psid, all_trim.psid, &quot;optimal_pair&quot;), wrap_match_entries(optimal_full_trim_comb.psid, all_trim.psid, &quot;optimal_full&quot;), wrap_match_entries(genetic_trim_comb.psid, all_trim.psid, &quot;genetic&quot;), wrap_match_entries(exact_trim_comb.psid, all_trim.psid, &quot;exact&quot;), wrap_match_entries(cem_trim_comb.psid, all_trim.psid, &quot;cem&quot;), wrap_match_entries(subcl_trim_comb.psid, all_trim.psid, &quot;subcl&quot;) ) list_cps &lt;- c(all_trim.cps, match_lookup_cps) list_psid &lt;- c(all_trim.psid, match_lookup_psid) # create samples corresponding to the top 5 methods for each sample top5_samples.cps &lt;- create_top5_samples(list_cps, top5_methods.cps) top5_samples.psid &lt;- create_top5_samples(list_psid, top5_methods.psid) # extract top 5 objects top5_objects.cps &lt;- lapply(top5_methods.cps, function(d) list_cps[[d]]) top5_objects.psid &lt;- lapply(top5_methods.psid, function(d) list_psid[[d]]) # save samples into .RData files save_top5_samples(list_cps, top5_methods.cps, prefix = &quot;ldw_model_a_cps1&quot;) save_top5_samples(list_psid, top5_methods.psid, prefix = &quot;ldw_model_a_psid1&quot;) 2.7 Estimating 2.7.1 Average treatment effect on the treated (ATT) Next, we estimate the average treatment effect on the treated (ATT) using the LDW-Experimental sample, the top‑ranked observational samples (LDW‑CPS-1 and LDW‑PSID-1), and, for comparison, the plus‑samples. We employ a suite of estimators, including difference-in-means, regression adjustment, the Oaxaca-Blinder estimator, generalized random forests (GRF) as an outcome model, 1:5 nearest neighbor matching with bias correction, inverse probability weighting (IPW) with GRF-based propensity scores, covariate balancing propensity score (CBPS), entropy balancing, double/debiased machine learning using elastic net, and augmented inverse probability weighting via GRF (AIPW-GRF). We also incorporate the recently introduced estimand-specific AIPW estimator implemented through an expansion of the OutcomeWeights R package by Knaus and Pfleiderer (2024) (AIPW-OW). We utilize the estimate_all() and plot_coef() functions as defined by Imbens and Xu (2024). # estimate ATT out1 &lt;- estimate_all(ldw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(ldw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(ldw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps &lt;- lapply(top5_samples.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid &lt;- lapply(top5_samples.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.cps_trim &lt;- lapply(all_trim.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid_trim &lt;- lapply(all_trim.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) load(&quot;data/trimmed.RData&quot;) out4 &lt;- estimate_all(ldw_trim_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(ldw_trim_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out6 &lt;- estimate_all(ldw_cps_trim, &quot;re78&quot;, &quot;treat&quot;, covar) out7 &lt;- estimate_all(ldw_psid_trim, &quot;re78&quot;, &quot;treat&quot;, covar) In each plot the black dots represent the ATT point estimates from the respective sample. The red dashed line indicates the respective benchmark and the light red band the 95% confidence interval. par(mfrow = c(4, 1), mar = c(4, 4, 2, 2)) # get experimental benchmark band.exp &lt;- out1[1, 3:4] est.exp &lt;- out1[1, 1] # plot results plot_coef(out1, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(A) LDW-Experimental&quot;) plot_coef(out2, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(B) LDW-CPS-1&quot;) plot_coef(out3, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(C) LDW-PSID-1&quot;) # get benchmarks method_names_cps &lt;- sapply(top5_methods.cps, function(m) { matches &lt;- names(out.cps_trim)[sapply(names(out.cps_trim), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) method_names_psid &lt;- sapply(top5_methods.psid, function(m) { matches &lt;- names(out.cps_trim)[sapply(names(out.cps_trim), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) band.cps &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]][1, 3:4]) est.cps &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]][1, 1]) band.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 3:4]) est.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 1]) # plot results for (i in seq_along(out.cps)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+3], &quot;) Top CPS-1: &quot;, top5_methods.cps[i]) plot_coef(out.cps[[i]], band = band.cps[[i]], line = est.cps[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 2.6: FIGUREA2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.7: FIGUREA2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples for (i in seq_along(out.psid)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+8], &quot;) Top PSID-1: &quot;, top5_methods.psid[i]) plot_coef(out.psid[[i]], band = band.psid[[i]], line = est.psid[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 2.8: FIGUREA2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples # get benchmarks band.cps_plus &lt;- out4[1, 3:4] est.cps_plus &lt;- out4[1, 1] band.psid_plus &lt;- out5[1, 3:4] est.psid_plus &lt;- out5[1, 1] # plot results plot_coef(out6, band = band.cps_plus, line = est.cps_plus, ylim = c(-15500, 5500), main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;) plot_coef(out7, band = band.psid_plus, line = est.psid_plus, ylim = c(-15500, 5500), main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) Figure 2.9: FIGUREA2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples # get all outputs all_outs &lt;- c(list(out1, out2, out3), out.cps, out.psid, list(out6, out7)) # get all plot titles all_plot_titles &lt;- c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS-1&quot;, &quot;(C) LDW-PSID-1&quot;, paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps), paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid), &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;, &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) # get all confidence interval bounds all_bands &lt;- c(list(band.exp, band.exp, band.exp), band.cps, band.psid, list(band.cps_plus, band.psid_plus)) all_ests &lt;- c(list(est.exp, est.exp, est.exp), est.cps, est.psid, list(est.cps_plus, est.psid_plus)) # save results save_att_panels( out_list = all_outs, plot_titles = all_plot_titles, band_list = all_bands, est_list = all_ests, prefix = &quot;ldw_model_a_est_comb&quot; ) The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS-1, LDW-PSID-1, a series of top-ranked samples of both LDW-CPS-1 and LDW-PSID-1 based on various trimming and integrated trimming and matching criteria and trimmed and matched versions of the LDW-CPS-1-PLUS and LDW-PSID-1-PLUS samples (similar to Imbens and Xu (2024)). Figure (A) presents the benchmark from the experimental sample (LDW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the original observational samples, LDW-CPS-1 and LDW-PSID-1, while figures (D) through (H) display results for LDW-CPS-1-based samples constructed with the top-ranked methods. Analogously, figures (I) through (M) summarize results for the corresponding LDW-PSID-1-based samples under parallel rules. Figures (N) and (O) present results for the trimmed and matched versions of the LDW-CPS-1-PLUS and LDW-PSID-1-PLUS, replicating the tutorial results of Imbens &amp; Xu (2024). The LDW-CPS-1 sample produces ATT estimates that closely align with the experimental benchmark with an exception for one estimator. Its top-ranked samples produce ATT estimates that are consistently positive and cluster reasonably close around the benchmark, except for the cem_stuermer (G) sample that exhibits somewhat larger deviations from the benchmark and increased standard errors. In contrast, the LDW-PSID-1 sample and its top-ranked samples frequently exhibit greater dispersion and substantially higher standard errors compared to the LDW-CPS-1 samples, while almost all its ATT estimates are negative. Further, while ATT estimates for LDW-CPS1-PLUS overly resemble those obtained from respective non-plus samples, the LDW-PSID-PLUS sample produces ATT estimates notably closer to the benchmark compared to all LDW-PSID-1-based samples, demonstrating that the trimmed and matched approach of the extended sample may improve the accuracy of the ATT estimates. # evaluate results all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- all_plot_titles # print table output datatable(att_summary, caption = &quot;ATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The ATT results are presented in the table below. # get result matrix out.cps_top &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]]) out.psid_top &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]]) all_out_mat &lt;- c(list(out1), out.cps_top, out.psid_top, list(out4, out5)) result_mat &lt;- create_matrix_results(all_outs, all_out_mat, all_plot_titles) # print table output datatable(result_mat, caption = &quot;ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The first value in each cell represents the point estimate from the respective estimator and sample. The number in brackets directly following shows the robust standard error (SE) associated with that estimate, indicating the uncertainty or variability around the point estimate. The tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS-1 sample, and column (C) for the LDW-PSID-1 sample. Columns (D)-(O) summarize the top-ranked sample results for both LDW-CPS-1 and LDW-PSID-1. Columns (N) and (O) present estimates for the trimmed and matched versions of the LDW-PSID-1-PLUS and LDW-PSID-1-PLUS samples. For most LDW-CPS-1-based samples, estimates remain not only positive but also comparatively close to the experimental benchmark, with moderate variance inflation. In contrast, the LDW-PSID-1-based samples produce estimates that exhibit greater variability, more frequently negative values, and larger standard errors, reflecting an increased challenge of achieving adequate estimates in the LDW-PSID-1 sample. Overall, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental effect estimation, and that certain criteria can bring observational estimates closer to the benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;ldw_att_est_model_a&quot;) Improved overlap generally leads to estimates closer to the experimental benchmark, but often at the cost of increased standard errors. This trade-off highlights the need to carefully balance bias reduction against precision when selecting methods for robust causal inference. Next, we explore alternative estimands such as heterogeneous treatment effects and quantile treatment effects, which may provide deeper insights into the validity of the unconfoundedness assumption. 2.7.2 Conditional average treatment effect on the treated (CATT) CATT enables analysis of treatment effect heterogeneity across covariate-defined subpopulations. We estimate the CATT for the same samples previously considered in the ATT estimation by AIPW-GRF via the catt() function established by Imbens and Xu (2024). # estimate CATT catt.ldw &lt;- catt(ldw, Y, treat, covar) catt.cps &lt;- catt(ldw_cps, Y, treat, covar) catt.psid &lt;- catt(ldw_psid, Y, treat, covar) catt.top5_cps &lt;- lapply(top5_samples.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid &lt;- lapply(top5_samples.psid, function(d) catt(d, Y, treat, covar)) catt.top5_cps_trim &lt;- lapply(all_trim.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) catt(d, Y, treat, covar)) # similar to Imbens &amp; Xu (2024) catt.trim_cps &lt;- catt(ldw_trim_cps, Y, treat, covar) catt.trim_psid &lt;- catt(ldw_trim_psid, Y, treat, covar) catt.cps_trim &lt;- catt(ldw_cps_trim, Y, treat, covar) catt.psid_trim &lt;- catt(ldw_psid_trim, Y, treat, covar) Then, we employ the function plot_catt() from Imbens and Xu (2024) to visualize the results for the initial observational samples and plus-samples, as well as a modified version of this function for the remaining samples. This approach plots the estimated CATTs for all samples at the covariate values of each treated unit against their corresponding benchmarks. In the CATT plots, the gray dots represent pairs of CATT estimates, while the red crosses indicate pairs of estimated ATTs. par(mfrow = c(2,2)) par(cex.main = 0.9) # plot results plot_catt( catt1 = catt.ldw$catt, catt2 = catt.cps$catt, att1 = catt.ldw$att[1], att2 = catt.cps$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS-1)&quot;, main = &quot;(B) LDW-CPS-1&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 = catt.ldw$catt, catt2 = catt.psid$catt, att1 = catt.ldw$att[1], att2 = catt.psid$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID-1)&quot;, main = &quot;(C) LDW-PSID-1&quot;, axes.range = c(-8000, 8000) ) plot_catt_panels( exp_catt = catt.top5_cps_trim, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps) ) Figure 2.10: FIGUREA3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 2.11: FIGUREA3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental plot_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid) ) Figure 2.12: FIGUREA3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 2.13: FIGUREA3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental plot_catt( catt1 &lt;- catt.trim_cps$catt, catt2 &lt;- catt.cps_trim$catt, att1 &lt;- catt.trim_cps$att[1], att2 &lt;- catt.cps_trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS-1-PLUS-Trimmed)&quot;, main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 &lt;- catt.trim_psid$catt, catt2 &lt;- catt.psid_trim$catt, att1 &lt;- catt.trim_psid$att[1], att2 &lt;- catt.psid_trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID-1-PLUS-Trimmed)&quot;, main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;, axes.range = c(-8000, 8000) ) Figure 2.14: FIGUREA3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid), catt.top5_cps, catt.top5_psid, list(catt.cps_trim, catt.psid_trim)) # evaluate results all_catt_eval &lt;- eval_catt(all_catt, all_plot_titles) # print table output datatable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) Specifically, with the LDW-CPS-1 sample, CATT estimates span from $-5,334.04 to $6,947.08, contrasting with the CATT estimated from experimental data (LDW-Experimental) which ranges from $-106.73 to $4009.54, with a mean CATT estimate of $1,748.62. The LDW-PSID-1 sample shows an even broader CATT estimate range, spanning from $-8,552.26 to $4,635.64, and a notably lower mean of approximately $766.50. Among the top-ranked LDW-CPS-1 samples, CATT ranges vary substantially, yet their mean estimates are generally closer to the experimental benchmark compared to the LDW-CPS-1 sample. The sample cs_crump (E) produces the minimum CATT estimate among corresponding top-ranked samples, but still produces a positive mean CATT estimate. The CATT estimates for the LDW-PSID-1 top-ranked samples reveal substantially decreased mean CATT estimates compared to the LDW-CPS-1 top-ranked samples, reflecting greater difficulties in producing reliable treatment effect estimates. The mean CATT estimate for the trimmed and matched version of the LDW-CPS-1-PLUS sample aligns more closely with the benchmark, whereas for the trimmed and matched version of the LDW-PSID-1-PLUS sample the mean CATT estimates remains notably lower. This variation in range and means across methods and samples reflects substantial heterogeneity in treatment effect estimation, indicating that while some criteria improve alignment with the experimental benchmark, others introduce considerable discrepancies and variability in estimated heterogeneous effects. # save results save_main_catt_panels( catt_refs = list(catt.ldw), catt_comps = list(catt.cps, catt.psid), ylabels = c(&quot;CATT (CPS-1)&quot;, &quot;CATT (PSID-1)&quot;), prefix = &quot;ldw_model_a_catt_main_panels&quot;, main_titles = c(&quot;(B) LDW-CPS-1&quot;, &quot;(C) LDW-PSID-1&quot;) ) save_catt_panels( exp_catt = catt.top5_cps_trim, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps), prefix = &quot;ldw_model_a_catt_top5_cps&quot; ) save_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid), prefix = &quot;ldw_model_a_catt_top5_psid&quot; ) save_plus_catt_panels( catt1_list = list(catt.trim_cps, catt.trim_psid), catt2_list = list(catt.cps_trim, catt.psid_trim), ylabels = c(&quot;CATT (Trimmed CPS-1-PLUS)&quot;, &quot;CATT (Trimmed PSID-1-PLUS)&quot;), prefix = &quot;ldw_model_a_catt_plus_panels&quot;, main_titles = c(&quot;(N) LDW-CPS-1-PLUS&quot;, &quot;(O) LDW-PSID-1-PLUS&quot;) ) 2.7.3 Quantile treatment effect on the treated (QTET) QTET provides a robust way to analyze treatment effect heterogeneity while being less impacted by outliers compared to average treatment effect measures. The QTET estimates are obtained using the propensity score re-weighting method introduced by Firp (2007), implemented through the est_qte() function established by Imbens and Xu (2024). Visualization is conducted using their plot_qte() function and a modified version thereof. # estimate QTET qte.ldw &lt;- est_qte(Y, treat, covar, data = ldw, cores = 4) qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) qte.top5_cps &lt;- lapply(top5_samples.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid &lt;- lapply(top5_samples.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_cps_trim &lt;- lapply(all_trim.cps, function(d) est_qte_safe(Y, treat, covar, data = d)) qte.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) est_qte_safe(Y, treat, covar, data = d)) qte.trim.ldw_cps &lt;- est_qte(Y, treat, NULL, data = ldw_trim_cps) qte.trim.ldw_psid &lt;- est_qte(Y, treat, NULL, data = ldw_trim_psid) qte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps_trim) qte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid_trim) qte.ldw0 &lt;- est_qte(Y, treat, NULL, data = ldw) qte.ldw_cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) qte.ldw_psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) qte.top5_cps_trim0 &lt;- lapply(top5_samples.cps, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid_trim0 &lt;- lapply(top5_samples.psid, function(d) est_qte(Y, treat, NULL, data = d)) qte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps_trim) qte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid_trim) Each QTET plot displays three distinct series for every sample analyzed: (1) The blue line with diamond-shaped points represents QTET estimates derived from the experimental sample, serving as the benchmark. (2) The red line with triangles shows QTET estimates from the observational data before any adjustment. (3) The black line with circles presents QTET estimates for the observational data after applying covariate adjustment. par(mfrow = c(2,2)) par(cex.main = 0.9) ylim = c(-25000, 15000) # plot results plot_qte(qte.ldw_cps, qte.ldw_cps0, qte.ldw, main = &quot;(B) LDW-CPS-1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte(qte.ldw_psid, qte.ldw_psid0, qte.ldw, main = &quot;(C) LDW-PSID-1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte_top(qte.top5_cps_trim, qte.top5_cps_trim0, qte.top5_cps, all_plot_titles, main_start = 4) Figure 2.15: FIGUREA4. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental plot_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 9) Figure 2.16: FIGUREA4. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 2.17: FIGUREA4. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.trim.ldw_cps, main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.trim.ldw_psid, main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 2.18: FIGUREA4. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the experimental and various observational samples. The QTETs estimated from the LDW-CPS-1 sample (B) and their top-ranked samples (D, E and H), except for k2_crump (F) and cem_stuermer (G), corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the trimmed and matched version of LDW-CPS-1-PLUS (N) also correspond well with the true QTET. The QTET estimates from the LDW-PSID-1 (C) and their top-ranked samples (I-M) show clear biases and noticeably wider confidence bands when compared to the experimental benchmark, which clusters near zero, indicating greater estimation uncertainty. Only the top-ranked samples mahvars_walker (L) and k2_walker (K) produce QTET estimates that are slightly closer to the true QTET. The QTET estimates from the trimmed and matched version of LDW-PSID-1-PLUS (N) also exhibit clear biases. # list results plots_ldw &lt;- list( list(mod = qte.ldw_cps, mod0 = qte.ldw_cps0, bm = qte.ldw, main = &quot;(B) LDW-CPS-1&quot;), list(mod = qte.ldw_psid, mod0 = qte.ldw_psid0, bm = qte.ldw, main = &quot;(C) LDW-PSID-1&quot;), list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.trim.ldw_cps, main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;), list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.trim.ldw_psid, main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) ) # save results save_qtet(plots_ldw, prefix = &quot;ldw_model_a&quot;) save_qte_top(qte.top5_cps_trim, qte.top5_cps_trim0, qte.top5_cps, all_plot_titles, main_start = 4, prefix = &quot;ldw_model_a_top&quot;) save_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 9, prefix = &quot;ldw_model_a_top&quot;) 2.7.4 Assessing outcome weights (OW) The outcome weights are not obtained directly from the ATT point estimates due to computational design of other methods. Instead, the ATT is separately estimated for each sample following the approach developed by Knaus and Pfleiderer (2024). Subsequently, the outcome weights are derived and analysed. # list all samples all_samples &lt;- c(list(ldw, ldw_cps, ldw_psid), top5_samples.cps, top5_samples.psid, list(ldw_trim_cps, ldw_trim_psid)) # estimate ATT res_att &lt;- get_res_att(all_samples, Y, treat, covar) ## OUTCOME WEIGHTS SUMMARY: 15 succeeded, 0 failed out of 15 samples # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.9) # plot outcome weights distribution plot_ow(ow_att, all_plot_titles) Figure 2.19: FIGUREA5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model A using LDW Data Figure 2.20: FIGUREA5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model A using LDW Data Figure 2.21: FIGUREA5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model A using LDW Data Figure 2.22: FIGUREA5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model A using LDW Data The results of the behavior of outcome weights are presented in the table below. # evaluate results res_ow &lt;- eval_ow(ow_att, all_samples, all_plot_titles, treat, &quot;AIPW-ATT&quot;) # print table output datatable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The evaluation reveals that across each sample the estimated outcome weights sum to one within the treated group and minus one within the untreated group, resulting in an overall sum of zero. Note, that minor deviations from exact values are attributable to floating-point rounding error in numerical summation. #save results save_ow(ow_att, all_plot_titles, prefix = &quot;ldw_model_a&quot;) save_csv(res_ow, &quot;ldw_model_a_ow&quot;) 2.8 Validation through placebo analyses To further evaluate the credibility of the unconfoundedness assumption, a placebo analysis is performed by designating 1975 earnings (re75) as the (placebo) outcome variable and omitting both re75 and u75 from the set of covariates. The analysis uses all previously considered samples and recomputes the ATT via the function estimate_all, initially established by Imbens and Xu (2024) and adapted for specific purposes within this study, conditioning only on the remaining set of covariates. # define variables Y &lt;- &quot;re75&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;u74&quot;) # estimate placebo ATT on original and observational samples out1_pl &lt;- estimate_all(ldw, Y, &quot;treat&quot;, covar) out2_pl &lt;- estimate_all(ldw_cps, Y, &quot;treat&quot;, covar) out3_pl &lt;- estimate_all(ldw_psid, Y, &quot;treat&quot;, covar) # estimate placebo ATT on top ranked samples out.cps_pl &lt;- lapply(top5_samples.cps, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.psid_pl &lt;- lapply(top5_samples.psid, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.cps_trim_pl &lt;- lapply(all_trim.cps, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.psid_trim_pl &lt;- lapply(all_trim.psid, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) # estimate placebo ATT on plus samples load(&quot;data/trimmed.RData&quot;) out4_pl &lt;- estimate_all(ldw_trim_cps_pl, Y, &quot;treat&quot;, covar) out5_pl &lt;- estimate_all(ldw_trim_psid_pl, Y, &quot;treat&quot;, covar) out6_pl &lt;- estimate_all(ldw_cps_trim_pl, Y, &quot;treat&quot;, covar) out7_pl &lt;- estimate_all(ldw_psid_trim_pl, Y, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 1)) # get experimental benchmark band.exp_pl &lt;- out1_pl[1, 3:4] est.exp_pl &lt;- out1_pl[1, 1] # plot placebo results plot_coef(out1_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(A) LDW-Experimental&quot;) plot_coef(out2_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(B) LDW-CPS-1&quot;) plot_coef(out3_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(C) LDW-PSID-1&quot;) # get benchmarks method_names_cps &lt;- sapply(top5_methods.cps, function(m) { matches &lt;- names(out.cps_trim_pl)[sapply(names(out.cps_trim_pl), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) method_names_psid &lt;- sapply(top5_methods.psid, function(m) { matches &lt;- names(out.psid_trim_pl)[sapply(names(out.psid_trim_pl), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) band.cps_pl &lt;- lapply(method_names_cps, function(j) {as.numeric(out.cps_trim_pl[[j]][1, 3:4])}) est.cps_pl &lt;- lapply(method_names_cps, function(j) out.cps_trim_pl[[j]][1, 1]) band.psid_pl &lt;- lapply(method_names_psid, function(j) {as.numeric(out.psid_trim_pl[[j]][1, 3:4])}) est.psid_pl &lt;- lapply(method_names_psid, function(j) out.psid_trim_pl[[j]][1, 1]) # plot placebo results for (i in seq_along(out.cps_pl)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+3], &quot;) Top CPS-1: &quot;, top5_methods.cps[i]) plot_coef(out.cps_pl[[i]], band = band.cps_pl[[i]], line = est.cps_pl[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 2.23: FIGUREA6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model A: ’75 Earnings as the Outcome Figure 2.24: FIGUREA6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model A: ’75 Earnings as the Outcome for (i in seq_along(out.psid_pl)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+8], &quot;) Top PSID-1: &quot;, top5_methods.psid[i]) plot_coef(out.psid_pl[[i]], band = band.psid_pl[[i]], line = est.psid_pl[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 2.25: FIGUREA6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model A: ’75 Earnings as the Outcome # get benchmarks band.cps_plus_pl &lt;- out4_pl[1, 3:4] est.cps_plus_pl &lt;- out4_pl[1, 1] band.psid_plus_pl &lt;- out5_pl[1, 3:4] est.psid_plus_pl &lt;- out5_pl[1, 1] # plot placebo results plot_coef(out6_pl, band = band.cps_plus_pl, line = est.cps_plus_pl, ylim = c(-12000, 2000), main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;) plot_coef(out7_pl, band = band.psid_plus_pl, line = est.psid_plus_pl, ylim = c(-12000, 2000), main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) Figure 2.26: FIGUREA6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model A: ’75 Earnings as the Outcome # combine all results all_outs_pl &lt;- c(list(out1_pl, out2_pl, out3_pl), out.cps_pl, out.psid_pl, list(out6_pl, out7_pl)) all_bands_pl &lt;- c(list(band.exp_pl, band.exp_pl, band.exp_pl), band.cps_pl, band.psid_pl, list(band.cps_plus_pl, band.psid_plus_pl)) all_ests_pl &lt;- c(list(est.exp_pl, est.exp_pl, est.exp_pl), est.cps_pl, est.psid_pl, list(est.cps_plus_pl, est.psid_plus_pl)) # save results save_att_panels( out_list = all_outs_pl, plot_titles = all_plot_titles, band_list = all_bands_pl, est_list = all_ests_pl, prefix = &quot;ldw_model_a_pl_est_comb&quot; ) The placebo ATT results are presented in the table below. # get all placebo results all_outs_pl &lt;- c(list(out1_pl, out2_pl, out3_pl), out.cps_pl, out.psid_pl, list(out6_pl, out7_pl)) out.cps_top_pl &lt;- lapply(method_names_cps, function(j) out.cps_trim_pl[[j]]) out.psid_top_pl &lt;- lapply(method_names_psid, function(j) out.psid_trim_pl[[j]]) all_out_mat_pl &lt;- c(list(out1_pl), out.cps_top_pl, out.psid_top_pl, list(out4_pl, out5_pl)) # create result matrix result_mat_pl &lt;- create_matrix_results(all_outs_pl, all_out_mat_pl, all_plot_titles) # print table output datatable(result_mat_pl, caption = &quot;Placebo ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The placebo analysis reveals that the experimental benchmark is positive, near zero and statistically insignificant, while all benchmarks for the top-ranked samples negative and all estimators applied to the observational samples, LDW-CPS-1 and LDW-PSID-1, yield by majority large, negative ATT estimates. For LDW-CPS-1 (B), most ATT estimates are negative. For LDW-CPS-1 top-ranked samples (D-H), ATT estimates remain largely negative with only a few exceptions but show reasonable improvement in ATT estimates towards the benchmark and overly decreased standard errors compared to the LDW-CPS-1 (B) sample, still indicating persistent bias. For LDW-PSID-1 top-ranked samples (I-M) a similar pattern results compared to the LDW-PSID-1 sample. The trimmed and matched versions of LDW-CPS-1-PLUS and LDW-PSID-1-PLUS exhibit mainly even larger negative ATT estimates compared to the initial observational samples, reflecting substantial bias and deviation from the true effect. Overall, across most observational samples and estimators, the placebo test produces ATT estimates that are substantially biased and far from the benchmark. This highlights the persistent challenge in recovering unbiased ATT estimates outside of experimental data. # save results save_csv(result_mat_pl, &quot;ldw_att_estimates_pl_model_a&quot;) 2.9 Validation through sensitivity analyses Finally, a sensitivity analyses using the LDW data is conducted and results are depicted in contour plots using the function sens_ana introduced by Imbens and Xu (2024). # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid samples filtered_samples_sens &lt;- check_filter_samples(all_samples, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid samples and plot results for (i in seq_along(filtered_samples_sens)) { sens_ana(filtered_samples_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = all_plot_titles[i]) } Figure 2.27: FIGUREA7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model A Figure 2.28: FIGUREA7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model A Figure 2.29: FIGUREA7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model A Figure 2.30: FIGUREA7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model A # save results save_sensitivity_plots(filtered_samples_sens, Y, treat, covar, bm, all_plot_titles, &quot;ldw_model_a&quot;) ## SUMMARY: Sensitivity plots - 15 succeeded, 0 failed out of 15 total The sensitivity analysis shows that for the LDW-Experimental sample, as well as for the LDW-CPS-1 (B) and its top-ranked samples nn_crump, cs_crump,k2_crump and genetic_crump (D-F and H) the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of the confounder. For the trimmed and matched LDW-CPS1-PLUS and LDW-PSID-1-PLUS samples (N-O) the estimated treatment effects remain also consistently robust, indicating improved resistance to unmeasured confounding. For the top-ranked sample cem_stuermer (G) of the LDW-CPS-1 sample as well as for the LDW-PSID-1 sample (C) and all its top-ranked samples (I-M) the estimated treatment effects are sensitive to unmeasured confounding with more pronounced swings, as evidenced by sizable shifts in the estimates. Overall, these results highlight sample-specific differences in robustness against potential unobserved confounding. The analyses suggest that some samples maintain stable treatment effect estimates despite increasing confounder strength, while others show greater sensitivity. This highlights the importance of assessing robustness across different samples (respectively methods used to derive specific samples) to account for potential unobserved confounding. 2.10 Inspection of re74 and re75 2.10.1 Correlation To evaluate potential collinearity between re74 and re75, we compute their correlation. To determine whether re74 may act as a confounder in the treatment effect estimation, we report its correlation with both the treatment assignment (treat) and the outcome (re78). # compute correlations cor_treat &lt;- sapply(all_samples, function(d) cor(d$re74, d$treat, use = &quot;complete.obs&quot;)) cor_outcome &lt;- sapply(all_samples, function(d) cor(d$re74, d$re78, use = &quot;complete.obs&quot;)) cor_cov &lt;- sapply(all_samples, function(d) cor(d$re74, d$re75, use = &quot;complete.obs&quot;)) cor_table &lt;- data.frame(Method = all_plot_titles, Cor_re74_treat = cor_treat, Cor_re74_out = cor_outcome, Cor_re74_re75 = cor_cov) # print table output datatable(cor_table, caption = &quot;Correlations of re74 with treatment and outcome across samples&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The tabulated results indicate that 1974 earnings (re74) is effectively independent of the treatment assignment across all samples, with correlations ranging from approximately −0.32 to 0.18. In contrast, 1974 earnings exhibits moderately strong positive correlations with the outcome, ranging from approximately −0.03 to 0.70, suggesting that this pretreatment characteristic constitutes a meaningful confounder of post-program earnings, but not an important determinant of the treatment assignment. Further, 1974 earnings exhibits substantial correlation with 1975 earnings, implying considerable collinearity between these two lagged covariates and suggesting that the informational gain from including both may be limited. Overall, these results do not provide clear guidance on whether to include 1974 earnings in the set of covariates, but suggest that one should weigh the trade-off between potential omitted variable bias and increased collinearity when making covariate selection decisions. # save results save_csv(cor_table, &quot;ldw_model_a_corr_results&quot;) 2.10.2 Distributional balance To further assess the risk of confounding, we examine the distributional balance of re74 and, for comparison, of re75 by plotting their density distributions for treated and control units. As model B intentionally omits re74, the analysis directly informs whether any covariate imbalance may induce bias in estimated treatment effects. # re75 for (i in seq_along(all_samples)) { tryCatch({ print( bal.plot(treat ~ re75, data = all_samples[[i]], which = &quot;both&quot;) + ggplot2::ggtitle(all_plot_titles[i]) ) }, error = function(e) { cat(sprintf(&quot;Could not plot %s: %s\\n&quot;, all_plot_titles[i], e$message)) }) } Figure 2.31: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.32: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.33: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.34: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.35: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.36: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.37: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.38: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.39: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.40: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.41: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.42: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.43: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.44: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.45: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 # re74 for (i in seq_along(all_samples)) { tryCatch({ print( bal.plot(treat ~ re74, data = all_samples[[i]], which = &quot;both&quot;) + ggplot2::ggtitle(all_plot_titles[i]) ) }, error = function(e) { cat(sprintf(&quot;Could not plot %s: %s\\n&quot;, all_plot_titles[i], e$message)) }) } Figure 2.46: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.47: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.48: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.49: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.50: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.51: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.52: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.53: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.54: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.55: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.56: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.57: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.58: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.59: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 2.60: FIGUREA8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 # save results save_balance(all_samples, all_plot_titles, balance_var = &quot;re75&quot;, prefix = &quot;ldw_model_a_balance_panels_75&quot;) save_balance(all_samples, all_plot_titles, balance_var = &quot;re74&quot;, prefix = &quot;ldw_model_a_balance_panels_74&quot;) The density plots indicate that treated and control units do not substantially differ in re74 across all samples. However, clear while moderate discrepancies are present in the top‑ranked LDW–PSID‑1 samples. The corresponding plots for re75 show a broadly comparable degree of difference but slightly more pronounced distributional differences between treated and control units across most samples. Overall, this pattern suggests that the risk of confounding from re74 is limited and that the bias from omitting re74 from the covariate set is reasonably small. Thus, considering the pronounced collinearity with 1975 earnings, the moderate correlation with the outcome, and the minor balance concerns, 1974 earnings may be excluded from the covariate set. However, whether its inclusion or exclusion materially affects the treatment effect estimates warrants validation. Accordingly, model B is specified without 1974 earnings and the complete analysis is redone. 2.11 Summary After reexamining model A, that is based on the LDW sample, several insights emerge. First, we confirm that ensuring overlap between treated and control groups remains crucial for credible causal estimation. The LDW-Experimental sample exhibits almost perfect overlap, while the observational samples show poorer overlap, with many treated units outside the control range. Second, controlling for covariates such as age, education, race, and prior earnings, and using various methods including trimming, and integrated approaches, largely yields consistent effect estimates. Thereby, the propensity score plays an important role in constructing samples and assessing overlap between groups. Further, placebo tests and sensitivity analyses reveal lingering concerns about the unconfoundedness assumption and robustness of some estimators. The correlation and balance analysis reveals that its important to control for 1975 earnings, while for 1974 earnings it may be limited, although this warrants further investigation. Overall, this section highlights the importance of overlap, the utility of propensity scores, and the need for rigorous validation of the unconfoundedness assumption to produce credible effect estimates. References Firp, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Greifer, Noah. 2025. “Matching Methods.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” Stürmer, Til, Michael Webster-Clark, Jennifer L. Lund, Richard Wyss, Alan R. Ellis, Mark Lunt, Kenneth J. Rothman, and Robert J. Glynn. 2021. “Propensity Score Weighting and Trimming Strategies for Reducing Variance and Bias of Treatment Effect Estimates: A Simulation Study.” American Journal of Epidemiology. "],["lalonde-dehejia-wahba-ldw-data-1.html", "Chapter 3 LaLonde-Dehejia-Wahba (LDW) Data 3.1 Set up 3.2 LDW-Model B 3.3 Pre-assessing methods 3.4 Improving overlap 3.5 Post-assessing methods 3.6 Identifying most efficient methods 3.7 Estimating 3.8 Validation through placebo analyses 3.9 Validation through sensitivity analyses 3.10 Inspection of re74 and re75 3.11 Summary", " Chapter 3 LaLonde-Dehejia-Wahba (LDW) Data This section (3) covers model B, which, similar to model A, uses 1978 earnings (re78) as the outcome variable but adjusts for a slightly different set of covariates: age, education, race indicators (black, hispanic), marital status (married), high school dropouts (nodegree), 1975 earnings (re75), and unemployment status in 1974 and 1975 (u74, u75), explicitly excluding 1974 earnings (re74) to identify potential multicollinearity or confounding. The model is specified via a regression formula based on these covariates. To enhance covariate balance between treated and untreated groups, the same comprehensive suite of methods is employed as in model A, organized into two categories. From these approaches, the top five methods are selected based on a the overlapping coefficient (OVL) and reranked by the mean absolute standardized mean difference (ASMD), and their resulting samples are used to inform subsequent analysis. Notably, the estimation of the average treatment effect on the treated (ATT) incorporates also incorporates the augmented inverse probability weighting (AIPW) estimator from the OutcomeWeights R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (re75) as the outcome variable to assess potential biases and the validity of the unconfoundedness assumption. Finally, sensitivity analyses are performed to evaluate the robustness of the treatment effect estimates to violations of these assumptions. For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the model B–specific results. 3.1 Set up 3.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 3.1.2 Inspect data # collect samples in a list data &lt;- list(ldw = ldw, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid) # print and inspect key metrics of each sample summary_stats &lt;- inspect_data(data) datatable(summary_stats, caption = &quot;Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) 3.1.3 Load and preprocess data # assigns 1 to the experimental controls ldw_co$treat &lt;- 1 # merge experimental data with CPS-1 data ldw_cps_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_cps # CPS-1 data (16177 observations) ) # merge experimental data with PSID-1 data ldw_psid_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_psid # PSID-1 data (2675 observations) ) samples &lt;- list(ldw_cps_plus = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus) # inspect each sample summary_stats_plus &lt;- inspect_data(samples) datatable(summary_stats_plus, caption = &quot;Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) 3.2 LDW-Model B # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) #re74 excluded # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 3.3 Pre-assessing methods 3.3.1 Overlap ldw.ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar) ## -1.26191 0.7410732 Figure 3.1: FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. ldw_cps.ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar) ## -16.1181 1.813362 Figure 3.2: FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. ldw_psid.ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar) ## -11.47475 3.722802 Figure 3.3: FIGUREB1. SubfigureA:LDW. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. Model B exhibits overlap patterns that are very similar to those observed for model A. As anticipated, LDW-Experimental again exhibits an almost perfect overlap. In contrast, the observational samples LDW-CPS-1 and LDW-PSID-1 show poor overlap. Notably, many treated units have propensity scores outside the range of the controls, while a large share of control units have propensity scores concentrated at very low log-odds. ldw_cps_plus.ps &lt;- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) ## -16.1181 3.425533 Figure 3.4: FIGUREB1. SubfigureD:LDW-CPS-1-PLUS. SubfigureE:LDW-PSID-1-PLUS. ldw_psid_plus.ps &lt;- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) ## -11.65343 7.149751 Figure 3.5: FIGUREB1. SubfigureD:LDW-CPS-1-PLUS. SubfigureE:LDW-PSID-1-PLUS. The LDW-CPS-1-PLUS and LDW-PSID-1-PLUS samples also exhibit improved overlap relative to their non-plus counterparts in model B, as in model A, but again are used here only as reference samples for comparison. # combine results data_list &lt;- list(ldw, ldw_cps, ldw_psid, ldw_cps_plus, ldw_psid_plus) plot_titles &lt;- c(&quot;(A) LDW-Experimental&quot;,&quot;(B) LDW-CPS-1&quot;, &quot;(C) LDW-PSID-1&quot;, &quot;(D) LDW-CPS-1-PLUS&quot;, &quot;(E) LDW-PSID-1-PLUS&quot;) # save results save_overlap_panels( data_list = data_list, treat = treat, covar = covar, plot_titles = plot_titles, prefix = &quot;ldw_overlap_model_b_panels&quot; ) ## -1.26191 0.7410732 ## -16.1181 1.813362 ## -11.47475 3.722802 ## -16.1181 3.425533 ## -11.65343 7.149751 3.4 Improving overlap 3.4.1 Single methods 3.4.1.1 Trimming Propensity score threshold trimming # apply trimming with a (maximum) threshold ldw_cps.ps_trim &lt;- ps_trim(ldw_cps.ps, threshold = 0.9) ldw_psid.ps_trim &lt;- ps_trim(ldw_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.ps_trim &lt;- ps_estimate(data = ldw_cps.ps_trim, treat = treat, cov = covar) ldw_psid.ps_trim &lt;- ps_estimate(data = ldw_psid.ps_trim, treat = treat, cov = covar) Common range trimming # trim observations outside the common support region of propensity scores ldw_cps.ps_common &lt;- common_range_trim(ldw_cps.ps) ldw_psid.ps_common &lt;- common_range_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.ps_common &lt;- ps_estimate(data = ldw_cps.ps_common, treat = treat, cov = covar) ldw_psid.ps_common &lt;- ps_estimate(data = ldw_psid.ps_common, treat = treat, cov = covar) Crump trimming # trim observations with propensity scores outside an interval ldw_cps.ps_crump &lt;- crump_trim(ldw_cps.ps, lower = 0.05, upper = 0.95) ldw_psid.ps_crump &lt;- crump_trim(ldw_psid.ps, lower = 0.05, upper = 0.95) # re-estimate propensity scores on trimmed data ldw_cps.ps_crump &lt;- ps_estimate(data = ldw_cps.ps_crump, treat = treat, cov = covar) ldw_psid.ps_crump &lt;- ps_estimate(data = ldw_psid.ps_crump, treat = treat, cov = covar) Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control ldw_cps.ps_stuermer &lt;- stuermer_trim(ldw_cps.ps) ldw_psid.ps_stuermer &lt;- stuermer_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.ps_stuermer &lt;- ps_estimate(data = ldw_cps.ps_stuermer, treat = treat, cov = covar) ldw_psid.ps_stuermer &lt;- ps_estimate(data = ldw_psid.ps_stuermer, treat = treat, cov = covar) Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations ldw_cps.ps_walker &lt;- walker_trim(ldw_cps.ps) ldw_psid.ps_walker &lt;- walker_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.ps_walker &lt;- ps_estimate(data = ldw_cps.ps_walker, treat = treat, cov = covar) ldw_psid.ps_walker &lt;- ps_estimate(data = ldw_psid.ps_walker, treat = treat, cov = covar) 3.4.2 Integrated methods 3.4.2.1 Trimming and matching 3.4.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # apply trimming with a (maximum) threshold ldw_cps_trim &lt;- ps_trim(ldw_cps_plus.ps, threshold = 0.9) ldw_psid_trim &lt;- ps_trim(ldw_psid_plus.ps, threshold = 0.8) # excluding the experimental controls ldw_cps.trim_match &lt;- subset(ldw_cps_trim, sample %in% c(1,3) &amp; ps_assoverlap) ldw_psid.trim_match &lt;- subset(ldw_psid_trim, sample %in% c(1,4) &amp; ps_assoverlap) # re-estimate propensity scores and employ 1:1 matching ldw_cps.trim_match &lt;- psmatch(data = ldw_cps.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.trim_match &lt;- psmatch(data = ldw_psid.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) # further subset data and re-assign treat variable ldw_trim_cps &lt;- subset(ldw_cps_trim, sample %in% c(1,2) &amp; ps_assoverlap &lt;= 0.9) ldw_trim_cps$treat[which(ldw_trim_cps$sample == 2)] &lt;- 0 ldw_trim_psid &lt;- subset(ldw_psid_trim, sample %in% c(1,2) &amp; ps_assoverlap &lt;= 0.8) ldw_trim_psid$treat[which(ldw_trim_psid$sample == 2)] &lt;- 0 3.4.2.1.2 Initial samples # combine trimmed samples all_trim.cps &lt;- list( ps_threshold = ldw_cps.ps_trim, common_range = ldw_cps.ps_common, stuermer = ldw_cps.ps_stuermer, walker = ldw_cps.ps_walker, crump = ldw_cps.ps_crump) all_trim.psid &lt;- list( ps_threshold = ldw_psid.ps_trim, common_range = ldw_psid.ps_common, stuermer = ldw_psid.ps_stuermer, walker = ldw_psid.ps_walker, crump = ldw_psid.ps_crump) 3.4.2.1.2.1 Distance matching 1:1 Nearest neighbor matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=1, logistic propensity score and replacement nn_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) nn_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) k:1 matching (k=2) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=2, logistic propensity score and replacement k&lt;-2 k2_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k2_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k:1 matching (k=3) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=3, logistic propensity score and replacement k&lt;-3 k3_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k3_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) Caliper matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score and replacement caliper_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) caliper_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) Common support restriction matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with exclusion of units outside common support and replacement cs_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) cs_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) Mahalanobis distance matching (mahvars) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching using mahalanobis distance without replacement mahvars_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) mahvars_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) Optimal pair matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal pair matching that minimizes total within-pair distance on propensity scores optimal_pair_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) optimal_pair_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Optimal full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion optimal_full_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) optimal_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Generalized full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios general_full_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) general_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Genetic matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform genetic matching genetic_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) genetic_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) 3.4.2.1.2.2 Stratum matching Exact matching (exact) # match units exactly by raw covariate profiles exact_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;exact&quot;) exact_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;exact&quot;) Coarsened matching (cem) # match units exactly within coarse strata cem_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cem&quot;) cem_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cem&quot;) Subclassification # partition sample into fixed number of bins based on propensity score subcl_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;subclass&quot;, subclass = 3) subcl_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;subclass&quot;, subclass = 3) 3.4.2.1.2.3 Pure subset selection Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units card_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) card_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact profile_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) profile_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) 3.5 Post-assessing methods 3.5.1 Single methods 3.5.1.1 Trimming 3.5.1.1.1 SMD # compute absolute standardized mean differences smd_trim.cps &lt;- compute_abs_smd_trim(all_trim.cps, &quot;treat&quot;, covar) smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 3.5.1.1.2 OVL # compute overlap coefficients ovl_trim.cps &lt;- compute_ovl_trim(all_trim.cps, &quot;ps_assoverlap&quot;, &quot;treat&quot;) ovl_trim.psid &lt;- compute_ovl_trim(all_trim.psid, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 3.5.2 Integrated methods 3.5.2.1 Trimming and matching 3.5.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # list all trimmed and matched samples trim_match_comb.cps_plus &lt;- list(ps_threshold_match = ldw_cps.trim_match) trim_match_comb.psid_plus &lt;- list(ps_threshold_match = ldw_psid.trim_match) 3.5.2.1.1.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.cps_plus &lt;- compute_abs_smd_trim(trim_match_comb.cps_plus, &quot;treat&quot;, covar) smd_trim_match_comb.psid_plus &lt;- compute_abs_smd_trim(trim_match_comb.psid_plus, &quot;treat&quot;, covar) 3.5.2.1.1.2 OVL # compute overlap coefficients ovl_trim_match_comb.cps_plus &lt;- compute_ovl_trim(trim_match_comb.cps_plus, &quot;ps_assoverlap&quot;, &quot;treat&quot;) ovl_trim_match_comb.psid_plus &lt;- compute_ovl_trim(trim_match_comb.psid_plus, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 3.5.2.1.2 Initial samples # list all trimmed and matched samples trim_match_comb.cps &lt;- list( nn = nn_trim_comb.cps, k2 = k2_trim_comb.cps, k3 = k3_trim_comb.cps, caliper = caliper_trim_comb.cps, cs = cs_trim_comb.cps, mahvars = mahvars_trim_comb.cps, optimal_pair = optimal_pair_trim_comb.cps, optimal_full = optimal_full_trim_comb.cps, genetic = genetic_trim_comb.cps, exact = exact_trim_comb.cps, cem = cem_trim_comb.cps, subcl = subcl_trim_comb.cps ) trim_match_comb.psid &lt;- list( nn = nn_trim_comb.psid, k2 = k2_trim_comb.psid, k3 = k3_trim_comb.psid, caliper = caliper_trim_comb.psid, cs = cs_trim_comb.psid, mahvars = mahvars_trim_comb.psid, optimal_pair = optimal_pair_trim_comb.psid, optimal_full = optimal_full_trim_comb.psid, genetic = genetic_trim_comb.psid, exact = exact_trim_comb.psid, cem = cem_trim_comb.psid, subcl = subcl_trim_comb.psid ) 3.5.2.1.2.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.cps &lt;- compute_abs_smd_matchit(trim_match_comb.cps, all_trim.cps) smd_trim_match_comb.psid &lt;- compute_abs_smd_matchit(trim_match_comb.psid, all_trim.psid) 3.5.2.1.2.2 OVL # compute overlap coefficients ovl_trim_match_comb.cps &lt;- compute_ovl_matchit(trim_match_comb.cps, all_trim.cps, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = covar) ovl_trim_match_comb.psid &lt;- compute_ovl_matchit(trim_match_comb.psid, all_trim.psid, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = covar) 3.6 Identifying most efficient methods 3.6.1 Ranking # combine all results all_cps &lt;- combine_results(&quot;cps&quot;) all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_cps, &quot;ldw_model_b_cps1_all_results&quot;) save_csv(all_psid, &quot;ldw_model_b_psid1_all_results&quot;) # rank comparatively ranked_cps &lt;- assess_methods(all_cps) ranked_psid &lt;- assess_methods(all_psid) # get top 5 methods top5_methods.cps &lt;- get_top_methods(ranked_cps, top_n = 5) top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # rerank top 5 methods top5_methods_df.cps &lt;- ranked_cps %&gt;% arrange(desc(OVL)) %&gt;% head(5) %&gt;% arrange(Mean_Abs_SMD) top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(OVL)) %&gt;% head(5) %&gt;% arrange(Mean_Abs_SMD) # get results top5_methods.cps &lt;- top5_methods_df.cps$Method top5_methods.psid &lt;- top5_methods_df.psid$Method # print table output datatable(top5_methods_df.cps, caption = &quot;Top 5 Methods for CPS-1&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) datatable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID-1&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) # save results save_csv(top5_methods.cps, &quot;ldw_model_b_cps1_top5_methods&quot;) save_csv(top5_methods.psid, &quot;ldw_model_b_psid1_top5_methods&quot;) 3.6.2 Sample construction # create lookup lists match_lookup_cps &lt;- c( wrap_match_entries(nn_trim_comb.cps, all_trim.cps, &quot;nn&quot;), wrap_match_entries(k2_trim_comb.cps, all_trim.cps, &quot;k2&quot;), wrap_match_entries(k3_trim_comb.cps, all_trim.cps, &quot;k3&quot;), wrap_match_entries(caliper_trim_comb.cps, all_trim.cps, &quot;caliper&quot;), wrap_match_entries(cs_trim_comb.cps, all_trim.cps, &quot;cs&quot;), wrap_match_entries(mahvars_trim_comb.cps, all_trim.cps, &quot;mahvars&quot;), wrap_match_entries(optimal_pair_trim_comb.cps, all_trim.cps, &quot;optimal_pair&quot;), wrap_match_entries(optimal_full_trim_comb.cps, all_trim.cps, &quot;optimal_full&quot;), wrap_match_entries(genetic_trim_comb.cps, all_trim.cps, &quot;genetic&quot;), wrap_match_entries(exact_trim_comb.cps, all_trim.cps, &quot;exact&quot;), wrap_match_entries(cem_trim_comb.cps, all_trim.cps, &quot;cem&quot;), wrap_match_entries(subcl_trim_comb.cps, all_trim.cps, &quot;subcl&quot;) ) match_lookup_psid &lt;- c( wrap_match_entries(nn_trim_comb.psid, all_trim.psid, &quot;nn&quot;), wrap_match_entries(k2_trim_comb.psid, all_trim.psid, &quot;k2&quot;), wrap_match_entries(k3_trim_comb.psid, all_trim.psid, &quot;k3&quot;), wrap_match_entries(caliper_trim_comb.psid, all_trim.psid, &quot;caliper&quot;), wrap_match_entries(cs_trim_comb.psid, all_trim.psid, &quot;cs&quot;), wrap_match_entries(mahvars_trim_comb.psid, all_trim.psid, &quot;mahvars&quot;), wrap_match_entries(optimal_pair_trim_comb.psid, all_trim.psid, &quot;optimal_pair&quot;), wrap_match_entries(optimal_full_trim_comb.psid, all_trim.psid, &quot;optimal_full&quot;), wrap_match_entries(genetic_trim_comb.psid, all_trim.psid, &quot;genetic&quot;), wrap_match_entries(exact_trim_comb.psid, all_trim.psid, &quot;exact&quot;), wrap_match_entries(cem_trim_comb.psid, all_trim.psid, &quot;cem&quot;), wrap_match_entries(subcl_trim_comb.psid, all_trim.psid, &quot;subcl&quot;) ) list_cps &lt;- c(all_trim.cps, match_lookup_cps) list_psid &lt;- c(all_trim.psid, match_lookup_psid) # create samples corresponding to the top 5 methods for each sample top5_samples.cps &lt;- create_top5_samples(list_cps, top5_methods.cps) top5_samples.psid &lt;- create_top5_samples(list_psid, top5_methods.psid) # extract top 5 objects top5_objects.cps &lt;- lapply(top5_methods.cps, function(m) list_cps[[m]]) top5_objects.psid &lt;- lapply(top5_methods.psid, function(m) list_psid[[m]]) # save samples into .RData files save_top5_samples(list_cps, top5_methods.cps, prefix = &quot;ldw_model_a_cps1&quot;) save_top5_samples(list_psid, top5_methods.psid, prefix = &quot;ldw_model_a_psid1&quot;) 3.7 Estimating 3.7.1 Average treatment effect on the treated (ATT) # estimate ATT out1 &lt;- estimate_all(ldw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(ldw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(ldw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps &lt;- lapply(top5_samples.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid &lt;- lapply(top5_samples.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.cps_trim &lt;- lapply(all_trim.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid_trim &lt;- lapply(all_trim.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) load(&quot;data/trimmed.RData&quot;) out4 &lt;- estimate_all(ldw_trim_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(ldw_trim_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out6 &lt;- estimate_all(ldw_cps_trim, &quot;re78&quot;, &quot;treat&quot;, covar) out7 &lt;- estimate_all(ldw_psid_trim, &quot;re78&quot;, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 2)) # get experimental benchmark band.exp &lt;- out1[1, 3:4] est.exp &lt;- out1[1, 1] # plot results plot_coef(out1, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(A) LDW-Experimental&quot;) plot_coef(out2, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(B) LDW-CPS-1&quot;) plot_coef(out3, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(C) LDW-PSID-1&quot;) # get benchmarks method_names_cps &lt;- sapply(top5_methods.cps, function(m) { matches &lt;- names(out.cps_trim)[sapply(names(out.cps_trim), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) method_names_psid &lt;- sapply(top5_methods.psid, function(m) { matches &lt;- names(out.cps_trim)[sapply(names(out.cps_trim), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) band.cps &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]][1, 3:4]) est.cps &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]][1, 1]) band.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 3:4]) est.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 1]) # plot results for (i in seq_along(out.cps)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+3], &quot;) Top CPS-1: &quot;, top5_methods.cps[i]) plot_coef(out.cps[[i]], band = band.cps[[i]], line = est.cps[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 3.6: FIGUREB2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 3.7: FIGUREB2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples for (i in seq_along(out.psid)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+8], &quot;) Top PSID-1: &quot;, top5_methods.psid[i]) plot_coef(out.psid[[i]], band = band.psid[[i]], line = est.psid[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 3.8: FIGUREB2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples # get benchmarks band.cps_plus &lt;- out4[1, 3:4] est.cps_plus &lt;- out4[1, 1] band.psid_plus &lt;- out5[1, 3:4] est.psid_plus &lt;- out5[1, 1] # plot results plot_coef(out6, band = band.cps_plus, line = est.cps_plus, ylim = c(-15500, 5500), main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;) plot_coef(out7, band = band.psid_plus, line = est.psid_plus, ylim = c(-15500, 5500), main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) Figure 3.9: FIGUREB2. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples # get all outputs all_outs &lt;- c(list(out1, out2, out3), out.cps, out.psid, list(out6, out7)) # get all plot titles all_plot_titles &lt;- c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS-1&quot;, &quot;(C) LDW-PSID-1&quot;, paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps), paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid), &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;, &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) # get all confidence interval bounds all_bands &lt;- c(list(band.exp, band.exp, band.exp), band.cps, band.psid, list(band.cps_plus, band.psid_plus)) all_ests &lt;- c(list(est.exp, est.exp, est.exp), est.cps, est.psid, list(est.cps_plus, est.psid_plus)) # save results save_att_panels( out_list = all_outs, plot_titles = all_plot_titles, band_list = all_bands, est_list = all_ests, prefix = &quot;ldw_model_b_est_comb&quot; ) As in model A, the above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS-1, LDW-PSID-1, trimmed and matched versions of the LDW-CPS-1-PLUS and LDW-PSID-1-PLUS samples (analogous to Imbens and Xu (2024)) and a series of top-ranked samples of both LDW-CPS-1 and LDW-PSID-1 based on various trimming and integrated trimming and matching criteria. Again, figure (A) presents the benchmark, serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the LDW-CPS-1 and LDW-PSID-1, respectively. Figures (D) through (H) display results for LDW-CPS-1-based samples constructed with the top-ranked methods. Analogously, figures (I) through (M) summarize results for the corresponding LDW-PSID-1-based samples under parallel rules. Figures (N) and (O) present results for the trimmed and matched versions, replicating the tutorial results of Imbens &amp; Xu (2024). The LDW-CPS-1 sample produces ATT estimates that closely align with the experimental benchmark with an exception for one estimator similar as in model A. Across its top-ranked samples, nn_crump (G) and caliper_crump (H) and genetic_crump (F), all estimators produce ATT estimates that reasonably closely align with the benchmark. Some larger deviations from the benchmark occur for the genetic_common_range (E) and genetic_ps_threshold (D) samples. As for the LDW-CPS-1 sample, the LDW-PSID-1 sample produces ATT estimates that reasonably closely align with the experimental benchmark with an exception for only one estimator. Across its top-ranked samples, all estimators generally yield ATT estimates that exhibit greater dispersion from the benchmark and considerably larger standard errors. Further, the ATT estimates from the LDW-CPS1-PLUS sample align near the benchmark, while those from the LDW-PSID-PLUS remain reasonably close, though slightly more distant. Overall, these results show a similar pattern as observed in model A. # evaluate results all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- all_plot_titles # print table output datatable(att_summary, caption = &quot;ATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) # get result matrix out.cps_top &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]]) out.psid_top &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]]) all_out_mat &lt;- c(list(out1), out.cps_top, out.psid_top, list(out4, out5)) result_mat &lt;- create_matrix_results(all_outs, all_out_mat, all_plot_titles) # print table output datatable(result_mat, caption = &quot;ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) As in model A, the tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS-1 sample, and column (C) for the LDW-PSID-1 sample. Columns (D)-(O) summarize the top-ranked sample results for both LDW-CPS-1 and LDW-PSID-1. Columns (N) and (O) present estimates for the trimmed and matched versions of the LDW-PSID-1-PLUS and LDW-PSID-1-PLUS samples. In model B, most LDW-CPS-1-based samples yield ATT estimates that are closer to the benchmark than in model A, with still modest variance. By contrast, the LDW-PSID-1-based produce estimates that, while somewhat closer to the benchmark than in model A, continue to exhibit substantially larger standard errors compared to LDW-CPS-1 samples. This again reflects the greater challenge of obtaining reliable estimates from the observational sample LDW-PSID-1. Overall, figures and table jointly demonstrate again that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;ldw_att_est_model_b&quot;) 3.7.2 Conditional average treatment effect on the treated (CATT) # estimate CATT catt.ldw &lt;- catt(ldw, Y, treat, covar) catt.cps &lt;- catt(ldw_cps, Y, treat, covar) catt.psid &lt;- catt(ldw_psid, Y, treat, covar) catt.top5_cps &lt;- lapply(top5_samples.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid &lt;- lapply(top5_samples.psid, function(d) catt(d, Y, treat, covar)) catt.top5_cps_trim &lt;- lapply(all_trim.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) catt(d, Y, treat, covar)) # similar to Imbens &amp; Xu (2024) catt.trim_cps &lt;- catt(ldw_trim_cps, Y, treat, covar) catt.trim_psid &lt;- catt(ldw_trim_psid, Y, treat, covar) catt.cps_trim &lt;- catt(ldw_cps_trim, Y, treat, covar) catt.psid_trim &lt;- catt(ldw_psid_trim, Y, treat, covar) par(mfrow = c(2,2)) par(cex.main = 0.9) # plot results plot_catt( catt1 = catt.ldw$catt, catt2 = catt.cps$catt, att1 = catt.ldw$att[1], att2 = catt.cps$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS-1)&quot;, main = &quot;(B) LDW-CPS-1&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 = catt.ldw$catt, catt2 = catt.psid$catt, att1 = catt.ldw$att[1], att2 = catt.psid$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID-1)&quot;, main = &quot;(C) LDW-PSID-1&quot;, axes.range = c(-8000, 8000) ) plot_catt_panels( exp_catt = catt.top5_cps_trim, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps) ) Figure 3.10: FIGUREB3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model B using LDW Data: Experimental vs. Nonexperimental Figure 3.11: FIGUREB3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model B using LDW Data: Experimental vs. Nonexperimental plot_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid) ) Figure 3.12: FIGUREB3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model B using LDW Data: Experimental vs. Nonexperimental Figure 3.13: FIGUREB3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model B using LDW Data: Experimental vs. Nonexperimental plot_catt( catt1 &lt;- catt.trim_cps$catt, catt2 &lt;- catt.cps_trim$catt, att1 &lt;- catt.trim_cps$att[1], att2 &lt;- catt.cps_trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS-1-PLUS-Trimmed)&quot;, main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 &lt;- catt.trim_psid$catt, catt2 &lt;- catt.psid_trim$catt, att1 &lt;- catt.trim_psid$att[1], att2 &lt;- catt.psid_trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID-1-PLUS-Trimmed)&quot;, main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;, axes.range = c(-8000, 8000) ) Figure 3.14: FIGUREB3. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. CATT Estimates Model B using LDW Data: Experimental vs. Nonexperimental # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid), catt.top5_cps, catt.top5_psid, list(catt.cps_trim, catt.psid_trim)) # evaluate results all_catt_eval &lt;- eval_catt(all_catt, all_plot_titles) # print table output datatable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) In model B, using LDW-CPS-1 data, CATT estimates range from $-3,316.41 to $7,047.93. This span is considerably narrower than in model A, but still performs worse when contrasted with the experimental benchmark, where CATT estimates range from $-195.61 to $3,809.38 with a mean of $1,744.41. Further, the LDW-PSID-1 sample shows an increased CATT estimate range, from $-7,666.25 to $4,739.52, and a reasonable lower mean of approximately $433.02 compared to LDW-CPS-1 sample. These patterns mirror those observed in model A. For the top-ranked samples of LDW-CPS-1, CATT ranges vary considerably, yet their mean estimates are generally closer to the experimental benchmark, as in model A. Their minimum CATT estimates are less negative, which reduces the spread between minimum and maximum estimates. The top-ranked samples of LDW-PSID-1 by contrast, again yield decreased mean CATT estimates with varying CATT ranges compared to the LDW-CPS-1 sample, signaling persistent difficulties in generating reliable effect estimates. Still, compared to model A, the minimum CATT estimates are less strongly negative, though the mean CATTs do not improve marginally in their proximity to the experimental benchmark. The CATT estimates ranges for the trimmed and matched versions of the LDW-CPS-1-PLUS and LDW-PSID-1-PLUS samples are substantially expanded relative to their respective top-ranked samples, yet they remain narrower than their respective observational samples. The mean CATT estimate of the former sample aligns closer to the experimental benchmark than the corresponding top-ranked samples, whereas the mean CATT estimate for the latter sample remains similar relative to its corresponding top-ranked samples. However, compared to model A, the mean CATT estimate for the trimmed and matched version of LDW-CPS-1-PLUS remains comparable, while for LDW-PSID-1-PLUS, this estimate shows considerably degraded alignment with the experimental benchmark, indicating that the specific integrated approach introduced by Imbens and Xu (2024) increases rather than reduces the proximity of the estimates to the experimental benchmark within model B. Hence, alike model A, these results show that there is considerable variation in ranges and means across methods and samples, reflecting substantial heterogeneity in treatment effect estimation. While certain criteria may improve consistency with the experimental benchmark, they may also introduce notable discrepancies and variability in estimated effects. # save results save_main_catt_panels( catt_refs = list(catt.ldw), catt_comps = list(catt.cps, catt.psid), ylabels = c(&quot;CATT (CPS-1)&quot;, &quot;CATT (PSID-1)&quot;), prefix = &quot;ldw_model_b_catt_main_panels&quot;, main_titles = c(&quot;(B) LDW-CPS-1&quot;, &quot;(C) LDW-PSID-1&quot;) ) save_catt_panels( exp_catt = catt.top5_cps_trim, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps), prefix = &quot;ldw_model_b_catt_top5_cps&quot; ) save_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid), prefix = &quot;ldw_model_b_catt_top5_psid&quot; ) save_plus_catt_panels( catt1_list = list(catt.trim_cps, catt.trim_psid), catt2_list = list(catt.cps_trim, catt.psid_trim), ylabels = c(&quot;CATT (CPS-1-PLUS-Trimmed)&quot;, &quot;CATT (PSID-1-PLUS-Trimmed)&quot;), prefix = &quot;ldw_model_b_catt_plus_panels&quot;, main_titles = c(&quot;(N) LDW-CPS-1-PLUS&quot;, &quot;(O) LDW-PSID-1-PLUS&quot;) ) 3.7.3 Quantile treatment effect on the treated (QTET) # estimate QTET qte.ldw &lt;- est_qte(Y, treat, covar, data = ldw, cores = 4) qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) qte.top5_cps &lt;- lapply(top5_samples.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid &lt;- lapply(top5_samples.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_cps_trim &lt;- lapply(all_trim.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.trim.ldw_cps &lt;- est_qte(Y, treat, NULL, data = ldw_trim_cps) qte.trim.ldw_psid &lt;- est_qte(Y, treat, NULL, data = ldw_trim_psid) qte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps_trim) qte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid_trim) qte.ldw0 &lt;- est_qte(Y, treat, NULL, data = ldw) qte.ldw_cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) qte.ldw_psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) qte.top5_cps_trim0 &lt;- lapply(top5_samples.cps, function(d) est_qte_safe(Y, treat, NULL, data = d)) qte.top5_psid_trim0 &lt;- lapply(top5_samples.psid, function(d) est_qte_safe(Y, treat, NULL, data = d)) qte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps_trim) qte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid_trim) par(mfrow = c(2,2)) par(cex.main = 0.9) ylim = c(-25000, 15000) # plot results plot_qte(qte.ldw_cps, qte.ldw_cps0, qte.ldw, main = &quot;(B) LDW-CPS-1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte(qte.ldw_psid, qte.ldw_psid0, qte.ldw, main = &quot;(C) LDW-PSID-1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte_top(qte.top5_cps_trim, qte.top5_cps_trim0, qte.top5_cps, all_plot_titles, main_start = 4) Figure 3.15: FIGUREB4. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental plot_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 9) Figure 3.16: FIGUREB4. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 3.17: FIGUREB4. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.trim.ldw_cps, main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.trim.ldw_psid, main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 3.18: FIGUREB4. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the experimental and various observational samples. The QTETs estimated from LDW-Experimental (A), the LDW-CPS-1 sample (B), its top-ranked nn_crump (G), caliper_crump (H) and genetic_ps_threshold (D) samples as well as the trimmed and matched version of LDW-CPS-1-PLUS (N) continue to correspond well with the true QTET. The QTET estimates from the LDW-PSID-1 sample (C), its top-ranked samples and the trimmed and matched version of LDW-PSID-1-PLUS (O) show clear biases and noticeably wider confidence bands when compared to the experimental benchmark, indicating greater estimation uncertainty. Overall, these patterns mirror those observed in model A. # list results plots_ldw &lt;- list( list(mod = qte.ldw_cps, mod0 = qte.ldw_cps0, bm = qte.ldw, main = &quot;(B) LDW-CPS-1&quot;), list(mod = qte.ldw_psid, mod0 = qte.ldw_psid0, bm = qte.ldw, main = &quot;(C) LDW-PSID-1&quot;), list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.trim.ldw_cps, main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;), list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.trim.ldw_psid, main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) ) # save results save_qtet(plots_ldw, prefix = &quot;ldw_model_b&quot;) save_qte_top(qte.top5_cps_trim, qte.top5_cps_trim0, qte.top5_cps, all_plot_titles, main_start = 4, prefix = &quot;ldw_model_b_top&quot;) save_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 9, prefix = &quot;ldw_model_b_top&quot;) 3.7.4 Assessing outcome weights (OW) # list all samples all_samples &lt;- c(list(ldw, ldw_cps, ldw_psid), top5_samples.cps, top5_samples.psid, list(ldw_trim_cps, ldw_trim_psid)) # estimate ATT res_att &lt;- get_res_att(all_samples, Y, treat, covar) ## OUTCOME WEIGHTS SUMMARY: 15 succeeded, 0 failed out of 15 samples # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.9) # plot outcome weights distribution plot_ow(ow_att, all_plot_titles) Figure 3.19: FIGUREB5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model B using LDW Data Figure 3.20: FIGUREB5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model B using LDW Data Figure 3.21: FIGUREB5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model B using LDW Data Figure 3.22: FIGUREB5. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Outcome Weights Model B using LDW Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_samples, all_plot_titles, treat, &quot;AIPW-ATT&quot;) # print table output datatable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) In model B, the evaluation once again confirms that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. Note, that minor deviations from exact values are attributable to floating-point rounding error in numerical summation. #save results save_ow(ow_att, all_plot_titles, prefix = &quot;ldw_model_b&quot;) save_csv(res_ow, &quot;ldw_model_b_ow&quot;) 3.8 Validation through placebo analyses # define variables Y &lt;- &quot;re75&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;u74&quot;) # estimate placebo ATT on original and observational samples out1_pl &lt;- estimate_all(ldw, Y, &quot;treat&quot;, covar) out2_pl &lt;- estimate_all(ldw_cps, Y, &quot;treat&quot;, covar) out3_pl &lt;- estimate_all(ldw_psid, Y, &quot;treat&quot;, covar) # estimate placebo ATT on top ranked samples out.cps_pl &lt;- lapply(top5_samples.cps, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.psid_pl &lt;- lapply(top5_samples.psid, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.cps_trim_pl &lt;- lapply(all_trim.cps, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.psid_trim_pl &lt;- lapply(all_trim.psid, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) # estimate placebo ATT on plus samples load(&quot;data/trimmed.RData&quot;) out4_pl &lt;- estimate_all(ldw_trim_cps_pl, Y, &quot;treat&quot;, covar) out5_pl &lt;- estimate_all(ldw_trim_psid_pl, Y, &quot;treat&quot;, covar) out6_pl &lt;- estimate_all(ldw_cps_trim_pl, Y, &quot;treat&quot;, covar) out7_pl &lt;- estimate_all(ldw_psid_trim_pl, Y, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 1)) # get experimental benchmark band.exp_pl &lt;- out1_pl[1, 3:4] est.exp_pl &lt;- out1_pl[1, 1] # plot placebo results plot_coef(out1_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(A) LDW-Experimental&quot;) plot_coef(out2_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(B) LDW-CPS-1&quot;) plot_coef(out3_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(C) LDW-PSID-1&quot;) # get benchmarks method_names_cps &lt;- sapply(top5_methods.cps, function(m) { matches &lt;- names(out.cps_trim_pl)[sapply(names(out.cps_trim_pl), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) method_names_psid &lt;- sapply(top5_methods.psid, function(m) { matches &lt;- names(out.psid_trim_pl)[sapply(names(out.psid_trim_pl), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) band.cps_pl &lt;- lapply(method_names_cps, function(j) {as.numeric(out.cps_trim_pl[[j]][1, 3:4])}) est.cps_pl &lt;- lapply(method_names_cps, function(j) out.cps_trim_pl[[j]][1, 1]) band.psid_pl &lt;- lapply(method_names_psid, function(j) {as.numeric(out.psid_trim_pl[[j]][1, 3:4])}) est.psid_pl &lt;- lapply(method_names_psid, function(j) out.psid_trim_pl[[j]][1, 1]) # plot placebo results for (i in seq_along(out.cps_pl)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+3], &quot;) Top CPS-1: &quot;, top5_methods.cps[i]) plot_coef(out.cps_pl[[i]], band = band.cps_pl[[i]], line = est.cps_pl[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 3.23: FIGUREB6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.24: FIGUREB6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model B: ’75 Earnings as the Outcome for (i in seq_along(out.psid_pl)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+8], &quot;) Top PSID-1: &quot;, top5_methods.psid[i]) plot_coef(out.psid_pl[[i]], band = band.psid_pl[[i]], line = est.psid_pl[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 3.25: FIGUREB6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model B: ’75 Earnings as the Outcome # get benchmarks band.cps_plus_pl &lt;- out4_pl[1, 3:4] est.cps_plus_pl &lt;- out4_pl[1, 1] band.psid_plus_pl &lt;- out5_pl[1, 3:4] est.psid_plus_pl &lt;- out5_pl[1, 1] # plot placebo results plot_coef(out6_pl, band = band.cps_plus_pl, line = est.cps_plus_pl, ylim = c(-12000, 2000), main = &quot;(N) Trimmed LDW-CPS-1-PLUS&quot;) plot_coef(out7_pl, band = band.psid_plus_pl, line = est.psid_plus_pl, ylim = c(-12000, 2000), main = &quot;(O) Trimmed LDW-PSID-1-PLUS&quot;) Figure 3.26: FIGUREB6. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Placebo Test Model B: ’75 Earnings as the Outcome # combine all results all_outs_pl &lt;- c(list(out1_pl, out2_pl, out3_pl), out.cps_pl, out.psid_pl, list(out6_pl, out7_pl)) all_bands_pl &lt;- c(list(band.exp_pl, band.exp_pl, band.exp_pl), band.cps_pl, band.psid_pl, list(band.cps_plus_pl, band.psid_plus_pl)) all_ests_pl &lt;- c(list(est.exp_pl, est.exp_pl, est.exp_pl), est.cps_pl, est.psid_pl, list(est.cps_plus_pl, est.psid_plus_pl)) # save results save_att_panels( out_list = all_outs_pl, plot_titles = all_plot_titles, band_list = all_bands_pl, est_list = all_ests_pl, prefix = &quot;ldw_model_b_pl_est_comb&quot; ) # get all placebo results all_outs_pl &lt;- c(list(out1_pl, out2_pl, out3_pl), out.cps_pl, out.psid_pl, list(out6_pl, out7_pl)) out.cps_top_pl &lt;- lapply(method_names_cps, function(j) out.cps_trim_pl[[j]]) out.psid_top_pl &lt;- lapply(method_names_psid, function(j) out.psid_trim_pl[[j]]) all_out_mat_pl &lt;- c(list(out1_pl), out.cps_top_pl, out.psid_top_pl, list(out4_pl, out5_pl)) # create result matrix result_mat_pl &lt;- create_matrix_results(all_outs_pl, all_out_mat_pl, all_plot_titles) # print table output datatable(result_mat_pl, caption = &quot;Placebo ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The placebo analysis shows that the experimental benchmark remains close to zero and statistically insignificant, closely mirroring the results in model A. The results for LDW-CPS-1 and LDW-PSID-1 are similar to those observed in model A. For LDW-CPS-1 samples (D-H), ATT estimates remain largely negative with only a few exceptions, with modest improvement toward the benchmark compared to LDW-CPS-1 (B) estimates and notably wider confidence intervals, revealing persistent bias and increased uncertainty. For LDW-PSID-1 samples (I-M), a similar pattern results compared to the LDW-PSID-1 sample. As in model A, the trimmed and matched versions of LDW-CPS-1-PLUS and LDW-PSID-1-PLUS exhibit even larger negative ATT estimates, continuing to reflect substantial bias and deviation from the true effect and highlighting the persistent challenges in adjusting for confounding using observational data. # save results save_csv(result_mat_pl, &quot;ldw_att_estimates_pl_model_b&quot;) 3.9 Validation through sensitivity analyses # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid samples filtered_samples_sens &lt;- check_filter_samples(all_samples, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid samples and plot results for (i in seq_along(filtered_samples_sens)) { sens_ana(filtered_samples_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = all_plot_titles[i]) } Figure 3.27: FIGUREB7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model B Figure 3.28: FIGUREB7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model B Figure 3.29: FIGUREB7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model B Figure 3.30: FIGUREB7. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Sensitivity Analyses Model B # save results save_sensitivity_plots(filtered_samples_sens, Y, treat, covar, bm, all_plot_titles, &quot;ldw_model_b&quot;) ## SUMMARY: Sensitivity plots - 15 succeeded, 0 failed out of 15 total The sensitivity analysis demonstrates identical results for LDW-Experimental, LDW-CPS-1 and LDW-PSID-1 as in model A. Specifically, it shows that for the LDW-Experimental sample, as well as for the LDW-CPS-1 and its top-ranked samples nn_crump, caliper_crump and genetic_crump (F-H) the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of the confounder. For the trimmed and matched LDW-CPS1-PLUS and LDW-PSID1-PLUS samples the estimated treatment effects remain also fairly robust, indicating improved resistance to unmeasured confounding due to this integrated approach. For two top-ranked samples of LDW-CPS-1, including genetic_common_range (E) and genetic_ps_threshold (D) and three top-ranked samples of LDW-PSID-1, including optimal_pair_walker (I), mahvars_walker (L) and genetic_walker (M), the estimated treatment effects are reasonably sensitive to unmeasured confounding. In contrast, the LDW-PSID-1 sample (C) and its top-ranked samples optimal_pair_stuermer (J) and k2_walker (K) produce treatment effects estimates that are even more sensitive to unmeasured confounding. Similar to model A, these results overall highlights sample-specific differences in robustness against potential unobserved confounding. 3.10 Inspection of re74 and re75 3.10.1 Correlation # compute correlations cor_treat &lt;- sapply(all_samples, function(d) cor(d$re74, d$treat, use = &quot;complete.obs&quot;)) cor_outcome &lt;- sapply(all_samples, function(d) cor(d$re74, d$re78, use = &quot;complete.obs&quot;)) cor_cov &lt;- sapply(all_samples, function(d) cor(d$re74, d$re75, use = &quot;complete.obs&quot;)) cor_table &lt;- data.frame(Method = all_plot_titles, Cor_re74_treat = cor_treat, Cor_re74_out = cor_outcome, Cor_re74_re75 = cor_cov) # print table output datatable(cor_table, caption = &quot;Correlations of re74 with treatment and outcome across samples&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The tabulated results demonstrate correlations patterns consistent with model A. This indicates that 1974 earnings does not add substantial information beyond 1975 earnings and may constitute a negligible confounder. # save results save_csv(cor_table, &quot;ldw_model_b_corr_results&quot;) 3.10.2 Distributional balance # re75 for (i in seq_along(all_samples)) { tryCatch({ print( bal.plot(treat ~ re75, data = all_samples[[i]], which = &quot;both&quot;) + ggplot2::ggtitle(all_plot_titles[i]) ) }, error = function(e) { cat(sprintf(&quot;Could not plot %s: %s\\n&quot;, all_plot_titles[i], e$message)) }) } Figure 3.31: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.32: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.33: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.34: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.35: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.36: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.37: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.38: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.39: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.40: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.41: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.42: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.43: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.44: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.45: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 # re74 for (i in seq_along(all_samples)) { tryCatch({ print( bal.plot(treat ~ re74, data = all_samples[[i]], which = &quot;both&quot;) + ggplot2::ggtitle(all_plot_titles[i]) ) }, error = function(e) { cat(sprintf(&quot;Could not plot %s: %s\\n&quot;, all_plot_titles[i], e$message)) }) } Figure 3.46: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.47: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.48: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.49: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.50: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.51: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.52: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.53: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.54: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.55: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.56: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.57: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.58: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.59: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 Figure 3.60: FIGUREB8. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS-1. SubfigureC:LDW-PSID-1. SubfigureD-H:Top-LDW-CPS-1. SubfigureI-M:Top-LDW-PSID-1. SubfigureN:LDW-CPS-1-PLUS. SubfigureO:LDW-PSID-1-PLUS. Balance Model A of re75 # save results save_balance(all_samples, all_plot_titles, balance_var = &quot;re75&quot;, prefix = &quot;ldw_model_b_balance_panels_75&quot;) save_balance(all_samples, all_plot_titles, balance_var = &quot;re74&quot;, prefix = &quot;ldw_model_b_balance_panels_74&quot;) The density plots show that treated and control units do not substantially differ in re74 across all samples of model B, although pronounced discrepancies remain in several top-ranked LDW-PSID-1 samples. Relative to model A, there is no consistent pattern of distributional changes in overlap across comparable samples. This suggests that for the LDW samples, any confounding bias from the omission of 1974 earnings is likely limited. Taken together with the correlation and balance results of model A, we may conclude that 1974 earnings does not appear to constitute a material confounder and that including only 1975 earnings in the set of covariates is a plausible model specification. The modest improvements in certain treatment effect estimates and sensitivity patterns within model B further corroborate the validity of this model specification. 3.11 Summary After reexamining model B, which uses the LaLonde-Dehejia-Wahba (LDW) data with a reduced set of covariates, we find that changing the covariate set leads to modest shifts in effect estimates. For LDW-CPS-1, estimates remain close to the experimental benchmark, though standard errors are considerably large. In contrast, LDW-PSID-1 continues to show greater dispersion and substantially larger standard errors, highlighting persistent challenges with this observational sample. Conditional and quantile treatment effect estimates confirm that, while some methods bring estimates closer to the experimental benchmark, considerable heterogeneity and estimator-dependent variability remain. Placebo tests using lagged earnings as the outcome reveal that, despite some improvements, bias and deviation from the true effect persist. Sensitivity analyses indicate that most treatment effect estimates are fairly sensitive to increasing confounder strength, but some upward shifts are observed compared to model A. Furthermore, considering the correlation and balance results alongside the modest shifts in ATT estimates between models A and B, the exclusion of re74 from the covariate set appears to incur limited confounding risk and is supported by some results. Overall, these results reinforce the importance of overlap, covariate balance, and careful model selection, while underscoring the ongoing difficulty of recovering credible causal effects from observational data. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["lalonde-nsw-data.html", "Chapter 4 LaLonde (NSW) Data 4.1 Set up 4.2 NSW 4.3 Pre-assessing methods 4.4 Improving overlap 4.5 Post-assessing methods 4.6 Identifying most efficient methods 4.7 Estimating 4.8 Validation through sensitivity analyses 4.9 Summary", " Chapter 4 LaLonde (NSW) Data This section (4) examines the effect of the treatment (participation in the job training program) on the participants’ earnings in 1978 (re78) in the original LaLonde data (loaded as nsw, similar to Imbens and Xu (2024)). For detailed explanations of the analysis steps and notes, please refer to section 2. Here, we only explain the NSW–specific results. 4.1 Set up 4.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) load(&quot;data/trimmed.RData&quot;) # set seed set.seed(42) 4.1.2 Load and preprocess data treat &lt;- &quot;treat&quot; nsw_co$treat &lt;- 1 # drop re74, u74, tau from CPS-1 and PSID-1 and merge data cps1a &lt;- subset(cps1, select = -c(re74, u74)) nsw_cps &lt;- rbind.data.frame(nsw_tr, cps1a) psid1a &lt;- subset(psid1, select = -c(re74, u74)) nsw_psid &lt;- rbind.data.frame(nsw_tr, psid1a) nsw_cps.plus &lt;- rbind.data.frame(nsw_cps, nsw_co) nsw_psid.plus &lt;- rbind.data.frame(nsw_psid, nsw_co) 4.1.3 Inspect data # collect samples in a list data &lt;- list(nsw = nsw, nsw_cps = nsw_cps, nsw_psid = nsw_psid, nsw_cps.plus = nsw_cps.plus, nsw_psid.plus = nsw_psid.plus) # print and inspect key metrics of each sample summary_stats &lt;- inspect_data(data) datatable(summary_stats, caption = &quot;Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) 4.2 NSW # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u75&quot;) # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 4.3 Pre-assessing methods 4.3.1 Overlap nsw_ps &lt;- assess_overlap(data = nsw, treat = treat, cov = covar, xlim = c(-2, 1.5)) Figure 4.1: FIGUREC1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. nsw_cps_ps &lt;- assess_overlap(data = nsw_cps, treat = treat, cov = covar, xlim = c(-15, 5)) Figure 4.2: FIGUREC1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. nsw_psid_ps &lt;- assess_overlap(data = nsw_psid, treat = treat, cov = covar, xlim = c(-15, 5)) Figure 4.3: FIGUREC1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. As anticipated, the NSW-Experimental data exhibits an almost perfect overlap. In contrast, the observational samples NSW-CPS1 and NSW-PSID1 show poor overlap. nsw_cps.plus_ps &lt;- assess_overlap(data = nsw_cps.plus, treat = treat, cov = covar, xlim = c(-15, 5)) Figure 4.4: FIGUREC1. SubfigureD:NSW-CPS1-PLUS. SubfigureE:NSW-PSID1-PLUS. nsw_psid.plus_ps &lt;- assess_overlap(data = nsw_psid.plus, treat = treat, cov = covar, xlim = c(-15, 5)) Figure 4.5: FIGUREC1. SubfigureD:NSW-CPS1-PLUS. SubfigureE:NSW-PSID1-PLUS. With the expanded samples NSW-CPS1-PLUS and NSW-PSID1-PLUS, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater coverage of log-odds densities across both samples. # combine results data_list &lt;- list(nsw, nsw_cps, nsw_psid, nsw_cps.plus, nsw_psid.plus) plot_titles &lt;- c(&quot;(A) NSW-Experimental&quot;,&quot;(B) NSW-CPS-1&quot;, &quot;(C) NSW-PSID-1&quot;, &quot;(D) NSW-CPS-1-PLUS&quot;, &quot;(E) NSW-PSID-1-PLUS&quot;) # save results save_overlap_panels( data_list = data_list, treat = treat, covar = covar, plot_titles = plot_titles, prefix = &quot;nsw_overlap_panels&quot; ) ## -1.375215 0.6394217 ## -12.49703 1.660349 ## -10.70941 3.573044 ## -11.56837 2.929738 ## -9.367327 6.41566 In the subsequent analysis, the primary focus is on improving overlap between treated and control groups. However, covariate imbalance is also addressed, as it may induce bias in estimated treatment effects. Only the original observational samples NSW-CPS-1 and NSW-PSID-1 are considered. The NSW-CPS-1-PLUS and NSW-PSID1-PLUS samples are included exclusively for comparison and replication purposes. The NSW-Experimental data is only consulted as benchmark, as randomization already ensures adequate overlap. 4.4 Improving overlap 4.4.1 Single methods 4.4.1.1 Trimming Propensity score threshold trimming # apply trimming with a (maximum) threshold nsw_cps.ps_trim &lt;- ps_trim(nsw_cps_ps, threshold = 0.9) nsw_psid.ps_trim &lt;- ps_trim(nsw_psid_ps, threshold = 0.9) # re-estimate propensity scores on trimmed data nsw_cps.ps_trim &lt;- ps_estimate(data = nsw_cps.ps_trim, treat = &quot;treat&quot;, cov = covar) nsw_psid.ps_trim &lt;- ps_estimate(data = nsw_psid.ps_trim, treat = &quot;treat&quot;, cov = covar) Common range trimming # trim observations outside the common support region of propensity scores nsw_cps.ps_common &lt;- common_range_trim(nsw_cps_ps) nsw_psid.ps_common &lt;- common_range_trim(nsw_psid_ps) # re-estimate propensity scores on trimmed data nsw_cps.ps_common &lt;- ps_estimate(data = nsw_cps.ps_common, treat = &quot;treat&quot;, cov = covar) nsw_psid.ps_common &lt;- ps_estimate(data = nsw_psid.ps_common, treat = &quot;treat&quot;, cov = covar) Crump trimming # trim observations with propensity scores outside an interval nsw_cps.ps_crump &lt;- crump_trim(nsw_cps_ps, lower = 0.1, upper = 0.9) nsw_psid.ps_crump &lt;- crump_trim(nsw_psid_ps, lower = 0.1, upper = 0.9) # re-estimate propensity scores on trimmed data nsw_cps.ps_crump &lt;- ps_estimate(data = nsw_cps.ps_crump, treat = &quot;treat&quot;, cov = covar) nsw_psid.ps_crump &lt;- ps_estimate(data = nsw_psid.ps_crump, treat = &quot;treat&quot;, cov = covar) Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control nsw_cps.ps_stuermer &lt;- stuermer_trim(nsw_cps_ps, lower_percentile = 0.05, upper_percentile = 0.95) nsw_psid.ps_stuermer &lt;- stuermer_trim(nsw_psid_ps, lower_percentile = 0.05, upper_percentile = 0.95) # re-estimate propensity scores on trimmed data nsw_cps.ps_stuermer &lt;- ps_estimate(data = nsw_cps.ps_stuermer, treat = &quot;treat&quot;, cov = covar) nsw_psid.ps_stuermer &lt;- ps_estimate(data = nsw_psid.ps_stuermer, treat = &quot;treat&quot;, cov = covar) Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations nsw_cps.ps_walker &lt;- walker_trim(nsw_cps_ps) nsw_psid.ps_walker &lt;- walker_trim(nsw_psid_ps) # re-estimate propensity scores on trimmed data nsw_cps.ps_walker &lt;- ps_estimate(data = nsw_cps.ps_walker, treat = &quot;treat&quot;, cov = covar) nsw_psid.ps_walker &lt;- ps_estimate(data = nsw_psid.ps_walker, treat = &quot;treat&quot;, cov = covar) 4.4.2 Integrated methods 4.4.2.1 Trimming and matching 4.4.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # apply trimming with a (maximum) threshold nsw_cps_trim &lt;- ps_trim(nsw_cps.plus_ps, threshold = 0.85) nsw_psid_trim &lt;- ps_trim(nsw_psid.plus_ps, threshold = 0.85) # excluding the experimental controls nsw_cps_trim_match &lt;- subset(nsw_cps_trim, sample %in% c(0,3) &amp; ps_assoverlap) nsw_psid_trim_match &lt;- subset(nsw_psid_trim, sample %in% c(0,4) &amp; ps_assoverlap) # re-estimate propensity scores on trimmed data nsw_cps_trim_match &lt;- psmatch(data = nsw_cps_trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid_trim_match &lt;- psmatch(data = nsw_psid_trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) # further subset data and re-assign treat variable nsw_trim_cps &lt;- subset(nsw_cps_trim, sample %in% c(0,0.5)) nsw_trim_cps$treat[which(nsw_trim_cps$sample == 0.5)] &lt;- 0 nsw_trim_psid &lt;- subset(nsw_psid_trim, sample %in% c(0,0.5)) nsw_trim_psid$treat[which(nsw_trim_psid$sample == 0.5)] &lt;- 0 4.4.2.1.2 Initial samples # combine trimmed samples all_trim.cps &lt;- list( ps_threshold = nsw_cps.ps_trim, common_range = nsw_cps.ps_common, stuermer = nsw_cps.ps_stuermer, walker = nsw_cps.ps_walker, crump = nsw_cps.ps_crump) all_trim.psid &lt;- list( ps_threshold = nsw_psid.ps_trim, common_range = nsw_psid.ps_common, stuermer = nsw_psid.ps_stuermer, walker = nsw_psid.ps_walker, crump = nsw_psid.ps_crump) 4.4.2.1.2.1 Distance matching 1:1 Nearest neighbor matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=1, logistic propensity score and replacement nn_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) nn_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) k:1 matching (k=2) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=2, logistic propensity score and replacement k&lt;-2 k2_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k2_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k:1 matching (k=3) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=3, logistic propensity score and replacement k&lt;-3 k3_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k3_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) Caliper matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score and replacement caliper_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) caliper_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) Common support restriction matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with exclusion of units outside common support and replacement cs_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) cs_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) Mahalanobis distance matching (mahvars) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching using mahalanobis distance without replacement mahvars_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) mahvars_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) Optimal pair matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal pair matching that minimizes total within-pair distance on propensity scores optimal_pair_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) optimal_pair_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Optimal full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion optimal_full_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) optimal_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Generalized full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios general_full_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) general_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Genetic matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform genetic matching genetic_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) genetic_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) 4.4.2.1.2.2 Stratum matching Exact matching (exact) # match units exactly by raw covariate profiles exact_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;exact&quot;) ## MATCHING SUMMARY: 4 succeeded, 1 failed. Failed: walker exact_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;exact&quot;) ## MATCHING SUMMARY: 4 succeeded, 1 failed. Failed: walker Coarsened matching (cem) # match units exactly within coarse strata cem_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cem&quot;) cem_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cem&quot;) Subclassification # partition sample into fixed number of bins based on propensity score subcl_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;subclass&quot;, subclass = 3) subcl_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;subclass&quot;, subclass = 3) 4.4.2.1.2.3 Pure subset selection Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units card_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) card_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact profile_trim_comb.cps &lt;- attach_matchit(model, data_list = all_trim.cps, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) profile_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) 4.5 Post-assessing methods 4.5.1 Single methods 4.5.1.1 Trimming 4.5.1.1.1 SMD # compute absolute standardized mean differences smd_trim.cps &lt;- compute_abs_smd_trim(all_trim.cps, &quot;treat&quot;, covar) smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 4.5.1.1.2 OVL # compute overlap coefficients ovl_trim.cps &lt;- compute_ovl_trim(all_trim.cps, &quot;ps_assoverlap&quot;, &quot;treat&quot;) ovl_trim.psid &lt;- compute_ovl_trim(all_trim.psid, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 4.5.2 Integrated methods 4.5.2.1 Trimming and matching 4.5.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # list all trimmed and matched samples trim_match_comb.cps_plus &lt;- list(ps_threshold_match = nsw_cps_trim_match) trim_match_comb.psid_plus &lt;- list(ps_threshold_match = nsw_psid_trim_match) 4.5.2.1.1.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.cps_plus &lt;- compute_abs_smd_trim(trim_match_comb.cps_plus, &quot;treat&quot;, covar) smd_trim_match_comb.psid_plus &lt;- compute_abs_smd_trim(trim_match_comb.psid_plus, &quot;treat&quot;, covar) 4.5.2.1.1.2 OVL # compute overlap coefficients ovl_trim_match_comb.cps_plus &lt;- compute_ovl_trim(trim_match_comb.cps_plus, &quot;ps_assoverlap&quot;, &quot;treat&quot;) ovl_trim_match_comb.psid_plus &lt;- compute_ovl_trim(trim_match_comb.psid_plus, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 4.5.2.1.2 Initial samples # list all trimmed and matched samples trim_match_comb.cps &lt;- list( nn = nn_trim_comb.cps, k2 = k2_trim_comb.cps, k3 = k3_trim_comb.cps, caliper = caliper_trim_comb.cps, cs = cs_trim_comb.cps, mahvars = mahvars_trim_comb.cps, optimal_pair = optimal_pair_trim_comb.cps, optimal_full = optimal_full_trim_comb.cps, genetic = genetic_trim_comb.cps, exact = exact_trim_comb.cps, cem = cem_trim_comb.cps, subcl = subcl_trim_comb.cps ) trim_match_comb.psid &lt;- list( nn = nn_trim_comb.psid, k2 = k2_trim_comb.psid, k3 = k3_trim_comb.psid, caliper = caliper_trim_comb.psid, cs = cs_trim_comb.psid, mahvars = mahvars_trim_comb.psid, optimal_pair = optimal_pair_trim_comb.psid, optimal_full = optimal_full_trim_comb.psid, genetic = genetic_trim_comb.psid, exact = exact_trim_comb.psid, cem = cem_trim_comb.psid, subcl = subcl_trim_comb.psid ) 4.5.2.1.2.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.cps &lt;- compute_abs_smd_matchit(trim_match_comb.cps, all_trim.cps) smd_trim_match_comb.psid &lt;- compute_abs_smd_matchit(trim_match_comb.psid, all_trim.psid) 4.5.2.1.2.2 OVL # compute overlap coefficients ovl_trim_match_comb.cps &lt;- compute_ovl_matchit(trim_match_comb.cps, all_trim.cps, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = covar) ovl_trim_match_comb.psid &lt;- compute_ovl_matchit(trim_match_comb.psid, all_trim.psid, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = covar) 4.6 Identifying most efficient methods 4.6.1 Ranking # combine all results all_cps &lt;- combine_results(&quot;cps&quot;) all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_cps, &quot;nsw_cps1_all_results&quot;) save_csv(all_psid, &quot;nsw_psid1_all_results&quot;) # rank comparatively ranked_cps &lt;- assess_methods(all_cps) ranked_psid &lt;- assess_methods(all_psid) # get top 5 methods top5_methods.cps &lt;- get_top_methods(ranked_cps, top_n = 5) top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # rerank top 5 methods top5_methods_df.cps &lt;- ranked_cps %&gt;% arrange(desc(OVL)) %&gt;% head(5) %&gt;% arrange(Mean_Abs_SMD) top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(OVL)) %&gt;% head(5) %&gt;% arrange(Mean_Abs_SMD) # get results top5_methods.cps &lt;- top5_methods_df.cps$Method top5_methods.psid &lt;- top5_methods_df.psid$Method # print table output datatable(top5_methods_df.cps, caption = &quot;Top 5 Methods for CPS-1&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) datatable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID-1&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) # save results save_csv(top5_methods.cps, &quot;nsw_cps1_top5_methods&quot;) save_csv(top5_methods.psid, &quot;nsw_psid1_top5_methods&quot;) The table shows that NSW-CPS-1 and NSW-PSID-1 share only one top method, all others are based on various trimming and matching methods. 4.6.2 Sample construction # create lookup lists trim_only_cps &lt;- list( ps_threshold = nsw_cps.ps_trim, common_range = nsw_cps.ps_common, stuermer = nsw_cps.ps_stuermer, walker = nsw_cps.ps_walker, crump = nsw_cps.ps_crump ) match_lookup_cps &lt;- c( wrap_match_entries(nn_trim_comb.cps, all_trim.cps, &quot;nn&quot;), wrap_match_entries(k2_trim_comb.cps, all_trim.cps, &quot;k2&quot;), wrap_match_entries(k3_trim_comb.cps, all_trim.cps, &quot;k3&quot;), wrap_match_entries(caliper_trim_comb.cps, all_trim.cps, &quot;caliper&quot;), wrap_match_entries(cs_trim_comb.cps, all_trim.cps, &quot;cs&quot;), wrap_match_entries(mahvars_trim_comb.cps, all_trim.cps, &quot;mahvars&quot;), wrap_match_entries(optimal_pair_trim_comb.cps, all_trim.cps, &quot;optimal_pair&quot;), wrap_match_entries(optimal_full_trim_comb.cps, all_trim.cps, &quot;optimal_full&quot;), wrap_match_entries(genetic_trim_comb.cps, all_trim.cps, &quot;genetic&quot;), wrap_match_entries(exact_trim_comb.cps, all_trim.cps, &quot;exact&quot;), wrap_match_entries(cem_trim_comb.cps, all_trim.cps, &quot;cem&quot;), wrap_match_entries(subcl_trim_comb.cps, all_trim.cps, &quot;subcl&quot;) ) trim_only_psid &lt;- list( ps_threshold = nsw_psid.ps_trim, common_range = nsw_psid.ps_common, stuermer = nsw_psid.ps_stuermer, walker = nsw_psid.ps_walker, crump = nsw_psid.ps_crump ) match_lookup_psid &lt;- c( wrap_match_entries(nn_trim_comb.psid, all_trim.psid, &quot;nn&quot;), wrap_match_entries(k2_trim_comb.psid, all_trim.psid, &quot;k2&quot;), wrap_match_entries(k3_trim_comb.psid, all_trim.psid, &quot;k3&quot;), wrap_match_entries(caliper_trim_comb.psid, all_trim.psid, &quot;caliper&quot;), wrap_match_entries(cs_trim_comb.psid, all_trim.psid, &quot;cs&quot;), wrap_match_entries(mahvars_trim_comb.psid, all_trim.psid, &quot;mahvars&quot;), wrap_match_entries(optimal_pair_trim_comb.psid, all_trim.psid, &quot;optimal_pair&quot;), wrap_match_entries(optimal_full_trim_comb.psid, all_trim.psid, &quot;optimal_full&quot;), wrap_match_entries(genetic_trim_comb.psid, all_trim.psid, &quot;genetic&quot;), wrap_match_entries(exact_trim_comb.psid, all_trim.psid, &quot;exact&quot;), wrap_match_entries(cem_trim_comb.psid, all_trim.psid, &quot;cem&quot;), wrap_match_entries(subcl_trim_comb.psid, all_trim.psid, &quot;subcl&quot;) ) list_cps &lt;- c(trim_only_cps, match_lookup_cps) list_psid &lt;- c(trim_only_psid, match_lookup_psid) # create samples corresponding to the top 5 methods for each sample top5_samples.cps &lt;- create_top5_samples(list_cps, top5_methods.cps) top5_samples.psid &lt;- create_top5_samples(list_psid, top5_methods.psid) # extract top5 objects top5_objects.cps &lt;- lapply(top5_methods.cps, function(m) list_cps[[m]]) top5_objects.psid &lt;- lapply(top5_methods.psid, function(m) list_psid[[m]]) # save samples into .RData files save_top5_samples(list_cps, top5_methods.cps, prefix = &quot;nsw_cps1&quot;) save_top5_samples(list_psid, top5_methods.psid, prefix = &quot;nsw_psid1&quot;) 4.7 Estimating 4.7.1 Average treatment effect on the treated (ATT) # estimate ATT out1 &lt;- estimate_all(nsw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(nsw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(nsw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps &lt;- lapply(top5_samples.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid &lt;- lapply(top5_samples.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.cps_trim &lt;- lapply(all_trim.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid_trim &lt;- lapply(all_trim.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out4 &lt;- estimate_all(nsw_trim_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(nsw_trim_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out6 &lt;- estimate_all(nsw_cps_trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) out7 &lt;- estimate_all(nsw_psid_trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 1)) # get experimental benchmark band.exp &lt;- out1[1, 3:4] est.exp &lt;- out1[1, 1] # plot results plot_coef(out1, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(A) NSW-Experimental&quot;) plot_coef(out2, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(B) NSW-CPS-1&quot;) plot_coef(out3, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(C) NSW-PSID-1&quot;) # get benchmarks method_names_cps &lt;- sapply(top5_methods.cps, function(m) { matches &lt;- names(out.cps_trim)[sapply(names(out.cps_trim), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) method_names_psid &lt;- sapply(top5_methods.psid, function(m) { matches &lt;- names(out.cps_trim)[sapply(names(out.cps_trim), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) band.cps &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]][1, 3:4]) est.cps &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]][1, 1]) band.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 3:4]) est.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 1]) # plot results for (i in seq_along(out.cps)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+3], &quot;) Top CPS-1: &quot;, top5_methods.cps[i]) plot_coef(out.cps[[i]], band = band.cps[[i]], line = est.cps[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 4.6: FIGUREC2. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. SubfigureD-H:Top-NSW-CPS1. SubfigureI-M:Top-NSW-PSID1. SubfigureN:NSW-CPS1-PLUS. SubfigureO:NSW-PSID1-PLUS. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.7: FIGUREC2. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. SubfigureD-H:Top-NSW-CPS1. SubfigureI-M:Top-NSW-PSID1. SubfigureN:NSW-CPS1-PLUS. SubfigureO:NSW-PSID1-PLUS. ATT Estimates Given Unconfoundedness using NSW Samples for (i in seq_along(out.psid)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+8], &quot;) Top PSID-1: &quot;, top5_methods.psid[i]) plot_coef(out.psid[[i]], band = band.psid[[i]], line = est.psid[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 4.8: FIGUREC2. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. SubfigureD-H:Top-NSW-CPS1. SubfigureI-M:Top-NSW-PSID1. SubfigureN:NSW-CPS1-PLUS. SubfigureO:NSW-PSID1-PLUS. ATT Estimates Given Unconfoundedness using NSW Samples # get benchmarks band.cps_plus &lt;- out4[1, 3:4] est.cps_plus &lt;- out4[1, 1] band.psid_plus &lt;- out5[1, 3:4] est.psid_plus &lt;- out5[1, 1] # plot results plot_coef(out6, band = band.cps_plus, line = est.cps_plus, ylim = c(-15500, 5500), main = &quot;(N) Trimmed NSW-CPS-1-PLUS&quot;) plot_coef(out7, band = band.psid_plus, line = est.psid_plus, ylim = c(-15500, 5500), main = &quot;(O) Trimmed NSW-PSID-1-PLUS&quot;) Figure 4.9: FIGUREC2. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. SubfigureD-H:Top-NSW-CPS1. SubfigureI-M:Top-NSW-PSID1. SubfigureN:NSW-CPS1-PLUS. SubfigureO:NSW-PSID1-PLUS. ATT Estimates Given Unconfoundedness using NSW Samples # get all outputs all_outs &lt;- c(list(out1, out2, out3), out.cps, out.psid, list(out6, out7)) # get all plot titles all_plot_titles &lt;- c(&quot;(A) NSW-Experimental&quot;, &quot;(B) NSW-CPS1&quot;, &quot;(C) NSW-PSID1&quot;, paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS1: &quot;, top5_methods.cps), paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID1: &quot;, top5_methods.psid), &quot;(N) Trimmed NSW-CPS1-PLUS&quot;, &quot;(O) Trimmed NSW-PSID1-PLUS&quot;) # get all confidence interval bounds all_bands &lt;- c(list(band.exp, band.exp, band.exp), band.cps, band.psid, list(band.cps_plus, band.psid_plus)) all_ests &lt;- c(list(est.exp, est.exp, est.exp), est.cps, est.psid, list(est.cps_plus, est.psid_plus)) # save results save_att_panels( out_list = all_outs, plot_titles = all_plot_titles, band_list = all_bands, est_list = all_ests, prefix = &quot;nsw_est_comb&quot; ) The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: NSW-Experimental, NSW-CPS-1, NSW-PSID-1, trimmed and matched versions of the NSW-CPS-1-PLUS and NSW-PSID1-PLUS samples (analogous to Imbens &amp; Xu (2024)) and a series of top-ranked samples of both NSW-CPS-1 and NSW-PSID-1 based on various trimming and integrated trimming and matching criteria. Figure (A) presents the benchmark from the experimental sample (NSW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the observational samples, NSW-CPS-1 and NSW-PSID-1, while figures (N) and (O) present those for the trimmed and matched versions of NSW-CPS-1-PLUS and NSW-PSID-1-PLUS, respectively, replicating the tutorial results of Imbens &amp; Xu (2024). Figures (D) through (H) display results for NSW-CPS1-based samples constructed with the top-ranked methods. Analogously, figures (I) through (M) summarize results for the corresponding NSW-PSID-1-based samples under parallel rules. The NSW-CPS-1 sample and NSW-PSID-1 sample produce ATT estimates that closely align with the experimental benchmark with an exception for one estimator. Across the top-ranked samples of NSW-CPS-1, specifically the genetic_crump (E) and cem_crump (D) samples, all estimators produce ATT estimates that closely align with the benchmark, though some estimates are negative. Some larger deviations from the benchmark occur for the optimal_pair_walker (H), nn_walker (G) and k3_walker (F) samples. Nevertheless, these ATT estimates deviate considerably stronger from the benchmark than those obtained under parallel rules within models A and B given LDW data. In comparison, NSW-PSID-1-based samples exhibit significantly greater deviation and substantially larger standard errors than the NSW-CPS-1-based samples, consistent with previous observations from LDW data. All their ATT estimates remain negatively aligned, reflecting persistent difficulties in improving ATT estimates for the NSW-PSID-1 sample. Overall, the ATT estimates across all NSW samples follow similar patterns as observed in model A and B given LDW data, yet show a noticeable negative shift. # evaluate results all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- all_plot_titles # print table output datatable(att_summary, caption = &quot;ATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) # create result matrix out.cps_top &lt;- lapply(method_names_cps, function(j) out.cps_trim[[j]]) out.psid_top &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]]) all_out_mat &lt;- c(list(out1), out.cps_top, out.psid_top, list(out4, out5)) result_mat &lt;- create_matrix_results(all_outs, all_out_mat, all_plot_titles) # print table output datatable(result_mat, caption = &quot;ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The tabulated results confirm visual patterns: Column (A) reports the estimates for the NSW-Experimental sample, column (B) for the NSW-CPS-1 sample, and column (C) for the NSW-PSID-1 sample. Columns (D)-(M) summarize results for the top-ranked samples for both NSW-CPS-1 and NSW-PSID1. Columns (N) and (O) report results for the trimmed and matched versions of NSW-CPS-1-PLUS and NSW-PSID-1-PLUS sample, respectively. Specifically, for most NSW-CPS-1-based samples, ATT estimates remain negative. The sample genetic_crump (E) and cem_crump (D) exhibit frequently positive estimates and are relatively close to the benchmark. In contrast, the for the NSW-PSID-1-based samples, the ATT estimates exhibit larger negative magnitudes, and increased standard errors, underscoring the heightened difficulty of achieving consistent ATT effect estimates in this observational sample. Overall, consistent with findings from models A and B, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain methods can bring observational estimates closer to the benchmark. # save results save_csv(result_mat, &quot;nsw_att_estimates&quot;) 4.7.2 Conditional average treatment effect on the treated (CATT) # estimate CATT catt.nsw &lt;- catt(nsw, Y, treat, covar) catt.cps &lt;- catt(nsw_cps, Y, treat, covar) catt.psid &lt;- catt(nsw_psid, Y, treat, covar) catt.top5_cps &lt;- lapply(top5_samples.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid &lt;- lapply(top5_samples.psid, function(d) catt(d, Y, treat, covar)) catt.top5_cps_trim &lt;- lapply(all_trim.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) catt(d, Y, treat, covar)) catt.cps.trim &lt;- catt(nsw_cps_trim_match, Y, treat, covar) catt.psid.trim &lt;- catt(nsw_psid_trim_match, Y, treat, covar) catt.nsw.cps &lt;- catt(nsw_trim_cps, Y, treat, covar) catt.nsw.psid &lt;- catt(nsw_trim_psid, Y, treat, covar) par(mfrow = c(2,2)) par(cex.main = 0.9) # plot results plot_catt( catt1 = catt.nsw$catt, catt2 = catt.cps$catt, att1 = catt.nsw$att[1], att2 = catt.cps$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS-1)&quot;, main = &quot;(B) NSW-CPS-1&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 = catt.nsw$catt, catt2 = catt.psid$catt, att1 = catt.nsw$att[1], att2 = catt.psid$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID-1)&quot;, main = &quot;(C) NSW-PSID-1&quot;, axes.range = c(-8000, 8000) ) plot_catt_panels( exp_catt = catt.top5_cps_trim, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps) ) Figure 4.10: FIGUREC3. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. CATT Estimates using NSW Data: Experimental vs. Nonexperimental Figure 4.11: FIGUREC3. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. CATT Estimates using NSW Data: Experimental vs. Nonexperimental plot_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid) ) Figure 4.12: FIGUREC3. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. CATT Estimates using NSW Data: Experimental vs. Nonexperimental Figure 4.13: FIGUREC3. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. CATT Estimates using NSW Data: Experimental vs. Nonexperimental plot_catt( catt1 &lt;- catt.nsw.cps$catt, catt2 &lt;- catt.cps.trim$catt, att1 &lt;- catt.nsw.cps$att[1], att2 &lt;- catt.cps.trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS-1-PLUS-Trimmed)&quot;, main = &quot;(N) Trimmed NSW-CPS-1-PLUS&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 &lt;- catt.nsw.psid$catt, catt2 &lt;- catt.psid.trim$catt, att1 &lt;- catt.nsw.psid$att[1], att2 &lt;- catt.psid.trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID-1-PLUS-Trimmed)&quot;, main = &quot;(O) Trimmed NSW-PSID-1-PLUS&quot;, axes.range = c(-8000, 8000) ) Figure 4.14: FIGUREC3. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. CATT Estimates using NSW Data: Experimental vs. Nonexperimental # combine all catt objects all_catt &lt;- c(list(catt.nsw, catt.cps, catt.psid), catt.top5_cps, catt.top5_psid, list(catt.cps.trim, catt.psid.trim)) # evaluate results all_catt_eval &lt;- eval_catt(all_catt, all_plot_titles) # print table output datatable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) With NSW-CPS-1, the CATT estimates range from $-8,994.51 to $6,328.35, contrasting with the experimental benchmark where CATT estimates span from $-1,146.76 to $3,347.6, with a mean CATT estimate of $814.53. Unlike in the previous sections, the NSW-PSID-1 sample exhibits a narrower CATT estimates range compared to the NSW-CPS-1 sample, with a range spanning from $-8,179.54 to $867,51. Yet its mean CATT estimate remains substantially negative, at approximately $-2,364.14, contrary to the positive mean CATT estimates observed in models A and B given LDW data. Among the top-ranked NSW-CPS-1 samples, CATT estimates exhibit substantial variability. Samples such as optimal_pair_walker (H), nn_walker (G) or k3_walker (F) yield notably negative minimum CATT values alongside substantial negative mean CATT estimates. Similarly, the genetic_crump (E) and cem_crump (D) samples produce consistently negative CATT estimates, whereas their mean CATT estimates are positive and closer to the benchmark. The NSW-PSID-1 top-ranked samples deliver substantially decreased mean CATT estimates, reflecting greater difficulties in producing reliable effect estimates, while producing narrower extremes compared to the NSW-CPS-1 top-ranked samples. Overall, this variation in range and means of CATT estimates across all observational samples indicates substantial heterogeneity in treatment effect estimation and substantiates that certain criteria improve alignment with the experimental benchmark, while others introduce considerable discrepancies. # save results save_main_catt_panels( catt_refs = list(catt.nsw), catt_comps = list(catt.cps, catt.psid), ylabels = c(&quot;CATT (CPS-1)&quot;, &quot;CATT (PSID-1)&quot;), prefix = &quot;nsw_catt_main_panels&quot;, main_titles = c(&quot;(B) NSW-CPS-1&quot;, &quot;(C) NSW-PSID-1&quot;) ) save_catt_panels( exp_catt = catt.top5_cps_trim, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS-1: &quot;, top5_methods.cps), prefix = &quot;nsw_catt_top5_cps&quot; ) save_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID-1: &quot;, top5_methods.psid), prefix = &quot;nsw_catt_top5_psid&quot; ) save_plus_catt_panels( catt1_list = list(catt.nsw.cps, catt.nsw.psid), catt2_list = list(catt.cps.trim, catt.psid.trim), ylabels = c(&quot;CATT (CPS-1-PLUS-Trimmed)&quot;, &quot;CATT (PSID-1-PLUS-Trimmed)&quot;), prefix = &quot;nsw_catt_plus_panels&quot;, main_titles = c(&quot;(N) Trimmed NSW-CPS-1-PLUS&quot;, &quot;(O) Trimmed NSW-PSID-1-PLUS&quot;), folder = &quot;graphs/lalonde&quot; ) 4.7.3 Quantile treatment effect on the treated (QTET) # estimate QTET qte.nsw &lt;- est_qte(Y, treat, covar, data = nsw, cores = 4) qte.nsw_cps &lt;- est_qte(Y, treat, covar, data = nsw_cps) qte.nsw_psid &lt;- est_qte(Y, treat, covar, data = nsw_psid) qte.top5_cps &lt;- lapply(top5_samples.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid &lt;- lapply(top5_samples.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_cps_trim &lt;- lapply(all_trim.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.nsw.cps &lt;- est_qte(Y, treat, NULL, data = nsw_trim_cps) qte.nsw.psid &lt;- est_qte(Y, treat, NULL, data = nsw_trim_psid) qte.nsw_cps.trim &lt;- est_qte(Y, treat, covar, data = nsw_cps_trim_match) qte.nsw_psid.trim &lt;- est_qte(Y, treat, covar, data = nsw_psid_trim_match) qte.nsw0 &lt;- est_qte(Y, treat, NULL, data = nsw) qte.nsw_cps0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps) qte.nsw_psid0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid) qte.top5_cps_trim0 &lt;- lapply(top5_samples.cps, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid_trim0 &lt;- lapply(top5_samples.psid, function(d) est_qte(Y, treat, NULL, data = d)) qte.nsw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps_trim_match) qte.nsw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid_trim_match) par(mfrow = c(2,2)) par(cex.main = 0.9) ylim = c(-25000, 15000) # plot results plot_qte(qte.nsw_cps, qte.nsw_cps0, qte.nsw, main = &quot;(B) NSW-CPS-1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte(qte.nsw_psid, qte.nsw_psid0, qte.nsw, main = &quot;(C) NSW-PSID-1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte_top(qte.top5_cps_trim, qte.top5_cps_trim0, qte.top5_cps, all_plot_titles, main_start = 4) Figure 4.15: FIGUREC4. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. QTET Estimates using NSW Data: Experimental vs. Nonexperimental plot_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 9) Figure 4.16: FIGUREC4. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. QTET Estimates using NSW Data: Experimental vs. Nonexperimental Figure 4.17: FIGUREC4. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. QTET Estimates using NSW Data: Experimental vs. Nonexperimental plot_qte(qte.nsw_cps.trim, qte.nsw_cps.trim0, qte.nsw.cps, main = &quot;(N) Trimmed NSW-CPS-1-PLUS&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte(qte.nsw_psid.trim, qte.nsw_psid.trim0, qte.nsw.psid, main = &quot;(O) Trimmed NSW-PSID-1-PLUS&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 4.18: FIGUREC4. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. QTET Estimates using NSW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the NSW experimental and various observational samples. The QTET estimates from the NSW-CPS-1 sample (B) correspond well with the true QTET, although they are often underpowered. The QTET estimates from top-ranked samples show clear biases when compared to the experimental benchmark (E, G and H), except for k3_walker and cem_crump (F and D), where the QTET estimates align reasonably well with the true QTET. The QTETs estimated from the NSW-PSID-1 sample (C) show notable biases in contrast to the experimental benchmark. Among its top-ranked samples (I-M) the QTET estimates exhibit substantial bias and are highly underpowered, reflecting great estimation uncertainty. For the trimmed and matched NSW-CPS-1-PLUS sample (N), the QTET estimates align reasonably well with the experimental benchmark, whereas for the trimmed and matched NSW-PSID-1-PLUS sample (O), the QTET estimates shows notable biases. # list results plots_nsw &lt;- list( list(mod = qte.nsw_cps, mod0 = qte.nsw_cps0, bm = qte.nsw, main = &quot;(B) NSW-CPS-1&quot;), list(mod = qte.nsw_psid, mod0 = qte.nsw_psid0, bm = qte.nsw, main = &quot;(C) NSW-PSID-1&quot;), list(mod = qte.nsw_cps.trim, mod0 = qte.nsw_cps.trim0, bm = qte.nsw.cps, main = &quot;(N) Trimmed NSW-CPS-1-PLUS &quot;), list(mod = qte.nsw_psid.trim, mod0 = qte.nsw_psid.trim0, bm = qte.nsw.psid, main = &quot;(O) Trimmed NSW-PSID-1-PLUS&quot;) ) # save results save_qtet(plots_nsw, prefix = &quot;nsw&quot;) save_qte_top(qte.top5_cps_trim, qte.top5_cps_trim0, qte.top5_cps, all_plot_titles, main_start = 4, prefix = &quot;nsw_top&quot;) save_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 9, prefix = &quot;nsw_top&quot;) 4.7.4 Assessing outcome weights (OW) # list all samples all_samples &lt;- c(list(nsw, nsw_cps, nsw_psid), top5_samples.cps, top5_samples.psid, list(nsw_cps_trim_match, nsw_psid_trim_match)) # estimate ATT res_att &lt;- get_res_att(all_samples, Y, treat, covar) ## OUTCOME WEIGHTS SUMMARY: 15 succeeded, 0 failed out of 15 samples # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, all_plot_titles) Figure 4.19: FIGUREC5. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Outcome Weights using NSW Data Figure 4.20: FIGUREC5. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Outcome Weights using NSW Data Figure 4.21: FIGUREC5. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Outcome Weights using NSW Data Figure 4.22: FIGUREC5. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Outcome Weights using NSW Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_samples, all_plot_titles, treat, &quot;AIPW-ATT&quot;) # print table output datatable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) #save results save_ow(ow_att, all_plot_titles, prefix = &quot;nsw&quot;) save_csv(res_ow, &quot;nsw_ow&quot;) Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. Note, that minor deviations from exact values are attributable to floating-point rounding error in numerical summation. A placebo test is not performed as the NSW data arises from a randomized controlled trial, where random assignment provides internal validity and guards against systematic confounding. 4.8 Validation through sensitivity analyses # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid samples filtered_samples_sens &lt;- check_filter_samples(all_samples, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid samples and plot results for (i in seq_along(filtered_samples_sens)) { sens_ana(filtered_samples_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = all_plot_titles[i]) } Figure 4.23: FIGUREC6. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Sensitivity Analyses NSW Figure 4.24: FIGUREC6. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Sensitivity Analyses NSW Figure 4.25: FIGUREC6. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Sensitivity Analyses NSW Figure 4.26: FIGUREC6. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS-1. SubfigureC:NSW-PSID-1. SubfigureD-H:Top-NSW-CPS-1. SubfigureI-M:Top-NSW-PSID-1. SubfigureN:NSW-CPS-1-PLUS. SubfigureO:NSW-PSID-1-PLUS. Sensitivity Analyses NSW # save results save_sensitivity_plots(filtered_samples_sens, Y, treat, covar, bm, all_plot_titles, &quot;nsw&quot;) ## SUMMARY: Sensitivity plots - 14 succeeded, 0 failed out of 14 total The sensitivity analysis shows that for the NSW-Experimental sample, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of the confounder. For the NSW-CPS-1 (B) and NSW-PSID-1 (C) sample, as well as the top-ranked samples (I), (J), (K) and (M) of NSW-PSID-1 the treatment effect estimates are highly sensitive to unmeasured confounding. For the sample (M) and all top-ranked samples of NSW-CPS-1 (D-H) the treatment effect estimates are reasonably sensitive. Whereas, for the NSW-CPS-1-PLUS sample (N) the estimates are fairly robust to unmeasured confounding. 4.9 Summary After reexamining the original LaLonde (NSW) data, the results confirm that the NSW-Experimental data shows nearly perfect overlap between treated and control groups, while the observational samples (NSW-CPS-1 and NSW-PSID-1) display weak overlap, with many treated units outside the control range. Expanding these samples with experimental controls and applying the exact approach as defined by Imbens and Xu (2024) improves effect estimates considerably. These findings reinforce the lessons from previous LDW analyses: even with improved overlap and some gains in covariate balance, achieving consistent and reliable effect estimates with observational data remains difficult. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["lalonde-calónico-smith-lcs-data.html", "Chapter 5 LaLonde-Calónico-Smith (LCS) Data 5.1 Set up 5.2 LCS 5.3 Pre-assessing methods 5.4 Improving overlap 5.5 Post-assessing methods 5.6 Identifying most efficient methods 5.7 Estimating 5.8 Validation through placebo analyses 5.9 Validation through sensitivity analyses 5.10 Summary", " Chapter 5 LaLonde-Calónico-Smith (LCS) Data This section (5) examines the LaLonde female samples reconstructed by Calónico and Smith (2017), referred to as the LaLonde-Calónico-Smith (LCS) sample (loaded as lcs below, similar to Imbens and Xu (2024)). For detailed explanations of the analysis steps and notes, please refer to section 2. Here, we only present and explain the LCS–specific results. 5.1 Set up 5.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lcs.RData&quot;) # set seed set.seed(42) 5.1.2 Load and preprocess data # expc = 0: experimental treated; # expc = 1: experimental control; # expc = 2: psid control; lcs_psid$expc &lt;- 0 lcs_psid[lcs_psid$treat==0, ]$expc &lt;- 2 lcs_tr &lt;- lcs[lcs$treat==1, ] lcs_co &lt;- lcs[lcs$treat==0, ] lcs_co$treat &lt;- 1 lcs_co$expc &lt;- 1 lcs_psid_plus &lt;- rbind.data.frame(lcs_psid, lcs_co) 5.1.3 Inspect data # collect samples in a list data &lt;- list(lcs = lcs, lcs_psid = lcs_psid, lcs_psid_plus = lcs_psid_plus) # print and inspect key metrics of each sample summary_stats &lt;- inspect_data(data) datatable(summary_stats, caption = &quot;Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) 5.2 LCS # define variables Y &lt;- &quot;re79&quot; treat &lt;- &quot;treat&quot; # redefine covariates: removing &quot;nchildren75&quot; to be used as placebo outcome covar &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) In the following analysis, only LCS-PSID-1 data is used as the original LaLonde study and its reconstruction by Calónico and Smith (2017) designate LCS-PSID-1 as the appropriate nonexperimental control group for women, providing a comparable observational sample that aligns with the experimental sample’s characteristics (Imbens and Xu (2024)). The LCS-Experimental data is only consulted as benchmark, as randomization already ensures adequate overlap. 5.3 Pre-assessing methods 5.3.1 Overlap lcs.ps &lt;- assess_overlap(data = lcs, treat = treat, cov = covar, xlim = c(-1.5, 1.5), breaks = 40) Figure 5.1: FIGURED1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. lcs_psid.ps &lt;- assess_overlap(data = lcs_psid, treat = treat, cov = covar, xlim = c(-11, 7), breaks = 40) Figure 5.2: FIGURED1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. As anticipated, the LCS-Experimental data exhibit an almost perfect overlap. In contrast, the observational sample LCS-PSID-1 displays weak overlap. lcs_psid_plus.ps &lt;- assess_overlap(data = lcs_psid_plus, treat = treat, cov = covar, xlim = c(-15, 5)) Figure 5.3: FIGURED1. SubfigureC:LCS-PSID-1-PLUS. With the expanded sample LCS-PSID-1-PLUS, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater coverage of the log-odds densities across the treatment groups. # combine results data_list &lt;- list(lcs, lcs_psid, lcs_psid_plus) plot_titles &lt;- c(&quot;(A) LCS-Experimental&quot;,&quot;(B) LCS-PSID-1&quot;, &quot;(C) LDW-PSID-1-PLUS&quot;) # save results save_overlap_panels( data_list = data_list, treat = treat, covar = covar, plot_titles = plot_titles, prefix = &quot;lcs_overlap_panels&quot; ) ## -1.003419 0.9414338 ## -7.208955 2.596894 ## -6.793963 4.127747 5.4 Improving overlap 5.4.1 Single methods 5.4.1.1 Trimming 5.4.1.2 Propensity score threshold trimming # apply trimming with a (maximum) threshold lcs_psid.ps_trim &lt;- ps_trim(lcs_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data lcs_psid.ps_trim &lt;- ps_estimate(data = lcs_psid.ps_trim, treat = &quot;treat&quot;, cov = covar) 5.4.1.3 Common range trimming # trim observations outside the common support region of propensity scores lcs_psid.ps_common &lt;- common_range_trim(lcs_psid.ps) # re-estimate propensity scores on trimmed data lcs_psid.ps_common &lt;- ps_estimate(data = lcs_psid.ps_common, treat = &quot;treat&quot;, cov = covar) 5.4.1.4 Crump trimming # trim observations with propensity scores outside an interval lcs_psid.ps_crump &lt;- crump_trim(lcs_psid.ps, lower = 0.1, upper = 0.9) # re-estimate propensity scores on trimmed data lcs_psid.ps_crump &lt;- ps_estimate(data = lcs_psid.ps_crump, treat = &quot;treat&quot;, cov = covar) 5.4.1.5 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control lcs_psid.ps_stuermer &lt;- stuermer_trim(lcs_psid.ps, lower_percentile = 0.05, upper_percentile = 0.95) # re-estimate propensity scores on trimmed data lcs_psid.ps_stuermer &lt;- ps_estimate(data = lcs_psid.ps_stuermer, treat = &quot;treat&quot;, cov = covar) 5.4.1.6 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations lcs_psid.ps_walker &lt;- walker_trim(lcs_psid.ps) # re-estimate propensity scores on trimmed data lcs_psid.ps_walker &lt;- ps_estimate(data = lcs_psid.ps_walker, treat = &quot;treat&quot;, cov = covar) 5.4.2 Integrated methods 5.4.2.1 Trimming and matching 5.4.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # apply trimming with (maximum) threshold lcs_psid_trim &lt;- ps_trim(lcs_psid_plus.ps, threshold = 0.9) # exclude experimental controls lcs_psid.trim_match &lt;- subset(lcs_psid_trim, expc %in% c(0, 2) &amp; ps_assoverlap) # re-estimate propensity scores and employ 1:1 matching lcs_psid.trim_match &lt;- psmatch(data = lcs_psid.trim_match, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) # trim experimental data lcs_trim_psid &lt;- subset(lcs_psid_trim, expc %in% c(0, 1)) lcs_trim_psid$treat[which(lcs_trim_psid$expc == 1)] &lt;- 0 5.4.2.1.2 Initial samples # combine trimmed samples all_trim.psid &lt;- list( ps_threshold = lcs_psid.ps_trim, common_range = lcs_psid.ps_common, stuermer = lcs_psid.ps_stuermer, walker = lcs_psid.ps_walker, crump = lcs_psid.ps_crump) 5.4.2.1.2.1 Distance matching 1:1 Nearest neighbor matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=1, logistic propensity score and replacement nn_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) k:1 matching (k=2) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=2, logistic propensity score and replacement k&lt;-2 k2_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) k:1 matching (k=3) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with k=3, logistic propensity score and replacement k&lt;-3 k3_trim_comb.psid &lt;- attach_matchit(model, data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) Caliper matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score and replacement caliper_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) Common support restriction matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching with exclusion of units outside common support and replacement cs_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) Mahalanobis distance matching (mahvars) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform nearest neighbor matching using mahalanobis distance without replacement mahvars_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) Optimal pair matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal pair matching that minimizes total within-pair distance on propensity scores optimal_pair_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Optimal full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion optimal_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Generalized full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios general_full_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) Genetic matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming # perform genetic matching genetic_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) 5.4.2.1.2.2 Stratum matching Exact matching (exact) # match units exactly by raw covariate profiles exact_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;exact&quot;) Coarsened matching (cem) # match units exactly within coarse strata cem_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cem&quot;) Subclassification # partition sample into fixed number of bins based on propensity score subcl_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;subclass&quot;, subclass = 3) 5.4.2.1.2.3 Pure subset selection Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units card_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact profile_trim_comb.psid &lt;- attach_matchit(model,data_list = all_trim.psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) 5.5 Post-assessing methods 5.5.1 Single methods 5.5.1.1 Trimming 5.5.1.1.1 SMD # compute absolute standardized mean differences smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 5.5.1.1.2 OVL # compute overlap coefficients ovl_trim.psid &lt;- compute_ovl_trim(all_trim.psid, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 5.5.2 Integrated methods 5.5.2.1 Trimming and matching 5.5.2.1.1 Extended samples (Similar to tutorial by Imbens and Xu (2024)) # list all trimmed and matched samples trim_match_comb.psid_plus &lt;- list(ps_threshold_match = lcs_psid.trim_match) 5.5.2.1.1.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.psid_plus &lt;- compute_abs_smd_trim(trim_match_comb.psid_plus, &quot;treat&quot;, covar) 5.5.2.1.1.2 OVL # compute overlap coefficients ovl_trim_match_comb.psid_plus &lt;- compute_ovl_trim(trim_match_comb.psid_plus, &quot;ps_assoverlap&quot;, &quot;treat&quot;) 5.5.2.1.2 Initial samples # list all trimmed and matched samples trim_match_comb.psid &lt;- list( nn = nn_trim_comb.psid, k2 = k2_trim_comb.psid, k3 = k3_trim_comb.psid, caliper = caliper_trim_comb.psid, cs = cs_trim_comb.psid, mahvars = mahvars_trim_comb.psid, optimal_pair = optimal_pair_trim_comb.psid, optimal_full = optimal_full_trim_comb.psid, genetic = genetic_trim_comb.psid, exact = exact_trim_comb.psid, cem = cem_trim_comb.psid, subcl = subcl_trim_comb.psid ) 5.5.2.1.2.1 SMD # compute absolute standardized mean differences smd_trim_match_comb.psid &lt;- compute_abs_smd_matchit(trim_match_comb.psid, all_trim.psid) 5.5.2.1.2.2 OVL # compute overlap coefficients ovl_trim_match_comb.psid &lt;- compute_ovl_matchit(trim_match_comb.psid, all_trim.psid, ps = &quot;ps_assoverlap&quot;, treat = &quot;treat&quot;, covar = covar) 5.6 Identifying most efficient methods 5.6.1 Ranking # combine all results all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_psid, &quot;lcs_psid1_all_results&quot;) # rank comparatively ranked_psid &lt;- assess_methods(all_psid) # get top 5 methods top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # rerank top 5 methods top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(OVL)) %&gt;% head(5) %&gt;% arrange(Mean_Abs_SMD) # get results top5_methods.psid &lt;- top5_methods_df.psid$Method # print table output datatable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID-1&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) # save results save_csv(top5_methods.psid, &quot;lcs_psid1_top5_methods&quot;) 5.6.2 Sample construction # create lookup lists trim_only_psid &lt;- list( ps_threshold = lcs_psid.ps_trim, common_range = lcs_psid.ps_common, stuermer = lcs_psid.ps_stuermer, walker = lcs_psid.ps_walker, crump = lcs_psid.ps_crump ) match_lookup_psid &lt;- c( wrap_match_entries(nn_trim_comb.psid, all_trim.psid, &quot;nn&quot;), wrap_match_entries(k2_trim_comb.psid, all_trim.psid, &quot;k2&quot;), wrap_match_entries(k3_trim_comb.psid, all_trim.psid, &quot;k3&quot;), wrap_match_entries(caliper_trim_comb.psid, all_trim.psid, &quot;caliper&quot;), wrap_match_entries(cs_trim_comb.psid, all_trim.psid, &quot;cs&quot;), wrap_match_entries(mahvars_trim_comb.psid, all_trim.psid, &quot;mahvars&quot;), wrap_match_entries(optimal_pair_trim_comb.psid, all_trim.psid, &quot;optimal_pair&quot;), wrap_match_entries(optimal_full_trim_comb.psid, all_trim.psid, &quot;optimal_full&quot;), wrap_match_entries(genetic_trim_comb.psid, all_trim.psid, &quot;genetic&quot;), wrap_match_entries(exact_trim_comb.psid, all_trim.psid, &quot;exact&quot;), wrap_match_entries(cem_trim_comb.psid, all_trim.psid, &quot;cem&quot;), wrap_match_entries(subcl_trim_comb.psid, all_trim.psid, &quot;subcl&quot;) ) list_psid &lt;- c(trim_only_psid, match_lookup_psid) # create samples corresponding to the top 5 methods for each sample top5_samples.psid &lt;- create_top5_samples(list_psid, top5_methods.psid) # extract top5 objects top5_objects.psid &lt;- lapply(top5_methods.psid, function(m) list_psid[[m]]) # save samples into .RData files save_top5_samples(list_psid, top5_methods.psid, prefix = &quot;lcs_psid1&quot;) 5.7 Estimating 5.7.1 Average treatment effect on the treated (ATT) # get estimates out1 &lt;- estimate_all(lcs, &quot;re79&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(lcs_psid, &quot;re79&quot;, &quot;treat&quot;, covar) out.psid &lt;- lapply(top5_samples.psid, function(d) estimate_all(d, &quot;re79&quot;, &quot;treat&quot;, covar)) out.psid_trim &lt;- lapply(all_trim.psid, function(d) estimate_all(d, &quot;re79&quot;, &quot;treat&quot;, covar)) load(&quot;data/lcs.RData&quot;) out3 &lt;- estimate_all(lcs_trim_psid, Y, &quot;treat&quot;, covar) out4 &lt;- estimate_all(lcs_psid_trim, Y, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 1)) # get experimental benchmark band.exp &lt;- out1[1, 3:4] est.exp &lt;- out1[1, 1] # plot results plot_coef(out1, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(A) LCS-Experimental&quot;) plot_coef(out2, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(B) LCS-PSID-1&quot;) # get benchmarks method_names_psid &lt;- sapply(top5_methods.psid, function(m) { matches &lt;- names(out.psid_trim)[sapply(names(out.psid_trim), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) band.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 3:4]) est.psid &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]][1, 1]) # plot results for (i in seq_along(out.psid)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+2], &quot;) Top PSID-1: &quot;, top5_methods.psid[i]) plot_coef(out.psid[[i]], band = band.psid[[i]], line = est.psid[[i]], ylim = c(-15500, 5500), main = this_title) } Figure 5.4: FIGURED2. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. ATT Estimates Given Unconfoundedness using LCS Samples # get benchmarks band.psid_plus &lt;- out3[1, 3:4] est.psid_plus &lt;- out3[1, 1] # plot results plot_coef(out4, band = band.psid_plus, line = est.psid_plus, ylim = c(-15500, 5500), main = &quot;(H) Trimmed LCS-PSID-1-PLUS&quot;) Figure 5.5: FIGURED2. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. ATT Estimates Given Unconfoundedness using LCS Samples # get all outputs all_outs &lt;- c(list(out1, out2), out.psid, list(out4)) # get all plot titles all_plot_titles &lt;- c(&quot;(A) LCS-Experimental&quot;, &quot;(B) LCS-PSID-1&quot;, paste0(&quot;(&quot;, LETTERS[3:7], &quot;) Top PSID-1: &quot;, top5_methods.psid), &quot;(H) Trimmed LCS-PSID-1-PLUS&quot;) # get all confidence interval bounds all_bands &lt;- c(list(band.exp, band.exp), band.psid, list(band.psid_plus)) all_ests &lt;- c(list(est.exp, est.exp), est.psid, list(est.psid_plus)) # save results save_att_panels( out_list = all_outs, plot_titles = all_plot_titles, band_list = all_bands, est_list = all_ests, prefix = &quot;lcs_est_comb&quot; ) The above figures show the ATT estimates and their 95% confidence intervals for eight samples: LCS-Experimental, LCS-PSID-1, a series of top-ranked samples of LCS-PSID-1 based on various trimming or integrated criteria, as well as a trimmed and matched version of the LCS-PSID-1-PLUS sample (analogous to Imbens and Xu (2024)). Figure (A) presents the experimental sample (LCS-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) shows results for the observational sample LCS-PSID-1 and figures (C) through (G) display results for LCS-PSID-1-based top-ranked samples. Figure (H) shows results for a trimmed and matched version of LCS-PSID-1-PLUS, replicating the tutorial results of Imbens &amp; Xu (2024). Across the LCS-PSID-1 sample and its top-ranked samples, all estimators yield ATT estimates that largely cluster around the benchmark except for genetric_walker (E) and exact_common_range (C), which tend to produce estimates that deviate slightly more from the benchmark. # evaluate results all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- all_plot_titles # print table output datatable(att_summary, caption = &quot;ATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The ATT results are presented in the table below. # create result matrix out.psid_top &lt;- lapply(method_names_psid, function(j) out.psid_trim[[j]]) all_out_mat &lt;- c(list(out1), out.psid_top, list(out4)) result_mat &lt;- create_matrix_results(all_outs, all_out_mat, all_plot_titles) # print table output datatable(result_mat, caption = &quot;ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The tabulated results confirm visual patterns: Column (A) reports the estimates for the LCS-Experimental sample, column (B) for the LCS-PSID-1 sample, columns (D)-(H) for the top-ranked sample of LCS-PSID-1, and column (C) for its trimmed and matched version of LCS-PSID-1-PLUS. For all LCS-PSID-1-based samples, the ATT estimates remain overly positive. However, the ATT estimates obtained with the diff and psm estimators are in at least one case negative. # save results save_csv(result_mat, &quot;lcs_att_est&quot;) 5.7.2 Conditional average treatment effect on the treated (CATT) catt.lcs &lt;- catt(lcs, Y, treat, covar) catt.psid &lt;- catt(lcs_psid, Y, treat, covar) catt.top5_psid &lt;- lapply(top5_samples.psid, function(d) catt(d, Y, treat, covar)) catt.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) catt(d, Y, treat, covar)) catt.lcs.psid &lt;- catt(lcs_trim_psid, Y, treat, covar) catt.psid.trim &lt;- catt(lcs_psid_trim, Y, treat, covar) par(mfrow = c(2,2)) par(cex.main = 0.9) # plot results plot_catt( catt1 = catt.lcs$catt, catt2 = catt.psid$catt, att1 = catt.lcs$att[1], att2 = catt.psid$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS-1)&quot;, main = &quot;(B) LCS-PSID-1&quot;, axes.range = c(-8000, 8000) ) plot_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[3:7], &quot;) Top PSID-1: &quot;, top5_methods.psid) ) Figure 5.6: FIGURED3. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. CATT Estimates using LCS Data: Experimental vs. Nonexperimental Figure 5.7: FIGURED3. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. CATT Estimates using LCS Data: Experimental vs. Nonexperimental plot_catt( catt1 &lt;- catt.lcs.psid$catt, catt2 &lt;- catt.psid.trim$catt, att1 &lt;- catt.lcs.psid$att[1], att2 &lt;- catt.psid.trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID-1-PLUS-Trimmed)&quot;, main = &quot;(H) Trimmed LCS-PSID-1-PLUS&quot;, axes.range = c(-8000, 8000) ) Figure 5.8: FIGURED3. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. CATT Estimates using LCS Data: Experimental vs. Nonexperimental # combine all catt all_catt &lt;- c(list(catt.lcs, catt.psid), catt.top5_psid, list(catt.psid.trim)) # evaluate catt all_catt_eval &lt;- eval_catt(all_catt, all_plot_titles) # print table output datatable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) With LCS-PSID-1, CATT estimates span from $-3,149.81 to $2,395.66, contrasting with the CATT estimated from experimental data which ranges from $-478.45 to $2,895.23, with a mean CATT estimate of $886.31. In contract, across the LCS-PSID-1-based samples, the ranges of CATT estimates are considerably large. Importantly, the mean CATT estimates remain positive in all cases. However, for the optimal_pair_stuermer sample as well as the trimmed and matched version of LCS-PSID-1-PLUS the mean CATT values are notably reduced. # save results save_main_catt_panels( catt_refs = list(catt.lcs), catt_comps = list(catt.psid), ylabels = c(&quot;CATT (PSID1)&quot;), prefix = &quot;lcs_catt_main_panels&quot;, main_titles = c(&quot;(B) LCS-PSID-1&quot;) ) save_catt_panels( exp_catt = catt.top5_psid_trim, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[3:7], &quot;) Top PSID-1: &quot;, top5_methods.psid), prefix = &quot;lcs_catt_top5_psid&quot; ) save_plus_catt_panels( catt1_list = list(catt.lcs.psid), catt2_list = list(catt.psid.trim), ylabels = c(&quot;CATT (PSID-1-PLUS-Trimmed)&quot;), prefix = &quot;lcs_catt_plus_panels&quot;, main_titles = c(&quot;(H) Trimmed LCS-PSID-1-PLUS&quot;) ) 5.7.3 Quantile treatment effect on the treated (QTET) # estimate QTET qte.lcs &lt;- est_qte(Y, treat, covar, data = lcs, cores = 4) qte.lcs_psid &lt;- est_qte(Y, treat, covar, data = lcs_psid) qte.top5_psid &lt;- lapply(top5_samples.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid_trim &lt;- lapply(all_trim.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.lcs.psid &lt;- est_qte(Y, treat, NULL, data = lcs_trim_psid) qte.lcs_psid.trim &lt;- est_qte(Y, treat, covar, data = lcs_psid_trim) qte.lcs0 &lt;- est_qte(Y, treat, NULL, data = lcs) qte.lcs_psid0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid) qte.top5_psid_trim0 &lt;- lapply(top5_samples.psid, function(d) est_qte(Y, treat, NULL, data = d)) qte.lcs_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid_trim) par(mfrow = c(2,2)) par(cex.main = 0.9) ylim = c(-25000, 15000) # plot results plot_qte(qte.lcs_psid, qte.lcs_psid0, qte.lcs, main = &quot;(B) LCS-PSID-1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) plot_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 3) Figure 5.9: FIGURED4. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. QTET Estimates using LCS Data: Experimental vs. Nonexperimental plot_qte(qte.lcs_psid.trim, qte.lcs_psid.trim0, qte.lcs.psid, main = &quot;(H) Trimmed LCS-PSID-1-PLUS&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 5.10: FIGURED4. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. QTET Estimates using LCS Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the LCS experimental and various observational samples. The QTETs estimated from both the original and trimmed and matched LCS-PSID1-PLUS sample (B and H), as well as from the top-ranked samples (C through G), align comparatively close with the true QTET. However, the QTETs from sample (C) and (E) exhibit substantial bias, suggesting greater estimation uncertainty. # list results plots_lcs &lt;- list(list(mod = qte.lcs_psid, mod0 = qte.lcs_psid0, bm = qte.lcs, main = &quot;(B) LCS-PSID-1&quot;), list(mod = qte.lcs_psid.trim, mod0 = qte.lcs_psid.trim0, bm = qte.lcs.psid, main = &quot;(H) Trimmed LCS-PSID-1-PLUS&quot;)) # save results save_qtet(plots_lcs, prefix = &quot;lcs&quot;) save_qte_top(qte.top5_psid_trim, qte.top5_psid_trim0, qte.top5_psid, all_plot_titles, main_start = 3, prefix = &quot;lcs_top&quot;) 5.7.4 Assessing outcome weights (OW) # list all samples all_samples &lt;- c(list(lcs, lcs_psid), top5_samples.psid, list(lcs_trim_psid)) # estimate ATT res_att &lt;- get_res_att(all_samples, Y, treat, covar) ## OUTCOME WEIGHTS SUMMARY: 8 succeeded, 0 failed out of 8 samples # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.9) # plot outcome weights distribution plot_ow(ow_att, all_plot_titles) Figure 5.11: FIGURED5. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. Outcome Weights using LCS Data Figure 5.12: FIGURED5. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. Outcome Weights using LCS Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_samples, all_plot_titles, treat, &quot;AIPW-ATT&quot;) # print table output datatable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. Note, that minor deviations from exact values are attributable to floating-point rounding error in numerical summation. # save results save_ow(ow_att, all_plot_titles, prefix = &quot;lcs&quot;) save_csv(res_ow, &quot;lcs_ow&quot;) 5.8 Validation through placebo analyses # define variables Y &lt;- &quot;nchildren75&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) # estimate placebo ATT on original and observational samples out1_pl &lt;- estimate_all(lcs, Y, &quot;treat&quot;, covar) out2_pl &lt;- estimate_all(lcs_psid, Y, &quot;treat&quot;, covar) # estimate placebo ATT on top ranked samples out.psid_pl &lt;- lapply(top5_samples.psid, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.psid_trim_pl &lt;- lapply(all_trim.psid, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) # estimate placebo ATT on plus samples load(&quot;data/trimmed.RData&quot;) out3_pl &lt;- estimate_all(lcs_trim_psid, Y, &quot;treat&quot;, covar) out4_pl &lt;- estimate_all(lcs_psid_trim, Y, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 1)) # get experimental benchmark band.exp_pl &lt;- out1_pl[1, 3:4] est.exp_pl &lt;- out1_pl[1, 1] # plot placebo results plot_coef(out1_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-1.5, 1), main = &quot;(A) LCS-Experimental&quot;) plot_coef(out2_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-1.5, 1), main = &quot;(B) LCS-PSID-1&quot;) # get benchmarks method_names_psid &lt;- sapply(top5_methods.psid, function(m) { matches &lt;- names(out.psid_trim_pl)[sapply(names(out.psid_trim_pl), function(n) grepl(n, m, fixed=TRUE))] if (length(matches) &gt; 0) matches[which.max(nchar(matches))] else NA }) band.psid_pl &lt;- lapply(method_names_psid, function(j) {as.numeric(out.psid_trim_pl[[j]][1, 3:4])}) est.psid_pl &lt;- lapply(method_names_psid, function(j) out.psid_trim_pl[[j]][1, 1]) # plot placebo results for (i in seq_along(out.psid_pl)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+2], &quot;) Top PSID1: &quot;, top5_methods.psid[i]) plot_coef(out.psid_pl[[i]], band = band.psid_pl[[i]], line = est.psid_pl[[i]], ylim = c(-1.5, 1), main = this_title) } Figure 5.13: FIGURED6. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. Placebo Test: Number of Children in 1975 as the Outcome # get benchmarks band.psid_plus_pl &lt;- out3_pl[1, 3:4] est.psid_plus_pl &lt;- out3_pl[1, 1] # plot placebo results plot_coef(out4_pl, band = band.psid_plus_pl, line = est.psid_plus_pl, ylim = c(-1.5, 1), main = &quot;(H) Trimmed LCS-PSID-1-PLUS&quot;) Figure 5.14: FIGURED6. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. Placebo Test: Number of Children in 1975 as the Outcome # combine all results all_outs_pl &lt;- c(list(out1_pl, out2_pl), out.psid_pl, list(out4_pl)) all_bands_pl &lt;- c(list(band.exp_pl, band.exp_pl), band.psid_pl, list(band.psid_plus_pl)) all_ests_pl &lt;- c(list(est.exp_pl, est.exp_pl), est.psid_pl, list(est.psid_plus_pl)) # save results save_att_panels( out_list = all_outs_pl, plot_titles = all_plot_titles, band_list = all_bands_pl, est_list = all_ests_pl, prefix = &quot;lcs_pl_est_comb&quot; ) # get all placebo results all_outs_pl &lt;- c(list(out1_pl, out2_pl), out.psid_pl, list(out4_pl)) out.psid_top_pl &lt;- lapply(method_names_psid, function(j) out.psid_trim_pl[[j]]) all_out_mat_pl &lt;- c(list(out1_pl), out.psid_top_pl, list(out4_pl)) # create result matrix result_mat_pl &lt;- create_matrix_results(all_outs_pl, all_out_mat_pl, all_plot_titles) # print table output datatable(result_mat_pl, caption = &quot;Placebo ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The placebo analysis shows that the experimental benchmark is close to zero and statistically insignificant, while all estimators applied to the observational samples produce large negative estimates, remaining statistically different from zero, stressing the persistent challenges in adjusting for confounding using observational data. # save results save_csv(result_mat_pl, &quot;lcs_att_estimates_pl&quot;) 5.9 Validation through sensitivity analyses # define variables Y &lt;- &quot;re79&quot; treat &lt;- &quot;treat&quot; # redefine covariates covar &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid samples filtered_samples_sens &lt;- check_filter_samples(all_samples, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid samples and plot results for (i in seq_along(filtered_samples_sens)) { sens_ana(filtered_samples_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = all_plot_titles[i]) } Figure 5.15: FIGURED7. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. Sensitivity Analyses LCS Figure 5.16: FIGURED7. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID-1. SubfigureC-G:Top-LCS-PSID-1. SubfigureH:LCS-PSID-1-PLUS. Sensitivity Analyses LCS # save results save_sensitivity_plots(filtered_samples_sens, Y, treat, covar, bm, all_plot_titles, &quot;lcs&quot;) ## SUMMARY: Sensitivity plots - 6 succeeded, 0 failed out of 6 total The sensitivity analysis shows that treatment effect estimates in LCS-Experimental (A) are robust to unmeasured confounding, as expected. Instead, the treatment effect estimates in the observational sample LCS-PSID-1 (B) are reasonable sensitive, whereas the top-ranked LCS-PSID-1 samples (C-F) as well as the trimmed and matched version of LCS-PSID-1-PLUS (H) produce treatment effects that are rather robust to increasing confounder strength, despite up to triple the correlation levels of the confounder with the treatment and outcome. 5.10 Summary After reexamining the LaLonde-Calónico-Smith (LCS) data, the results confirm that, as with the NSW and LDW samples, overlap between treated and control groups is generally greater in the experimental sample than in the observational (LCS-PSID-1) sample. Augmenting the sample with experimental controls generally improves overlap. However, with respect to estimates and robustness measures, the findings for LCS data differ from those observed given LDW and NSW data. Specifically, ATT estimates remain close to the benchmark with only slight deviations and small standard errors. Further, CATT and QTET estimates align comparatively well with the experimental benchmark, and sensitivity analyses suggest that estimates are robust to increasing confounder strength. Conversely, the placebo test reveals pronounced deviations from the benchmark. Overall, consistent with the LDW and NSW results, while certain methods can bring effect estimates closer to the benchmark, estimator-dependent variability and sensitivity to sample construction persist. References Calónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["references.html", "References", " References Calónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Firp, Sergio. 2007. “Efficient Semiparametric Estimation of Quantile Treatment Effects.” Greifer, Noah. 2025. “Matching Methods.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” Stürmer, Til, Michael Webster-Clark, Jennifer L. Lund, Richard Wyss, Alan R. Ellis, Mark Lunt, Kenneth J. Rothman, and Robert J. Glynn. 2021. “Propensity Score Weighting and Trimming Strategies for Reducing Variance and Bias of Treatment Effect Estimates: A Simulation Study.” American Journal of Epidemiology. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
