[["index.html", "Application of the Outcome Weights Framework for Double Machine Learning to the Lalonde Study Preface", " Application of the Outcome Weights Framework for Double Machine Learning to the Lalonde Study Laura Kreisel 2025-10-06 Preface This book replicates the LaLonde study as revisited by Imbens and Xu (2024), comparing full and reduced covariate models to reduce potential confounding. It evaluates various methods to improve overlap and covariate balance for more robust treatment effect estimation and applies the outcome weights framework by Knaus and Pfleiderer (2024) to LaLonde data variants as well as analyzes the distributional properties of outcome weights. Section 1 introduces required packages and wrapper functions used throughout the analysis. Section 2 replicates and extends the full covariate model from Imbens and Xu (2024) using the LaLonde-Dehejia-Wahba (LDW) dataset. Section 3 applies a reduced covariate set to the same LDW data. Section 4 analyzes the original LaLonde dataset following similar methods and section 5 explores the LaLonde-Calónico-Smith (LCS) dataset, focusing on female samples. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” "],["getting-started.html", "Chapter 1 Getting started 1.1 Installation 1.2 Wrapper functions 1.3 Outcome weights analysis 1.4 Sensitivity analysis", " Chapter 1 Getting started The functions presented below constitute the core wrapper functions utilized throughout the analysis, including three adapted function originally from the Imbens and Xu (2024) tutorial, which were modified to suit specific analytical purpose (highlighted by ***), as well as others integrated without modification. For the full collection of functions by Imbens and Xu (2024), please consult their official source code available on their GitHub repository. 1.1 Installation Several R packages are required for the data analysis and visualization. The code below checks for all required packages and installs those that are missing. After the installation, the packages need to be loaded. Since the analysis sources functions directly from the Imbens and Xu (2024) tutorial, the required packages are automatically installed and loaded as part of that process. Therefore, it is only necessary to install and load any additional packages as well as add custom functions that are required for the analysis. Packages: “data.table”, “dplyr”, “ggplot2”, “gridExtra”, “highr”, “highs” , “MatchIt”, “optmatch”, “optweight”, “quickmatch”, “readr”, “rgenoud”, “tidyr”, “tidyverse”, “WeightIt” # required packages packages &lt;- c(&quot;data.table&quot;, &quot;dplyr&quot;, &quot;ggplot2&quot;, &quot;gridExtra&quot;, &quot;highr&quot;, &quot;highs&quot; , &quot;MatchIt&quot;, &quot;optmatch&quot;, &quot;optweight&quot;, &quot;quickmatch&quot;, &quot;readr&quot;, &quot;rgenoud&quot;, &quot;tidyr&quot;, &quot;tidyverse&quot;, &quot;WeightIt&quot; ) # install packages install_all &lt;- function(packages) { installed_pkgs &lt;- installed.packages()[, &quot;Package&quot;] for (pkg in packages) { if (!pkg %in% installed_pkgs) { install.packages(pkg) } } } install_all(packages) # load packages library(cobalt) library(data.table) library(dplyr) library(ggplot2) library(gridExtra) library(highr) library(highs) library(MatchIt) library(optmatch) library(optweight) library(quickmatch) library(readr) library(tidyr) library(tidyverse) library(WeightIt) 1.2 Wrapper functions Next, we outline the wrapper functions designed to manage the datasets, address overlap and covariate balance, estimate treatment effects as well as analyze outcome weights. To use the wrapper functions, the simplest method is to source the R script with the following code. source(&quot;tutorial/functions.R&quot;) If RStudio is used, the functions should now be seen in the environment section. 1.2.1 Overview Function Description Code inspect_data() Inspects datasets. More matchit_profile(),create_smr_weights(),create_overlap_weights(), truncate_weights_fixed(), truncate_weights_percentile(), check_weights(), truncate_weights_adaptive(), ps_trim(), common_range_trim(), crump_trim(), stuermer_trim (), walker_trim(), trim_attach_weights() Implements methods to improve covariate balancing and overlap. More get_smd_stats(), compute_abs_smd_matchit(), compute_ess_matchit(), plot_matchit(), compute_abs_smd_weight(), compute_ess_weight(), plot_weighting_methods(), compute_abs_smd_trunc(), compute_ess_trunc(), plot_trunc_methods(), compute_abs_smd_trim(), compute_ess_trim(), plot_trim(), compute_smd_all_datasets (), compute_ess_all_datasets(), plot_comb_overlap(), plot_comb_love_plots(), combine_results(), save_csv(), assess_methods(), get_top_methods(), create_top5_datasets(), save_top5_individual_files() Evaluates performance of previous methods through comparative metrics (absolute standardized mean differences (SMD) and effective sample size (ESS)). More estimate_all(), plot_coef(), plot_att_panels(), save_att_panels(), create_matrix_results(), eval_att(), plot_catt_panels(), save_catt_panels(), eval_catt(), plot_qte_top(), save_qtet(), save_qte_top() Computes and visualizes the Average Treatment Effect on the Treated (ATT) using a number of estimators. More get_res_att(), derive_ow(), plot_ow(), eval_ow(), save_ow() Analyses outcome weights of datasets. More check_filter_datasets(), save_sensitivity_plots() Validates and filters datasets. More 1.2.2 Inspection inspect_data() summarizes one or more datasets by returning a single data frame with each dataset’s name, number of observations, number of variables, and the concatenated names of its variables. inspect_data &lt;- function(data) { if (is.data.frame(data)) { data &lt;- list(dataset = data) } data.frame( dataset = names(data), num_obs = sapply(data, nrow), num_vars = sapply(data, ncol), name_vars = sapply(data, function(df) paste(names(df), collapse = &quot;, &quot;)), row.names = NULL ) } Argument data_list: A data frame or a list of data frames containing structured data. 1.2.3 Improving covariate balance and overlap 1.2.3.1 Matching matchit_profile() performs nearest neighbor matching based on a combination of specified covariates and each observation’s distance from the overall covariate mean, returning a matchit object for balance diagnostics and matched sampling. matchit_profile &lt;- function(data, treat, covar) { overall_means &lt;- colMeans(data[, covar], na.rm = TRUE) cov_matrix &lt;- as.matrix(data[, covar]) dist_from_target &lt;- apply(cov_matrix, 1, function(x) sqrt(sum((x - overall_means)^2))) data$dist_from_target &lt;- dist_from_target formula &lt;- as.formula(paste(treat, &quot;~&quot;, paste(c(covar, &quot;dist_from_target&quot;), collapse = &quot;+&quot;))) match_out &lt;- matchit(formula, data = data, method = &quot;nearest&quot;, distance = &quot;glm&quot;) return(match_out) } Arguments data: A data frame containing structured data. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. 1.2.3.2 Weighting create_smr_weights() calculates standardized mortality ratio (SMR) weights based on estimated propensity scores, allowing for ATT or average treatment effect (ATE) weighting according to the estimand specified. create_smr_weights &lt;- function(data, formula, estimand = &quot;ATT&quot;) { ps_model &lt;- glm(formula, data = data, family = binomial()) ps &lt;- predict(ps_model, type = &quot;response&quot;) if (estimand == &quot;ATT&quot;) { weights &lt;- ifelse(data$treat == 1, 1/ps, 1/(1-ps)) } else if (estimand == &quot;ATE&quot;) { weights &lt;- ifelse(data$treat == 1, 1/ps, 1/(1-ps)) } return(weights) } Arguments data: The data frame containing structured data. formula: The model formula specifying the relation between the treatment variable and a set of covariates, defining the model structure. estimand = ATT: The name of the target estimand (default is ATT). create_overlap_weights() computes overlap weights based on propensity scores. create_overlap_weights &lt;- function(data, formula) { ps_model &lt;- glm(formula, data = data, family = binomial()) ps &lt;- predict(ps_model, type = &quot;response&quot;) return(ifelse(data$treat == 1, 1 - ps, ps)) } Arguments data: The data frame containing structured data. formula: The model formula specifying the relation between the treatment variable and a set of covariates, defining the model structure. 1.2.3.3 Truncation truncate_weights_fixed() caps weights at a fixed maximum value to limit extreme weight influence. truncate_weights_fixed &lt;- function(data, weight_col, max_weight = 10) { data[[weight_col]] &lt;- pmin(data[[weight_col]], max_weight) return(data) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string. max_weight: The maximum allowed weight value as integer. truncate_weights_percentile() caps weights at a specified percentile threshold to reduce outliers in weight distribution. truncate_weights_percentile &lt;- function(data, weight_col, percentile = 0.99) { weight_cutoff &lt;- quantile(data[[weight_col]], probs = percentile, na.rm = TRUE) data[[weight_col]] &lt;- pmin(data[[weight_col]], weight_cutoff) return(data) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string. percentile: The quantile cutoff value as integer. check_weights() prints the variance of the specified weight vector to assess variability and relevance for adaptive truncation. check_weights &lt;- function(data, weight_col = &quot;weight&quot;) { w &lt;- data[[weight_col]] variance &lt;- var(w, na.rm = TRUE) data.frame( Weight_Column = weight_col, Variance = variance ) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string. truncate_weights_adaptive() caps weights adaptively at a threshold defined by the mean plus a multiple of the standard deviation. truncate_weights_adaptive &lt;- function(data, weight_col, c = 3) { w &lt;- data[[weight_col]] # Only apply if variance is positive if (var(w, na.rm = TRUE) &gt; 0) { cutoff &lt;- mean(w, na.rm = TRUE) + c * sd(w, na.rm = TRUE) data[[weight_col]] &lt;- pmin(w, cutoff) } return(data) } Arguments data: The data frame containing structured data. weight_col: The column name of the weights in the dataset as string. c: The multiplier for the standard deviation added to the mean to define the cutoff value as integer. 1.2.3.4 Trimming ps_trim() trims the dataset based on a specified propensity score threshold, removing observations whose propensity scores exceed the given cutoff value.*** ps_trim &lt;- function(data, ps = &quot;ps_assoverlap&quot;, threshold = 0.9) { sub &lt;- data[which(data[, ps] &lt; threshold), ] return(sub) } Arguments data: The data frame containing structured data. ps: The name of the propensity score variable as string. threshold: The upper limit for propensity score inclusion as integer. common_range_trim() trims the dataset to observations with propensity scores within the common support range for treated and control groups. common_range_trim &lt;- function(data, ps_col = &quot;ps_assoverlap&quot;, treat_col = &quot;treat&quot;) { lower_cut &lt;- max( min(data[[ps_col]][data[[treat_col]] == 1], na.rm = TRUE), min(data[[ps_col]][data[[treat_col]] == 0], na.rm = TRUE) ) upper_cut &lt;- min( max(data[[ps_col]][data[[treat_col]] == 1], na.rm = TRUE), max(data[[ps_col]][data[[treat_col]] == 0], na.rm = TRUE) ) sub &lt;- data[data[[ps_col]] &gt;= lower_cut &amp; data[[ps_col]] &lt;= upper_cut, ] return(sub) } Arguments data: The data frame containing structured data. ps_col: The column name of propensity scores as string. treat_col: The column name of the (binary) treatment indicator as string. crump_trim() trims the dataset to observations with propensity scores outside specified lower and upper bounds (default 0.1 and 0.9). crump_trim &lt;- function(data, ps_col = &quot;ps_assoverlap&quot;, lower = 0.1, upper = 0.9) { sub &lt;- data[data[[ps_col]] &gt;= lower &amp; data[[ps_col]] &lt;= upper, ] return(sub) } Arguments data: The data frame containing structured data. ps_col: The column name of propensity scores as string. lower: The lower bound for inclusion as integer. upper: The upper bound for inclusion as integer. stuermer_trim () trims the dataset to observations based on propensity score quantiles separately for treated and control group. stuermer_trim &lt;- function(data, treat_col = &quot;treat&quot;, ps_col = &quot;ps_assoverlap&quot;, lower_percentile = 0.05, upper_percentile = 0.95) { treated_ps &lt;- data[[ps_col]][data[[treat_col]] == 1] untreated_ps &lt;- data[[ps_col]][data[[treat_col]] == 0] lower_cutoff &lt;- quantile(treated_ps, probs = lower_percentile, na.rm = TRUE) upper_cutoff &lt;- quantile(untreated_ps, probs = upper_percentile, na.rm = TRUE) sub &lt;- data[data[[ps_col]] &gt;= lower_cutoff &amp; data[[ps_col]] &lt;= upper_cutoff, ] return(sub) } Arguments data: The data frame containing structured data. treat_col: The column name of the (binary) treatment indicator as string. ps_col: The column name of propensity scores as string. walker_trim() trims the dataset to observations based on preference scores that adjust for treatment prevalence using logit transformations. walker_trim &lt;- function(data, treat_col = &quot;treat&quot;, ps_col = &quot;ps_assoverlap&quot;, lower_cutoff = 0.3, upper_cutoff = 0.7) { treat_prevalence &lt;- mean(data[[treat_col]], na.rm = TRUE) logit_ps &lt;- log(data[[ps_col]] / (1 - data[[ps_col]])) logit_prevalence &lt;- log(treat_prevalence / (1 - treat_prevalence)) preference_score &lt;- 1 / (1 + exp(-(logit_ps - logit_prevalence))) sub &lt;- data[preference_score &gt;= lower_cutoff &amp; preference_score &lt;= upper_cutoff, ] return(sub) } Arguments data: The data frame containing structured data. treat_col: The column name of the (binary) treatment indicator as string. ps_col: The column name of propensity scores as string. 1.2.3.5 Combined methods trim_attach_weights() merges trimmed data with original weights, preserving corresponding weight values after trimming. trim_attach_weights &lt;- function(trimmed_data, original_data, weight_col){ trimmed_data$orig_row &lt;- as.integer(rownames(trimmed_data)) original_data$orig_row &lt;- as.integer(rownames(original_data)) trimmed_data &lt;- merge( trimmed_data, original_data[, c(&quot;orig_row&quot;, weight_col)], by = &quot;orig_row&quot;, all.x = TRUE ) colnames(trimmed_data)[colnames(trimmed_data) == weight_col] &lt;- &quot;weight&quot; trimmed_data$orig_row &lt;- NULL original_data$orig_row &lt;- NULL return(trimmed_data) } Arguments trimmed_data: A data frame containing the subsetted dataset after trimming procedures. original_data: A data frame containing the full dataset before trimming. weight_col: The name of the column in original_data that holds the weights to be transferred, given as string. 1.2.4 Reassessing methods 1.2.4.1 Matching get_smd_stats() extracts mean and maximum absolute standardized mean differences (SMDs) from a balance object to assess covariate balance. get_smd_stats &lt;- function(match_object) { bal &lt;- bal.tab(match_object, stats = &quot;mean.diffs&quot;, un = TRUE, s.d.denom = &quot;treated&quot;) smds &lt;- bal$Balance$Diff.Adj smds &lt;- smds[!(rownames(bal$Balance) %in% c(&quot;distance&quot;))] mean_smd &lt;- mean(abs(smds), na.rm = TRUE) max_smd &lt;- max(abs(smds), na.rm = TRUE) return(c(Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd)) } Argument match_object: The balance / matching object, containing information on covariate balance. compute_abs_smd_matchit() computes absolute SMDs for a list of MatchIt objects and returns summary statistics. compute_abs_smd_matchit &lt;- function(match_list) { smd_list &lt;- lapply(match_list, get_smd_stats) smd_mat &lt;- do.call(rbind, smd_list) smd_df &lt;- data.frame( Method = names(match_list), Mean_Abs_SMD = smd_mat[, &quot;Mean_Abs_SMD&quot;], Max_Abs_SMD = smd_mat[, &quot;Max_Abs_SMD&quot;], row.names = NULL ) return(smd_df) } Argument match_list: A list of MatchIt objects. compute_ess_matchit() extracts and formats effective sample size (ESS) information from the balance summary of a MatchIt object. compute_ess_matchit &lt;- function(bal_tab_object) { samples &lt;- bal_tab_object$Observations df &lt;- as.data.frame(samples) df$Method &lt;- rownames(samples) df &lt;- df[, c(&quot;Method&quot;,&quot;Control&quot;, &quot;Treated&quot;)] rownames(df) &lt;- NULL df } Argument bal_tab_object: A balance table object that contains ESS information from matched data. plot_matchit() generates balance plots for a list of MatchIt objects, visualizing covariate balance before and after matching. plot_matchit &lt;- function(match_list, dataset_name) { for (method_name in names(match_list)) { match_obj &lt;- match_list[[method_name]] if (method_name == &quot;subcl&quot;) { plot(summary(match_obj, subclass = TRUE), main = paste0(dataset_name, &quot; - &quot;, method_name,&quot; matching&quot;)) } else { plot(summary(match_obj), main = paste0(dataset_name, &quot; - &quot;, method_name,&quot; matching&quot;)) } } } Arguments match_list: A list of MatchIt objects. dataset_name: A string naming the dataset for use in plot titles. 1.2.4.2 Weighting compute_abs_smd_weight() calculates absolute SMDs for datasets weighted by specified weight vectors. compute_abs_smd_weight &lt;- function(data, treat, covar, weight_cols) { smd_list &lt;- lapply(weight_cols, function(wcol) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = data[[wcol]], un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Adj) mean_smd &lt;- mean(smd_vals, na.rm = TRUE) max_smd &lt;- max(smd_vals, na.rm = TRUE) return(data.frame( Method = wcol, Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd )) }) do.call(rbind, smd_list) } Arguments data: The data frame containing structured data. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: A string containing the column names holding the weights. compute_ess_weight() extracts ESS associated with different weighting schemes. compute_ess_weight &lt;- function(data, treat, covar, weight_cols) { ess_list &lt;- lapply(weight_cols, function(wcol) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = data[[wcol]], un = FALSE ) samples &lt;- bal_obj$Observations if (&quot;Adjusted&quot; %in% rownames(samples)) { df &lt;- samples[&quot;Adjusted&quot;, c(&quot;Control&quot;, &quot;Treated&quot;), drop = FALSE] } else { df &lt;- samples[1, c(&quot;Control&quot;, &quot;Treated&quot;), drop = FALSE] } df &lt;- cbind(Method = wcol, df) rownames(df) &lt;- NULL return(df) }) do.call(rbind, ess_list) } Arguments data: The data frame containing structured data. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: The name of the columns holding the weights. plot_weighting_methods() generates love plots, visualizing covariate balance under different weighting methods. plot_weighting_methods &lt;- function(data, treat, covar, weight_list, dataset_name = NULL) { for (wcol in names(weight_list)) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = weight_list[[wcol]], un = TRUE, s.d.denom = &quot;treated&quot; ) title_text &lt;- if (!is.null(dataset_name)) paste(dataset_name, &quot;-&quot;, wcol, &quot;weighting&quot;) else wcol lp &lt;- cobalt::love.plot( bal_obj, stats = &quot;mean.diffs&quot;, abs = TRUE, var.order = &quot;unadjusted&quot;, thresholds = c(m = 0.1), title = title_text ) print(lp) } } Arguments data: The data frame containing structured data. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_list: A list of weight vectors. dataset_name: The dataset name for plot titles. 1.2.4.3 Truncation compute_abs_smd_trunc() calculates absolute SMDs for truncated weight datasets across different truncation methods and weighting variables. compute_abs_smd_trunc &lt;- function(trunc_list, treat, covar, weight_cols) { all_smd &lt;- list() for(trunc_name in names(trunc_list)) { dataset &lt;- trunc_list[[trunc_name]] smd_list &lt;- lapply(weight_cols, function(wcol) { if (wcol %in% names(dataset)) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = dataset, weights = dataset[[wcol]], un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Adj) data.frame( Method = paste(trunc_name, wcol, sep = &quot;_&quot;), Mean_Abs_SMD = mean(smd_vals, na.rm = TRUE), Max_Abs_SMD = max(smd_vals, na.rm = TRUE) ) } else { NULL } }) all_smd[[trunc_name]] &lt;- do.call(rbind, smd_list) } smd_summary &lt;- do.call(rbind, all_smd) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments trunc_list: A list of data frames, each containing a dataset with truncated weights. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: The name of the columns holding the weights. compute_ess_trunc() computes ESS values for truncated weight datasets considering different methods and weights. compute_ess_trunc &lt;- function(trunc_list, treat, covar, weight_cols) { all_ess &lt;- list() for(trunc_name in names(trunc_list)) { dataset &lt;- trunc_list[[trunc_name]] ess_list &lt;- lapply(weight_cols, function(wcol) { if (wcol %in% names(dataset)) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = dataset, weights = dataset[[wcol]], un = FALSE, s.d.denom = &quot;treated&quot; ) samples &lt;- bal_obj$Observations if (&quot;Adjusted&quot; %in% rownames(samples)) { df &lt;- data.frame( Method = paste(trunc_name, wcol, sep = &quot;_&quot;), Control = samples[&quot;Adjusted&quot;, &quot;Control&quot;], Treated = samples[&quot;Adjusted&quot;, &quot;Treated&quot;] ) } else { df &lt;- data.frame( Method = paste(trunc_name, wcol, sep = &quot;_&quot;), Control = samples[1, &quot;Control&quot;], Treated = samples[1, &quot;Treated&quot;] ) } df } else { NULL } }) all_ess[[trunc_name]] &lt;- do.call(rbind, ess_list) } ess_summary &lt;- do.call(rbind, all_ess) rownames(ess_summary) &lt;- NULL return(ess_summary) } Arguments trunc_list: A list of data frames, each containing a dataset with truncated weights. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: The name of the columns holding the weights. plot_trunc_methods() produces love plots for various truncation methods and weight types, visualizing covariate balance before and after truncation. plot_trunc_methods &lt;- function(trunc_list, treat, covar, weight_cols, dataset_name = NULL) { for(trunc_name in names(trunc_list)) { dataset &lt;- trunc_list[[trunc_name]] for(wcol in weight_cols) { if(wcol %in% names(dataset)) { bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = dataset, weights = dataset[[wcol]], un = TRUE, s.d.denom = &quot;treated&quot; ) title_text &lt;- if (!is.null(dataset_name)) { paste(dataset_name, &quot;-&quot;, trunc_name, &quot;-&quot;, wcol, &quot;truncation&quot;) } else { paste(trunc_name, wcol, &quot;truncation&quot;) } lp &lt;- cobalt::love.plot( bal_obj, stats = &quot;mean.diffs&quot;, abs = TRUE, var.order = &quot;unadjusted&quot;, thresholds = c(m = 0.1), stars = &quot;none&quot;, title = title_text ) print(lp) } } } } Arguments trunc_list: A list of data frames, each containing a dataset with truncated weights. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. weight_cols: The name of the columns holding the weights. dataset_name: The dataset name for plot titles. 1.2.4.4 Trimming compute_abs_smd_trim() computes absolute SMDs for multiple trimmed datasets. compute_abs_smd_trim &lt;- function(trimming_list, treat, covar) { smd_list &lt;- lapply(names(trimming_list), function(name) { data &lt;- trimming_list[[name]] bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Un) mean_smd &lt;- mean(smd_vals, na.rm = TRUE) max_smd &lt;- max(smd_vals, na.rm = TRUE) return(data.frame( Method = name, Mean_Abs_SMD = mean_smd, Max_Abs_SMD = max_smd )) }) smd_summary &lt;- do.call(rbind, smd_list) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments trimming_list: A list of data frames, each a trimmed dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. compute_ess_trim() extracts ESS information for multiple trimmed datasets. compute_ess_trim &lt;- function(trimming_list, treat, covar) { ess_list &lt;- lapply(trimming_list, function(data) { bal_obj &lt;- cobalt::bal.tab(as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, un = TRUE) samples &lt;- bal_obj$Observations df &lt;- as.data.frame(samples)[c(&quot;Control&quot;, &quot;Treated&quot;)] return(df) }) ess_df &lt;- do.call(rbind, ess_list) ess_df$Method &lt;- names(trimming_list) rownames(ess_df) &lt;- NULL ess_df &lt;- ess_df[, c(&quot;Method&quot;, &quot;Control&quot;, &quot;Treated&quot;)] return(ess_df) } Arguments trimming_list: A list of data frames, each a trimmed dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. plot_trim() plots overlap diagnostics for a set of trimmed datasets, visualizing covariate balance before and after matching. plot_trim &lt;- function(data_list, treat, covar) { par(mfrow = c(2,3)) for (data_obj in data_list) { assess_overlap(data_obj, treat = treat, cov = covar) } } Arguments data_list: A list of data frames to plot. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. 1.2.4.5 Combined methods compute_smd_all_datasets () aggregates absolute SMD statistics across multiple datasets, weighting methods, and trimming techniques. compute_smd_all_datasets &lt;- function(combined_list, treat, covar) { smd_list &lt;- lapply(names(combined_list), function(weight_method) { method_list &lt;- combined_list[[weight_method]] res &lt;- lapply(names(method_list), function(trim_method) { data &lt;- method_list[[trim_method]] # Use equal weights if weight column missing if (!&quot;weight&quot; %in% colnames(data)) { data$weight &lt;- rep(1, nrow(data)) } bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = data$weight, un = TRUE, s.d.denom = &quot;treated&quot; ) smd_df &lt;- as.data.frame(bal_obj$Balance) smd_vals &lt;- abs(smd_df$Diff.Adj) method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) data.frame( Method = method_name, Mean_Abs_SMD = mean(smd_vals, na.rm = TRUE), Max_Abs_SMD = max(smd_vals, na.rm = TRUE) ) }) do.call(rbind, res) }) smd_summary &lt;- do.call(rbind, smd_list) rownames(smd_summary) &lt;- NULL return(smd_summary) } Arguments combined_list: A list of data frames grouped by weighting and trimming methods. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. compute_ess_all_datasets() aggregates ESS information across various datasets, weighting methods, and trimming techniques. compute_ess_all_datasets &lt;- function(combined_list, treat, covar) { ess_list &lt;- lapply(names(combined_list), function(weight_method) { method_list &lt;- combined_list[[weight_method]] res &lt;- lapply(names(method_list), function(trim_method) { data &lt;- method_list[[trim_method]] # Use equal weights if weight column missing if (!&quot;weight&quot; %in% colnames(data)) { data$weight &lt;- rep(1, nrow(data)) } bal_obj &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = data, weights = data$weight, un = TRUE, s.d.denom = &quot;treated&quot; ) samples &lt;- bal_obj$Observations if (&quot;Adjusted&quot; %in% rownames(samples)) { control_ess &lt;- samples[&quot;Adjusted&quot;, &quot;Control&quot;] treated_ess &lt;- samples[&quot;Adjusted&quot;, &quot;Treated&quot;] } else { control_ess &lt;- samples[1, &quot;Control&quot;] treated_ess &lt;- samples[1, &quot;Treated&quot;] } method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) data.frame( Method = method_name, Control = control_ess, Treated = treated_ess ) }) do.call(rbind, res) }) ess_summary &lt;- do.call(rbind, ess_list) rownames(ess_summary) &lt;- NULL return(ess_summary) } Arguments combined_list: A list of data frames grouped by weighting and trimming methods. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. plot_comb_overlap() creates plots assessing overlap for combinations of weighting and trimming methods across datasets. plot_comb_overlap &lt;- function(comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) { all_combined_list &lt;- list() if (!is.null(comb_meth_cps)) all_combined_list$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_combined_list$PSID &lt;- comb_meth_psid for (ds_name in names(all_combined_list)) { combined_list &lt;- all_combined_list[[ds_name]] plot_list &lt;- list() method_names &lt;- character() for (weight_method in names(combined_list)) { for (trim_method in names(combined_list[[weight_method]])) { full_method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) plot_list[[full_method_name]] &lt;- list( data = combined_list[[weight_method]][[trim_method]], method_name = full_method_name ) method_names &lt;- c(method_names, full_method_name) } } total_plots &lt;- length(plot_list) plots_per_page &lt;- 4 # 2x2 layout for (i in seq(1, total_plots, by = plots_per_page)) { page_plots &lt;- plot_list[i:min(i + plots_per_page - 1, total_plots)] par(mfrow = c(2, 2), mar = c(4, 4, 2, 1)) for (p in page_plots) { assess_overlap(p$data, treat = treat, cov = covar) idx &lt;- match(p$method_name, method_names) prefix &lt;- if (ds_name == &quot;CPS&quot; &amp;&amp; idx &lt;= 25) prefix_cps else if (ds_name == &quot;PSID&quot; &amp;&amp; idx &lt;= 25) prefix_psid else &quot;&quot; title(main = paste0(prefix, &quot; - &quot;, p$method_name)) } } } } Arguments comb_meth_cps: A list combining weighting and trimming results for CPS dataset. comb_meth_psid: A list combining weighting and trimming results for PSID dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix_cps: A string prefix for plot titles related to CPS results. prefix_psid: A string prefix for plot titles related to PSID results. plot_comb_love_plots() visualizes SMDs via love plots for combined weighting and trimming approaches. plot_comb_love_plots &lt;- function(comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) { all_datasets &lt;- list() if (!is.null(comb_meth_cps)) all_datasets$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_datasets$PSID &lt;- comb_meth_psid for (ds_name in names(all_datasets)) { method_list &lt;- all_datasets[[ds_name]] method_names &lt;- unlist(lapply(names(method_list), function(weighting) { trimmed_list &lt;- method_list[[weighting]] sapply(names(trimmed_list), function(trim) paste(weighting, trim, sep = &quot;_&quot;)) })) plot_counter &lt;- 0 for (weighting in names(method_list)) { trimmed_list &lt;- method_list[[weighting]] for (trim in names(trimmed_list)) { df &lt;- trimmed_list[[trim]] plot_counter &lt;- plot_counter + 1 if (!&quot;weight&quot; %in% names(df)) df$weight &lt;- 1 bal &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = df, weights = df$weight, un = TRUE, s.d.denom = &quot;treated&quot; ) method_name &lt;- paste(weighting, trim, sep = &quot;_&quot;) prefix &lt;- &quot;&quot; if (ds_name == &quot;CPS&quot; &amp;&amp; plot_counter &lt;= 25) prefix &lt;- prefix_cps if (ds_name == &quot;PSID&quot; &amp;&amp; plot_counter &lt;= 25) prefix &lt;- prefix_psid title_text &lt;- paste(prefix, method_name, sep = &quot; - &quot;) lp &lt;- cobalt::love.plot( bal, stats = &quot;mean.diffs&quot;, absolute = TRUE, var.order = &quot;unadjusted&quot;, thresholds = c(m = .1), title = title_text ) print(lp) } } } } Arguments comb_meth_cps: A list combining weighting and trimming results for CPS dataset. comb_meth_psid: A list combining weighting and trimming results for PSID dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix_cps: A string prefix for plot titles related to CPS results. prefix_psid: A string prefix for plot titles related to PSID results. save_comb_hist() saves the histograms into a pdf file. save_comb_hist &lt;- function(comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, prefix = &quot;model_a&quot;, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;, path = &quot;../graphs/lalonde&quot;) { dir.create(path, showWarnings = FALSE, recursive = TRUE) all_combined_list &lt;- list() if (!is.null(comb_meth_cps)) all_combined_list$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_combined_list$PSID &lt;- comb_meth_psid file_index &lt;- 1 for (ds_name in names(all_combined_list)) { combined_list &lt;- all_combined_list[[ds_name]] method_names &lt;- character() plot_list &lt;- list() for (weight_method in names(combined_list)) { for (trim_method in names(combined_list[[weight_method]])) { full_method_name &lt;- paste(weight_method, trim_method, sep = &quot;_&quot;) plot_list[[full_method_name]] &lt;- combined_list[[weight_method]][[trim_method]] method_names &lt;- c(method_names, full_method_name) } } total_plots &lt;- length(plot_list) for (i in seq_len(total_plots)) { data &lt;- plot_list[[i]] pdf_file &lt;- file.path(path, sprintf(&quot;%s_overlap_%d.pdf&quot;, prefix, file_index)) pdf(pdf_file, width = 8, height = 6) invisible(capture.output({ assess_overlap(data, treat = treat, cov = covar) prefix_str &lt;- if (ds_name == &quot;CPS&quot;) prefix_cps else prefix_psid title(main = paste0(prefix_str, &quot; - &quot;, method_names[i])) }, type = &quot;output&quot;)) dev.off() file_index &lt;- file_index + 1 } } } Arguments comb_meth_cps: A list combining weighting and trimming results for CPS dataset. comb_meth_psid: A list combining weighting and trimming results for PSID dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix: A string prefix for plot titles related to the respective dataset or model. prefix_cps: A string prefix for plot titles related to CPS results. prefix_psid: A string prefix for plot titles related to PSID results. save_comb_loveplots() saves the loveplots into a pdf file. save_comb_loveplots &lt;- function(comb_meth_cps = NULL, comb_meth_psid = NULL, treat, covar, prefix = &quot;model_a&quot;, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;, path = &quot;../graphs/lalonde&quot;) { dir.create(path, showWarnings = FALSE, recursive = TRUE) all_datasets &lt;- list() if (!is.null(comb_meth_cps)) all_datasets$CPS &lt;- comb_meth_cps if (!is.null(comb_meth_psid)) all_datasets$PSID &lt;- comb_meth_psid file_index &lt;- 1 for (ds_name in names(all_datasets)) { method_list &lt;- all_datasets[[ds_name]] method_names &lt;- unlist(lapply(names(method_list), function(weighting) { trimmed_list &lt;- method_list[[weighting]] sapply(names(trimmed_list), function(trim) paste(weighting, trim, sep = &quot;_&quot;)) })) for (weighting in names(method_list)) { trimmed_list &lt;- method_list[[weighting]] for (trim in names(trimmed_list)) { df &lt;- trimmed_list[[trim]] if (!&quot;weight&quot; %in% names(df)) df$weight &lt;- 1 bal &lt;- cobalt::bal.tab( as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))), data = df, weights = df$weight, un = TRUE, s.d.denom = &quot;treated&quot; ) method_name &lt;- paste(weighting, trim, sep = &quot;_&quot;) prefix_str &lt;- ifelse(ds_name == &quot;CPS&quot;, prefix_cps, prefix_psid) pdf_file &lt;- file.path(path, sprintf(&quot;%s_balance_%d.pdf&quot;, prefix, file_index)) pdf(pdf_file, width = 8, height = 6) lp &lt;- cobalt::love.plot( bal, stats = &quot;mean.diffs&quot;, absolute = TRUE, var.order = &quot;unadjusted&quot;, thresholds = c(m = .1), title = paste(prefix_str, method_name, sep = &quot; - &quot;) ) print(lp) dev.off() file_index &lt;- file_index + 1 } } } } Arguments comb_meth_cps: A list combining weighting and trimming results for CPS dataset. comb_meth_psid: A list combining weighting and trimming results for PSID dataset. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. prefix: A string prefix used for saved file names to identify dataset. prefix_cps: A string prefix for plot titles related to CPS results. prefix_psid: A string prefix for plot titles related to PSID results. 1.2.4.6 Getting top methods and datasets combine_results() merges and summarizes SMD and ESS statistics from various analysis stages into a final comparison table. combine_results &lt;- function(dataset_name) { dataset_lower &lt;- tolower(dataset_name) # Retrieve matching results smd_matching &lt;- get(paste0(&quot;smd_matchit.&quot;, dataset_lower)) ess_matching &lt;- get(paste0(&quot;ess_matchit.&quot;, dataset_lower)) # Retrieve trimming results smd_trimming &lt;- get(paste0(&quot;smd_trim.&quot;, dataset_lower)) ess_trimming &lt;- get(paste0(&quot;ess_trim.&quot;, dataset_lower)) # Retrieve truncation results smd_trunc &lt;- get(paste0(&quot;smd_trunc.&quot;, dataset_lower)) ess_trunc &lt;- get(paste0(&quot;ess_trunc.&quot;, dataset_lower)) # Retrieve weighting results smd_weighting &lt;- get(paste0(&quot;smd_weight.&quot;, dataset_lower)) ess_weighting &lt;- get(paste0(&quot;ess_weight.&quot;, dataset_lower)) # Retrieve combined SMD and ESS # Make sure you have these variables in your environment per dataset smd_combined_var &lt;- paste0(&quot;smd_all_comb_meth.&quot;, dataset_lower) ess_combined_var &lt;- paste0(&quot;ess_all_comb_meth.&quot;, dataset_lower) smd_combined &lt;- get(smd_combined_var) ess_combined &lt;- get(ess_combined_var) # Combine all SMD results smd_all &lt;- do.call(rbind, list( smd_matching, smd_trimming, smd_trunc, smd_weighting, smd_combined[, c(&quot;Method&quot;, &quot;Mean_Abs_SMD&quot;, &quot;Max_Abs_SMD&quot;)] )) # Combine all ESS results ess_all &lt;- do.call(rbind, list( ess_matching, ess_trimming, ess_trunc, ess_weighting, ess_combined[, c(&quot;Method&quot;, &quot;Control&quot;, &quot;Treated&quot;)] )) # Merge SMD and ESS results by Method final_df &lt;- merge(smd_all, ess_all, by = &quot;Method&quot;, all = TRUE) # Remove dataset suffixes like &quot;.cps_plus&quot; or &quot;.psid_plus&quot; from Method names for cleaner labels final_df$Method &lt;- gsub(&quot;\\\\.psid_plus&quot;, &quot;&quot;, final_df$Method, ignore.case = TRUE) final_df$Method &lt;- gsub(&quot;\\\\.cps_plus&quot;, &quot;&quot;, final_df$Method, ignore.case = TRUE) # Reset row names rownames(final_df) &lt;- NULL return(final_df) } Arguments dataset_name: The dataset name for which to combine SMD and ESS summaries. save_csv() saves the tables into a CSV file. save_csv &lt;- function(data, filename) { folder &lt;- &quot;../tables&quot; if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) file_csv &lt;- file.path(folder, paste0(filename, &quot;.csv&quot;)) write.csv(data, file = file_csv, row.names = FALSE) } Arguments data: The dataset. filename: The name of the file that is to be saved as CSV. assess_methods() scores and ranks methods based on a weighted combination of balance and sample size metrics. assess_methods &lt;- function(df) { df %&gt;% mutate( # ess score ess_balance_ratio = pmin(Control, Treated) / pmax(Control, Treated), ess_total = Control + Treated, # Normalize balance_ratio and ess_total ess_balance_score = (ess_balance_ratio - min(ess_balance_ratio, na.rm = TRUE)) / (max(ess_balance_ratio, na.rm = TRUE) - min(ess_balance_ratio, na.rm = TRUE)), ess_size_score = (ess_total - min(ess_total, na.rm = TRUE)) / (max(ess_total, na.rm = TRUE) - min(ess_total, na.rm = TRUE)), # Combine size and balance equally ess_score = 0.5 * ess_balance_score + 0.5 * ess_size_score, # smd score smd_score = 1 - (Mean_Abs_SMD - min(Mean_Abs_SMD, na.rm = TRUE)) / (max(Mean_Abs_SMD, na.rm = TRUE) - min(Mean_Abs_SMD, na.rm = TRUE)), # final score Score = 0.5 * smd_score + 0.5 * ess_score ) %&gt;% dplyr::select(Method, Score) %&gt;% arrange(desc(Score)) } Argument df: A data frame containing method performance metrics. get_top_methods() retrieves the top-performing methods based on combined scoring criteria. get_top_methods &lt;- function(summary_df, top_n = 5) { if (!all(c(&quot;Method&quot;, &quot;Score&quot;) %in% names(summary_df))) { stop(&quot;Data frame must contain columns &#39;Method&#39; and &#39;Score&#39;&quot;) } top_methods_df &lt;- summary_df %&gt;% arrange(desc(Score)) %&gt;% head(top_n) return(top_methods_df$Method) } Arguments summary_df: A data frame including columns used for ranking. top_n: Integer specifying the number of top-performing methods to return (default 5). create_top5_datasets() extracts datasets corresponding to the top five ranked methods for further analysis or presentation. create_top5_datasets &lt;- function(dataset_list, top5_method_names) { lapply(top5_method_names, function(method_name) { if (!method_name %in% names(dataset_list)) { stop(paste0(&quot;Method &#39;&quot;, method_name, &quot;&#39; not found in the dataset lookup list&quot;)) } ds &lt;- dataset_list[[method_name]] if (inherits(ds, &quot;matchit&quot;)) { # for matchit class, extract matched data return(as.data.frame(match.data(ds))) } else if (is.data.frame(ds)) { # if already dataframe, return as is return(ds) } else if (is.vector(ds)) { # merge with original data if (!&quot;original&quot; %in% names(dataset_list)) { stop(&quot;Original dataset not found in dataset_list to merge weights&quot;) } original_df &lt;- dataset_list[[&quot;original&quot;]] if (length(ds) != nrow(original_df)) { stop(paste0(&quot;Length of weight vector for method &#39;&quot;, method_name, &quot;&#39; does not match number of rows in original dataset&quot;)) } # create new data frame with weights appended weighted_df &lt;- original_df weighted_df[[&quot;weights&quot;]] &lt;- ds return(weighted_df) } else { stop(paste(&quot;Unsupported data type for method&quot;, method_name)) } }) } Arguments dataset_list: A list of datasets or MatchIt objects containing processed results for different methods. top5_method_names: A character vector of method names corresponding to the top-ranked datasets. save_top5_individual_files() saves datasets of the top five methods as individual files for reproducibility or sharing. save_top5_individual_files &lt;- function(combined_methods_list, top5_method_names, prefix) { for (i in seq_along(top5_method_names)) { method_name &lt;- top5_method_names[i] if (!method_name %in% names(combined_methods_list)) { warning(paste0(&quot;Method &#39;&quot;, method_name, &quot;&#39; not found in combined methods list&quot;)) next } dataset_to_save &lt;- combined_methods_list[[method_name]] file_name &lt;- sprintf(&quot;data/top%d_%s_method_%s.RData&quot;, i, prefix, method_name) save(dataset_to_save, file = file_name) } } Arguments combined_methods_list: A list of all combined method results. top5_method_names: A character vector of method names corresponding to the top-ranked datasets. prefix: A string prefix used for saved file names to identify dataset. 1.2.5 Estimating 1.2.5.1 Average treatment effect of the treated (ATT) estimate_all() runs multiple treatment effect estimators on a dataset and returns point estimates, standard errors and confidence intervals.*** # difference in means diff &lt;- function(data, Y, treat) { fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) out &lt;- summary(lm_robust(fml, data = data, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] return(out) # extract coef, se, ci.lower, ci.upper } # regression adjustment reg &lt;- function(data, Y, treat, covar) { fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat, &quot;+&quot;, paste(covar, collapse = &quot; + &quot;))) out &lt;- summary(lm_robust(fml, data = data, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] # extract coef, se, ci.lower, ci.upper return(out) } # matching #library(Matching) matching &lt;- function(data, Y, treat, covar) { m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = data[, covar], Z = data[, covar], estimand = &quot;ATT&quot;, M = 5, replace = TRUE, ties = TRUE, BiasAdjust = TRUE) out &lt;- c(m.out$est[1], m.out$se[1], m.out$est[1] - 1.96 * m.out$se[1], m.out$est[1] + 1.96 * m.out$se[1]) return(out) } # psm psm &lt;- function(data, Y, treat, covar) { ps &lt;- probability_forest(X = data[, covar], Y = as.factor(data[,treat]), seed = 1234, num.trees = 4000)$predictions[,2] m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = matrix(ps, nrow(data), 1), estimand = &quot;ATT&quot;, M = 5, replace = TRUE, ties = FALSE, BiasAdjust = FALSE) if (is.null(m.out$se)==FALSE) { se &lt;- m.out$se[1] } else { se &lt;- m.out$se.standard[1] } out &lt;- c(m.out$est[1], se, m.out$est[1] - 1.96 * se, m.out$est[1] + 1.96 * se) return(out) } # OM (reg) om.reg &lt;- function(data, Y, treat, covar) { tr &lt;- which(data[, treat] == 1) co &lt;- which(data[, treat] == 0) fml &lt;- as.formula(paste(Y, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) out.co &lt;- lm(fml, data = data[co, ]) Y.tr.hat &lt;- predict(out.co, newdata = data[tr, covar, drop = FALSE]) newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr))) out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = &quot;stata&quot;))$coefficients[&quot;treat&quot;, c(1, 2, 5, 6)] return(out) } # OM (grf) #library(grf) om.grf &lt;- function(data, Y, treat, covar) { tr &lt;- which(data[, treat] == 1) co &lt;- which(data[, treat] == 0) out.co &lt;- regression_forest(X = data[co, covar, drop = FALSE], Y = as.vector(data[co, Y]) ) Y.tr.hat &lt;- as.vector(unlist(predict(out.co, newdata = data[tr, covar, drop = FALSE]))) newdata &lt;- cbind.data.frame(Y = c(data[tr, Y], Y.tr.hat), treat = rep(c(1, 0), each = length(tr))) out &lt;- summary(lm_robust(Y ~ treat, data = newdata, se_type = &quot;stata&quot;))$coefficients[&quot;treat&quot;, c(1, 2, 5, 6)] return(out) } # IPW ipw &lt;- function(data, Y, treat, covar) { ps &lt;- probability_forest(X = data[, covar, drop = FALSE], Y = as.factor(data[, treat]), seed = 1234)$predictions[,2] fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) weights &lt;- rep(1, nrow(data)) co &lt;- which(data[, treat] == 0) weights[co] &lt;- ps[co]/(1-ps[co]) out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] # extract coef, se, ci.lower, ci.upper return(out) } # CBPS #library(&quot;CBPS&quot;) cbps &lt;- function(data, Y, treat, covar) { fml &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) ps &lt;- quiet(CBPS(fml, data = data, standardize = TRUE)$fitted.values) fml &lt;- as.formula(paste(Y, &quot;~&quot;, treat)) weights &lt;- rep(1, nrow(data)) co &lt;- which(data[, treat] == 0) weights[co] &lt;- ps[co]/(1-ps[co]) out &lt;- summary(lm_robust(fml, data = data, weights = weights, se_type = &quot;stata&quot;))$coefficients[treat, c(1, 2, 5, 6)] return(out) } # ebal #library(hbal) ebal &lt;- function(data, Y, treat, covar) { ebal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar, data = data, expand.degree = 1) out &lt;- hbal::att(ebal.out, dr = FALSE)[1, c(1, 2, 5, 6)] return(out) } # hbal # hbal &lt;- function(data, Y, treat, covar) { # hbal.out &lt;- hbal::hbal(Y = Y, Treat = treat, X = covar, data = data, expand.degree = 2, # cv = TRUE) # out &lt;- hbal::att(hbal.out, dr = FALSE)[1, c(1, 2, 5, 6)] # return(out) # } # aipw_grf aipw &lt;- function(data, Y, treat, covar) { #library(&quot;grf&quot;) for (var in c(Y, treat, covar)) { data[, var] &lt;- as.vector(data[, var]) } c.forest &lt;- causal_forest(X = data[, covar, drop = FALSE], Y = data[, Y], W = data[, treat], seed = 1234) att &lt;- average_treatment_effect(c.forest, target.sample = &quot;treated&quot;, method = &quot;AIPW&quot;) att &lt;- c(att, att[1] - 1.96 * att[2], att[1] + 1.96 * att[2]) return(att) } aipw.match &lt;- function(data, Y, treat, covar) { # match on ps ps &lt;- probability_forest(X = data[, covar], Y = as.factor(data[, treat]), seed = 1234)$predictions[,2] m.out &lt;- Match(Y = data[, Y], Tr = data[, treat], X = ps, estimand = &quot;ATT&quot;, M = 1, replace = FALSE, ties = FALSE, BiasAdjust = FALSE) mb &lt;- quiet(MatchBalance(treat ~ ps, data = data, match.out = m.out, nboots= 0)) ks &lt;- mb$AfterMatching[[1]]$ks$ks$statistic s &lt;- data[c(m.out$index.treated, m.out$index.control), ] out &lt;- aipw(s, Y, treat, covar) #return(out) return(c(out, ks)) } aipw_ow &lt;- function(data, Y, treat, covar) { for (var in c(Y, treat, covar)) { data[, var] &lt;- as.vector(data[, var]) } X &lt;- data[, covar, drop = FALSE] Y &lt;- data[, Y] W &lt;- data[, treat] # run dml_with_smoother with AIPW_ATT dml_fit &lt;- dml_with_smoother(Y = Y, D = W, X = X, estimators = c(&quot;AIPW_ATT&quot;), smoother = &quot;honest_forest&quot;, n_cf_folds = 5, n_reps = 1) # extract estimate and SE from summary summ &lt;- summary(dml_fit, quiet = TRUE) est &lt;- summ[&quot;AIPW-ATT&quot;, &quot;Estimate&quot;] se &lt;- summ[&quot;AIPW-ATT&quot;, &quot;SE&quot;] ci_lower &lt;- est - 1.96 * se ci_upper &lt;- est + 1.96 * se return(c(est, se, ci_lower, ci_upper)) } ### dml dml &lt;-function(data, Y = NULL, treat = NULL, covar = NULL, clust_var = NULL, ml_l = lrn(&quot;regr.lm&quot;), ml_m = lrn(&quot;regr.lm&quot;)){ if(is.null(covar)){ stop(&quot;No controls in specification.&quot;) } #require(DoubleML) #require(mlr3learners) #require(fixest) #require(ggplot2) if(is.null(clust_var) == TRUE){ dat = data[,c(Y,treat,covar)] dat = na.omit(dat) dml_dat = DoubleMLData$new(dat, y_col = Y, d_cols = treat, use_other_treat_as_covariate = FALSE, x_cols = covar) }else{ dat = data[,c(Y, treat, covar, clust_var)] dat[,clust_var] = as.numeric(factor(dat[,clust_var])) dat = dat[is.na(dat[,Y]) == FALSE,] dat = dat[is.na(dat[,D]) == FALSE,] features = data.frame(model.matrix(formula(paste(c(&#39;~ 1&#39;,treat,covar), collapse=&quot;+&quot;)), dat)) dat = cbind(dat[,c(Y,clust_var)],features) dml_dat = DoubleMLClusterData$new(dat, y_col = Y, d_cols = treat, cluster_cols = clust_var, use_other_treat_as_covariate = FALSE, x_cols = covar) } # Set active treatment treatment dml_dat$set_data_model(treat) # Estimate with DML set.seed(pi) dml_mod = DoubleMLPLR$new(dml_dat, ml_l=ml_l, ml_m=ml_m) quiet(dml_mod$fit()) out = c(dml_mod$coef[treat], dml_mod$se[treat], dml_mod$confint()[treat,]) return(out) } # execute all estimators estimate_all &lt;- function(data, Y, treat, covar, methods = c(&quot;diff&quot;, &quot;reg&quot;, &quot;om.reg&quot;, &quot;om.grf&quot;, &quot;matching&quot;, &quot;psm&quot;, &quot;ipw&quot;, &quot;cbps&quot;, &quot;ebal&quot;, &quot;dml&quot;, &quot;aipw_grf&quot;, &quot;aipw_ow&quot;)) { results &lt;- as.data.frame(matrix(NA, length(methods), 4)) rownames(results) &lt;- methods colnames(results) &lt;- c(&quot;Estimate&quot;, &quot;SE&quot;, &quot;CI_lower&quot;, &quot;CI_upper&quot;) m &lt;- 1 if (&quot;diff&quot; %in% methods) { results[m, ] &lt;- diff(data, Y, treat) m &lt;- m + 1 } if (&quot;reg&quot; %in% methods) { results[m, ] &lt;- reg(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;om.reg&quot; %in% methods) { results[m, ] &lt;- om.reg(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;om.grf&quot; %in% methods) { results[m, ] &lt;- om.grf(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;matching&quot; %in% methods) { results[m, ] &lt;- matching(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;psm&quot; %in% methods) { results[m, ] &lt;- psm(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;ipw&quot; %in% methods) { results[m, ] &lt;- ipw(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;cbps&quot; %in% methods) { results[m, ] &lt;- cbps(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;ebal&quot; %in% methods) { results[m, ] &lt;- quiet(ebal(data, Y, treat, covar)) m &lt;- m + 1 } # if (&quot;hbal&quot; %in% methods) { # results[m, ] &lt;- quiet(hbal(data, Y, treat, covar)) # m &lt;- m + 1 # } if (&quot;dml&quot; %in% methods) { results[m, ] &lt;-dml(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;aipw_grf&quot; %in% methods) { results[m, ] &lt;- aipw(data, Y, treat, covar) m &lt;- m + 1 } if (&quot;aipw_ow&quot; %in% methods) { results[m, ] &lt;- aipw_ow(data, Y, treat, covar) m &lt;- m + 1 } return(results) } Function calls quiet: Suppresses output from a function call. diff: Difference in means estimator. It runs a linear regression adjusting for robust standard errors and returns the coefficient, standard error, and confidence interval for the treatment variable. reg: Regression adjustment. Similar to diff but includes additional covariates in the regression model. matching: Propensity score matching using the Matching package. It aligns treated units to control units based on covariates and returns the estimated ATT and its confidence interval. psm: Propensity score matching using a probability forest, followed by matching and estimation of the ATT. om.reg: Outcome modeling using regression. It predicts the outcome for the treated units based on the model fitted to the control units, and then estimates the ATT. om.grf: Outcome modeling using generalized random forests, noted as GRF. ipw: Inverse probability weighting,denoted as IPW. It weights observations by the inverse of their estimated propensity scores and calculates the treatment effect with a weighted regression. cbps: Covariate balancing propensity score, noted as CBPS. It estimates propensity scores to achieve balance on covariates across groups. ebal: Entropy balancing. It reweights the data to balance the covariate distributions. hbal: Hierarchical balancing. It is an extension of ebal with more complex balancing methods. aipw: Augmented inverse probability weighting, noted as AIPW. aipw.match: Combines matching on propensity scores with AIPW. aipw_ow: AIPW computed via outcome weights. dml: Double machine learning. It uses machine learning algorithms to control for confounders when estimating treatment effects. plot_coef() plots treatment effect point estimates and corresponding confidence intervals comparatively across various estimators.*** plot_coef &lt;- function(out, methods = c(&quot;diff&quot;, &quot;reg&quot;, &quot;om.reg&quot;, &quot;om.grf&quot;, &quot;matching&quot;, &quot;psm&quot;, &quot;ipw&quot;, &quot;cbps&quot;, &quot;ebal&quot;, &quot;dml&quot;, &quot;aipw_grf&quot;, &quot;aipw_ow&quot;), labels = c(&quot;Diff-in-Means&quot;, &quot;Reg&quot;, &quot;OM: Reg&quot;, &quot;OM: GRF&quot;, &quot;NN\\nMatching&quot;, &quot;PS\\nMatching&quot;, &quot;IPW&quot;, &quot;CBPS&quot;, &quot;Ebal&quot;, &quot;DML\\nElasnet&quot;, &quot;AIPW-GRF&quot;, &quot;AIPW-OW&quot;), main = NULL, ylab = &quot;Estimate&quot;, band = NULL, line = NULL, grid = TRUE, main.pos = 1, main.line = -2, ylim = NULL, textsize = 0.8 ) { if (is.null(methods) == TRUE) { methods &lt;- rownames(out) } if (is.null(labels) == TRUE) { labels &lt;- methods } # # check # if (is.null(out)==FALSE) { # if (inherits(out, &quot;ivDiag&quot;) == FALSE) {stop(&quot;\\&quot;out\\&quot; needs to be a \\&quot;ltz\\&quot; object.&quot;)} # } # # # title # if (is.null(main)==TRUE) { # main &lt;- &quot;Estimates with 95% CIs&quot; # } # data for the plot data &lt;- out rg &lt;- range(data[,c(3,4)], na.rm = TRUE) adj &lt;- rg[2] - rg[1] if (is.null(ylim) == TRUE) { ylim &lt;- c(min(0, rg[1] - 0.3*adj), max(0, rg[2] + 0.35*adj)) } adj2 &lt;- ylim[2] - ylim[1] # Set up the plot ncoefs &lt;- length(methods) par(mar = c(2.5, 4, 1, 2)) plot(1: ncoefs, data[, 1], xlim = c(0.5, ncoefs + 0.5), ylim = ylim, ylab = &quot;&quot;, xlab = &quot;&quot;, main = &quot;&quot;, axes = FALSE, xaxt = &quot;n&quot;, yaxt = &quot;n&quot;, type = &quot;n&quot;) axis(1, at = 1: ncoefs, labels = labels, las = 1, cex.axis = 0.8) axis(2, cex.axis = 0.7) mtext(main, main.pos, line = main.line, cex = textsize) mtext(ylab, 2, line = 2.5) if (is.null(band) == FALSE) { rect(-0.5, band[1], ncoefs + 1, band[2], col = &quot;#ff000030&quot;, border = &quot;white&quot;) # label at bottom } if (is.null(line) == FALSE) { abline(h = line, col = &quot;red&quot;, lty = 2) } if (grid == TRUE) { abline(h = axTicks(2), lty = &quot;dotted&quot;, col = &quot;gray50&quot;) abline(v = c(0.5, c(1: ncoefs) + 0.5), lty = &quot;dotted&quot;, col = &quot;gray50&quot;) # horizontal grid } abline(h = 0, col = &quot;red&quot;, lwd = 2, lty = &quot;solid&quot;) segments(y0 = data[, 3], x0 = c(1: ncoefs), y1 = data[, 4], x1 = c(1: ncoefs), lwd = 2) #CI points(1: ncoefs, data[, 1], pch = 16, col = 1, cex = 1.2) #point coefs box() } plot_att_panels() produces panels of ATT estimates with confidence intervals for multiple methods and datasets. plot_att_panels &lt;- function(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), plots_per_page = 4, ylab = &quot;Estimate&quot;, textsize = 1) { num_pages &lt;- ceiling(length(all_outs) / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, length(all_outs)) par(mfrow = c(plots_per_page, 1), mar = c(3, 4, 3, 2)) for (i in start_idx:end_idx) { out &lt;- all_outs[[i]] plot_coef(out, band = band, line = est, ylim = ylim, main = plot_titles[i], ylab = ylab, textsize = textsize) } } } Arguments all_outs: A list of output objects containing ATT estimates and confidence intervals for different methods. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_outs. band: A numeric vector specifying the confidence interval bounds. est: A numeric value representing the point estimate. ylim: A numeric vector specifying the y-axis limits for the plots (default c(-15500, 5500)). plots_per_page: The number of plots to display per page / panel (default 4). ylab: The label for the y-axis (default “Estimate”). textsize: A numeric scaling factor for text size in plots (default 1). save_att_panels() generates and saves paginated pdf plots that display ATT estimates and their confidence bands from multiple methods. save_att_panels &lt;- function( all_outs, plot_titles, band, est, prefix, plots_per_page = 4, ylab = &quot;Estimate&quot;, textsize = 1) { folder &lt;- &quot;../graphs/lalonde&quot; ylim &lt;- c(-15500, 5500) if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) num_pages &lt;- ceiling(length(all_outs) / plots_per_page) for (page in seq_len(num_pages)) { file_name &lt;- file.path(folder, paste0(prefix, &quot;_&quot;, page, &quot;.pdf&quot;)) pdf(file_name, width = 8, height = 11) par(mfrow = c(plots_per_page, 1), mar = c(3,4,3,2)) start_idx &lt;- (page - 1) * plots_per_page + 1 end_idx &lt;- min(page * plots_per_page, length(all_outs)) for (i in start_idx:end_idx) { plot_coef(all_outs[[i]], band = band, line = est, ylim = ylim, main = plot_titles[i], ylab = ylab, textsize = textsize) } dev.off() } } Arguments all_outs: A list of output objects containing ATT estimates and confidence intervals for different methods. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_outs. band: A numeric vector specifying the confidence interval bounds. est: A numeric value representing the point estimate. prefix: A string prefix used for saved file names to identify dataset. plots_per_page: The number of plots to display per page / panel (default 4). ylab: The label for the y-axis (default “Estimate”). textsize: A numeric scaling factor for text size in plots (default 1). create_matrix_results() organizes estimation results into a formatted matrix suitable for reporting or tables. create_matrix_results &lt;- function(all_outs, sample_names) { n_samples &lt;- length(sample_names) n_estimators &lt;- nrow(all_outs[[1]]) result_mat &lt;- matrix(&quot;&quot;, nrow = n_estimators + 1, ncol = n_samples * 2) # Set up alternating column names cnames &lt;- character(n_samples * 2) for (j in seq_along(sample_names)) { cnames[(j-1)*2 + 1] &lt;- sample_names[j] cnames[(j-1)*2 + 2] &lt;- &quot;&quot; # SE/parenthesis column } colnames(result_mat) &lt;- cnames estimator_names &lt;- rownames(all_outs[[1]]) rownames(result_mat) &lt;- c(&quot;Experimental Benchmark&quot;, estimator_names) # Fill values for (j in seq_along(all_outs)) { out &lt;- all_outs[[j]] result_mat[1, (j-1)*2 + 1] &lt;- sprintf(&quot;%.2f&quot;, out[1, 1]) result_mat[1, (j-1)*2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, out[1, 2]), &quot;)&quot;) for (i in 2:(n_estimators+1)) { result_mat[i, (j-1)*2 + 1] &lt;- sprintf(&quot;%.2f&quot;, out[i-1, 1]) result_mat[i, (j-1)*2 + 2] &lt;- paste0(&quot;(&quot;, sprintf(&quot;%.2f&quot;, out[i-1, 2]), &quot;)&quot;) } } return(result_mat) } Arguments all_outs: A list of output objects containing ATT estimates and confidence intervals for different methods. sample_names: A character vector of sample / dataset names corresponding to all_outs. eval_att() computes summary statistics of the treatment effect estimates. eval_att &lt;- function(result) { data.frame( Mean_SE = mean(result[, &quot;SE&quot;], na.rm = TRUE), # mean standard error across all estimator results Min_Estimate = min(result[, &quot;Estimate&quot;], na.rm = TRUE), # maximum estimate of all estimator results Max_Estimate = max(result[, &quot;Estimate&quot;], na.rm = TRUE), # minimum estimate of all estimator results Diff_Estimate = max(result[, &quot;Estimate&quot;], na.rm = TRUE) - min(result[, &quot;Estimate&quot;], na.rm = TRUE) ) } Argument result: A data frame containing treatment effect estimation results. 1.2.5.2 Conditional average treatment effect on the treated (CATT) plot_catt_panels() visualizes CATT comparing multiple methods. plot_catt_panels &lt;- function(all_catt, plot_titles, plots_per_page = 4, range = c(-8000, 8000)) { num_pages &lt;- ceiling((length(all_catt) - 1) / plots_per_page) catt_ldw &lt;- all_catt[[1]]$catt att_ldw &lt;- all_catt[[1]]$att[1] id_ldw &lt;- if (!is.null(all_catt[[1]]$id)) all_catt[[1]]$id else seq_along(catt_ldw) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 2 # skip experimental vs itself end_idx &lt;- min(page * plots_per_page + 1, length(all_catt)) par(mfrow = c(plots_per_page, 1), mar = c(4.5, 5, 3, 2)) for (i in start_idx:end_idx) { other &lt;- all_catt[[i]] main_label &lt;- plot_titles[i] catt2 &lt;- other$catt att2 &lt;- other$att[1] id2 &lt;- if (!is.null(other$id)) other$id else seq_along(catt2) common_ids &lt;- intersect(id_ldw, id2) idx_ldw &lt;- match(common_ids, id_ldw) idx_other &lt;- match(common_ids, id2) catt1_plot &lt;- catt_ldw[idx_ldw] catt2_plot &lt;- catt2[idx_other] plot_catt( catt1 = catt1_plot, catt2 = catt2_plot, att1 = att_ldw, att2 = att2, xlab = &quot;CATT (Experimental)&quot;, ylab = main_label, main = main_label, axes.range = range ) } } } Arguments all_catt: A list of objects containing conditional average treatment effect on treated (CATT) estimates. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_catt. plots_per_page: The number of plots to display per page / panel (default 4). range: A numeric vector of axis limits for plots (default c(-8000, 8000)). save_catt_panels()generates and saves multi-page PDF plots comparing CATT estimates across different methods. save_catt_panels &lt;- function(all_catt, plot_titles, range = c(-8000, 8000), prefix = &quot;model_a&quot;, plots_per_page = 4) { dir.create(&quot;../graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) catt_ldw &lt;- all_catt[[1]]$catt att_ldw &lt;- all_catt[[1]]$att[1] id_ldw &lt;- if (!is.null(all_catt[[1]]$id)) all_catt[[1]]$id else seq_along(catt_ldw) num_panels &lt;- length(all_catt) - 1 # skip experimental on page num_pages &lt;- ceiling(num_panels / plots_per_page) for (page in seq_len(num_pages)) { start_idx &lt;- (page - 1) * plots_per_page + 2 # always skip all_catt[[1]] end_idx &lt;- min(page * plots_per_page + 1, length(all_catt)) plots_this_page &lt;- end_idx - start_idx + 1 file_name &lt;- sprintf(&quot;../graphs/lalonde/%s_catt_estimates_%d.pdf&quot;, prefix, page) pdf(file = file_name, width = 10, height = 12) par(mfrow = c(2, 2), mar = c(4, 4, 2, 2)) for (i in start_idx:end_idx) { other &lt;- all_catt[[i]] main_label &lt;- plot_titles[i] catt2 &lt;- other$catt att2 &lt;- other$att[1] id2 &lt;- if (!is.null(other$id)) other$id else seq_along(catt2) common_ids &lt;- intersect(id_ldw, id2) idx_ldw &lt;- match(common_ids, id_ldw) idx_other &lt;- match(common_ids, id2) catt1_plot &lt;- catt_ldw[idx_ldw] catt2_plot &lt;- catt2[idx_other] plot_catt( catt1 = catt1_plot, catt2 = catt2_plot, att1 = att_ldw, att2 = att2, xlab = &quot;CATT (Experimental)&quot;, ylab = main_label, main = main_label, axes.range = range ) } # blanks if fewer than 4 plots on last page if (plots_this_page &lt; plots_per_page) { for (k in seq_len(plots_per_page - plots_this_page)) plot.new() } dev.off() } } Arguments all_catt: A list of objects containing conditional average treatment effect on treated (CATT) estimates. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_catt. range: A numeric vector of axis limits for plots (default c(-8000, 8000)). prefix: A string prefix for saved PDF filenames. plots_per_page: The number of plots to display per page / panel (default 4). eval_catt() computes summary statistics of CATT vectors for each method, returning the minimum, maximum, mean, and range (difference) of the CATT estimates. eval_catt &lt;- function(all_catt, plot_titles) { do.call(rbind, lapply(seq_along(all_catt), function(i) { catt_vec &lt;- all_catt[[i]]$catt data.frame( Method = plot_titles[i], Min_Catt = min(catt_vec, na.rm = TRUE), Max_Catt = max(catt_vec, na.rm = TRUE), Mean_Catt = mean(catt_vec, na.rm = TRUE), Diff_Catt = max(catt_vec, na.rm = TRUE) - min(catt_vec, na.rm = TRUE), stringsAsFactors = FALSE ) })) } Arguments all_catt: A list of objects containing conditional average treatment effect on treated (CATT) estimates. plot_titles: A character vector of titles for each plot, corresponding to the outputs in all_catt. 1.2.5.3 Quantile treatment effect on treated (QTET) plot_qte_top() plots QTET of top-ranked samples for comparison against an experimental benchmark. plot_qte_top &lt;- function(qtet_top, qtet_top0, bm, plot_titles, main_start = 1, ylim = NULL, col = NULL) { n &lt;- length(qtet_top) for (i in 1:n) { main_title &lt;- plot_titles[main_start + i - 1] mod &lt;- qtet_top[[i]] mod2 &lt;- qtet_top0[[i]] plot_qte(mod, mod2, bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) } } Arguments qtet_top: A list of objects containing QTET estimates for top-ranked samples. qtet_top0: A list of objects containing unadjusted QTET estimates. bm: Experimental benchmark. plot_titles: A character vector of titles for each plot, matching the order of elements in qtet_top. main_start: Integer index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots. col: Color specification. save_qtet() generates and saves quantile treatment effect on the treated (QTET) plots for a given list of estimates. save_qtet &lt;- function(plots, plot_titles = NULL, main_start = 1, ylim = NULL, col = NULL, prefix = &quot;model_a&quot;) { dir.create(&quot;../graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) n &lt;- length(plots) for (i in seq_len(n)) { p &lt;- plots[[i]] main_title &lt;- if (is.null(plot_titles)) p$main else plot_titles[main_start + i - 1] clean_title &lt;- gsub(&quot;[^a-zA-Z0-9]&quot;, &quot;_&quot;, main_title) file_name &lt;- sprintf(&quot;../graphs/lalonde/%s_qtet_estimates_%s.pdf&quot;, prefix, clean_title) pdf(file = file_name, width = 7, height = 5) plot_qte(p$mod, p$mod0, p$bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) dev.off() } } Arguments plots: A list of objects containing QTET estimates and corresponding unadjusted estimates. plot_titles: A character vector of titles for each plot, matching the order of elements in plots. main_start: Integer index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots. col: Color specification. prefix: A string prefix for saved PDF filenames. save_qte_top() generates and saves quantile treatment effect on the treated (QTET) plots for a given list of estimates of top-ranked samples. save_qte_top &lt;- function(qtet_top, qtet_top0, bm, plot_titles, main_start = 1, ylim = NULL, col = NULL, prefix = &quot;model_a_top&quot;) { n &lt;- length(qtet_top) dir.create(&quot;../graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) for (i in seq_len(n)) { mod &lt;- qtet_top[[i]] mod2 &lt;- qtet_top0[[i]] main_title &lt;- plot_titles[main_start + i - 1] clean_title &lt;- gsub(&quot;[^a-zA-Z0-9]&quot;, &quot;_&quot;, main_title) file_name &lt;- sprintf(&quot;../graphs/lalonde/%s_qte_estimates_%s.pdf&quot;, prefix, clean_title) pdf(file = file_name, width = 7, height = 5) plot_qte(mod, mod2, bm, main = main_title, ylim = ylim, col = col) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) dev.off() } } Arguments qtet_top: A list of objects containing QTET estimates for top-ranked samples. qtet_top0: A list of objects containing unadjusted QTET estimates. plot_titles: A character vector of titles for each plot, matching the order of elements in qtet_top. main_start: Integer index specifying where to start selecting titles from plot_titles (default is 1). ylim: A numeric vector specifying the y-axis limits for the plots. col: Color specification. prefix: A string prefix for saved PDF filenames. 1.3 Outcome weights analysis get_res_att() estimates average treatment effects on the treated (ATT) using augmented inverse probability weighting with cross-fitting on a list of datasets. get_res_att &lt;- function(dataset_list, Y, treat, covar, estimators = &quot;AIPW_ATT&quot;, smoother = &quot;honest_forest&quot;, n_cf_folds = 5, n_reps = 1) { lapply(dataset_list, function(data) { dml_with_smoother( Y = data[[Y]], D = data[[treat]], X = data[, covar, drop = FALSE], estimators = estimators, smoother = smoother, n_cf_folds = n_cf_folds, n_reps = n_reps ) } ) } Arguments dataset_list: A list of datasets. Y: String specifying the name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. estimators: String specifying the estimator to use (default is “AIPW_ATT”). smoother: String specifying the smoothing method (default is “honest_forest”). n_cf_folds: Integer specifying the number of cross-fitting folds (default is 5). n_reps: Integer specifying the number of repetitions for robustness (default is 1). derive_ow() extracts outcome weights from a list of estimation results. derive_ow &lt;- function(results_list) { lapply(results_list, function(res) get_outcome_weights(res)) } Argument results_list: A list of objects obtained from get_res_att(). plot_ow() plots the distribution of the outcome weights. plot_ow &lt;- function(outcome_weights, plot_titles = NULL, breaks = 50, col = &quot;#ff000080&quot;, xlab = &quot;Outcome Weight&quot;, estimator = &quot;AIPW-ATT&quot;) { N &lt;- length(outcome_weights) for (i in seq_len(N)) { weights &lt;- outcome_weights[[i]]$omega[estimator, ] main_title &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Dataset&quot;, i) hist(weights, breaks = breaks, main = main_title, xlab = xlab, col = col) mtext(paste(&quot;N =&quot;, length(weights)), side = 3, line = -1.5, cex = 0.8) } par(mfrow = c(1, 1)) } Arguments outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. breaks: Integer specifying the number of bins for the histogram plots (default is 50). col: Color specification (default is “#ff000080”). xlab: String specifying the label for the x-axis (default is “Outcome Weight”) estimator: String specifying the estimator to use (default is “AIPW-ATT”). eval_ow() computes summary statistics of outcome weights by treatment group for a list of datasets and returns a data frame for comparison. eval_ow &lt;- function(outcome_weights, dataset_list, plot_titles = NULL, treat_var = &quot;treat&quot;, estimator = &quot;AIPW-ATT&quot;) { results &lt;- lapply(seq_along(outcome_weights), function(i) { ow &lt;- outcome_weights[[i]]$omega[estimator, ] treat &lt;- dataset_list[[i]][[treat_var]] method &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Dataset&quot;, i) sum_treated &lt;- sum(ow[treat == 1]) sum_untreated &lt;- sum(ow[treat == 0]) data.frame( Method = method, Sum_Treated = sum_treated, Sum_Untreated = sum_untreated, stringsAsFactors = FALSE ) }) do.call(rbind, results) } **Arguments* outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. treat_var: String specifying the treatment variable in each dataset (default is “treat”). estimator: String specifying the estimator to use (default is “AIPW-ATT”). save_ow() saves the outcome weight histograms as PDF files, one per dataset, with optional custom titles and formatting. save_ow &lt;- function(outcome_weights, plot_titles = NULL, breaks = 50, col = &quot;#ff000080&quot;, xlab = &quot;Outcome Weight&quot;, prefix = &quot;model_a&quot;, estimand = &quot;AIPW-ATT&quot;) { dir.create(&quot;../graphs/lalonde&quot;, showWarnings = FALSE, recursive = TRUE) N &lt;- length(outcome_weights) for (i in seq_len(N)) { file_name &lt;- sprintf(&quot;../graphs/lalonde/%s_outcomewt_%d.pdf&quot;, prefix, i) pdf(file = file_name, width = 8, height = 6) weights &lt;- outcome_weights[[i]]$omega[estimand, ] main_title &lt;- if (!is.null(plot_titles)) plot_titles[i] else paste(&quot;Dataset&quot;, i) hist(weights, breaks = breaks, main = main_title, xlab = xlab, col = col) mtext(paste(&quot;N =&quot;, length(weights)), side = 3, line = -1.5, cex = 0.8) dev.off() } } Argument outcome_weights: A list of outcome weight objects. plot_titles: A character vector of titles for each plot. breaks: Integer specifying the number of bins for the histogram plots (default is 50). col: Color specification (default is “#ff000080”). xlab: String specifying the label for the x-axis (default is “Outcome Weight”) prefix: A string prefix for saved PDF filenames. estimator: String specifying the estimator to use (default is “AIPW-ATT”). 1.4 Sensitivity analysis check_filter_datasets() filters a list of datasets to retain only those with all required variables, no missing data, binary treatment, and sufficient baseline/covariate variation. check_filter_datasets &lt;- function(datasets, Y, treat, covar, bm) { valid_datasets &lt;- list() for (i in seq_along(datasets)) { data &lt;- datasets[[i]] name &lt;- names(datasets)[i] if (is.null(name) || name == &quot;&quot;) name &lt;- paste0(&quot;dataset_&quot;, i) # provide a name if missing vars_needed &lt;- c(Y, treat, covar, bm) if (!all(vars_needed %in% names(data))) { # check all variables exist message(&quot;Removed &quot;, name, &quot;: missing required variables&quot;) next } sub &lt;- data[, vars_needed, drop = FALSE] if (any(is.na(sub))) { # check no missing values message(&quot;Removed &quot;, name, &quot;: contains missing values&quot;) next } tvals &lt;- unique(sub[[treat]]) # check treatment binary if (!all(tvals %in% c(0, 1)) &amp;&amp; !all(tvals %in% c(TRUE, FALSE))) { message(&quot;Removed &quot;, name, &quot;: treatment variable not binary&quot;) next } if (any(sapply(sub[bm], function(x) length(unique(x)) &lt;= 1))) { # check baseline variables have variation message(&quot;Removed &quot;, name, &quot;: baseline variable(s) lack variation&quot;) next } if (any(sapply(sub[covar], function(x) length(unique(x)) &lt;= 1))) { # check covariates have variation message(&quot;Removed &quot;, name, &quot;: covariate variable(s) lack variation&quot;) next } valid_datasets[[name]] &lt;- data # if all passed dataset is kept } return(valid_datasets) } Arguments datasets: A list of data frames containing data to be filtered. Y: The name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. bm: A vector of baseline variable names. save_sensitivity_plots() generates sensitivity analysis plots for a series of filtered datasets, saving each as a pdf file. save_sensitivity_plots &lt;- function(filtered_datasets, Y, treat, covar, bm, plot_titles, prefix) { folder &lt;- &quot;../graphs/lalonde&quot; if (!dir.exists(folder)) dir.create(folder, recursive = TRUE) for (i in seq_along(filtered_datasets)) { idx &lt;- i file_name &lt;- file.path(folder, paste0(prefix, &quot;_sensitivity_&quot;, idx, &quot;.pdf&quot;)) pdf(file_name, width = 8, height = 8) sens_ana(filtered_datasets[[i]], Y, treat, covar, bm, kd = 1:3) if (!missing(plot_titles) &amp;&amp; length(plot_titles) &gt;= idx) { title(main = plot_titles[idx]) } dev.off() } } Arguments filtered_datasets: A list of filtered datasets. Y: The name of the outcome variable. treat: The name of the binary treatment indicator variable as string. covar: A vector of covariate names. bm: A vector of baseline variable names. plot_titles: A vector of titles for plots corresponding to datasets. prefix: A string prefix for saving output PDF files. Please refer to the accompanying paper for a detailed explanation of the metrics used in the analysis, including absolute standardized mean differences (SMDs), effective sample sizes (ESS), and the composite scoring approach employed to evaluate covariate balance and overlap across multiple methods. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["lalonde-dehejia-wahba-ldw-data.html", "Chapter 2 LaLonde-Dehejia-Wahba (LDW) Data 2.1 Set up 2.2 Model A 2.3 Improving primarily covariate balance 2.4 Improving primarily overlap 2.5 Integrated methods 2.6 Reassessing methods 2.7 Integrated methods 2.8 Estimating 2.9 Validation through placebo analyses 2.10 Validation through sensitivity analyses 2.11 Summary", " Chapter 2 LaLonde-Dehejia-Wahba (LDW) Data LaLonde (1986) evaluated the effect of the National Supported Work Demonstration (NSW) program on both female and male participants. While the female participants were drawn from the Aid to Families with Dependent Children (AFDC) program, the male participants were drawn from three other groups: former drug addicts, ex-criminal offenders, and high-school dropouts. LaLonde relied on two main data sources: (1) CPS-SSA-1, based on Westat’s Matched Current Population Survey–Social Security Administration File for individuals under 55 matching specific criteria; (2) PSID-1, based on Panel Study of Income Dynamics for household heads under 55 from specific years who were not retired in 1975, adjusted for factors like employment status and poverty level, resulting in four additional comparison groups; Dehejia and Wahba (1999) constructed a subset of LaLonde’s original data, retaining 62% of observations and restricting the focus to male participants based on their 1974 earnings. As the dataset was formed entirely on pretreatment information like employment records or month of assignment, treatment allocation was effectively independent of all pretreatment variables. Thus they concluded that this subset, known as the LaLonde-Dehejia-Wahba (LDW) data, constitutes a valid experimental sample. The analysis in this section (2) and section 3 builds on the LDW data and considers in total three samples: (1) LDW-Experimental, consisting of 185 treated individuals and 280 controls from the experimental data; (2) LDW-CPS1, which pairs the same treated sample with 15,992 controls from CPS-SSA-1; (3) LDW-PSID1, featuring the same treated sample with 2,490 controls from PSID-1; In section 4, the analysis applies the same set of statistical tools to analyze a fourth sample as an additional demonstration: (4) LaLonde male samples (1986). In the last section, the analysis applies a reduced set of statistical tools to analyze a fifth sample again as an additional demonstration: (5) LaLonde female samples (2017). This section (2) covers model A, which includes the outcome variable 1978 earnings (re78) and adjusts for a set of covariates: age, education, race (black, hispanic), marital status, lack of high school degree, 1974 and 1975 earnings (re74, re75), and unemployment status in 1974 and 1975 (u74, u75). The model is defined by a regression formula for treatment assignment using these covariates. To improve covariate balance and overlap between treated and control groups, various methods are applied and are structured into five parts: Matching, Weighting, Truncation, Trimming and Combined Methods integrating these techniques. From these methods, the top 5 ranked are identified based on absolute standardized mean differences (SMDs) and effective sample size (ESS). The corresponding datasets are used to estimate the average treatment effect on the treated (ATT). Notably, the estimation incorporates the recently introduced augmented inverse probability weighting (AIPW) estimator, implemented via the OutcomeWeights R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify potential patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (re75) as an outcome to assess potential biases and the validity of unconfoundedness assumptions. Finally, sensitivity analyses are performed to evaluate the robustness of treatment effect estimates to violations of these assumptions. 2.1 Set up 2.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 2.1.2 Inspect data # collect datasets in a list data &lt;- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 2.1: Summary Statistics dataset num_obs num_vars name_vars lalonde 2675 13 nsw, age, educ, black, hisp, married, re74, re75, re78, u74, u75, u78, nodegr ldw_tr 185 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_co 260 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_cps 16177 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid 2675 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 2.1.3 Load and preprocess data We merge the experimental controls from LDW-Experimental into LDW-CPS1 and LDW-PSID1 to augment the control groups with additional observations, following a similar approach as by Imbens and Xu (2024). # assigns 1 to the experimental controls ldw_co$treat &lt;- 1 # merge experimental data with CPS1 data ldw_cps_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_cps # CPS1 data (16177 observations) ) # merge experimental data with PSID1 data ldw_psid_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_psid # PSID1 data (2675 observations) ) datasets &lt;- list(ldw_cps_plus = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus) # inspect key metrics of each dataset summary_stats_plus &lt;- inspect_data(datasets) knitr::kable(summary_stats_plus, caption = &quot;Summary Statistics&quot;) Table 2.2: Summary Statistics dataset num_obs num_vars name_vars ldw_cps_plus 16437 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid_plus 2935 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 2.2 Model A # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) #re74 included 2.2.1 Assessing overlap and covariate balance 2.2.1.1 Overlap To identify the average causal effect under unconfoundedness (that asserts that the treatment assignment is independent of the potential outcomes), it must be ensured that one can estimate the average effect at every value for the covariates. Thus, overlaps between the treated and untreated units (meaning that for every combination of covariates, there are both treated and untreated units in the dataset) are required. The assess_overlap() function of Imbens and Xu (2024) is used to assess overlaps in the propensity scores and to visualize results using histograms of their log-odds. In a properly balanced experimental design, the distributions of the treatment group (red) and the control group (gray) would show considerable coverage. # assess overlap ldw.ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar) ## -1.310867 0.7158619 Figure 2.1: FIGURE A1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_cps.ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar) ## -16.1181 1.787343 Figure 2.2: FIGURE A1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_psid.ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar) ## -16.1181 3.752723 Figure 2.3: FIGURE A1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. As anticipated, LDW-Experimental exhibits an almost perfect overlap. In contrast, the observational datasets LDW-CPS1 and LDW-PSID1 show weak overlap. In particular, many treated units have propensity scores outside the range of the controls, while a large share of control units have propensity scores concentrated at very low log-odds. Next, we examine the overlap of the expanded observational datasets. # assess overlap ldw_cps_plus.ps &lt;- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) ## -16.1181 3.63151 Figure 2.4: FIGURE A1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. ldw_psid_plus.ps &lt;- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) ## -16.1181 7.271394 Figure 2.5: FIGURE A1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. As expected, the datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS show an improved overlap compared to their non-plus states. For the following analysis, we set up a model formula. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 2.2.1.2 Covariate balance Initial covariate balance checks reveal the degree to which treatment and control groups differ on observed characteristics. We employ the bal.tab() function from the cobalt package to generate detailed balance statistics, complemented by visual summaries using love.plot(), which depicts standardized mean differences across covariates before and after adjustment. love.plot(ldw, ldw_cps, treat, covar = covar, title = &quot;LDW-CPS1&quot;) Figure 2.6: FIGURE A2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = &quot;LDW-CPS1-PLUS&quot;) Figure 2.7: FIGURE A2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid, treat, covar = covar, title = &quot;LDW-PSID1&quot;) Figure 2.8: FIGURE A2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = &quot;LDW-PSID1-PLUS&quot;) Figure 2.9: FIGURE A2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. Neither LDW-CPS1-PLUS nor LDW-PSID1-PLUS shows consistently improved covariate balance compared with their non-plus counterparts based on raw standardized mean differences. Although some specific covariates improve slightly, most show the same or increased imbalance. For the subsequent analysis aimed at enhancing covariate balance and overlap, only the two datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS are used. The LDW-Experimental dataset is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 2.3 Improving primarily covariate balance 2.3.1 Matching The purpose of matching is to create comparable treated and control groups by pairing units with similar covariate profiles, thereby reducing covariate imbalance and confounding bias. We apply several matching methods in the following. 2.3.1.1 Distance Matching 2.3.1.1.1 1:1 Nearest neighbor matching # perform nearest neighbor matching with k=1, logistic propensity score and replacement m.out.cps_plus.nearest &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) m.out.psid_plus.nearest &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) 2.3.1.1.2 k:1 matching (k=2) k&lt;-2 # perform nearest neighbor matching with k=2, logistic propensity score and replacement m.out.cps_plus.k2 &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid_plus.k2 &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 2.3.1.1.3 k:1 matching (k=3) k&lt;-3 # perform nearest neighbor matching with k=3, logistic propensity score and replacement m.out.cps_plus.k3 &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid_plus.k3 &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 2.3.1.1.4 Caliper matching # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score m.out.cps_plus.caliper &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) m.out.psid_plus.caliper &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) 2.3.1.1.5 Common support restriction matching # perform nearest neighbor matching with exclusion of units outside common support m.out.cps_plus.cs &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, replace = TRUE) m.out.psid_plus.cs &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, replace = TRUE) 2.3.1.1.6 Mahalanobis distance matching (mahvars) # perform nearest neighbor matching using mahalanobis distance on selected covariates m.out.cps_plus.mahvars &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re74 + re75, replace = FALSE) m.out.psid_plus.mahvars &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re74 + re75, replace = FALSE) 2.3.1.1.7 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.cps_plus.optimal_pair &lt;- matchit(model, data = ldw_cps_plus, method = &quot;optimal&quot;, distance = &quot;logit&quot;) m.out.psid_plus.optimal_pair &lt;- matchit(model, data = ldw_psid_plus, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 2.3.1.1.8 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.cps_plus.optimal_full &lt;- matchit(model, data = ldw_cps_plus, method = &quot;full&quot;, distance = &quot;logit&quot;) m.out.psid_plus.optimal_full &lt;- matchit(model, data = ldw_psid_plus, method = &quot;full&quot;, distance = &quot;logit&quot;) 2.3.1.1.9 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.cps_plus.general_full &lt;- matchit(model, data = ldw_cps_plus, method = &quot;quick&quot;, distance = &quot;logit&quot;) m.out.psid_plus.general_full &lt;- matchit(model, data = ldw_psid_plus, method = &quot;quick&quot;, distance = &quot;logit&quot;) 2.3.1.1.10 Genetic matching # perform genetic matching m.out.cps_plus.genetic &lt;- matchit(model, data = ldw_cps_plus, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) m.out.psid_plus.genetic &lt;- matchit(model, data = ldw_psid_plus, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) 2.3.1.2 Stratum matching 2.3.1.2.1 Exact matching (exact) Strata = unique covariate profiles (raw covariates) # match units exactly by raw covariate profiles m.out.cps_plus.exact &lt;- matchit(model, data = ldw_cps_plus, method = &quot;exact&quot;) m.out.psid_plus.exact &lt;- matchit(model, data = ldw_psid_plus, method = &quot;exact&quot;) 2.3.1.2.2 Coarsened matching (cem) Strata = coarsened versions of covariates # match units exactly within coarse strata m.out.cps_plus.cem &lt;- matchit(model, data = ldw_cps_plus, method = &quot;cem&quot;) m.out.psid_plus.cem &lt;- matchit(model, data = ldw_psid_plus, method = &quot;cem&quot;) 2.3.1.2.3 Subclassification Strata = bins of the propensity score # partition sample into fixed number of bins based on propensity score m.out.cps_plus.subcl &lt;- matchit(model, data = ldw_cps_plus, method = &quot;subclass&quot;, subclass = 5) m.out.psid_plus.subcl &lt;- matchit(model, data = ldw_psid_plus, method = &quot;subclass&quot;, subclass = 5) 2.3.1.3 Pure subset selection 2.3.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances m.out.cps_plus.card &lt;- matchit(model, data = ldw_cps_plus, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) m.out.psid_plus.card &lt;- matchit(model, data = ldw_psid_plus, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) 2.3.1.3.2 Profile matching # matching by directly optimizing balance profile measures across covariates m.out.cps_plus.profile &lt;- matchit_profile(ldw_cps_plus, treat, covar) m.out.psid_plus.profile &lt;- matchit_profile(ldw_psid_plus, treat, covar) 2.3.2 Weighting The purpose of weighting is to reweight the units in order to create a synthetic population in which the distributions of covariates is balanced between treatment and control groups. In the following, several weighting methods are applied. 2.3.2.1 Inverse probability weights (IPW) # compute weights as inverse of estimated propensity scores w.out.cps_plus.ipw &lt;- weightit(model, data = ldw_cps_plus, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.ipw &lt;- weightit(model, data = ldw_psid_plus, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) ldw_cps_plus$ipw_weight &lt;- w.out.cps_plus.ipw$weights ldw_psid_plus$ipw_weight &lt;- w.out.psid_plus.ipw$weights 2.3.2.2 Standardized mortality ratio (SMR) treated weights # calculate weights for ATT by assigning weight = 1 to treated units and weights proportional to odds of treatment to control ldw_cps_plus$smr_weight &lt;- create_smr_weights(ldw_cps_plus, model, &quot;ATT&quot;) ldw_psid_plus$smr_weight &lt;- create_smr_weights(ldw_psid_plus, model, &quot;ATT&quot;) 2.3.2.3 Matching weights # derive optimal matching weights intending to minimize covariate imbalance while targeting ATT w.out.cps_plus.opt &lt;- weightit(model, data = ldw_cps_plus, method = &quot;optweight&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.opt &lt;- weightit(model, data = ldw_psid_plus, method = &quot;optweight&quot;, estimand = &quot;ATT&quot;) ldw_cps_plus$opt_weight &lt;- w.out.cps_plus.opt$weights ldw_psid_plus$opt_weight &lt;- w.out.psid_plus.opt$weights 2.3.2.4 Overlap weights # calculate overlap weights emphasizing units with propensity scores near 0.5 ldw_cps_plus$overlap_weight &lt;- create_overlap_weights(ldw_cps_plus, model) ldw_psid_plus$overlap_weight &lt;- create_overlap_weights(ldw_psid_plus, model) 2.3.2.5 Entropy weights # compute entropy balancing weights w.out.cps_plus.ebal &lt;- weightit(model, data = ldw_cps_plus, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.ebal &lt;- weightit(model, data = ldw_psid_plus, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;) ldw_cps_plus$ebal_weight &lt;- w.out.cps_plus.ebal$weights ldw_psid_plus$ebal_weight &lt;- w.out.psid_plus.ebal$weights 2.4 Improving primarily overlap Truncation aims at limiting the influence of extreme weights by capping them at a specified threshold. This helps to reduce variance and improve the stability of causal effect estimates. In the following, several truncation methods are applied. 2.4.1 Truncation # list weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;smr_weight&quot;, &quot;opt_weight&quot;, &quot;overlap_weight&quot;, &quot;ebal_weight&quot;) 2.4.1.1 Fixed maximum value truncation # truncate weights by imposing a maximum threshold of 10 ldw_cps_plus.fixed &lt;- ldw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus.fixed)) { ldw_cps_plus.fixed &lt;- truncate_weights_fixed(ldw_cps_plus.fixed, weight_col = wcol, max_weight = 10) } } ldw_psid_plus.fixed &lt;- ldw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus.fixed)) { ldw_psid_plus.fixed &lt;- truncate_weights_fixed(ldw_psid_plus.fixed, weight_col = wcol, max_weight = 10) } } 2.4.1.2 At percentile truncation # truncate weights such that values above the 99th percentile are capped ldw_cps_plus.percent &lt;- ldw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus.percent)) { ldw_cps_plus.percent &lt;- truncate_weights_percentile(ldw_cps_plus.percent, weight_col = wcol, percentile = 0.99) } } ldw_psid_plus.percent &lt;- ldw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus.percent)) { ldw_psid_plus.percent &lt;- truncate_weights_percentile(ldw_psid_plus.percent, weight_col = wcol, percentile = 0.99) } } 2.4.1.3 Adaptive weight truncation We first inspect the variance of the weights. If variance is zero, adaptive weight truncation is not meaningful. # inspect variance of weights cps_results &lt;- list() psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus)) { cps_results[[paste0(&quot;cps_&quot;, wcol)]] &lt;- check_weights(ldw_cps_plus, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in ldw_cps_plus&quot;)) } } for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus)) { psid_results[[paste0(&quot;psid_&quot;, wcol)]] &lt;- check_weights(ldw_psid_plus, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in ldw_psid_plus&quot;)) } } var_cps_table &lt;- bind_rows(cps_results) var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_cps_table, caption = &quot;Variance of Weights (CPS)&quot;) Table 2.3: Variance of Weights (CPS) Weight_Column Variance ipw_weight 8.861700e-02 smr_weight 9.990349e+02 opt_weight 1.210057e+17 overlap_weight 1.256060e-02 ebal_weight 7.281612e+01 knitr::kable(var_psid_table, caption = &quot;Variance of Weights (PSID)&quot;) Table 2.3: Variance of Weights (PSID) Weight_Column Variance ipw_weight 15.195163 smr_weight 801.579106 opt_weight 75.777523 overlap_weight 0.025646 ebal_weight 111.869723 Regarding above results, we apply adaptive weight truncation to all weights, where it may help mitigate the influence of extreme weights. # truncate adaptively at mean + 3 standard deviations ldw_cps_plus.adapt &lt;- ldw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus.adapt)) { ldw_cps_plus.adapt &lt;- truncate_weights_adaptive(ldw_cps_plus.adapt, weight_col = wcol, c = 3) } } ldw_psid_plus.adapt &lt;- ldw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus.adapt)) { ldw_psid_plus.adapt &lt;- truncate_weights_adaptive(ldw_psid_plus.adapt, weight_col = wcol, c = 3) } } 2.4.2 Trimming The purpose of trimming is to remove units whose propensity scores are too dissimilar from the opposite group, thereby improving covariate balance between treated and control groups. We employ several trimming methods below. 2.4.2.1 Propensity score threshold trimming (similar to tutorial by Imbens and Xu (2024)) # apply trimming with thresholds 0.9 and 0.8 ldw_cps_trim &lt;- ps_trim(ldw_cps_plus.ps, threshold = 0.9) ldw_psid_trim &lt;- ps_trim(ldw_psid_plus.ps, threshold = 0.8) # exclude experimental controls, subset trimmed data appropriately ldw_cps.trim_match &lt;- subset(ldw_cps_trim, sample %in% c(1,3) &amp; ps_assoverlap) ldw_psid.trim_match &lt;- subset(ldw_psid_trim, sample %in% c(1,4) &amp; ps_assoverlap) # re-assign treat variable for controls in sample 3 or 4 (non-treated group) ldw_cps.trim_match$treat[ldw_cps.trim_match$sample == 3] &lt;- 0 ldw_psid.trim_match$treat[ldw_psid.trim_match$sample == 4] &lt;- 0 # re-estimate propensity scores on trimmed data and perform 1:1 matching ldw_cps.trim_match &lt;- psmatch(data = ldw_cps.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.trim_match &lt;- psmatch(data = ldw_psid.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 2.4.2.2 Common range trimming # trim observations outside the common support region of propensity scores ldw_cps_plus.common &lt;- common_range_trim(ldw_cps_plus.ps) ldw_psid_plus.common &lt;- common_range_trim(ldw_psid_plus.ps) 2.4.2.3 Propensity score trimming (Crump) # trim observations with propensity scores outside [0.1, 0.9] interval ldw_cps_plus.crump &lt;- crump_trim(ldw_cps_plus.ps, lower = 0.1, upper = 0.9) ldw_psid_plus.crump &lt;- crump_trim(ldw_psid_plus.ps, lower = 0.1, upper = 0.9) 2.4.2.4 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control ldw_cps_plus.stuermer &lt;- stuermer_trim(ldw_cps_plus.ps) ldw_psid_plus.stuermer &lt;- stuermer_trim(ldw_psid_plus.ps) 2.4.2.5 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations ldw_cps_plus.walker &lt;- walker_trim(ldw_cps_plus.ps) ldw_psid_plus.walker &lt;- walker_trim(ldw_psid_plus.ps) 2.5 Integrated methods The purpose of combining trimming and weighting methods is to leverage the strengths of both approaches for causal effect estimation. Trimming enhances overlap and reduces the influence of outliers by excluding units with extreme or non-comparable propensity scores, while weighting further adjusts for remaining covariate imbalance among the retained units. # list trimming methods trim_names &lt;- c(&quot;ps_threshold&quot;, &quot;common_range&quot;, &quot;stuermer&quot;, &quot;walker&quot;, &quot;crump&quot;) trimmed_cps &lt;- list(ps_threshold = ldw_cps_trim, common_range = ldw_cps_plus.common, stuermer = ldw_cps_plus.stuermer, walker = ldw_cps_plus.walker, crump = ldw_cps_plus.crump) trimmed_psid &lt;- list(ps_threshold = ldw_psid_trim, common_range = ldw_psid_plus.common, stuermer = ldw_psid_plus.stuermer, walker = ldw_psid_plus.walker, crump = ldw_psid_plus.crump) 2.5.0.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;ipw_weight&quot;)), trim_names ) ipw_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;ipw_weight&quot;)), trim_names ) 2.5.0.2 SMR treated weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply standardized mortality ratio (SMR) weighting with trimming and attach SMR weights smr_treat_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;smr_weight&quot;)), trim_names ) smr_treat_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;smr_weight&quot;)), trim_names ) 2.5.0.3 Overlap weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply overlap weighting with trimming and attach overlap weights ov_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;overlap_weight&quot;)), trim_names ) ov_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;overlap_weight&quot;)), trim_names ) 2.5.0.4 Entropy weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights entropy_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;ebal_weight&quot;)), trim_names ) entropy_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;ebal_weight&quot;)), trim_names ) 2.6 Reassessing methods We now systematically reassess all methods described above by evaluating covariate balance and sample representativeness. Specifically, we examine SMDs and ESS for each approach and use visual diagnostics—such as love plots and histograms—to assess covariate balance and overlap between treated and control groups. 2.6.1 Matching # list all matching methods methods.cps_plus &lt;- list( nn = m.out.cps_plus.nearest, k2 = m.out.cps_plus.k2, k3 = m.out.cps_plus.k3, caliper = m.out.cps_plus.caliper, cS = m.out.cps_plus.cs, mahvars = m.out.cps_plus.mahvars, optimal_pair = m.out.cps_plus.optimal_pair, optimal_full = m.out.cps_plus.optimal_full, gen_full = m.out.cps_plus.general_full, genetic = m.out.cps_plus.genetic, exact = m.out.cps_plus.exact, cem = m.out.cps_plus.cem, card = m.out.cps_plus.card, profile = m.out.cps_plus.profile, subcl = m.out.cps_plus.subcl ) methods.psid_plus &lt;- list( nn = m.out.psid_plus.nearest, k2 = m.out.psid_plus.k2, k3 = m.out.psid_plus.k3, caliper = m.out.psid_plus.caliper, cs = m.out.psid_plus.cs, mahvars = m.out.psid_plus.mahvars, optimal_pair = m.out.psid_plus.optimal_pair, optimal_full = m.out.psid_plus.optimal_full, gen_full = m.out.psid_plus.general_full, genetic = m.out.psid_plus.genetic, exact = m.out.psid_plus.exact, cem = m.out.psid_plus.cem, card = m.out.psid_plus.card, profile = m.out.psid_plus.profile, subcl = m.out.psid_plus.subcl ) # calculate balance statistics bal.cps_plus &lt;- cobalt::bal.tab(model, data = ldw_cps_plus, un = TRUE, weights = methods.cps_plus, s.d.denom = &quot;treated&quot;) bal.psid_plus &lt;- cobalt::bal.tab(model, data = ldw_psid_plus, un = TRUE, weights = methods.psid_plus, s.d.denom = &quot;treated&quot;) 2.6.1.1 SMD # compute SMD smd_matchit.cps_plus &lt;- compute_abs_smd_matchit(methods.cps_plus) smd_matchit.psid_plus &lt;- compute_abs_smd_matchit(methods.psid_plus) 2.6.1.2 ESS # compute ESS ess_matchit.cps_plus &lt;- compute_ess_matchit(bal.cps_plus) ess_matchit.psid_plus &lt;- compute_ess_matchit(bal.psid_plus) 2.6.1.3 Visuals # visualize covariate balance plot_matchit(methods.cps_plus, &quot;LDW-CPS1-PLUS&quot;) Figure 2.10: FIGURE A3. Figure 2.11: FIGURE A3. Figure 2.12: FIGURE A3. Figure 2.13: FIGURE A3. Figure 2.14: FIGURE A3. Figure 2.15: FIGURE A3. Figure 2.16: FIGURE A3. Figure 2.17: FIGURE A3. Figure 2.18: FIGURE A3. Figure 2.19: FIGURE A3. Figure 2.20: FIGURE A3. Figure 2.21: FIGURE A3. Figure 2.22: FIGURE A3. Figure 2.23: FIGURE A3. Figure 2.24: FIGURE A3. plot_matchit(methods.psid_plus, &quot;LDW-PSID1-PLUS&quot;) Figure 2.25: FIGURE A3. Figure 2.26: FIGURE A3. Figure 2.27: FIGURE A3. Figure 2.28: FIGURE A3. Figure 2.29: FIGURE A3. Figure 2.30: FIGURE A3. Figure 2.31: FIGURE A3. Figure 2.32: FIGURE A3. Figure 2.33: FIGURE A3. Figure 2.34: FIGURE A3. Figure 2.35: FIGURE A3. Figure 2.36: FIGURE A3. Figure 2.37: FIGURE A3. Figure 2.38: FIGURE A3. Figure 2.39: FIGURE A3. 2.6.2 Weighting # list all weights weight.cps_plus &lt;- list( ipw = ldw_cps_plus$ipw_weight, smr_tr = ldw_cps_plus$smr_weight, mw = ldw_cps_plus$opt_weight, ow = ldw_cps_plus$overlap_weight, ew = ldw_cps_plus$ebal_weight ) weight.psid_plus &lt;- list( ipw = ldw_psid_plus$ipw_weight, smr_tr = ldw_psid_plus$smr_weight, mw = ldw_psid_plus$opt_weight, ow = ldw_psid_plus$overlap_weight, ew = ldw_psid_plus$ebal_weight ) 2.6.2.1 SMD # compute SMD smd_weight.cps_plus &lt;- compute_abs_smd_weight(ldw_cps_plus, &quot;treat&quot;, covar, weight_columns) smd_weight.psid_plus &lt;- compute_abs_smd_weight(ldw_psid_plus, &quot;treat&quot;, covar, weight_columns) 2.6.2.2 ESS # compute ESS ess_weight.cps_plus &lt;- compute_ess_weight(ldw_cps_plus, &quot;treat&quot;, covar, weight_columns) ess_weight.psid_plus &lt;- compute_ess_weight(ldw_psid_plus, &quot;treat&quot;, covar, weight_columns) 2.6.2.3 Visuals # visualize covariate balance plot_weighting_methods(ldw_cps_plus, &quot;treat&quot;, covar, weight.cps_plus, &quot;LDW-CPS1-PLUS&quot;) Figure 2.40: FIGURE A4. Figure 2.41: FIGURE A4. Figure 2.42: FIGURE A4. Figure 2.43: FIGURE A4. Figure 2.44: FIGURE A4. plot_weighting_methods(ldw_psid_plus, &quot;treat&quot;, covar, weight.psid_plus, &quot;LDW-PSID1-PLUS&quot;) Figure 2.45: FIGURE A4. Figure 2.46: FIGURE A4. Figure 2.47: FIGURE A4. Figure 2.48: FIGURE A4. Figure 2.49: FIGURE A4. 2.6.3 Truncation # list truncation methods trunc.cps_plus &lt;- list( fix_max_value_trunc.cps_plus = ldw_cps_plus.fixed, at_perc_trunc.cps_plus = ldw_cps_plus.percent, adap_weight_trunc.cps_plus = ldw_cps_plus.adapt ) trunc.psid_plus &lt;- list( fix_max_value_trunc.psid_plus = ldw_psid_plus.fixed, at_perc_trunc.psid_plus = ldw_psid_plus.percent, adap_weight_trunc.psid_plus = ldw_psid_plus.adapt ) 2.6.3.1 SMD # compute SMD smd_trunc.cps_plus &lt;- compute_abs_smd_trunc(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns) smd_trunc.psid_plus &lt;- compute_abs_smd_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 2.6.3.2 ESS # compute ESS ess_trunc.cps_plus &lt;- compute_ess_trunc(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns) ess_trunc.psid_plus &lt;- compute_ess_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 2.6.3.3 Visuals # visualize covariate balance plot_trunc_methods(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns, &quot;LDW-CPS1-PLUS&quot;) Figure 2.50: FIGURE A5. Figure 2.51: FIGURE A5. Figure 2.52: FIGURE A5. Figure 2.53: FIGURE A5. Figure 2.54: FIGURE A5. Figure 2.55: FIGURE A5. Figure 2.56: FIGURE A5. Figure 2.57: FIGURE A5. Figure 2.58: FIGURE A5. Figure 2.59: FIGURE A5. Figure 2.60: FIGURE A5. Figure 2.61: FIGURE A5. Figure 2.62: FIGURE A5. Figure 2.63: FIGURE A5. Figure 2.64: FIGURE A5. plot_trunc_methods(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns, &quot;LDW-PSID1-PLUS&quot;) Figure 2.65: FIGURE A5. Figure 2.66: FIGURE A5. Figure 2.67: FIGURE A5. Figure 2.68: FIGURE A5. Figure 2.69: FIGURE A5. Figure 2.70: FIGURE A5. Figure 2.71: FIGURE A5. Figure 2.72: FIGURE A5. Figure 2.73: FIGURE A5. Figure 2.74: FIGURE A5. Figure 2.75: FIGURE A5. Figure 2.76: FIGURE A5. Figure 2.77: FIGURE A5. Figure 2.78: FIGURE A5. Figure 2.79: FIGURE A5. 2.6.4 Trimming # list trimming objects trim.cps_plus &lt;- list( original = ldw_cps_plus, ps_threshold = ldw_cps.trim_match, common_range = ldw_cps_plus.common, crump = ldw_cps_plus.crump, stuermer = ldw_cps_plus.stuermer, walker = ldw_cps_plus.walker ) trim.psid_plus &lt;- list( original = ldw_psid_plus, ps_threshold = ldw_psid.trim_match, common_range = ldw_psid_plus.common, crump = ldw_psid_plus.crump, stuermer = ldw_psid_plus.stuermer, walker = ldw_psid_plus.walker ) 2.6.4.1 SMD # compute SMD smd_trim.cps_plus &lt;- compute_abs_smd_trim(trim.cps_plus, &quot;treat&quot;, covar) smd_trim.psid_plus &lt;- compute_abs_smd_trim(trim.psid_plus, &quot;treat&quot;, covar) 2.6.4.2 ESS # compute ESS ess_trim.cps_plus &lt;- compute_ess_trim(trim.cps_plus, &quot;treat&quot;, covar) ess_trim.psid_plus &lt;- compute_ess_trim(trim.psid_plus, &quot;treat&quot;, covar) 2.6.4.3 Visuals # visualize overlap plot_trim(trim.cps_plus, treat, covar) ## -16.1181 3.63151 ## -1.249971 1.185584 ## -10.8512 3.856394 ## -2.516886 2.358809 ## -6.937733 -2.088278 ## -8.995388 -2.067383 Figure 2.80: FIGURE A6. plot_trim(trim.psid_plus, treat, covar) ## -16.1181 7.271394 ## -0.8915464 0.439935 ## -4.792402 4.068605 ## -1.685302 2.932933 ## -3.370286 -1.389719 ## -3.511349 -0.6656006 Figure 2.81: FIGURE A6. # visualize covariate balance love.plot(ldw_cps, ldw_cps.trim_match, treat, covar = covar, title = &quot;LDW-CPS1-PLUS - propensity threshold trimming&quot;) Figure 2.82: FIGURE A7. love.plot(ldw_cps, ldw_cps_plus.common, treat, covar, title = &quot;LDW-CPS1-PLUS - common range trimming&quot;) Figure 2.83: FIGURE A7. love.plot(ldw_cps, ldw_cps_plus.crump, treat, covar, title = &quot;LDW-CPS1-PLUS - crump trimming&quot;) Figure 2.84: FIGURE A7. love.plot(ldw_cps, ldw_cps_plus.stuermer, treat, covar, title = &quot;LDW-CPS1-PLUS - stuermer trimming&quot;) Figure 2.85: FIGURE A7. love.plot(ldw_cps, ldw_cps_plus.walker, treat, covar, title = &quot;LDW-CPS1-PLUS - walker trimming&quot;) Figure 2.86: FIGURE A7. love.plot(ldw_psid, ldw_psid.trim_match, treat, covar = covar, title = &quot;LDW-PSID1-PLUS - propensity threshold trimming&quot;) Figure 2.87: FIGURE A7. love.plot(ldw_psid, ldw_psid_plus.common, treat, covar, title = &quot;LDW-PSID1-PLUS - common range trimming&quot;) Figure 2.88: FIGURE A7. love.plot(ldw_psid, ldw_psid_plus.crump, treat, covar, title = &quot;LDW-PSID1-PLUS - crump trimming&quot;) Figure 2.89: FIGURE A7. love.plot(ldw_psid, ldw_psid_plus.stuermer, treat, covar, title = &quot;LDW-PSID1-PLUS - stuermer trimming&quot;) Figure 2.90: FIGURE A7. love.plot(ldw_psid, ldw_psid_plus.walker, treat, covar, title = &quot;LDW-PSID1-PLUS - walker trimming&quot;) Figure 2.91: FIGURE A7. 2.7 Integrated methods # list all combined method results comb_meth.cps_plus &lt;- list( ipw = ipw_comb.cps_plus, smr_treated = smr_treat_comb.cps_plus, overlap = ov_comb.cps_plus, entropy = entropy_comb.cps_plus ) comb_meth.psid_plus &lt;- list( ipw = ipw_comb.psid_plus, smr_treated = smr_treat_comb.psid_plus, overlap = ov_comb.psid_plus, entropy = entropy_comb.psid_plus ) 2.7.0.1 SMD # compute SMD smd_all_comb_meth.cps_plus &lt;- compute_smd_all_datasets(comb_meth.cps_plus, &quot;treat&quot;, covar) smd_all_comb_meth.psid_plus &lt;- compute_smd_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 2.7.0.2 ESS # compute ESS ess_all_comb_meth.cps_plus &lt;- compute_ess_all_datasets(comb_meth.cps_plus, &quot;treat&quot;, covar) ess_all_comb_meth.psid_plus &lt;- compute_ess_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 2.7.0.3 Visuals # visualize overlap plot_comb_overlap(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) ## -16.1181 2.629308 ## -11.64605 3.692112 ## -8.042516 -2.117255 ## -16.1181 -2.24017 Figure 2.92: FIGURE A8. ## -2.44024 2.290448 ## -16.1181 2.629308 ## -11.64605 3.692112 ## -8.042516 -2.117255 Figure 2.93: FIGURE A8. ## -16.1181 -2.24017 ## -2.44024 2.290448 ## -16.1181 2.629308 ## -11.64605 3.692112 Figure 2.94: FIGURE A8. ## -8.042516 -2.117255 ## -16.1181 -2.24017 ## -2.44024 2.290448 ## -16.1181 2.629308 Figure 2.95: FIGURE A8. ## -11.64605 3.692112 ## -8.042516 -2.117255 ## -16.1181 -2.24017 ## -2.44024 2.290448 Figure 2.96: FIGURE A8. ## -16.1181 1.120412 ## -4.466055 4.051763 ## -3.41373 -1.35641 ## -3.581103 -0.7108581 Figure 2.97: FIGURE A8. ## -1.693687 2.928433 ## -16.1181 1.120412 ## -4.466055 4.051763 ## -3.41373 -1.35641 Figure 2.98: FIGURE A8. ## -3.581103 -0.7108581 ## -1.693687 2.928433 ## -16.1181 1.120412 ## -4.466055 4.051763 Figure 2.99: FIGURE A8. ## -3.41373 -1.35641 ## -3.581103 -0.7108581 ## -1.693687 2.928433 ## -16.1181 1.120412 Figure 2.100: FIGURE A8. ## -4.466055 4.051763 ## -3.41373 -1.35641 ## -3.581103 -0.7108581 ## -1.693687 2.928433 Figure 2.101: FIGURE A8. # visualize covariate balance plot_comb_love_plots(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) Figure 2.102: FIGURE A9. Figure 2.103: FIGURE A9. Figure 2.104: FIGURE A9. Figure 2.105: FIGURE A9. Figure 2.106: FIGURE A9. Figure 2.107: FIGURE A9. Figure 2.108: FIGURE A9. Figure 2.109: FIGURE A9. Figure 2.110: FIGURE A9. Figure 2.111: FIGURE A9. Figure 2.112: FIGURE A9. Figure 2.113: FIGURE A9. Figure 2.114: FIGURE A9. Figure 2.115: FIGURE A9. Figure 2.116: FIGURE A9. Figure 2.117: FIGURE A9. Figure 2.118: FIGURE A9. Figure 2.119: FIGURE A9. Figure 2.120: FIGURE A9. Figure 2.121: FIGURE A9. Figure 2.122: FIGURE A9. Figure 2.123: FIGURE A9. Figure 2.124: FIGURE A9. Figure 2.125: FIGURE A9. Figure 2.126: FIGURE A9. Figure 2.127: FIGURE A9. Figure 2.128: FIGURE A9. Figure 2.129: FIGURE A9. Figure 2.130: FIGURE A9. Figure 2.131: FIGURE A9. Figure 2.132: FIGURE A9. Figure 2.133: FIGURE A9. Figure 2.134: FIGURE A9. Figure 2.135: FIGURE A9. Figure 2.136: FIGURE A9. Figure 2.137: FIGURE A9. Figure 2.138: FIGURE A9. Figure 2.139: FIGURE A9. Figure 2.140: FIGURE A9. Figure 2.141: FIGURE A9. # save results save_comb_hist(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix = &quot;model_a&quot;) save_comb_loveplots(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix = &quot;model_a&quot;) 2.7.1 Top methods and datasets To identify the top five methods for each observational dataset, we first combine all results for SMDs and ESS into a single data frame for each dataset. This allows for a comprehensive comparison across all methods. # combine all results all_cps_plus &lt;- combine_results(&quot;cps_plus&quot;) all_psid_plus &lt;- combine_results(&quot;psid_plus&quot;) # save results save_csv(all_cps_plus, &quot;CPS1_PLUS_all_results_model_a&quot;) save_csv(all_psid_plus, &quot;PSID1_PLUS_all_results_model_a&quot;) Next, we evaluate each method by constructing a final score that is build on two separate scores equally weighted: - smd_score rescales the mean absolute SMD to a 0-1 range, where a lower value leads to a higher score - ess_score measures sample size effectiveness by combining ESS of treated and control groups and normalizing between 0 and 1. ranked_cps_plus &lt;- assess_methods(all_cps_plus) ranked_psid_plus &lt;- assess_methods(all_psid_plus) Based on the final scores, we rank all methods and select the top five for each dataset. # get top 5 methods top5_methods.cps_plus &lt;- get_top_methods(ranked_cps_plus, top_n = 5) top5_methods.psid_plus &lt;- get_top_methods(ranked_psid_plus, top_n = 5) # print results top5_methods_df.cps_plus &lt;- ranked_cps_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid_plus &lt;- ranked_psid_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps_plus, caption = &quot;Top 5 Methods for CPS1-PLUS&quot;, booktabs = TRUE) Table 2.4: Top 5 Methods for CPS1-PLUS Method Score card 0.7380670 mahvars 0.7372034 overlap_crump 0.7085378 ps_threshold 0.7039160 optimal_pair 0.6892030 knitr::kable(top5_methods_df.psid_plus, caption = &quot;Top 5 Methods for PSID1-PLUS&quot;, booktabs = TRUE) Table 2.4: Top 5 Methods for PSID1-PLUS Method Score card 0.7584618 mahvars 0.7508530 overlap_crump 0.7305075 ps_threshold 0.7299305 overlap_common_range 0.7222421 # save results save_csv(top5_methods.cps_plus, &quot;CPS1_PLUS_top5_methods_model_a&quot;) save_csv(top5_methods.psid_plus, &quot;PSID1_PLUS_top5_methods_model_a&quot;) For estimation, we match the selected top method names back to their corresponding datasets, objects or vectors and construct final datasets. dataset_list_cps &lt;- list( &quot;All&quot; = ldw_cps_plus, &quot;original&quot; = ldw_cps_plus, &quot;nn&quot; = m.out.cps_plus.nearest, &quot;caliper&quot; = m.out.cps_plus.caliper, &quot;card&quot; = m.out.cps_plus.card, &quot;cem&quot; = m.out.cps_plus.cem, &quot;cS&quot; = m.out.cps_plus.cs, &quot;k2&quot; = m.out.cps_plus.k2, &quot;k3&quot; = m.out.cps_plus.k3, &quot;mahvars&quot; = m.out.cps_plus.mahvars, &quot;optimal_full&quot; = m.out.cps_plus.optimal_full, &quot;optimal_pair&quot; = m.out.cps_plus.optimal_pair, &quot;gen_full&quot; = m.out.cps_plus.general_full, &quot;genetic&quot; = m.out.cps_plus.genetic, &quot;exact&quot; = m.out.cps_plus.exact, &quot;subcl&quot; = m.out.cps_plus.subcl, &quot;profile&quot; = m.out.cps_plus.profile, &quot;ipw_weight&quot; = ldw_cps_plus$ipw_weight, &quot;smr_weight&quot; = ldw_cps_plus$smr_weight, &quot;opt_weight&quot; = ldw_cps_plus$opt_weight, &quot;overlap_weight&quot; = ldw_cps_plus$overlap_weight, &quot;ebal_weight&quot; = ldw_cps_plus$ebal_weight, &quot;fix_max_value_trunc_ebal_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_ipw_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_opt_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_overlap_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_smr_weight&quot; = ldw_cps_plus.fixed, &quot;at_perc_trunc_ebal_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_ipw_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_opt_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_overlap_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_smr_weight&quot; = ldw_cps_plus.percent, &quot;adap_weight_trunc_ebal_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_ipw_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_opt_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_overlap_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_smr_weight&quot; = ldw_cps_plus.adapt, &quot;ps_threshold&quot; = ldw_cps.trim_match, &quot;common_range&quot; = ldw_cps_plus.common, &quot;stuermer&quot; = ldw_cps_plus.stuermer, &quot;walker&quot; = ldw_cps_plus.walker, &quot;crump&quot; = ldw_cps_plus.crump, &quot;ipw_common_range&quot; = ipw_comb.cps_plus[[1]], &quot;ipw_crump&quot; = ipw_comb.cps_plus[[2]], &quot;ipw_ps_threshold&quot; = ipw_comb.cps_plus[[3]], &quot;ipw_stuermer&quot; = ipw_comb.cps_plus[[4]], &quot;ipw_walker&quot; = ipw_comb.cps_plus[[5]], &quot;smr_treated_common_range&quot; = smr_treat_comb.cps_plus[[1]], &quot;smr_treated_crump&quot; = smr_treat_comb.cps_plus[[2]], &quot;smr_treated_ps_threshold&quot; = smr_treat_comb.cps_plus[[3]], &quot;smr_treated_stuermer&quot; = smr_treat_comb.cps_plus[[4]], &quot;smr_treated_walker&quot; = smr_treat_comb.cps_plus[[5]], &quot;overlap_common_range&quot; = ov_comb.cps_plus[[1]], &quot;overlap_crump&quot; = ov_comb.cps_plus[[2]], &quot;overlap_ps_threshold&quot; = ov_comb.cps_plus[[3]], &quot;overlap_stuermer&quot; = ov_comb.cps_plus[[4]], &quot;overlap_walker&quot; = ov_comb.cps_plus[[5]], &quot;entropy_common_range&quot; = entropy_comb.cps_plus[[1]], &quot;entropy_crump&quot; = entropy_comb.cps_plus[[2]], &quot;entropy_ps_threshold&quot; = entropy_comb.cps_plus[[3]], &quot;entropy_stuermer&quot; = entropy_comb.cps_plus[[4]], &quot;entropy_walker&quot; = entropy_comb.cps_plus[[5]]) dataset_list_psid &lt;- list( &quot;All&quot; = ldw_psid_plus, &quot;original&quot; = ldw_psid_plus, &quot;nn&quot; = m.out.psid_plus.nearest, &quot;caliper&quot;= m.out.psid_plus.caliper, &quot;card&quot; = m.out.psid_plus.card, &quot;cem&quot; = m.out.psid_plus.cem, &quot;cS&quot; = m.out.psid_plus.cs, &quot;k2&quot; = m.out.psid_plus.k2, &quot;k3&quot; = m.out.psid_plus.k3, &quot;mahvars&quot; = m.out.psid_plus.mahvars, &quot;optimal_full&quot; = m.out.psid_plus.optimal_full, &quot;optimal_pair&quot; = m.out.psid_plus.optimal_pair, &quot;gen_full&quot; = m.out.psid_plus.general_full, &quot;genetic&quot; = m.out.psid_plus.genetic, &quot;exact&quot; = m.out.psid_plus.exact, &quot;subcl&quot; = m.out.psid_plus.subcl, &quot;profile&quot; = m.out.psid_plus.profile, &quot;ipw_weight&quot; = ldw_psid_plus$ipw_weight, &quot;smr_weight&quot; = ldw_psid_plus$smr_weight, &quot;opt_weight&quot; = ldw_psid_plus$opt_weight, &quot;overlap_weight&quot; = ldw_psid_plus$overlap_weight, &quot;ebal_weight&quot; = ldw_psid_plus$ebal_weight, &quot;fix_max_value_trunc_ebal_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_ipw_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_opt_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_overlap_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_smr_weight&quot; = ldw_psid_plus.fixed, &quot;at_perc_trunc_ebal_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_ipw_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_opt_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_overlap_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_smr_weight&quot; = ldw_psid_plus.percent, &quot;adap_weight_trunc_ebal_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_ipw_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_opt_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_overlap_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_smr_weight&quot; = ldw_psid_plus.adapt, &quot;ps_threshold&quot; = ldw_psid.trim_match, &quot;common_range&quot; = ldw_psid_plus.common, &quot;stuermer&quot; = ldw_psid_plus.stuermer, &quot;walker&quot; = ldw_psid_plus.walker, &quot;crump&quot; = ldw_psid_plus.crump, &quot;ipw_common_range&quot; = ipw_comb.psid_plus[[1]], &quot;ipw_crump&quot;= ipw_comb.psid_plus[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid_plus[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid_plus[[4]], &quot;ipw_walker&quot; = ipw_comb.psid_plus[[5]], &quot;smr_treated_common_range&quot; = smr_treat_comb.psid_plus[[1]], &quot;smr_treated_crump&quot;= smr_treat_comb.psid_plus[[2]], &quot;smr_treated_ps_threshold&quot; = smr_treat_comb.psid_plus[[3]], &quot;smr_treated_stuermer&quot; = smr_treat_comb.psid_plus[[4]], &quot;smr_treated_walker&quot; = smr_treat_comb.psid_plus[[5]], &quot;overlap_common_range&quot; = ov_comb.psid_plus[[1]], &quot;overlap_crump&quot; = ov_comb.psid_plus[[2]], &quot;overlap_ps_threshold&quot; = ov_comb.psid_plus[[3]], &quot;overlap_stuermer&quot; = ov_comb.psid_plus[[4]], &quot;overlap_walker&quot;= ov_comb.psid_plus[[5]], &quot;entropy_common_range&quot; = entropy_comb.psid_plus[[1]], &quot;entropy_crump&quot; = entropy_comb.psid_plus[[2]], &quot;entropy_ps_threshold&quot; = entropy_comb.psid_plus[[3]], &quot;entropy_stuermer&quot; = entropy_comb.psid_plus[[4]], &quot;entropy_walker&quot; = entropy_comb.psid_plus[[5]]) # create datasets corresponding to the top 5 methods for each dataset top5_datasets.cps_plus &lt;- create_top5_datasets(dataset_list_cps, top5_methods.cps_plus) top5_datasets.psid_plus &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid_plus) # save datasets into .RData files save_top5_individual_files(dataset_list_cps, top5_methods.cps_plus, prefix = &quot;model_a_cps&quot;) save_top5_individual_files(dataset_list_psid, top5_methods.psid_plus, prefix = &quot;model_a_psid&quot;) 2.8 Estimating 2.8.1 Average treatment effect on the treated (ATT) Next, we estimate the average treatment effect on the treated (ATT) using both the LDW-Experimental sample, the non-plus observational datasets and the newly constructed top five ranked samples for each observational dataset, LDW-CPS1 and LDW-PSID1, that achieved highest score results. We employ a broad set of estimators, including difference-in-means, regression, the Oaxaca-Blinder estimator, generalized random forests (GRF) as an outcome model, 1:5 nearest neighbor matching with bias correction, inverse probability weighting (IPW) with GRF-based propensity scores, covariate balancing propensity score (CBPS), entropy balancing, double/debiased machine learning using elastic net, and augmented inverse probability weighting (AIPW) via GRF. We also incorporate the recently introduced estimand-specific AIPW estimator implemented through an expansion of the OutcomeWeights R package by Knaus and Pfleiderer (2024). We utilize the estimate_all() and plot_coef() functions as defined by Imbens and Xu (2024). # estimate ATT out1 &lt;- estimate_all(ldw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(ldw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(ldw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out4 &lt;- estimate_all(ldw_cps.trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(ldw_psid.trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out6 &lt;- out.cps_plus[[1]] out7 &lt;- out.cps_plus[[2]] out8 &lt;- out.cps_plus[[3]] out9 &lt;- out.cps_plus[[4]] out10 &lt;- out.cps_plus[[5]] out11 &lt;- out.psid_plus[[1]] out12 &lt;- out.psid_plus[[2]] out13 &lt;- out.psid_plus[[3]] out14 &lt;- out.psid_plus[[4]] out15 &lt;- out.psid_plus[[5]] # build plot titles base_titles &lt;- c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS1&quot; , &quot;(C) LDW-PSID1&quot;, &quot;(D) Trimmed LDW-CPS1 &quot;, &quot;(E) Trimmed LDW-PSID1&quot;) top_start &lt;- 6 # F is 6th letter num_cps &lt;- length(top5_methods.cps_plus) num_psid &lt;- length(top5_methods.psid_plus) top_letters_cps &lt;- LETTERS[top_start:(top_start + num_cps - 1)] top_letters_psid &lt;- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)] top5_titles.cps_plus &lt;- paste0(&quot;(&quot;, top_letters_cps, &quot;) Top CPS1: &quot;, top5_methods.cps_plus) top5_titles.psid_plus &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid_plus) plot_titles &lt;- c(base_titles, top5_titles.cps_plus, top5_titles.psid_plus) # combine all results all_outs &lt;- c(list(out1, out2, out3, out4, out5), out.cps_plus, out.psid_plus) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 2.142: FIGURE A10. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.143: FIGURE A10. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.144: FIGURE A10. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 2.145: FIGURE A10. ATT Estimates Model A Given Unconfoundedness using LDW Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;model_a&quot;) The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, trimmed versions of the LDW-CPS1 and LDW-PSID1 samples (analogous to Imbens &amp; Xu (2024)) and a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria. Figure (A) presents the benchmark from the experimental sample (LDW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the observational samples, LDW-CPS1 and LDW-PSID1, while figures (D) and (E) present those for the trimmed versions, replicating the tutorial results of Imbens &amp; Xu (2024). Figures (F) through (J) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-based subsamples under parallel rules. Across the LDW-CPS1 dataset and its top-ranked subsamples, all estimators generally produce ATT estimates that closely cluster around the experimental benchmark. However, the overlap_crump and overlap_pair samples exhibit somewhat larger deviations. While most estimates are positive, the overlap_crump and optimal_pair subsample results include a few negative ATT estimates, and all ATT estimates for the mahvars subsample are consistently negative. In contrast, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors compared to LDW-CPS1 samples. Most ATT estimates are negatively aligned, indicating increased methodological uncertainty in these samples. Positive ATT estimates emerge only for the subsample based on overlap_crump. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 2.5: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) LDW-Experimental 676.7242 1568.8851 1960.9893 392.1041 (B) LDW-CPS1 672.2335 -8497.5161 1729.1183 10226.6344 (C) LDW-PSID1 831.8630 -15204.7774 2437.7016 17642.4790 (D) Trimmed LDW-CPS1 823.2756 717.9131 1352.1369 634.2238 (E) Trimmed LDW-PSID1 1126.5747 -1656.2410 -265.8659 1390.3751 (F) Top CPS1: card 487.2001 214.1581 1023.7365 809.5784 (G) Top CPS1: mahvars 519.5097 -317.8912 -161.1994 156.6918 (H) Top CPS1: overlap_crump 469.9964 -3635.0160 436.3931 4071.4091 (I) Top CPS1: ps_threshold 823.2722 717.9131 1342.1875 624.2744 (J) Top CPS1: optimal_pair 479.8301 -267.2669 749.0723 1016.3392 (K) Top PSID1: card 978.9970 -2402.7783 -393.9507 2008.8276 (L) Top PSID1: mahvars 892.0455 -2566.0998 -1436.7082 1129.3916 (M) Top PSID1: overlap_crump 687.3304 -6527.5722 1531.2657 8058.8379 (N) Top PSID1: ps_threshold 1126.4796 -1656.2410 -265.8659 1390.3751 (O) Top PSID1: overlap_common_range 767.0125 -15869.5446 -1167.7110 14701.8336 The ATT results are presented in the table below: # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) Table 2.6: ATT Estimates and SEs (A) LDW-Experimental (B) LDW-CPS1 (C) LDW-PSID1 (D) Trimmed LDW-CPS1 (E) Trimmed LDW-PSID1 (F) Top CPS1: card (G) Top CPS1: mahvars (H) Top CPS1: overlap_crump (I) Top CPS1: ps_threshold (J) Top CPS1: optimal_pair (K) Top PSID1: card (L) Top PSID1: mahvars (M) Top PSID1: overlap_crump (N) Top PSID1: ps_threshold (O) Top PSID1: overlap_common_range Experimental Benchmark 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) 766.99 (848.00) -349.21 (1101.43) 214.16 (475.53) -265.18 (535.18) -3635.02 (336.58) 766.99 (848.00) -267.27 (448.21) -586.61 (967.69) -1636.51 (928.51) -6527.57 (558.29) -349.21 (1101.43) -15869.54 (580.40) diff 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) 766.99 (848.00) -349.21 (1101.43) 214.16 (475.53) -265.18 (535.18) -3635.02 (336.58) 766.99 (848.00) -267.27 (448.21) -586.61 (967.69) -1636.51 (928.51) -6527.57 (558.29) -349.21 (1101.43) -15869.54 (580.40) reg 1670.71 (680.20) 1066.38 (626.85) 4.16 (854.15) 985.38 (836.01) -951.25 (1127.92) 369.99 (449.49) -252.44 (507.35) -260.71 (404.58) 985.38 (836.01) 295.33 (451.21) -623.64 (949.49) -1523.73 (878.90) -125.00 (825.19) -951.25 (1127.92) -2475.11 (746.10) om.reg 1706.20 (587.94) 1133.28 (624.26) 687.82 (635.26) 757.66 (695.08) -1446.73 (835.35) 410.61 (385.09) -166.50 (419.49) -122.75 (348.53) 757.66 (695.08) 599.45 (347.62) -887.73 (719.14) -1570.74 (726.93) 1531.27 (411.05) -1446.73 (835.35) -2303.97 (605.53) om.grf 1760.54 (582.13) 1098.04 (629.63) 744.36 (634.10) 1090.29 (661.52) -467.98 (723.15) 576.00 (372.85) -254.70 (395.51) 162.65 (347.26) 1066.12 (662.18) 505.30 (336.38) -510.31 (552.84) -1474.19 (646.96) -197.84 (404.17) -468.32 (722.01) -2369.64 (607.11) matching 1757.17 (764.06) 1729.12 (815.38) 2255.47 (1403.83) 722.23 (966.32) -658.55 (1208.09) 426.74 (641.43) -202.91 (592.72) 436.39 (628.42) 722.23 (966.32) 487.34 (649.91) -452.10 (911.75) -1436.71 (987.36) 1291.44 (1114.74) -658.55 (1208.09) -1634.69 (881.64) psm 1568.89 (707.14) 1271.98 (739.46) 2432.11 (740.90) 1352.14 (826.98) -265.87 (1074.72) 1023.74 (463.22) -161.20 (542.52) 45.66 (432.70) 1342.19 (826.29) 749.07 (415.46) -2402.78 (1376.05) -2566.10 (962.12) 1372.01 (489.57) -265.87 (1074.72) -1167.71 (766.28) ipw 1774.71 (680.01) 1223.77 (689.43) 722.78 (891.40) 943.92 (833.16) -568.83 (1140.41) 214.16 (475.53) -265.18 (535.18) -136.88 (511.71) 943.92 (833.16) -267.27 (448.21) -586.61 (967.69) -1636.51 (928.51) 131.27 (808.96) -568.83 (1140.41) -2315.11 (824.37) cbps 1709.55 (699.04) 1408.01 (654.96) 2437.70 (877.80) 739.52 (869.71) -1283.13 (1340.97) 214.16 (475.53) -265.18 (535.18) 280.70 (469.14) 739.52 (869.71) -267.27 (448.21) -586.61 (967.69) -1636.51 (928.51) 1147.48 (799.39) -1283.13 (1340.97) -1709.60 (963.61) ebal 1712.12 (699.26) 1406.27 (654.93) 2420.49 (876.85) 717.91 (884.14) -1606.41 (1512.52) 381.53 (489.72) -178.85 (550.29) 271.55 (469.80) 717.91 (884.14) 463.11 (482.64) -784.35 (1095.83) -1597.46 (947.90) 1387.00 (790.71) -1606.41 (1512.52) -1554.92 (989.77) dml 1960.99 (682.98) 1068.62 (627.81) 91.01 (861.30) 854.02 (810.50) -1656.24 (1163.41) 455.42 (449.47) -317.89 (510.14) -294.58 (404.28) 854.02 (810.50) 362.38 (447.22) -1184.06 (998.15) -1496.09 (871.83) -21.50 (837.05) -1656.24 (1163.41) -2312.30 (755.28) aipw_grf 1766.72 (685.93) 1451.06 (731.95) 1401.56 (790.67) 1092.32 (825.76) -482.67 (1133.77) 610.30 (635.53) -229.88 (556.38) 184.56 (770.70) 1092.32 (825.76) 663.80 (628.05) -883.21 (1140.69) -1695.77 (952.86) 439.92 (663.93) -482.67 (1133.77) -1702.63 (768.55) aipw_ow 1831.33 (681.18) 1412.96 (690.23) 1324.99 (760.19) 883.36 (822.13) -642.37 (1157.17) 746.10 (533.03) -170.77 (554.19) 109.07 (516.25) 883.36 (822.13) 470.33 (654.85) -393.95 (1100.95) -1517.32 (944.15) 368.00 (544.90) -642.37 (1157.17) -1799.21 (715.51) The first value in each cell represents the point estimate from the respective estimator and sample. The number in brackets directly following it is the robust standard error (SE) associated with that estimate, indicating the uncertainty or variability around the point estimate. The tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. For most LDW-CPS1-based samples, estimates remain not only positive but also comparatively close to the experimental benchmark, with modest variance inflation. In contrast, the LDW-PSID1-based estimates exhibit greater variability, more frequently negative values, and larger standard errors, reflecting an increased challenge of achieving balance and overlap in this observational dataset. Overall, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;LDW_att_estimates_model_a&quot;) Improved overlap and covariate balance generally leads to estimates closer to the experimental benchmark, but often at the cost of increased standard errors. This trade-off highlights the need to carefully balance bias reduction against precision when selecting methods for robust causal inference. Next, we explore alternative estimands such as heterogeneous treatment effects and quantile treatment effects, which may provide deeper insights into the validity of the unconfoundedness assumption. 2.8.2 Conditional average treatment effect on the treated (CATT) CATT enables analysis of treatment effect heterogeneity across covariate-defined subpopulations. We estimate the CATT for the same samples previously considered in the ATT estimation by applying the Augmented Inverse Probability Weighting Generalized Random Forest (AIPW-GRF) method via the catt() function from Imbens and Xu (2024). # estimate CATT catt.ldw &lt;- catt(ldw, Y, treat, covar) catt.cps &lt;- catt(ldw_cps, Y, treat, covar) catt.psid &lt;- catt(ldw_psid, Y, treat, covar) catt.cps.trim &lt;- catt(ldw_cps.trim_match, Y, treat, covar) catt.psid.trim &lt;- catt(ldw_psid.trim_match, Y, treat, covar) # estimate CATT catt.top5_cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) catt(d, Y, treat, covar)) catt.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) catt(d, Y, treat, covar)) Then, we employ a modified version of the function plot_catt() from Imbens and Xu (2024) to visualize the results by plotting the estimated CATTs for all samples at the covariate values of each treated unit against their corresponding experimental benchmarks. Gray dots represent pairs of CATT estimates at covariate values of treated units, while the red crosses indicate pairs of estimated ATTs. # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim), catt.top5_cps_plus, catt.top5_psid_plus) # plot results par(mfrow = c(2,2)) par(cex.main = 0.8) plot_catt_panels(all_catt, plot_titles) Figure 2.146: FIGURE A11. CATT Estimates Model A using LDW Data Figure 2.147: FIGURE A11. CATT Estimates Model A using LDW Data Figure 2.148: FIGURE A11. CATT Estimates Model A using LDW Data Figure 2.149: FIGURE A11. CATT Estimates Model A using LDW Data Although the AIPW estimator can produce ATT estimates closely aligned with the experimental benchmark using LDW data, its performance for revealing the true CATT is considerably worse. all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 2.7: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) LDW-Experimental -189.4044 3835.953 1713.2565 4025.357 (B) LDW-CPS1 -4979.9855 7201.811 2110.5891 12181.796 (C) LDW-PSID1 -8643.0238 4903.221 820.7716 13546.245 (D) Trimmed LDW-CPS1 -4154.2731 5406.182 1033.9441 9560.456 (E) Trimmed LDW-PSID1 -3207.5327 2111.529 -439.9444 5319.061 (F) Top CPS1: card -5903.1537 4489.183 445.6248 10392.337 (G) Top CPS1: mahvars -4051.6244 3396.121 -262.7898 7447.746 (H) Top CPS1: overlap_crump -7687.4678 6025.806 907.4079 13713.273 (I) Top CPS1: ps_threshold -4225.0277 5389.468 1000.6731 9614.496 (J) Top CPS1: optimal_pair -5786.6045 4813.637 569.3015 10600.241 (K) Top PSID1: card -6455.8452 3232.316 -821.1877 9688.161 (L) Top PSID1: mahvars -6574.0711 2237.617 -1638.6652 8811.688 (M) Top PSID1: overlap_crump -10584.1047 3982.547 -430.7264 14566.651 (N) Top PSID1: ps_threshold -3300.3964 1910.950 -495.4780 5211.347 (O) Top PSID1: overlap_common_range -11239.1191 2592.335 -1918.9256 13831.454 Specifically, with LDW-CPS1, CATT estimates span from $-4,979.99 to $7,201.81, contrasting with the CATT estimated from experimental data which ranges from $-189.40 to $3,835.95, with a mean CATT estimate of $1,713.26. The LDW-PSID1 data shows an even broader CATT estimate range, spanning from $-8,643.02 to $4,903.22, and a notably lower mean of approximately $820.77. Among the trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary substantially. Specific samples such as card or overlap_crump subsamples produce minimum CATTs that are considerably negative, but produce positive mean estimates. Subsamples like ps_threshold, and optimal_pair also deliver positive mean CATT estimates, though with smaller negative minimums, while mahvars is the only method among these to produce a negative mean CATT. Importantly, across all methods, the mean CATT estimates are far away from experimental mean estimate. The CATT estimates for the LDW-PSID1 trimmed and top-ranked subsamples reveal substantially decreased mean values and wider extremes compared to their CPS1 counterparts, reflecting greater difficulties in producing reliable treatment effect estimates. This variation in range and means across methods and samples reflects substantial heterogeneity in treatment effect estimation, indicating that while some criteria improve alignment with experimental benchmarks, others introduce considerable discrepancies and variability in estimated heterogeneous effects. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;model_a&quot;) 2.8.3 Quantile treatment effect on the treated (QTET) QTET provides a robust way to analyze treatment effect heterogeneity while being less impacted by outliers compared to average treatment effect measures. The QTET estimates are obtained using the propensity score re-weighting method introduced by Firpo (2007). Implementation leverages the qte() function from Imbens and Xu (2024), while visualization employs a modified version of their plot_qte() function. # estimate QTET qte.ldw &lt;- est_qte(Y, treat, covar, data = ldw, cores = 4) qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) qte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps.trim_match) qte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid.trim_match) # estimate QTET qte.top5_cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, covar, data = d)) # estimate QTET qte.ldw0 &lt;- est_qte(Y, treat, NULL, data = ldw) qte.ldw.cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) qte.ldw.psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) qte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps.trim_match) qte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid.trim_match) qte.top5_cps_plus0 &lt;- lapply(top5_datasets.cps_plus, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid_plus0 &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, NULL, data = d)) Each plot displays three distinct series for every dataset analyzed: (1) The blue line with diamond-shaped points represents QTET estimates derived from the experimental sample, serving as the benchmark. (2) The red line with triangles shows QTET estimates from the observational data before any adjustment. (3) The black line with circles presents QTET estimates for the observational data after applying covariate adjustment. par(mfrow = c(2,2)) par(cex.main = 0.8) # CPS plot_qte(qte.ldw_cps, qte.ldw.cps0, qte.ldw, main = &quot;(B) LDW-CPS&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID plot_qte(qte.ldw_psid, qte.ldw.psid0, qte.ldw, main = &quot;(C) LDW-PSID&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) ## CPS trimmed plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.ldw_cps, main = &quot;(D) LDW-CPS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID trimmed plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.ldw_psid, main = &quot;(E) LDW-PSID (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 2.150: FIGURE A12. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental # CPS top methods plot_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.ldw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000)) Figure 2.151: FIGURE A12. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental # PSID top methods plot_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.ldw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000)) Figure 2.152: FIGURE A12. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 2.153: FIGURE A12. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the experimental and various observational samples. The QTETs estimated from the original and trimmed LDW-CPS1 sample (B and D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original and trimmed LDW-PSID1 subsample (C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked LDW-CPS1-based subsamples, QTETs (F - J) continue to track the true experimental effect well, whereas LDW-PSID1-based subsamples produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty. # list results plots_ldw &lt;- list( list(mod = qte.ldw_cps, mod0 = qte.ldw.cps0, bm = qte.ldw, main = &quot;(A) LDW CPS1&quot;), list(mod = qte.ldw_psid, mod0 = qte.ldw.psid0, bm = qte.ldw, main = &quot;(B) LDW PSID1&quot;), list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.ldw_cps, main = &quot;(C) LDW CPS1 (Trimmed)&quot;), list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.ldw_psid, main = &quot;(D) LDW PSID1 (Trimmed)&quot;) ) # save results save_qtet(plots_ldw, prefix = &quot;ldw_model_a&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.ldw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000), prefix = &quot;ldw_model_a_top&quot;) save_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.ldw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000), prefix = &quot;ldw_model_a_top&quot;) 2.8.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c( list(ldw, ldw_cps, ldw_psid, ldw_cps.trim_match, ldw_psid.trim_match), top5_datasets.cps_plus, top5_datasets.psid_plus ) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 2.154: FIGURE A13. Outcome Weights Model A using LDW Data Figure 2.155: FIGURE A13. Outcome Weights Model A using LDW Data Figure 2.156: FIGURE A13. Outcome Weights Model A using LDW Data Figure 2.157: FIGURE A13. Outcome Weights Model A using LDW Data #evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat_var = treat, estimator = &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 2.8: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) LDW-Experimental 1 -1 (B) LDW-CPS1 1 -1 (C) LDW-PSID1 1 -1 (D) Trimmed LDW-CPS1 1 -1 (E) Trimmed LDW-PSID1 1 -1 (F) Top CPS1: card 1 -1 (G) Top CPS1: mahvars 1 -1 (H) Top CPS1: overlap_crump 1 -1 (I) Top CPS1: ps_threshold 1 -1 (J) Top CPS1: optimal_pair 1 -1 (K) Top PSID1: card 1 -1 (L) Top PSID1: mahvars 1 -1 (M) Top PSID1: overlap_crump 1 -1 (N) Top PSID1: ps_threshold 1 -1 (O) Top PSID1: overlap_common_range 1 -1 The outcome weights are not obtained directly from the ATT point estimates due to computational design of other methods. Instead, the ATT is separately estimated for each dataset following the approach developed by Knaus and Pfleiderer (2024). The evaluation reveals that across each sample the estimated outcome weights sum to one within the treated group and minus one within the untreated group, resulting in an overall sum of zero. #save results save_ow(ow_att, plot_titles, prefix = &quot;model_a&quot;) 2.9 Validation through placebo analyses To further evaluate the credibility of the unconfoundedness assumption, a placebo analysis is performed by designating 1975 earnings (re75) as the outcome variable and omitting both re75 and u75 from the list of covariates. The analysis utilizes all previously considered samples and recomputes the ATT via the function estimate_all, conditioning only on the remaining set of covariates. # define variables Y_pl &lt;- &quot;re75&quot; treat &lt;- &quot;treat&quot; covar_pl &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;u74&quot;) # estimate placebo ATT on experimental and observational datasets out1_pl &lt;- estimate_all(ldw, Y_pl, &quot;treat&quot;, covar_pl) out2_pl &lt;- estimate_all(ldw_cps, Y_pl, &quot;treat&quot;, covar_pl) out3_pl &lt;- estimate_all(ldw_psid, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on trimmed datasets out4_pl &lt;- estimate_all(ldw_cps.trim_match, Y_pl, &quot;treat&quot;, covar_pl) out5_pl &lt;- estimate_all(ldw_psid.trim_match, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on top ranked datasets out.cps_pl &lt;- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out.psid_pl &lt;- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out6_pl &lt;- out.cps_pl[[1]] out7_pl &lt;- out.cps_pl[[2]] out8_pl &lt;- out.cps_pl[[3]] out9_pl &lt;- out.cps_pl[[4]] out10_pl &lt;- out.cps_pl[[5]] out11_pl &lt;- out.psid_pl[[1]] out12_pl &lt;- out.psid_pl[[2]] out13_pl &lt;- out.psid_pl[[3]] out14_pl &lt;- out.psid_pl[[4]] out15_pl &lt;- out.psid_pl[[5]] # collect all placebo results all_outs.pl &lt;- c(list(out1_pl, out2_pl, out3_pl, out4_pl, out5_pl), out.cps_pl, out.psid_pl) # plot placebo results band_pl &lt;- out1_pl[1, 3:4] est_pl &lt;- out1_pl[1, 1] ylim_pl = c(-15500, 5500) plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.7) Figure 2.158: FIGURE A14. Placebo Test Model B: ’75 Earnings as the Outcome Figure 2.159: FIGURE A14. Placebo Test Model B: ’75 Earnings as the Outcome Figure 2.160: FIGURE A14. Placebo Test Model B: ’75 Earnings as the Outcome Figure 2.161: FIGURE A14. Placebo Test Model B: ’75 Earnings as the Outcome # save results save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, &quot;model_a_placebo&quot;) The placebo ATT results are presented in the table below: # print placebo results result_mat_pl &lt;- create_matrix_results(all_outs.pl, plot_titles) knitr::kable(result_mat_pl, booktabs = TRUE, caption = &quot;Placebo ATT Estimates and SEs&quot;) Table 2.9: Placebo ATT Estimates and SEs (A) LDW-Experimental (B) LDW-CPS1 (C) LDW-PSID1 (D) Trimmed LDW-CPS1 (E) Trimmed LDW-PSID1 (F) Top CPS1: card (G) Top CPS1: mahvars (H) Top CPS1: overlap_crump (I) Top CPS1: ps_threshold (J) Top CPS1: optimal_pair (K) Top PSID1: card (L) Top PSID1: mahvars (M) Top PSID1: overlap_crump (N) Top PSID1: ps_threshold (O) Top PSID1: overlap_common_range Experimental Benchmark 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -654.26 (419.29) -74.95 (660.61) -300.03 (257.91) 126.08 (309.13) -4373.18 (180.22) -654.26 (419.29) -748.14 (238.52) -314.46 (453.40) -416.97 (671.84) -6812.45 (322.20) -74.95 (660.61) -15746.50 (433.53) diff 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -654.26 (419.29) -74.95 (660.61) -300.03 (257.91) 126.08 (309.13) -4373.18 (180.22) -654.26 (419.29) -748.14 (238.52) -314.46 (453.40) -416.97 (671.84) -6812.45 (322.20) -74.95 (660.61) -15746.50 (433.53) reg 224.34 (218.33) -1134.82 (272.44) -2757.40 (589.02) -516.55 (330.19) -100.13 (683.14) -366.41 (206.44) 110.98 (217.76) -2789.26 (215.74) -516.55 (330.19) -178.54 (186.94) -439.52 (382.05) -184.84 (498.66) -4076.11 (505.87) -100.13 (683.14) -3331.37 (539.11) om.reg 165.70 (284.98) -1096.70 (395.18) -2640.76 (367.46) -450.69 (320.92) -205.47 (498.80) -515.22 (225.11) 145.67 (278.37) -2778.02 (233.06) -450.69 (320.92) -385.86 (192.96) -521.12 (393.05) -242.11 (581.06) -4794.24 (230.26) -205.47 (498.80) -3245.87 (571.43) om.grf 108.18 (283.83) -1590.61 (373.01) -4290.47 (343.87) -586.38 (304.18) -20.75 (483.64) -364.13 (201.15) 104.88 (260.17) -1631.80 (241.13) -565.05 (304.33) -249.54 (179.98) 5.42 (383.41) -182.80 (524.07) -3661.77 (223.47) -73.11 (483.85) -4904.63 (523.15) matching 148.67 (227.58) -1465.93 (351.78) -1913.65 (805.37) -761.19 (322.26) -315.32 (672.37) -708.53 (275.03) -23.90 (222.75) -1625.58 (306.31) -761.19 (322.26) -609.49 (251.48) -182.96 (488.69) -469.12 (484.86) -1951.37 (803.45) -315.32 (672.37) -3372.05 (580.70) psm 94.07 (316.23) -1335.04 (425.34) -2792.68 (496.82) -732.18 (416.01) -658.19 (652.82) -353.07 (248.00) -88.56 (322.39) -1137.04 (246.21) -726.27 (416.64) -434.70 (206.60) -243.04 (425.74) -236.12 (631.41) -2197.36 (300.83) -658.19 (652.82) -3490.62 (589.53) ipw 160.63 (311.24) -1515.20 (334.86) -3151.45 (739.64) -688.73 (427.16) -163.34 (666.18) -300.03 (257.91) 126.08 (309.13) -1609.45 (311.41) -688.73 (427.16) -748.14 (238.52) -314.46 (453.40) -416.97 (671.84) -2191.35 (822.44) -163.34 (666.18) -4387.37 (556.23) cbps 188.34 (304.79) -1227.83 (297.89) -2282.31 (834.92) -446.97 (404.83) -361.39 (826.77) -300.03 (257.91) 126.08 (309.13) -1358.71 (246.27) -446.97 (404.83) -748.14 (238.52) -314.46 (453.40) -416.97 (671.84) -2244.70 (827.79) -361.39 (826.77) -4107.03 (643.70) ebal 189.20 (304.71) -1228.49 (297.88) -2250.80 (842.15) -415.77 (400.12) -361.41 (826.77) -518.64 (324.44) 164.57 (317.64) -1349.13 (245.80) -415.77 (400.12) -306.53 (227.36) -456.28 (492.94) -222.37 (653.59) -2127.56 (798.86) -361.41 (826.77) -4080.14 (652.32) dml 275.69 (231.57) -1152.96 (271.75) -2725.28 (591.57) -404.20 (345.98) -204.84 (682.64) -375.70 (205.10) 113.17 (221.60) -2777.77 (216.26) -404.20 (345.98) -184.41 (186.39) -509.80 (381.79) -72.30 (484.27) -4016.45 (505.87) -204.84 (682.64) -3307.33 (538.48) aipw_grf 83.05 (228.21) -1249.88 (264.79) -2419.46 (623.46) -586.40 (365.00) -141.38 (577.59) -274.18 (259.11) 88.88 (235.81) -1408.57 (243.85) -586.40 (365.00) -287.21 (212.05) -34.90 (374.85) -214.28 (508.94) -2124.31 (698.56) -141.38 (577.59) -4258.93 (491.40) aipw_ow 108.01 (233.22) -1318.36 (276.40) -2904.04 (648.78) -618.87 (365.07) 47.81 (619.87) -336.51 (239.41) 91.41 (259.16) -1431.42 (210.14) -618.87 (365.07) -346.13 (230.48) -12.66 (369.88) -407.28 (566.49) -2678.40 (625.67) 47.81 (619.87) -4395.88 (469.68) The placebo analysis reveals that the experimental benchmarks are positive, near zero and statistically insignificant, while all estimators applied to the observational datasets, LDW-CPS1 and LDW-PSID1, yield by majority large, negative ATT estimates. For LDW-CPS1, most ATT estimates are negative. The overlap_crump subsample shows a modest improvement toward the experimental benchmark compared to LDW-CPS1 (B) results, but also produces notably poorer estimates for certain estimators. The trimmed subsamples (D) and (I), which use similar approaches, further improve upon the LDW-CPS1 (B) results. The optimal_pair and card subsamples provide even greater improvement. The mahvars (G) subsample delivers ATT estimates closest to the experimental benchmark and is the only case to yield positive ATT estimates across the LDW-CPS1 samples. For LDW-PSID1, the subsample (O) applying the overlap_common_range method shows no improvement compared to the LDW-PSID1 sample (C) except for the Diff-in-Means estimator. The overlap_crump subsample generally delivers ATT estimates closer to the experimental benchmark, while the card and mahvars subsamples producing estimates even closer to the experimental benchmark. The trimmed subsamples (E) and (N), which use similar approaches, achieve the closest alignment with the benchmark. Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis reveals substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underlines the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings. # save results save_csv(result_mat_pl, &quot;LDW_att_estimates_pl_model_a&quot;) 2.10 Validation through sensitivity analyses Finally, a sensitivity analyses using the LDW data is conducted and results are depicted in contour plots using the function sens_ana of Imbens &amp; Xu (2024). # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets datasets_sens &lt;- c(list(ldw, ldw_cps, ldw_psid), top5_datasets.cps_plus, top5_datasets.psid_plus) filtered_datasets_sens &lt;- check_filter_datasets(datasets_sens, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx]) } Figure 2.162: FIGURE A15. Sensitivity Analyses Model A Figure 2.163: FIGURE A15. Sensitivity Analyses Model A Figure 2.164: FIGURE A15. Sensitivity Analyses Model A Figure 2.165: FIGURE A15. Sensitivity Analyses Model A # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;model_a&quot;) The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of re75. Notably, some samples such as LDW-PSID1 exhibit a greater sensitivity with more pronounced swings including negative estimates at higher confounder strengths, contrasting with consistent positive effects in LDW-CPS1 variants. This highlights sample-specific differences in robustness against potential unobserved confounding. The analyses suggest that some samples maintain stable treatment effect estimates despite increasing confounder strength, while others show greater sensitivity. This highlights the importance of assessing robustness across different samples (respectively methods used to derive specific samples) to account for potential unobserved bias. 2.11 Summary After reexamining model A, that is based on the LaLonde-Dehejia-Wahba (LDW) data and its augmented versions with control groups from CPS-1 and PSID-1, several insights into causal inference challenges emerge. First, we confirm that ensuring overlap between treated and control groups remains crucial for credible causal estimation. The LDW-Experimental data exhibit excellent overlap, while the observational datasets (LDW-CPS1 and LDW-PSID1) show weaker overlap, with many treated units outside the control range. Augmenting these datasets with experimental controls improves overlap but does not consistently improve covariate balance. Second, controlling for covariates such as age, education, race, and prior earnings, and using various methods including matching, weighting, truncation, trimming, and combined approaches, largely yields consistent effects. The propensity score plays an important role in assessing overlap and balancing covariates across groups. Third, the LDW dataset is somewhat unique in that most methods approximate the experimental benchmark well for average treatment effects on the treated (ATT), an achievement not fully replicated in the original LaLonde samples. However, placebo tests using pre-treatment earnings and sensitivity analyses reveal lingering concerns about the unconfoundedness assumption and robustness of some estimators. Overall, this chapter highlights the importance of overlap and covariate balance, the utility of propensity scores, and the need for rigorous validation of treatment assignment assumptions to produce credible causal estimates. Despite improvements in data and methods, tests of unconfoundedness via placebo outcomes suggest caution in interpreting causal effects. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” "],["lalonde-dehejia-wahba-ldw-data-1.html", "Chapter 3 LaLonde-Dehejia-Wahba (LDW) Data 3.1 Set up 3.2 Model B 3.3 Improving primarily covariate balance 3.4 Improving primarily overlap 3.5 Reassessing methods 3.6 Integrated methods 3.7 Estimating 3.8 Validation through placebo analyses 3.9 Validation through sensitivity analyses 3.10 Summary", " Chapter 3 LaLonde-Dehejia-Wahba (LDW) Data This section (3) covers model B, which, similar to model A, uses 1978 earnings (re78) as the outcome variable but adjusts for a slightly different set of covariates: age, education, race indicators (black, hispanic), marital status, lack of a high school degree, 1975 earnings (re75), and unemployment status in 1974 and 1975 (u74, u75), explicitly excluding 1974 earnings (re74) to test the model’s robustness. The model is specified via a logistic regression formula based on these covariates. To enhance covariate balance between treated and untreated groups, the same comprehensive suite of methods is employed as in model A, organized into five categories. From these approaches, the top 5 ranked methods are selected based on absolute standardized mean differences (SMDs) and effective sample size (ESS), and their resulting datasets are used to estimate the average treatment effect on the treated (ATT). This estimation process also incorporates the augmented inverse probability weighting (AIPW) estimator from the OutcomeWeights R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (re75) as the outcome variable to assess potential biases and the validity of the unconfoundedness assumption. Finally, sensitivity analyses are performed to evaluate the robustness of the treatment effect estimates to violations of these assumptions. For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the model B–specific results. 3.1 Set up 3.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 3.1.2 Inspect data # collect datasets in a list data &lt;- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 3.1: Summary Statistics dataset num_obs num_vars name_vars lalonde 2675 13 nsw, age, educ, black, hisp, married, re74, re75, re78, u74, u75, u78, nodegr ldw_tr 185 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_co 260 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_cps 16177 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid 2675 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 3.1.3 Load and preprocess data # assigns 1 to the experimental controls ldw_co$treat &lt;- 1 # merge experimental data with CPS1 data ldw_cps_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_cps # CPS1 data (16177 observations) ) # merge experimental data with PSID1 data ldw_psid_plus &lt;- rbind.data.frame( ldw_co, # experimental controls (260 observations) ldw_psid # PSID1 data (2675 observations) ) datasets &lt;- list(ldw_cps_plus = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus) # inspect each dataset summary_stats_plus &lt;- inspect_data(datasets) knitr::kable(summary_stats_plus, caption = &quot;Summary Statistics&quot;) Table 3.2: Summary Statistics dataset num_obs num_vars name_vars ldw_cps_plus 16437 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid_plus 2935 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 3.2 Model B # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) #re74 excluded 3.2.1 Assessing overlap and covariate balance 3.2.1.1 Overlap # assess overlap ldw.ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar) ## -1.26191 0.7410732 Figure 3.1: FIGURE B1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_cps.ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar) ## -16.1181 1.813362 Figure 3.2: FIGURE B1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_psid.ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar) ## -11.47475 3.722802 Figure 3.3: FIGURE B1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. # assess overlap ldw_cps_plus.ps &lt;- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) ## -16.1181 3.425533 Figure 3.4: FIGURE B1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. ldw_psid_plus.ps &lt;- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) ## -11.65343 7.149751 Figure 3.5: FIGURE B1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 3.2.1.2 Covariate balance love.plot(ldw, ldw_cps, treat, covar = covar, title = &quot;LDW-CPS1&quot;) Figure 3.6: FIGURE B2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = &quot;LDW-CPS1-PLUS&quot;) Figure 3.7: FIGURE B2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid, treat, covar = covar, title = &quot;LDW-PSID1&quot;) Figure 3.8: FIGURE B2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = &quot;LDW-PSID1-PLUS&quot;) Figure 3.9: FIGURE B2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. 3.3 Improving primarily covariate balance 3.3.1 Matching 3.3.1.1 Distance Matching 3.3.1.1.1 1:1 Nearest neighbor matching # perform nearest neighbor matching with k=1, logistic propensity score and replacement m.out.cps_plus.nearest &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) m.out.psid_plus.nearest &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) 3.3.1.1.2 k:1 matching (k=2) k&lt;-2 # perform nearest neighbor matching with k=2, logistic propensity score and replacement m.out.cps_plus.k2 &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid_plus.k2 &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 3.3.1.1.3 k:1 matching (k=3) k&lt;-3 # perform nearest neighbor matching with k=3, logistic propensity score and replacement m.out.cps_plus.k3 &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid_plus.k3 &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 3.3.1.1.4 Caliper matching # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score m.out.cps_plus.caliper &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) m.out.psid_plus.caliper &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) 3.3.1.1.5 Common support restriction matching # perform nearest neighbor matching with exclusion of units outside common support m.out.cps_plus.cs &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, replace = TRUE) m.out.psid_plus.cs &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, replace = TRUE) 3.3.1.1.6 Mahalanobis distance matching (mahvars) # perform nearest neighbor matching using mahalanobis distance on selected covariates m.out.cps_plus.mahvars &lt;- matchit(model, data = ldw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) m.out.psid_plus.mahvars &lt;- matchit(model, data = ldw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) 3.3.1.1.7 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.cps_plus.optimal_pair &lt;- matchit(model, data = ldw_cps_plus, method = &quot;optimal&quot;, distance = &quot;logit&quot;) m.out.psid_plus.optimal_pair &lt;- matchit(model, data = ldw_psid_plus, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 3.3.1.1.8 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.cps_plus.optimal_full &lt;- matchit(model, data = ldw_cps_plus, method = &quot;full&quot;, distance = &quot;logit&quot;) m.out.psid_plus.optimal_full &lt;- matchit(model, data = ldw_psid_plus, method = &quot;full&quot;, distance = &quot;logit&quot;) 3.3.1.1.9 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.cps_plus.general_full &lt;- matchit(model, data = ldw_cps_plus, method = &quot;quick&quot;, distance = &quot;logit&quot;) m.out.psid_plus.general_full &lt;- matchit(model, data = ldw_psid_plus, method = &quot;quick&quot;, distance = &quot;logit&quot;) 3.3.1.1.10 Genetic matching # perform genetic matching m.out.cps_plus.genetic &lt;- matchit(model, data = ldw_cps_plus, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) m.out.psid_plus.genetic &lt;- matchit(model, data = ldw_psid_plus, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) 3.3.1.2 Stratum matching 3.3.1.2.1 Exact matching (exact) # match units exactly by raw covariate profiles m.out.cps_plus.exact &lt;- matchit(model, data = ldw_cps_plus, method = &quot;exact&quot;) m.out.psid_plus.exact &lt;- matchit(model, data = ldw_psid_plus, method = &quot;exact&quot;) 3.3.1.2.2 Coarsened matching (cem) # match units exactly within coarse strata m.out.cps_plus.cem &lt;- matchit(model, data = ldw_cps_plus, method = &quot;cem&quot;) m.out.psid_plus.cem &lt;- matchit(model, data = ldw_psid_plus, method = &quot;cem&quot;) 3.3.1.2.3 Subclassification # partition sample into fixed number of bins based on propensity score m.out.cps_plus.subcl &lt;- matchit(model, data = ldw_cps_plus, method = &quot;subclass&quot;, subclass = 5) m.out.psid_plus.subcl &lt;- matchit(model, data = ldw_psid_plus, method = &quot;subclass&quot;, subclass = 5) 3.3.1.3 Pure subset selection 3.3.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances m.out.cps_plus.card &lt;- matchit(model, data = ldw_cps_plus, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) m.out.psid_plus.card &lt;- matchit(model, data = ldw_psid_plus, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) 3.3.1.3.2 Profile matching # matching by directly optimizing balance profile measures across covariates m.out.cps_plus.profile &lt;- matchit_profile(ldw_cps_plus, treat, covar) m.out.psid_plus.profile &lt;- matchit_profile(ldw_psid_plus, treat, covar) 3.3.2 Weighting 3.3.2.1 Inverse probability weights (IPW) # compute weights as inverse of estimated propensity scores w.out.cps_plus.ipw &lt;- weightit(model, data = ldw_cps_plus, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.ipw &lt;- weightit(model, data = ldw_psid_plus, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) ldw_cps_plus$ipw_weight &lt;- w.out.cps_plus.ipw$weights ldw_psid_plus$ipw_weight &lt;- w.out.psid_plus.ipw$weights 3.3.2.2 Standardized mortality ratio (SMR) treated weights # calculate weights for ATT by assigning weight = 1 to treated units and weights proportional to odds of treatment for control ldw_cps_plus$smr_weight &lt;- create_smr_weights(ldw_cps_plus, model, &quot;ATT&quot;) ldw_psid_plus$smr_weight &lt;- create_smr_weights(ldw_psid_plus, model, &quot;ATT&quot;) 3.3.2.3 Matching weights # derive optimal matching weights intending to minimize covariate imbalance while targeting ATT w.out.cps_plus.opt &lt;- weightit(model, data = ldw_cps_plus, method = &quot;optweight&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.opt &lt;- weightit(model, data = ldw_psid_plus, method = &quot;optweight&quot;, estimand = &quot;ATT&quot;) ldw_cps_plus$opt_weight &lt;- w.out.cps_plus.opt$weights ldw_psid_plus$opt_weight &lt;- w.out.psid_plus.opt$weights 3.3.2.4 Overlap weights # calculate overlap weights emphasizing units with propensity scores near 0.5 ldw_cps_plus$overlap_weight &lt;- create_overlap_weights(ldw_cps_plus, model) ldw_psid_plus$overlap_weight &lt;- create_overlap_weights(ldw_psid_plus, model) 3.3.2.5 Entropy weights # compute entropy balancing weights w.out.cps_plus.ebal &lt;- weightit(model, data = ldw_cps_plus, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.ebal &lt;- weightit(model, data = ldw_psid_plus, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;) ldw_cps_plus$ebal_weight &lt;- w.out.cps_plus.ebal$weights ldw_psid_plus$ebal_weight &lt;- w.out.psid_plus.ebal$weights 3.4 Improving primarily overlap 3.4.1 Truncation # list weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;smr_weight&quot;, &quot;opt_weight&quot;, &quot;overlap_weight&quot;, &quot;ebal_weight&quot;) 3.4.1.1 Fixed maximum value truncation # truncate weights by imposing a maximum threshold of 10 ldw_cps_plus.fixed &lt;- ldw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus.fixed)) { ldw_cps_plus.fixed &lt;- truncate_weights_fixed(ldw_cps_plus.fixed, weight_col = wcol, max_weight = 10) } } ldw_psid_plus.fixed &lt;- ldw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus.fixed)) { ldw_psid_plus.fixed &lt;- truncate_weights_fixed(ldw_psid_plus.fixed, weight_col = wcol, max_weight = 10) } } 3.4.1.2 At percentile truncation # truncate weights such that values above the 99th percentile are capped ldw_cps_plus.percent &lt;- ldw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus.percent)) { ldw_cps_plus.percent &lt;- truncate_weights_percentile(ldw_cps_plus.percent, weight_col = wcol, percentile = 0.99) } } ldw_psid_plus.percent &lt;- ldw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus.percent)) { ldw_psid_plus.percent &lt;- truncate_weights_percentile(ldw_psid_plus.percent, weight_col = wcol, percentile = 0.99) } } 3.4.1.3 Adaptive weight truncation # inspect variance of weights cps_results &lt;- list() psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus)) { cps_results[[paste0(&quot;cps_&quot;, wcol)]] &lt;- check_weights(ldw_cps_plus, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in ldw_cps_plus&quot;)) } } for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus)) { psid_results[[paste0(&quot;psid_&quot;, wcol)]] &lt;- check_weights(ldw_psid_plus, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in ldw_psid_plus&quot;)) } } var_cps_table &lt;- bind_rows(cps_results) var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_cps_table, caption = &quot;Variance of Weights (CPS)&quot;) Table 3.3: Variance of Weights (CPS) Weight_Column Variance ipw_weight 8.275220e-02 smr_weight 1.811097e+03 opt_weight 1.210057e+17 overlap_weight 1.271230e-02 ebal_weight 7.065942e+01 knitr::kable(var_psid_table, caption = &quot;Variance of Weights (PSID)&quot;) Table 3.3: Variance of Weights (PSID) Weight_Column Variance ipw_weight 12.1074733 smr_weight 1139.8553936 opt_weight 74.5166468 overlap_weight 0.0257408 ebal_weight 109.7344945 Regarding these results we can apply adaptive weight truncation to all considered weights, where it may help mitigate the influence of extreme weights. # truncate adaptively at mean + 3 standard deviations ldw_cps_plus.adapt &lt;- ldw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_cps_plus.adapt)) { ldw_cps_plus.adapt &lt;- truncate_weights_adaptive(ldw_cps_plus.adapt, weight_col = wcol, c = 3) } } ldw_psid_plus.adapt &lt;- ldw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(ldw_psid_plus.adapt)) { ldw_psid_plus.adapt &lt;- truncate_weights_adaptive(ldw_psid_plus.adapt, weight_col = wcol, c = 3) } } 3.4.2 Trimming 3.4.2.1 Propensity score threshold trimming (analogous to tutorial of Imbens and Xu (2024)) # apply trimming with thresholds 0.9 and 0.8 ldw_cps_trim &lt;- ps_trim(ldw_cps_plus.ps, threshold = 0.9) ldw_psid_trim &lt;- ps_trim(ldw_psid_plus.ps, threshold = 0.8) # exclude experimental controls, subset trimmed data appropriately ldw_cps.trim_match &lt;- subset(ldw_cps_trim, sample %in% c(1,3) &amp; ps_assoverlap) ldw_psid.trim_match &lt;- subset(ldw_psid_trim, sample %in% c(1,4) &amp; ps_assoverlap) # re-assign treat variable for controls in sample 3 or 4 (non-treated group) ldw_cps.trim_match$treat[ldw_cps.trim_match$sample == 3] &lt;- 0 ldw_psid.trim_match$treat[ldw_psid.trim_match$sample == 4] &lt;- 0 # re-estimate propensity scores on trimmed data and perform 1:1 matching ldw_cps.trim_match &lt;- psmatch(data = ldw_cps.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.trim_match &lt;- psmatch(data = ldw_psid.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 3.4.2.2 Common range trimming # trim observations outside the common support region of propensity scores ldw_cps_plus.common &lt;- common_range_trim(ldw_cps_plus.ps) ldw_psid_plus.common &lt;- common_range_trim(ldw_psid_plus.ps) 3.4.2.3 Propensity score trimming (Crump) # trim observations with propensity scores outside [0.1, 0.9] interval ldw_cps_plus.crump &lt;- crump_trim(ldw_cps_plus.ps, lower = 0.1, upper = 0.9) ldw_psid_plus.crump &lt;- crump_trim(ldw_psid_plus.ps, lower = 0.1, upper = 0.9) 3.4.2.4 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control ldw_cps_plus.stuermer &lt;- stuermer_trim(ldw_cps_plus.ps) ldw_psid_plus.stuermer &lt;- stuermer_trim(ldw_psid_plus.ps) 3.4.2.5 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations ldw_cps_plus.walker &lt;- walker_trim(ldw_cps_plus.ps) ldw_psid_plus.walker &lt;- walker_trim(ldw_psid_plus.ps) 3.4.3 Integrated methods # list trimming methods trim_names &lt;- c(&quot;ps_threshold&quot;, &quot;common_range&quot;, &quot;stuermer&quot;, &quot;walker&quot;, &quot;crump&quot;) trimmed_cps &lt;- list(ps_threshold = ldw_cps_trim, common_range = ldw_cps_plus.common, stuermer = ldw_cps_plus.stuermer, walker = ldw_cps_plus.walker, crump = ldw_cps_plus.crump) trimmed_psid &lt;- list(ps_threshold = ldw_psid_trim, common_range = ldw_psid_plus.common, stuermer = ldw_psid_plus.stuermer, walker = ldw_psid_plus.walker, crump = ldw_psid_plus.crump) 3.4.3.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;ipw_weight&quot;)), trim_names ) ipw_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;ipw_weight&quot;)), trim_names ) 3.4.3.2 SMR treated weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply standardized mortality ratio (SMR) weighting with trimming and attach SMR weights smr_treat_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;smr_weight&quot;)), trim_names ) smr_treat_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;smr_weight&quot;)), trim_names ) 3.4.3.3 Overlap weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply overlap weighting with trimming and attach overlap weights ov_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;overlap_weight&quot;)), trim_names ) ov_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;overlap_weight&quot;)), trim_names ) 3.4.3.4 Entropy weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights entropy_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], ldw_cps_plus, &quot;ebal_weight&quot;)), trim_names ) entropy_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], ldw_psid_plus, &quot;ebal_weight&quot;)), trim_names ) 3.5 Reassessing methods 3.5.1 Matching # list all matching methods methods.cps_plus &lt;- list( nn = m.out.cps_plus.nearest, k2 = m.out.cps_plus.k2, k3 = m.out.cps_plus.k3, caliper = m.out.cps_plus.caliper, cS = m.out.cps_plus.cs, mahvars = m.out.cps_plus.mahvars, optimal_pair = m.out.cps_plus.optimal_pair, optimal_full = m.out.cps_plus.optimal_full, gen_full = m.out.cps_plus.general_full, genetic = m.out.cps_plus.genetic, exact = m.out.cps_plus.exact, cem = m.out.cps_plus.cem, card = m.out.cps_plus.card, profile = m.out.cps_plus.profile, subcl = m.out.cps_plus.subcl ) methods.psid_plus &lt;- list( nn = m.out.psid_plus.nearest, k2 = m.out.psid_plus.k2, k3 = m.out.psid_plus.k3, caliper = m.out.psid_plus.caliper, cs = m.out.psid_plus.cs, mahvars = m.out.psid_plus.mahvars, optimal_pair = m.out.psid_plus.optimal_pair, optimal_full = m.out.psid_plus.optimal_full, gen_full = m.out.psid_plus.general_full, genetic = m.out.psid_plus.genetic, exact = m.out.psid_plus.exact, cem = m.out.psid_plus.cem, card = m.out.psid_plus.card, profile = m.out.psid_plus.profile, subcl = m.out.psid_plus.subcl ) 3.5.1.1 SMD # compute SMD smd_matchit.cps_plus &lt;- compute_abs_smd_matchit(methods.cps_plus) smd_matchit.psid_plus &lt;- compute_abs_smd_matchit(methods.psid_plus) 3.5.1.2 ESS # calculate balance statistics bal.cps_plus &lt;- cobalt::bal.tab(model, data = ldw_cps_plus, un = TRUE, weights = methods.cps_plus, s.d.denom = &quot;treated&quot;) bal.psid_plus &lt;- cobalt::bal.tab(model, data = ldw_psid_plus, un = TRUE, weights = methods.psid_plus, s.d.denom = &quot;treated&quot;) # compute ESS ess_matchit.cps_plus &lt;- compute_ess_matchit(bal.cps_plus) ess_matchit.psid_plus &lt;- compute_ess_matchit(bal.psid_plus) 3.5.1.3 Visuals # visualize covariate balance plot_matchit(methods.cps_plus, &quot;LDW-CPS1-PLUS&quot;) Figure 3.10: FIGURE B3. Figure 3.11: FIGURE B3. Figure 3.12: FIGURE B3. Figure 3.13: FIGURE B3. Figure 3.14: FIGURE B3. Figure 3.15: FIGURE B3. Figure 3.16: FIGURE B3. Figure 3.17: FIGURE B3. Figure 3.18: FIGURE B3. Figure 3.19: FIGURE B3. Figure 3.20: FIGURE B3. Figure 3.21: FIGURE B3. Figure 3.22: FIGURE B3. Figure 3.23: FIGURE B3. Figure 3.24: FIGURE B3. plot_matchit(methods.psid_plus, &quot;LDW-PSID1-PLUS&quot;) Figure 3.25: FIGURE B3. Figure 3.26: FIGURE B3. Figure 3.27: FIGURE B3. Figure 3.28: FIGURE B3. Figure 3.29: FIGURE B3. Figure 3.30: FIGURE B3. Figure 3.31: FIGURE B3. Figure 3.32: FIGURE B3. Figure 3.33: FIGURE B3. Figure 3.34: FIGURE B3. Figure 3.35: FIGURE B3. Figure 3.36: FIGURE B3. Figure 3.37: FIGURE B3. Figure 3.38: FIGURE B3. Figure 3.39: FIGURE B3. 3.5.2 Weighting # list all weights weight.cps_plus &lt;- list( ipw = ldw_cps_plus$ipw_weight, smr_tr = ldw_cps_plus$smr_weight, mw = ldw_cps_plus$opt_weight, ow = ldw_cps_plus$overlap_weight, ew = ldw_cps_plus$ebal_weight ) weight.psid_plus &lt;- list( ipw = ldw_psid_plus$ipw_weight, smr_tr = ldw_psid_plus$smr_weight, mw = ldw_psid_plus$opt_weight, ow = ldw_psid_plus$overlap_weight, ew = ldw_psid_plus$ebal_weight ) 3.5.2.1 SMD # compute SMD smd_weight.cps_plus &lt;- compute_abs_smd_weight(ldw_cps_plus, &quot;treat&quot;, covar, weight_columns) smd_weight.psid_plus &lt;- compute_abs_smd_weight(ldw_psid_plus, &quot;treat&quot;, covar, weight_columns) 3.5.2.2 ESS # compute ESS ess_weight.cps_plus &lt;- compute_ess_weight(ldw_cps_plus, &quot;treat&quot;, covar, weight_columns) ess_weight.psid_plus &lt;- compute_ess_weight(ldw_psid_plus, &quot;treat&quot;, covar, weight_columns) 3.5.2.3 Visuals # visualize covariate balance plot_weighting_methods(ldw_cps_plus, &quot;treat&quot;, covar, weight.cps_plus, &quot;LDW-CPS1-PLUS&quot;) Figure 3.40: FIGURE B4. Figure 3.41: FIGURE B4. Figure 3.42: FIGURE B4. Figure 3.43: FIGURE B4. Figure 3.44: FIGURE B4. plot_weighting_methods(ldw_psid_plus, &quot;treat&quot;, covar, weight.psid_plus, &quot;LDW-PSID1-PLUS&quot;) Figure 3.45: FIGURE B4. Figure 3.46: FIGURE B4. Figure 3.47: FIGURE B4. Figure 3.48: FIGURE B4. Figure 3.49: FIGURE B4. 3.5.3 Truncation # list truncation methods trunc.cps_plus &lt;- list( fix_max_value_trunc.cps_plus = ldw_cps_plus.fixed, at_perc_trunc.cps_plus = ldw_cps_plus.percent, adap_weight_trunc.cps_plus = ldw_cps_plus.adapt ) trunc.psid_plus &lt;- list( fix_max_value_trunc.psid_plus = ldw_psid_plus.fixed, at_perc_trunc.psid_plus = ldw_psid_plus.percent, adap_weight_trunc.psid_plus = ldw_psid_plus.adapt ) 3.5.3.1 SMD # compute SMD smd_trunc.cps_plus &lt;- compute_abs_smd_trunc(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns) smd_trunc.psid_plus &lt;- compute_abs_smd_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 3.5.3.2 ESS # compute ESS ess_trunc.cps_plus &lt;- compute_ess_trunc(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns) ess_trunc.psid_plus &lt;- compute_ess_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 3.5.3.3 Visuals # visualize covariate balance plot_trunc_methods(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns, &quot;LDW-CPS1-PLUS&quot;) Figure 3.50: FIGURE B5. Figure 3.51: FIGURE B5. Figure 3.52: FIGURE B5. Figure 3.53: FIGURE B5. Figure 3.54: FIGURE B5. Figure 3.55: FIGURE B5. Figure 3.56: FIGURE B5. Figure 3.57: FIGURE B5. Figure 3.58: FIGURE B5. Figure 3.59: FIGURE B5. Figure 3.60: FIGURE B5. Figure 3.61: FIGURE B5. Figure 3.62: FIGURE B5. Figure 3.63: FIGURE B5. Figure 3.64: FIGURE B5. plot_trunc_methods(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns, &quot;LDW-PSID1-PLUS&quot;) Figure 3.65: FIGURE B5. Figure 3.66: FIGURE B5. Figure 3.67: FIGURE B5. Figure 3.68: FIGURE B5. Figure 3.69: FIGURE B5. Figure 3.70: FIGURE B5. Figure 3.71: FIGURE B5. Figure 3.72: FIGURE B5. Figure 3.73: FIGURE B5. Figure 3.74: FIGURE B5. Figure 3.75: FIGURE B5. Figure 3.76: FIGURE B5. Figure 3.77: FIGURE B5. Figure 3.78: FIGURE B5. Figure 3.79: FIGURE B5. 3.5.4 Trimming # list trimming objects trim.cps_plus &lt;- list( original = ldw_cps_plus, ps_threshold = ldw_cps.trim_match, common_range = ldw_cps_plus.common, crump = ldw_cps_plus.crump, stuermer = ldw_cps_plus.stuermer, walker = ldw_cps_plus.walker ) trim.psid_plus &lt;- list( original = ldw_psid_plus, ps_threshold = ldw_psid.trim_match, common_range = ldw_psid_plus.common, crump = ldw_psid_plus.crump, stuermer = ldw_psid_plus.stuermer, walker = ldw_psid_plus.walker ) 3.5.4.1 SMD # compute SMDs smd_trim.cps_plus &lt;- compute_abs_smd_trim(trim.cps_plus, &quot;treat&quot;, covar) smd_trim.psid_plus &lt;- compute_abs_smd_trim(trim.psid_plus, &quot;treat&quot;, covar) 3.5.4.2 ESS # compute ESS ess_trim.cps_plus &lt;- compute_ess_trim(trim.cps_plus, &quot;treat&quot;, covar) ess_trim.psid_plus &lt;- compute_ess_trim(trim.psid_plus, &quot;treat&quot;, covar) 3.5.4.3 Visuals # visualize overlap plot_trim(trim.cps_plus, treat, covar) ## -16.1181 3.425533 ## -1.202299 0.8705262 ## -9.631567 3.741997 ## -2.335917 2.233477 ## -7.250275 -2.186822 ## -9.93813 -2.116352 Figure 3.80: FIGURE B6. plot_trim(trim.psid_plus, treat, covar) ## -11.65343 7.149751 ## -0.7942771 0.5238475 ## -5.989901 4.08461 ## -1.995755 3.016909 ## -3.356205 -1.192685 ## -4.061815 -1.287922 Figure 3.81: FIGURE B6. # visualize covariate balance love.plot(ldw_cps, ldw_cps.trim_match, treat, covar = covar, title = &quot;LDW-CPS1-PLUS - propensity threshold trimming&quot;) Figure 3.82: FIGURE B7. love.plot(ldw_cps_plus, ldw_cps_plus.common, treat, covar, title = &quot;LDW-CPS1-PLUS - common range trimming&quot;) Figure 3.83: FIGURE B7. love.plot(ldw_cps_plus, ldw_cps_plus.crump, treat, covar, title = &quot;LDW-CPS1-PLUS - crump trimming&quot;) Figure 3.84: FIGURE B7. love.plot(ldw_cps_plus, ldw_cps_plus.stuermer, treat, covar, title = &quot;LDW-CPS1-PLUS - stuermer trimming&quot;) Figure 3.85: FIGURE B7. love.plot(ldw_cps_plus, ldw_cps_plus.walker, treat, covar, title = &quot;LDW-CPS1-PLUS - walker trimming&quot;) Figure 3.86: FIGURE B7. love.plot(ldw_psid, ldw_psid.trim_match, treat, covar = covar, title = &quot;LDW-PSID1-PLUS - propensity threshold trimming&quot;) Figure 3.87: FIGURE B7. love.plot(ldw_psid_plus, ldw_psid_plus.common, treat, covar, title = &quot;LDW-PSID1-PLUS - common range trimming&quot;) Figure 3.88: FIGURE B7. love.plot(ldw_psid_plus, ldw_psid_plus.crump, treat, covar, title = &quot;LDW-PSID1-PLUS - crump trimming&quot;) Figure 3.89: FIGURE B7. love.plot(ldw_psid_plus, ldw_psid_plus.stuermer, treat, covar, title = &quot;LDW-PSID1-PLUS - stuermer trimming&quot;) Figure 3.90: FIGURE B7. love.plot(ldw_psid_plus, ldw_psid_plus.walker, treat, covar, title = &quot;LDW-PSID1-PLUS - walker trimming&quot;) Figure 3.91: FIGURE B7. 3.6 Integrated methods # list all combined method results comb_meth.cps_plus &lt;- list( ipw = ipw_comb.cps_plus, smr_treated = smr_treat_comb.cps_plus, overlap = ov_comb.cps_plus, entropy = entropy_comb.cps_plus ) comb_meth.psid_plus &lt;- list( ipw = ipw_comb.psid_plus, smr_treated = smr_treat_comb.psid_plus, overlap = ov_comb.psid_plus, entropy = entropy_comb.psid_plus ) 3.6.0.1 SMD # compute SMD smd_all_comb_meth.cps_plus &lt;- compute_smd_all_datasets(comb_meth.cps_plus, &quot;treat&quot;, covar) smd_all_comb_meth.psid_plus &lt;- compute_smd_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 3.6.0.2 ESS # compute ESS ess_all_comb_meth.cps_plus &lt;- compute_ess_all_datasets(comb_meth.cps_plus, &quot;treat&quot;, covar) ess_all_comb_meth.psid_plus &lt;- compute_ess_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 3.6.0.3 Visuals # visualize overlap plot_comb_overlap(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) ## -13.48501 2.305571 ## -8.874661 3.659497 ## -7.861866 -2.176737 ## -9.05304 -2.081006 Figure 3.92: FIGURE B8. ## -2.289938 2.23231 ## -13.48501 2.305571 ## -8.874661 3.659497 ## -7.861866 -2.176737 Figure 3.93: FIGURE B8. ## -9.05304 -2.081006 ## -2.289938 2.23231 ## -13.48501 2.305571 ## -8.874661 3.659497 Figure 3.94: FIGURE B8. ## -7.861866 -2.176737 ## -9.05304 -2.081006 ## -2.289938 2.23231 ## -13.48501 2.305571 Figure 3.95: FIGURE B8. ## -8.874661 3.659497 ## -7.861866 -2.176737 ## -9.05304 -2.081006 ## -2.289938 2.23231 Figure 3.96: FIGURE B8. ## -10.38834 0.9649936 ## -5.718524 4.135585 ## -3.513045 -1.212378 ## -3.83598 -1.315594 Figure 3.97: FIGURE B8. ## -1.985899 2.972557 ## -10.38834 0.9649936 ## -5.718524 4.135585 ## -3.513045 -1.212378 Figure 3.98: FIGURE B8. ## -3.83598 -1.315594 ## -1.985899 2.972557 ## -10.38834 0.9649936 ## -5.718524 4.135585 Figure 3.99: FIGURE B8. ## -3.513045 -1.212378 ## -3.83598 -1.315594 ## -1.985899 2.972557 ## -10.38834 0.9649936 Figure 3.100: FIGURE B8. ## -5.718524 4.135585 ## -3.513045 -1.212378 ## -3.83598 -1.315594 ## -1.985899 2.972557 Figure 3.101: FIGURE B8. # visualize covariate balance plot_comb_love_plots(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) Figure 3.102: FIGURE B9. Figure 3.103: FIGURE B9. Figure 3.104: FIGURE B9. Figure 3.105: FIGURE B9. Figure 3.106: FIGURE B9. Figure 3.107: FIGURE B9. Figure 3.108: FIGURE B9. Figure 3.109: FIGURE B9. Figure 3.110: FIGURE B9. Figure 3.111: FIGURE B9. Figure 3.112: FIGURE B9. Figure 3.113: FIGURE B9. Figure 3.114: FIGURE B9. Figure 3.115: FIGURE B9. Figure 3.116: FIGURE B9. Figure 3.117: FIGURE B9. Figure 3.118: FIGURE B9. Figure 3.119: FIGURE B9. Figure 3.120: FIGURE B9. Figure 3.121: FIGURE B9. Figure 3.122: FIGURE B9. Figure 3.123: FIGURE B9. Figure 3.124: FIGURE B9. Figure 3.125: FIGURE B9. Figure 3.126: FIGURE B9. Figure 3.127: FIGURE B9. Figure 3.128: FIGURE B9. Figure 3.129: FIGURE B9. Figure 3.130: FIGURE B9. Figure 3.131: FIGURE B9. Figure 3.132: FIGURE B9. Figure 3.133: FIGURE B9. Figure 3.134: FIGURE B9. Figure 3.135: FIGURE B9. Figure 3.136: FIGURE B9. Figure 3.137: FIGURE B9. Figure 3.138: FIGURE B9. Figure 3.139: FIGURE B9. Figure 3.140: FIGURE B9. Figure 3.141: FIGURE B9. # save results save_comb_hist(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix = &quot;model_b&quot;) save_comb_loveplots(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix = &quot;model_b&quot;) 3.6.1 Top methods and datasets # combine all results all_cps_plus &lt;- combine_results(&quot;cps_plus&quot;) all_psid_plus &lt;- combine_results(&quot;psid_plus&quot;) # save results save_csv(all_cps_plus, &quot;CPS1_PLUS_all_results_model_b&quot;) save_csv(all_psid_plus, &quot;PSID1_PLUS_all_results_model_b&quot;) # rank methods ranked_cps_plus &lt;- assess_methods(all_cps_plus) ranked_psid_plus &lt;- assess_methods(all_psid_plus) # get top 5 methods top5_methods.cps_plus &lt;- get_top_methods(ranked_cps_plus, top_n = 5) top5_methods.psid_plus &lt;- get_top_methods(ranked_psid_plus, top_n = 5) # print results top5_methods_df.cps_plus &lt;- ranked_cps_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid_plus &lt;- ranked_psid_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps_plus, caption = &quot;Top 5 Methods for CPS1-PLUS&quot;, booktabs = TRUE) Table 3.4: Top 5 Methods for CPS1-PLUS Method Score mahvars 0.7340485 card 0.7325957 overlap_crump 0.7101653 ps_threshold 0.6939340 optimal_pair 0.6896214 knitr::kable(top5_methods_df.psid_plus, caption = &quot;Top 5 Methods for PSID1-PLUS&quot;, booktabs = TRUE) Table 3.4: Top 5 Methods for PSID1-PLUS Method Score card 0.7566410 mahvars 0.7461287 ps_threshold 0.7267397 fix_max_value_trunc_overlap_weight 0.7235709 overlap_weight 0.7235709 # save results save_csv(top5_methods.cps_plus, &quot;CPS1_PLUS_top5_methods_model_b&quot;) save_csv(top5_methods.psid_plus, &quot;PSID1_PLUS_top5_methods_model_b&quot;) dataset_list_cps &lt;- list( &quot;All&quot; = ldw_cps_plus, &quot;original&quot; = ldw_cps_plus, &quot;nn&quot; = m.out.cps_plus.nearest, &quot;caliper&quot; = m.out.cps_plus.caliper, &quot;card&quot; = m.out.cps_plus.card, &quot;cem&quot; = m.out.cps_plus.cem, &quot;cS&quot; = m.out.cps_plus.cs, &quot;k2&quot; = m.out.cps_plus.k2, &quot;k3&quot; = m.out.cps_plus.k3, &quot;mahvars&quot; = m.out.cps_plus.mahvars, &quot;optimal_full&quot; = m.out.cps_plus.optimal_full, &quot;optimal_pair&quot; = m.out.cps_plus.optimal_pair, &quot;gen_full&quot; = m.out.cps_plus.general_full, &quot;genetic&quot; = m.out.cps_plus.genetic, &quot;exact&quot; = m.out.cps_plus.exact, &quot;subcl&quot; = m.out.cps_plus.subcl, &quot;profile&quot; = m.out.cps_plus.profile, &quot;ipw_weight&quot; = ldw_cps_plus$ipw_weight, &quot;smr_weight&quot; = ldw_cps_plus$smr_weight, &quot;opt_weight&quot; = ldw_cps_plus$opt_weight, &quot;overlap_weight&quot; = ldw_cps_plus$overlap_weight, &quot;ebal_weight&quot; = ldw_cps_plus$ebal_weight, &quot;fix_max_value_trunc_ebal_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_ipw_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_opt_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_overlap_weight&quot; = ldw_cps_plus.fixed, &quot;fix_max_value_trunc_smr_weight&quot; = ldw_cps_plus.fixed, &quot;at_perc_trunc_ebal_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_ipw_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_opt_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_overlap_weight&quot; = ldw_cps_plus.percent, &quot;at_perc_trunc_smr_weight&quot; = ldw_cps_plus.percent, &quot;adap_weight_trunc_ebal_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_ipw_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_opt_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_overlap_weight&quot; = ldw_cps_plus.adapt, &quot;adap_weight_trunc_smr_weight&quot; = ldw_cps_plus.adapt, &quot;ps_threshold&quot; = ldw_cps.trim_match, &quot;common_range&quot; = ldw_cps_plus.common, &quot;stuermer&quot; = ldw_cps_plus.stuermer, &quot;walker&quot; = ldw_cps_plus.walker, &quot;crump&quot; = ldw_cps_plus.crump, &quot;ipw_common_range&quot; = ipw_comb.cps_plus[[1]], &quot;ipw_crump&quot; = ipw_comb.cps_plus[[2]], &quot;ipw_ps_threshold&quot; = ipw_comb.cps_plus[[3]], &quot;ipw_stuermer&quot; = ipw_comb.cps_plus[[4]], &quot;ipw_walker&quot; = ipw_comb.cps_plus[[5]], &quot;smr_treated_common_range&quot; = smr_treat_comb.cps_plus[[1]], &quot;smr_treated_crump&quot; = smr_treat_comb.cps_plus[[2]], &quot;smr_treated_ps_threshold&quot; = smr_treat_comb.cps_plus[[3]], &quot;smr_treated_stuermer&quot; = smr_treat_comb.cps_plus[[4]], &quot;smr_treated_walker&quot; = smr_treat_comb.cps_plus[[5]], &quot;overlap_common_range&quot; = ov_comb.cps_plus[[1]], &quot;overlap_crump&quot; = ov_comb.cps_plus[[2]], &quot;overlap_ps_threshold&quot; = ov_comb.cps_plus[[3]], &quot;overlap_stuermer&quot; = ov_comb.cps_plus[[4]], &quot;overlap_walker&quot; = ov_comb.cps_plus[[5]], &quot;entropy_common_range&quot; = entropy_comb.cps_plus[[1]], &quot;entropy_crump&quot; = entropy_comb.cps_plus[[2]], &quot;entropy_ps_threshold&quot; = entropy_comb.cps_plus[[3]], &quot;entropy_stuermer&quot; = entropy_comb.cps_plus[[4]], &quot;entropy_walker&quot; = entropy_comb.cps_plus[[5]]) dataset_list_psid &lt;- list( &quot;All&quot; = ldw_psid_plus, &quot;original&quot; = ldw_psid_plus, &quot;nn&quot; = m.out.psid_plus.nearest, &quot;caliper&quot;= m.out.psid_plus.caliper, &quot;card&quot; = m.out.psid_plus.card, &quot;cem&quot; = m.out.psid_plus.cem, &quot;cS&quot; = m.out.psid_plus.cs, &quot;k2&quot; = m.out.psid_plus.k2, &quot;k3&quot; = m.out.psid_plus.k3, &quot;mahvars&quot; = m.out.psid_plus.mahvars, &quot;optimal_full&quot; = m.out.psid_plus.optimal_full, &quot;optimal_pair&quot; = m.out.psid_plus.optimal_pair, &quot;gen_full&quot; = m.out.psid_plus.general_full, &quot;genetic&quot; = m.out.psid_plus.genetic, &quot;exact&quot; = m.out.psid_plus.exact, &quot;subcl&quot; = m.out.psid_plus.subcl, &quot;profile&quot; = m.out.psid_plus.profile, &quot;ipw_weight&quot; = ldw_psid_plus$ipw_weight, &quot;smr_weight&quot; = ldw_psid_plus$smr_weight, &quot;opt_weight&quot; = ldw_psid_plus$opt_weight, &quot;overlap_weight&quot; = ldw_psid_plus$overlap_weight, &quot;ebal_weight&quot; = ldw_psid_plus$ebal_weight, &quot;fix_max_value_trunc_ebal_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_ipw_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_opt_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_overlap_weight&quot; = ldw_psid_plus.fixed, &quot;fix_max_value_trunc_smr_weight&quot; = ldw_psid_plus.fixed, &quot;at_perc_trunc_ebal_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_ipw_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_opt_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_overlap_weight&quot; = ldw_psid_plus.percent, &quot;at_perc_trunc_smr_weight&quot; = ldw_psid_plus.percent, &quot;adap_weight_trunc_ebal_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_ipw_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_opt_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_overlap_weight&quot; = ldw_psid_plus.adapt, &quot;adap_weight_trunc_smr_weight&quot; = ldw_psid_plus.adapt, &quot;ps_threshold&quot; = ldw_psid.trim_match, &quot;common_range&quot; = ldw_psid_plus.common, &quot;stuermer&quot; = ldw_psid_plus.stuermer, &quot;walker&quot; = ldw_psid_plus.walker, &quot;crump&quot; = ldw_psid_plus.crump, &quot;ipw_common_range&quot; = ipw_comb.psid_plus[[1]], &quot;ipw_crump&quot;= ipw_comb.psid_plus[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid_plus[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid_plus[[4]], &quot;ipw_walker&quot; = ipw_comb.psid_plus[[5]], &quot;smr_treated_common_range&quot; = smr_treat_comb.psid_plus[[1]], &quot;smr_treated_crump&quot;= smr_treat_comb.psid_plus[[2]], &quot;smr_treated_ps_threshold&quot; = smr_treat_comb.psid_plus[[3]], &quot;smr_treated_stuermer&quot; = smr_treat_comb.psid_plus[[4]], &quot;smr_treated_walker&quot; = smr_treat_comb.psid_plus[[5]], &quot;overlap_common_range&quot; = ov_comb.psid_plus[[1]], &quot;overlap_crump&quot; = ov_comb.psid_plus[[2]], &quot;overlap_ps_threshold&quot; = ov_comb.psid_plus[[3]], &quot;overlap_stuermer&quot; = ov_comb.psid_plus[[4]], &quot;overlap_walker&quot;= ov_comb.psid_plus[[5]], &quot;entropy_common_range&quot; = entropy_comb.psid_plus[[1]], &quot;entropy_crump&quot; = entropy_comb.psid_plus[[2]], &quot;entropy_ps_threshold&quot; = entropy_comb.psid_plus[[3]], &quot;entropy_stuermer&quot; = entropy_comb.psid_plus[[4]], &quot;entropy_walker&quot; = entropy_comb.psid_plus[[5]]) # create datasets corresponding to the top 5 methods for each dataset top5_datasets.cps_plus &lt;- create_top5_datasets(dataset_list_cps, top5_methods.cps_plus) top5_datasets.psid_plus &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid_plus) # save datasets into .RData files save_top5_individual_files(dataset_list_cps, top5_methods.cps_plus, prefix = &quot;model_b_cps&quot;) save_top5_individual_files(dataset_list_psid, top5_methods.psid_plus, prefix = &quot;model_b_psid&quot;) 3.7 Estimating 3.7.1 Average treatment effect on the treated (ATT) # estimate ATT out1 &lt;- estimate_all(ldw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(ldw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(ldw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out4 &lt;- estimate_all(ldw_cps.trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(ldw_psid.trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out6 &lt;- out.cps_plus[[1]] out7 &lt;- out.cps_plus[[2]] out8 &lt;- out.cps_plus[[3]] out9 &lt;- out.cps_plus[[4]] out10 &lt;- out.cps_plus[[5]] out11 &lt;- out.psid_plus[[1]] out12 &lt;- out.psid_plus[[2]] out13 &lt;- out.psid_plus[[3]] out14 &lt;- out.psid_plus[[4]] out15 &lt;- out.psid_plus[[5]] # build plot titles base_titles &lt;- c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS1&quot; , &quot;(C) LDW-PSID1&quot;, &quot;(D) Trimmed LDW-CPS1 &quot;, &quot;(E) Trimmed LDW-PSID1&quot;) top_start &lt;- 6 # F is 6th letter num_cps &lt;- length(top5_methods.cps_plus) num_psid &lt;- length(top5_methods.psid_plus) top_letters_cps &lt;- LETTERS[top_start:(top_start + num_cps - 1)] top_letters_psid &lt;- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)] top5_titles.cps_plus &lt;- paste0(&quot;(&quot;, top_letters_cps, &quot;) Top CPS1: &quot;, top5_methods.cps_plus) top5_titles.psid_plus &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid_plus) plot_titles &lt;- c(base_titles, top5_titles.cps_plus, top5_titles.psid_plus) # combine all results all_outs &lt;- c(list(out1, out2, out3, out4, out5), out.cps_plus, out.psid_plus) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 3.142: FIGURE B10. ATT Estimates Model B Given Unconfoundedness using LDW Samples Figure 3.143: FIGURE B10. ATT Estimates Model B Given Unconfoundedness using LDW Samples Figure 3.144: FIGURE B10. ATT Estimates Model B Given Unconfoundedness using LDW Samples Figure 3.145: FIGURE B10. ATT Estimates Model B Given Unconfoundedness using LDW Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;model_b&quot;) As in model A, the above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, trimmed versions of the LDW-CPS1 and LDW-PSID1 samples (analogous to Imbens and Xu (2024)) and a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria. Again, figure (A) presents the benchmark, serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the LDW-CPS1 and LDW-PSID1y, while figures (D) and (E) present those for the trimmed versions. Figures (F) through (J) display results for CPS1-derived subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-derived subsamples under parallel rules. For LDW-CPS1, the top-ranked subsamples are derived with the same methods as in model A, though they appear in a slightly different order. However, for the LDW-PSID1, the top-ranked subsamples are based on two different methods, fix_max_value_trunc_overlap_weight and overlap_weight. Across the LDW-CPS1 and its top-ranked samples, all estimators generally yield ATT estimates that cluster near the experimental benchmark, overall slightly closer than in model A but with greater standard errors. Notable deviations from the experimental benchmark remain for the optimal_pair and overlap_crump subsamples. For LDW-PSID1 and its subsamples, the ATT estimates continue to exhibit greater dispersion and considerably larger standard errors compared to LDW-CPS1 counterpart samples, yet they lie closer to the benchmark than in model A. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 3.5: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) LDW-Experimental 673.0190 1583.55441 2228.37274 644.8183 (B) LDW-CPS1 670.8516 -8497.51615 1591.48975 10089.0059 (C) LDW-PSID1 878.2394 -15204.77742 2424.45272 17629.2301 (D) Trimmed LDW-CPS1 817.4108 943.22214 2079.09168 1135.8695 (E) Trimmed LDW-PSID1 1124.4889 -1984.81640 -726.28718 1258.5292 (F) Top CPS1: mahvars 533.9464 439.59826 878.13313 438.5349 (G) Top CPS1: card 480.2842 468.44377 1186.75803 718.3143 (H) Top CPS1: overlap_crump 479.4121 -3654.18460 536.10279 4190.2874 (I) Top CPS1: ps_threshold 817.4266 934.66402 2079.09168 1144.4277 (J) Top CPS1: optimal_pair 460.4078 -43.19702 774.12991 817.3269 (K) Top PSID1: card 912.7812 -1208.76339 38.97256 1247.7359 (L) Top PSID1: mahvars 912.7672 -2321.92141 -1320.75878 1001.1626 (M) Top PSID1: ps_threshold 1124.2991 -1984.81640 -726.28718 1258.5292 (N) Top PSID1: fix_max_value_trunc_overlap_weight 686.5378 -16253.15724 1863.97116 18117.1284 (O) Top PSID1: overlap_weight 675.2322 -16253.15724 1863.97116 18117.1284 # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) Table 3.6: ATT Estimates and SEs (A) LDW-Experimental (B) LDW-CPS1 (C) LDW-PSID1 (D) Trimmed LDW-CPS1 (E) Trimmed LDW-PSID1 (F) Top CPS1: mahvars (G) Top CPS1: card (H) Top CPS1: overlap_crump (I) Top CPS1: ps_threshold (J) Top CPS1: optimal_pair (K) Top PSID1: card (L) Top PSID1: mahvars (M) Top PSID1: ps_threshold (N) Top PSID1: fix_max_value_trunc_overlap_weight (O) Top PSID1: overlap_weight Experimental Benchmark 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) 1466.69 (827.73) -1870.71 (1183.54) 645.19 (544.37) 468.44 (467.88) -3654.18 (339.88) 1466.69 (827.73) -43.20 (438.92) -508.12 (972.27) -1966.48 (990.23) -1870.71 (1183.54) -16253.16 (442.57) -16253.16 (442.57) diff 1794.34 (670.82) -8497.52 (581.92) -15204.78 (655.91) 1466.69 (827.73) -1870.71 (1183.54) 645.19 (544.37) 468.44 (467.88) -3654.18 (339.88) 1466.69 (827.73) -43.20 (438.92) -508.12 (972.27) -1966.48 (990.23) -1870.71 (1183.54) -16253.16 (442.57) -16253.16 (442.57) reg 1605.52 (665.93) 1484.61 (631.51) 1227.70 (892.77) 1818.38 (858.86) -1609.82 (1081.50) 685.59 (521.98) 610.54 (450.71) -73.00 (406.43) 1818.38 (858.86) 439.83 (454.63) -184.58 (826.61) -1634.36 (893.10) -1609.82 (1081.50) -191.13 (720.76) -191.13 (720.76) om.reg 1709.79 (587.92) 1553.68 (621.16) 2052.84 (644.01) 1642.27 (665.91) -726.29 (966.76) 826.69 (442.69) 748.68 (383.40) 70.60 (341.86) 1642.27 (665.91) 680.25 (342.85) -46.64 (584.02) -1320.76 (739.29) -726.29 (966.76) 1116.83 (362.05) 1116.83 (362.05) om.grf 1728.97 (582.14) 1164.55 (625.47) 449.34 (636.41) 1729.56 (653.40) -1467.28 (782.27) 723.39 (435.27) 828.85 (367.12) 195.09 (343.18) 1728.14 (652.98) 429.55 (333.22) -439.68 (538.88) -1936.52 (606.72) -1410.88 (780.00) -343.91 (353.52) -380.97 (352.10) matching 1583.55 (785.15) 1591.49 (832.21) 2174.97 (1575.49) 1862.82 (979.63) -1349.74 (1230.15) 878.13 (627.58) 492.99 (647.89) 536.10 (637.64) 1862.82 (979.63) 667.85 (626.84) 38.97 (930.07) -1495.33 (973.79) -1349.74 (1230.15) 1519.05 (1274.41) 1519.05 (1274.41) psm 2228.37 (680.68) 1315.42 (723.13) 1384.63 (860.32) 943.22 (823.60) -1984.82 (1211.11) 439.60 (557.22) 1186.76 (448.82) 184.41 (423.25) 934.66 (824.20) 584.73 (418.10) -1208.76 (1154.82) -1342.83 (903.00) -1984.82 (1211.11) 1415.01 (418.97) 1384.35 (419.21) ipw 1769.67 (684.30) 1179.06 (685.01) 785.92 (929.81) 1568.81 (815.56) -1726.90 (1203.47) 645.19 (544.37) 468.44 (467.88) 203.13 (573.00) 1568.81 (815.56) -43.20 (438.92) -508.12 (972.27) -1966.48 (990.23) -1726.90 (1203.47) 556.59 (840.39) -999.49 (735.80) cbps 1699.09 (699.19) 1493.80 (652.71) 2359.12 (873.16) 1584.40 (846.33) -1608.85 (1163.08) 645.19 (544.37) 468.44 (467.88) 468.41 (461.43) 1584.40 (846.33) -43.20 (438.92) -508.12 (972.27) -1966.48 (990.23) -1608.85 (1163.08) 1366.58 (765.71) -999.49 (735.80) ebal 1701.38 (699.39) 1492.13 (652.66) 2424.45 (875.94) 1583.59 (846.23) -1507.76 (1217.52) 838.84 (552.25) 708.63 (469.88) 460.96 (461.18) 1583.59 (846.23) 569.38 (486.13) -147.82 (822.08) -1375.64 (915.57) -1507.76 (1217.52) 1863.97 (733.65) 1863.97 (733.65) dml 1831.36 (653.57) 1497.70 (632.53) 1286.02 (897.44) 2079.09 (850.38) -1774.26 (1069.88) 504.16 (509.99) 497.78 (448.06) -93.87 (407.13) 2079.09 (850.38) 467.53 (453.89) -460.17 (831.28) -1774.47 (894.17) -1774.26 (1069.88) -234.66 (716.61) -234.66 (716.61) aipw_grf 1780.89 (685.02) 1574.79 (724.51) 1490.48 (896.92) 1861.88 (808.74) -1565.14 (1177.20) 668.51 (561.49) 861.70 (610.18) 469.64 (681.16) 1861.88 (808.74) 727.02 (580.50) -881.70 (1267.75) -2162.17 (1032.69) -1565.14 (1177.20) 862.81 (799.17) 862.81 (799.17) aipw_ow 1848.58 (682.11) 1471.91 (687.41) 1234.26 (800.69) 1919.42 (832.56) -1267.56 (1207.37) 605.82 (565.80) 876.00 (533.71) 250.64 (676.80) 1919.42 (832.56) 774.13 (511.99) -286.38 (1081.05) -2321.92 (1024.19) -1267.56 (1207.37) 1191.13 (810.65) 1191.13 (810.65) As in model A, the tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. In model B, most LDW-CPS1-based samples yield ATT estimates that are closer to the experimental benchmark than in model A, with still modest variance. By contrast, the LDW-PSID1-based estimates, while somewhat closer to the experimental benchmark than in model A, continue to exhibit substantially larger standard errors compared to LDW-CPS1 samples. This again reflects the greater challenge of obtaining reliable estimates from the observational dataset LDW-PSID1. Overall, figures and table jointly demonstrate again that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;LDW_att_estimates_model_b&quot;) 3.7.2 Conditional average treatment effect on the treated (CATT) catt.ldw &lt;- catt(ldw, Y, treat, covar) catt.cps &lt;- catt(ldw_cps, Y, treat, covar) catt.psid &lt;- catt(ldw_psid, Y, treat, covar) catt.cps.trim &lt;- catt(ldw_cps.trim_match, Y, treat, covar) catt.psid.trim &lt;- catt(ldw_psid.trim_match, Y, treat, covar) catt.top5_cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) catt(d, Y, treat, covar)) catt.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) catt(d, Y, treat, covar)) # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim), catt.top5_cps_plus, catt.top5_psid_plus) # plot results par(mfrow = c(2,2)) par(cex.main = 0.8) plot_catt_panels(all_catt, plot_titles) Figure 3.146: FIGURE B11. CATT Estimates Model B using LDW Data Figure 3.147: FIGURE B11. CATT Estimates Model B using LDW Data Figure 3.148: FIGURE B11. CATT Estimates Model B using LDW Data Figure 3.149: FIGURE B11. CATT Estimates Model B using LDW Data all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 3.7: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) LDW-Experimental -213.9356 3858.5191 1720.1321 4072.455 (B) LDW-CPS1 -3868.5404 7128.4156 2169.8052 10996.956 (C) LDW-PSID1 -6772.1633 5032.3073 593.8834 11804.471 (D) Trimmed LDW-CPS1 -1548.4886 5299.3447 1746.5441 6847.833 (E) Trimmed LDW-PSID1 -3911.5664 557.3922 -1467.0941 4468.959 (F) Top CPS1: mahvars -2308.6089 4128.6433 636.0073 6437.252 (G) Top CPS1: card -3981.2823 4269.0121 897.5851 8250.294 (H) Top CPS1: overlap_crump -4888.8762 5634.4060 935.1903 10523.282 (I) Top CPS1: ps_threshold -1361.5987 5460.5305 1793.2761 6822.129 (J) Top CPS1: optimal_pair -4515.6099 4414.3269 726.3378 8929.937 (K) Top PSID1: card -2952.3256 3028.1330 -761.4534 5980.459 (L) Top PSID1: mahvars -6005.6110 1398.3316 -2155.7605 7403.943 (M) Top PSID1: ps_threshold -4008.2637 531.1040 -1516.6311 4539.368 (N) Top PSID1: fix_max_value_trunc_overlap_weight -7141.8467 3588.1338 -256.5465 10729.980 (O) Top PSID1: overlap_weight -7056.8100 3637.3123 -421.8611 10694.122 In model B, using LDW-CPS1, the CATT estimates range from $-3,868.54 to $7,128.42. This span is considerably narrower than in model A, but still performs worse when contrasted with the experimental benchmark, where CATT estimates range from $-213.93 to $3,858.52 with a mean of $1,720.13. The experimental mean CATT estimate remains closer to its corresponding ATT estimate than in model A. Further, LDW-PSID1 shows a narrower CATT estimate range, from $-6,772.16 to $5,032.31, compared to LDW-CPS1 and model A, with a mean CATT estimate of about $557.39, which deviates further from the experimental benchmark, indicating poorer performance. For trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary considerably, yet the mean estimates are generally closer to the experimental benchmark, as in model A. Moreover, the minimum CATT estimates are less negative, which reduces the spread between minimum and maximum estimates. Top-ranked LDW-PSID1 subsamples, on the other hand, again yield more negative mean CATT estimates and wider ranges compared to their LDW-CPS1 counterparts, signaling persistent difficulties in generating reliable effect estimates. Still, compared to model A, the minimum CATT estimates are less strongly negative, though the mean CATTs only improve marginally in their proximity to the experimental benchmark. Hence, alike model A, these results show that the variation in ranges and means across methods and samples reflects substantial heterogeneity in treatment effect estimation. While certain criteria may improve consistency with experimental benchmarks, they may also introduce notable discrepancies and variability in estimated heterogeneous effects. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;model_b&quot;) 3.7.3 Quantile treatment effect on the treated (QTET) qte.ldw &lt;- est_qte(Y, treat, covar, data = ldw, cores = 4) qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) qte.ldw_cps.trimm &lt;- est_qte(Y, treat, covar, data = ldw_cps.trim_match) qte.ldw_psid.trimm &lt;- est_qte(Y, treat, covar, data = ldw_psid.trim_match) qte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps_trim) qte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid_trim) qte.top5_cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, covar, data = d)) qte.ldw0 &lt;- est_qte(Y, treat, NULL, data = ldw) qte.ldw.cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) qte.ldw.psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) qte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps.trim_match) qte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid.trim_match) qte.top5_cps_plus0 &lt;- lapply(top5_datasets.cps_plus, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid_plus0 &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, NULL, data = d)) par(mfrow = c(2,2)) par(cex.main = 0.8) # CPS plot_qte(qte.ldw_cps, qte.ldw.cps0, qte.ldw, main = &quot;(B) LDW-CPS&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID plot_qte(qte.ldw_psid, qte.ldw.psid0, qte.ldw, main = &quot;(C) LDW-PSID&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) ## CPS trimmed plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.ldw_cps, main = &quot;(D) LDW-CPS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID trimmed plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.ldw_psid, main = &quot;(E) LDW-PSID (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 3.150: FIGURE B12. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental # CPS top methods plot_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.ldw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000)) Figure 3.151: FIGURE B12. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental # PSID top methods plot_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.ldw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000)) Figure 3.152: FIGURE B12. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental Figure 3.153: FIGURE B12. QTET Estimates Model B using LDW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the experimental and various non-experimental samples. Compared to model A, the QTET results of all samples closely resemble those of their respective counterparts. The QTETs estimated from the original and trimmed LDW-CPS1 sample continue to correspond well with the true QTET, although the estimates often suffer from low power. The QTET estimates from the original and trimmed LDW-PSID1 subsample show clear biases when compared to the experimental benchmark, which clusters near zero. The QTET estimates derived from the top-ranked subsamples of LDW-CPS1 (F - J) track the true experimental effect well. In contrast, the top-ranked subsamples of LDW-PSID1-based produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty. # list results plots_ldw &lt;- list( list(mod = qte.ldw_cps, mod0 = qte.ldw.cps0, bm = qte.ldw, main = &quot;(A) LDW CPS1&quot;), list(mod = qte.ldw_psid, mod0 = qte.ldw.psid0, bm = qte.ldw, main = &quot;(B) LDW PSID1&quot;), list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.ldw_cps, main = &quot;(C) LDW CPS1 (Trimmed)&quot;), list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.ldw_psid, main = &quot;(D) LDW PSID1 (Trimmed)&quot;) ) # save results save_qtet(plots_ldw, prefix = &quot;ldw_model_b&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.ldw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000), prefix = &quot;ldw_model_b_top&quot;) save_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.ldw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000), prefix = &quot;ldw_model_b_top&quot;) 3.7.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c( list(ldw, ldw_cps, ldw_psid, ldw_cps.trim_match, ldw_psid.trim_match), top5_datasets.cps_plus, top5_datasets.psid_plus ) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 3.154: FIGURE B13. Outcome Weights Model B using LDW Data Figure 3.155: FIGURE B13. Outcome Weights Model B using LDW Data Figure 3.156: FIGURE B13. Outcome Weights Model B using LDW Data Figure 3.157: FIGURE B13. Outcome Weights Model B using LDW Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat_var = treat, estimator = &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 3.8: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) LDW-Experimental 1 -1 (B) LDW-CPS1 1 -1 (C) LDW-PSID1 1 -1 (D) Trimmed LDW-CPS1 1 -1 (E) Trimmed LDW-PSID1 1 -1 (F) Top CPS1: mahvars 1 -1 (G) Top CPS1: card 1 -1 (H) Top CPS1: overlap_crump 1 -1 (I) Top CPS1: ps_threshold 1 -1 (J) Top CPS1: optimal_pair 1 -1 (K) Top PSID1: card 1 -1 (L) Top PSID1: mahvars 1 -1 (M) Top PSID1: ps_threshold 1 -1 (N) Top PSID1: fix_max_value_trunc_overlap_weight 1 -1 (O) Top PSID1: overlap_weight 1 -1 #save results save_ow(ow_att, plot_titles, prefix = &quot;model_b&quot;) In model B, the evaluation once again confirms that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. 3.8 Validation through placebo analyses # define variables Y_pl &lt;- &quot;re75&quot; treat &lt;- &quot;treat&quot; covar_pl &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;u74&quot;) # estimate placebo ATT on original and observational datasets out1_pl &lt;- estimate_all(ldw, Y_pl, &quot;treat&quot;, covar_pl) out2_pl &lt;- estimate_all(ldw_cps, Y_pl, &quot;treat&quot;, covar_pl) out3_pl &lt;- estimate_all(ldw_psid, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on trimmed datasets out4_pl &lt;- estimate_all(ldw_cps.trim_match, Y_pl, &quot;treat&quot;, covar_pl) out5_pl &lt;- estimate_all(ldw_psid.trim_match, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on top ranked datasets out.cps_pl &lt;- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out.psid_pl &lt;- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out6_pl &lt;- out.cps_pl[[1]] out7_pl &lt;- out.cps_pl[[2]] out8_pl &lt;- out.cps_pl[[3]] out9_pl &lt;- out.cps_pl[[4]] out10_pl &lt;- out.cps_pl[[5]] out11_pl &lt;- out.psid_pl[[1]] out12_pl &lt;- out.psid_pl[[2]] out13_pl &lt;- out.psid_pl[[3]] out14_pl &lt;- out.psid_pl[[4]] out15_pl &lt;- out.psid_pl[[5]] # collect all placebo results all_outs.pl &lt;- c(list(out1_pl, out2_pl, out3_pl, out4_pl, out5_pl), out.cps_pl, out.psid_pl) # plot placebo results band_pl &lt;- out1_pl[1, 3:4] est_pl &lt;- out1_pl[1, 1] ylim_pl = c(-15500, 5500) plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.7) Figure 3.158: FIGURE B14. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.159: FIGURE B14. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.160: FIGURE B14. Placebo Test Model B: ’75 Earnings as the Outcome Figure 3.161: FIGURE B14. Placebo Test Model B: ’75 Earnings as the Outcome # save results save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, &quot;model_b_placebo&quot;) # print placebo results result_mat_pl &lt;- create_matrix_results(all_outs.pl, plot_titles) knitr::kable(result_mat_pl, booktabs = TRUE, caption = &quot;Placebo ATT Estimates and SEs&quot;) Table 3.9: Placebo ATT Estimates and SEs (A) LDW-Experimental (B) LDW-CPS1 (C) LDW-PSID1 (D) Trimmed LDW-CPS1 (E) Trimmed LDW-PSID1 (F) Top CPS1: mahvars (G) Top CPS1: card (H) Top CPS1: overlap_crump (I) Top CPS1: ps_threshold (J) Top CPS1: optimal_pair (K) Top PSID1: card (L) Top PSID1: mahvars (M) Top PSID1: ps_threshold (N) Top PSID1: fix_max_value_trunc_overlap_weight (O) Top PSID1: overlap_weight Experimental Benchmark 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -847.26 (473.39) -362.39 (683.79) -78.07 (308.25) -293.01 (252.28) -4459.43 (186.69) -847.26 (473.39) -556.64 (229.22) -312.26 (457.85) -500.39 (639.19) -362.39 (683.79) -17686.20 (310.72) -17686.20 (310.72) diff 265.15 (305.00) -12118.75 (247.18) -17531.28 (360.60) -847.26 (473.39) -362.39 (683.79) -78.07 (308.25) -293.01 (252.28) -4459.43 (186.69) -847.26 (473.39) -556.64 (229.22) -312.26 (457.85) -500.39 (639.19) -362.39 (683.79) -17686.20 (310.72) -17686.20 (310.72) reg 224.34 (218.33) -1134.82 (272.44) -2757.40 (589.02) -579.29 (337.91) 421.22 (575.36) -211.99 (226.20) -478.10 (200.56) -2970.16 (224.50) -579.29 (337.91) -264.44 (186.82) -446.49 (387.79) -224.36 (472.91) 421.22 (575.36) -3006.44 (512.93) -3006.44 (512.93) om.reg 165.70 (284.98) -1096.70 (395.18) -2640.76 (367.46) -571.89 (363.79) 636.51 (604.23) -347.81 (294.63) -698.16 (238.12) -3001.18 (236.43) -571.89 (363.79) -502.54 (211.06) -537.13 (393.35) -275.36 (559.38) 636.51 (604.23) -2717.06 (248.87) -2717.06 (248.87) om.grf 97.01 (285.10) -1590.61 (373.01) -4290.47 (343.87) -551.44 (315.66) 184.01 (545.99) -99.82 (257.70) -431.18 (203.37) -1537.40 (240.74) -514.10 (314.25) -349.92 (186.32) 20.09 (383.85) -214.87 (512.55) 143.40 (545.41) -4495.00 (231.08) -4497.15 (231.51) matching 148.67 (227.58) -1465.93 (351.78) -1913.65 (805.37) -692.30 (329.36) 448.28 (582.18) -247.45 (236.55) -717.15 (279.17) -1545.60 (303.44) -692.30 (329.36) -739.24 (258.12) -171.76 (491.09) -210.91 (499.96) 448.28 (582.18) -1931.45 (856.38) -1931.45 (856.38) psm 106.02 (315.01) -1335.04 (425.34) -2792.68 (496.82) -765.63 (441.19) -111.65 (628.64) -138.09 (299.56) -485.45 (252.19) -1336.28 (254.39) -774.62 (442.17) -232.52 (204.04) 29.31 (427.60) 280.29 (575.27) -111.65 (628.64) -2451.49 (302.97) -2475.85 (301.36) ipw 160.63 (311.24) -1515.20 (334.86) -3151.45 (739.64) -660.70 (443.29) -11.78 (664.53) -78.07 (308.25) -293.01 (252.28) -1449.94 (319.23) -660.70 (443.29) -556.64 (229.22) -312.26 (457.85) -500.39 (639.19) -11.78 (664.53) -2348.05 (863.84) -0.00 (567.47) cbps 188.34 (304.79) -1227.83 (297.89) -2282.31 (834.92) -586.85 (440.58) 281.73 (657.31) -78.07 (308.25) -293.01 (252.28) -1346.75 (244.50) -586.85 (440.58) -556.64 (229.22) -312.26 (457.85) -500.39 (639.19) 281.73 (657.31) -2375.70 (946.53) -0.00 (567.47) ebal 189.20 (304.71) -1228.49 (297.88) -2250.80 (842.15) -578.03 (439.98) 617.65 (666.91) -373.04 (432.04) -670.12 (319.54) -1335.99 (243.98) -578.03 (439.98) -453.47 (283.66) -474.30 (496.79) -273.10 (625.31) 617.65 (666.91) -2227.14 (899.13) -2227.14 (899.13) dml 275.69 (231.57) -1152.96 (271.75) -2725.28 (591.57) -543.31 (343.84) 358.82 (537.73) -205.84 (232.47) -459.54 (203.06) -2978.69 (224.74) -543.31 (343.84) -270.86 (186.59) -432.11 (381.93) -212.57 (487.08) 358.82 (537.73) -2964.43 (510.26) -2964.43 (510.26) aipw_grf 83.05 (228.21) -1249.88 (264.79) -2419.46 (623.46) -544.18 (336.76) 191.04 (550.63) -120.99 (239.04) -461.72 (265.73) -1323.05 (242.39) -544.18 (336.76) -502.96 (243.34) 12.65 (374.71) -233.17 (475.60) 191.04 (550.63) -2064.82 (739.78) -2064.82 (739.78) aipw_ow 108.01 (233.22) -1318.36 (276.40) -2904.04 (648.78) -619.91 (378.14) 373.00 (591.94) -88.51 (246.40) -427.89 (298.28) -1319.86 (234.72) -619.91 (378.14) -449.75 (209.85) 56.70 (373.96) -99.92 (477.81) 373.00 (591.94) -2019.02 (1072.53) -2019.02 (1072.53) The placebo analysis shows that the experimental benchmarks remain close to zero and statistically insignificant, closely mirroring the results in model A. The results for LDW-CPS1 and LDW-PSID1 are identical to those observed in model A. For LDW-CPS1 samples (B and F through J), ATT estimates remain consistently negative. The overlap_crump estimates show modest improvement toward the benchmark compared to LDW-CPS1 (B) results, but also yields notably worse estimates for certain estimators. Further gains are observed with the trimmed sample (D), ps_threshold (I), card (G) and optimal_pair. The mahvars (G) sample performs best, producing ATT estimates closest to the experimental results. However, compared to model A, no clear pattern emerges: some methods perform better, while others produce poorer estimates. For LDW-PSID1, the sample (O) applying fix_max_value_truncation_overlap_weight shows some improvement relative to the PSID1 sample (C), though it also produces worse results for certain estimators. A similar pattern holds for the overlap_weight sample. The card (K), mahvars (L), trimmed sample (E) and theps_threshold (M) further reduce discrepancies, drawing estimates closer to the experimental benchmark results. Still, their performance not markedly surpass that of model A. Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis continues to reveal substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underscores the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings. # save results save_csv(result_mat_pl, &quot;LDW_att_estimates_pl_model_b&quot;) 3.9 Validation through sensitivity analyses # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets datasets_sens &lt;- c(list(ldw, ldw_cps, ldw_psid), top5_datasets.cps_plus, top5_datasets.psid_plus) filtered_datasets_sens &lt;- check_filter_datasets(datasets_sens, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx]) } Figure 3.162: FIGURE 15. Sensitivity Analyses Model B Figure 3.163: FIGURE 15. Sensitivity Analyses Model B Figure 3.164: FIGURE 15. Sensitivity Analyses Model B Figure 3.165: FIGURE 15. Sensitivity Analyses Model B # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;model_b&quot;) The sensitivity analysis demonstrates identical results for LDW-Experimental, LDW-CPS1 and LDW-PSID1 as in model A and indicates once again that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of re75. However, compared to Model A, these estimates tend to shift upwards, exhibiting somewhat more positive values across variants. 3.10 Summary After reexamining model B, which uses the LaLonde-Dehejia-Wahba (LDW) data with a revised set of covariates, we find that changing the covariate set leads to noticeable shifts in effect estimates. For CPS-1, estimates are generally more consistent and remain close to the experimental benchmark, though standard errors are somewhat larger than in model A. In contrast, PSID-1 continues to show greater dispersion and substantially larger standard errors, highlighting persistent challenges with this observational sample. Conditional and quantile treatment effect analyses confirm that, while some methods bring estimates closer to the experimental benchmark, considerable heterogeneity and estimator-dependent variability remain. Placebo tests using pre-treatment earnings as the outcome reveal that, despite some improvements, bias and deviation from the true effect persist. Sensitivity analyses indicate that most treatment effect estimates are fairly robust to increasing confounder strength, but some upward shifts are observed compared to model A. Overall, these results reinforce the importance of overlap, covariate balance, and careful method selection, while underscoring the ongoing difficulty of recovering unbiased causal effects from observational data. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["lalonde-nsw-data.html", "Chapter 4 LaLonde (NSW) Data 4.1 Set up 4.2 NSW 4.3 Improving primarily covariate balance 4.4 Improving primarily overlap 4.5 Reassessing methods 4.6 Integrated methods 4.7 Estimating 4.8 Validation through sensitivity analyses 4.9 Summary", " Chapter 4 LaLonde (NSW) Data This section (4) examines the effect of the treatment (participation in the job training program) on the participants’ earnings in 1978 (re78) in the original LaLonde dataset (loaded as nsw, similar to Imbens &amp; Xu). For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only explain the nsw–specific results. 4.1 Set up 4.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 4.1.2 Load and preprocess data treat &lt;- &quot;treat&quot; nsw_co$treat &lt;- 1 # drop re74, u74, tau from CPS1 and PSID1 and merge data cps1a &lt;- subset(cps1, select = -c(re74, u74)) nsw_cps &lt;- rbind.data.frame(nsw_tr, cps1a) psid1a &lt;- subset(psid1, select = -c(re74, u74)) nsw_psid &lt;- rbind.data.frame(nsw_tr, psid1a) nsw_cps_plus &lt;- rbind.data.frame(nsw_cps, nsw_co) nsw_psid_plus &lt;- rbind.data.frame(nsw_psid, nsw_co) 4.1.3 Inspect data # collect datasets in a list data &lt;- list(nsw = nsw, nsw_cps = nsw_cps, nsw_psid = nsw_psid, nsw_cps_plus = nsw_cps_plus, nsw_psid_plus = nsw_psid_plus) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 4.1: Summary Statistics dataset num_obs num_vars name_vars nsw 722 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_cps 16289 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_psid 2787 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_cps_plus 16714 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample nsw_psid_plus 3212 12 data_id, treat, age, education, black, hispanic, married, nodegree, re75, re78, u75, sample 4.2 NSW # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u75&quot;) 4.2.1 Assessing overlap and covariate balance 4.2.1.1 Overlap # assess overlap nsw.ps &lt;- assess_overlap(data = nsw, treat = treat, cov = covar) ## -1.375215 0.6394217 Figure 4.1: FIGURE C1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. nsw_cps.ps &lt;- assess_overlap(data = nsw_cps, treat = treat, cov = covar) ## -12.49703 1.660349 Figure 4.2: FIGURE C1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. nsw_psid.ps &lt;- assess_overlap(data = nsw_psid, treat = treat, cov = covar) ## -10.70941 3.573044 Figure 4.3: FIGURE C1. SubfigureA:NSW-Experimental. SubfigureB:NSW-CPS1. SubfigureC:NSW-PSID1. As anticipated, the NSW-Experimental data exhibit an almost perfect overlap. In contrast, the observational datasets NSW-CPS1 and NSW-PSID1 display weak overlap. # assess overlap nsw_cps_plus.ps &lt;- assess_overlap(data = nsw_cps_plus, treat = treat, cov = covar) ## -11.56837 2.929738 Figure 4.4: FIGURE C1. SubfigureD:NSW-CPS1-PLUS. SubfigureE:NSW-PSID1-PLUS. nsw_psid_plus.ps &lt;- assess_overlap(data = nsw_psid_plus, treat = treat, cov = covar) ## -9.367327 6.41566 Figure 4.5: FIGURE C1. SubfigureD:NSW-CPS1-PLUS. SubfigureE:NSW-PSID1-PLUS. With the expanded datasets NSW-CPS1-PLUS and NSW-PSID1-PLUS, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater coverage of log-odds densities across both samples. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 4.2.1.2 Covariate balance love.plot(nsw, nsw_cps, treat, covar = covar, title = &quot;NSW-CPS1&quot;) Figure 4.6: FIGURE C2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. love.plot(nsw, nsw_cps_plus, treat, covar = covar, title = &quot;NSW-CPS1-PLUS&quot;) Figure 4.7: FIGURE C2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. love.plot(nsw, nsw_psid, treat, covar = covar, title = &quot;NSW-PSID1&quot;) Figure 4.8: FIGURE C2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. love.plot(nsw, nsw_psid_plus, treat, covar = covar, title = &quot;NSW-PSID1-PLUS&quot;) Figure 4.9: FIGURE C2. SubfigureA:NSW-CPS1. SubfigureB:NSW-CPS1-PLUS. SubfigureC:NSW-PSID1. SubfigureD:NSW-PSID1-PLUS. Neither NSW-CPS1-PLUS nor NSW-PSID1-PLUS shows consistently improved covariate balance compared with their non-plus counterparts based on raw standardized differences. Although some specific covariates improve slightly, most show the same or increased imbalance. In the subsequent analysis, that is focused on improving covariate balance and overlap, only the two datasets NSW-CPS1-PLUS and NSW-PSID1-PLUS are considered. The NSW-Experimental data is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 4.3 Improving primarily covariate balance 4.3.1 Matching 4.3.1.1 Distance Matching 4.3.1.1.1 1:1 Nearest neighbor matching # perform nearest neighbor matching with k=1, logistic propensity score and replacement m.out.cps_plus.nearest &lt;- matchit(model, data = nsw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) m.out.psid_plus.nearest &lt;- matchit(model, data = nsw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, replace = TRUE) 4.3.1.1.2 k:1 matching (k=2) k&lt;-2 # perform nearest neighbor matching with k=2, logistic propensity score and replacement m.out.cps_plus.k2 &lt;- matchit(model, data = nsw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid_plus.k2 &lt;- matchit(model, data = nsw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 4.3.1.1.3 k:1 matching (k=3) k&lt;-3 # perform nearest neighbor matching with k=3, logistic propensity score and replacement m.out.cps_plus.k3 &lt;- matchit(model, data = nsw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid_plus.k3 &lt;- matchit(model, data = nsw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, ratio = k, replace = TRUE) 4.3.1.1.4 Caliper matching # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score m.out.cps_plus.caliper &lt;- matchit(model, data = nsw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) m.out.psid_plus.caliper &lt;- matchit(model, data = nsw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.1, replace = TRUE) 4.3.1.1.5 Common support restriction matching # perform nearest neighbor matching with exclusion of units outside common support m.out.cps_plus.cs &lt;- matchit(model, data = nsw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, replace = TRUE) m.out.psid_plus.cs &lt;- matchit(model, data = nsw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, discard = &quot;both&quot;, replace = TRUE) 4.3.1.1.6 Mahalanobis distance matching (mahvars) # perform nearest neighbor matching using mahalanobis distance on selected covariates m.out.cps_plus.mahvars &lt;- matchit(model, data = nsw_cps_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) m.out.psid_plus.mahvars &lt;- matchit(model, data = nsw_psid_plus, method = &quot;nearest&quot;, distance = &quot;logit&quot;, caliper = 0.2, mahvars = ~ age + education + re75, replace = FALSE) 4.3.1.1.7 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.cps_plus.optimal_pair &lt;- matchit(model, data = nsw_cps_plus, method = &quot;optimal&quot;, distance = &quot;logit&quot;) m.out.psid_plus.optimal_pair &lt;- matchit(model, data = nsw_psid_plus, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 4.3.1.1.8 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.cps_plus.optimal_full &lt;- matchit(model, data = nsw_cps_plus, method = &quot;full&quot;, distance = &quot;logit&quot;) m.out.psid_plus.optimal_full &lt;- matchit(model, data = nsw_psid_plus, method = &quot;full&quot;, distance = &quot;logit&quot;) 4.3.1.1.9 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.cps_plus.general_full &lt;- matchit(model, data = nsw_cps_plus, method = &quot;quick&quot;, distance = &quot;logit&quot;) m.out.psid_plus.general_full &lt;- matchit(model, data = nsw_psid_plus, method = &quot;quick&quot;, distance = &quot;logit&quot;) 4.3.1.1.10 Genetic matching # perform genetic matching m.out.cps_plus.genetic &lt;- matchit(model, data = nsw_cps_plus, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) m.out.psid_plus.genetic &lt;- matchit(model, data = nsw_psid_plus, method = &quot;genetic&quot;, distance = &quot;logit&quot;, replace = TRUE, pop.size = 100) 4.3.1.2 Stratum matching 4.3.1.2.1 Exact matching (exact) Strata = unique covariate profiles (raw covariates) # match units exactly by raw covariate profiles m.out.cps_plus.exact &lt;- matchit(model, data = nsw_cps_plus, method = &quot;exact&quot;) m.out.psid_plus.exact &lt;- matchit(model, data = nsw_psid_plus, method = &quot;exact&quot;) 4.3.1.2.2 Coarsened matching (cem) Strata = coarsened versions of covariates # match units exactly within coarse strata m.out.cps_plus.cem &lt;- matchit(model, data = nsw_cps_plus, method = &quot;cem&quot;) m.out.psid_plus.cem &lt;- matchit(model, data = nsw_psid_plus, method = &quot;cem&quot;) 4.3.1.2.3 Subclassification Strata = bins of the propensity score # partition sample into fixed number of bins based on propensity score m.out.cps_plus.subcl &lt;- matchit(model, data = nsw_cps_plus, method = &quot;subclass&quot;, subclass = 5) m.out.psid_plus.subcl &lt;- matchit(model, data = nsw_psid_plus, method = &quot;subclass&quot;, subclass = 5) 4.3.1.3 Pure subset selection 4.3.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances m.out.cps_plus.card &lt;- matchit(model, data = nsw_cps_plus, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) m.out.psid_plus.card &lt;- matchit(model, data = nsw_psid_plus, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) 4.3.1.3.2 Profile matching # matching by directly optimizing balance profile measures across covariates m.out.cps_plus.profile &lt;- matchit_profile(nsw_cps_plus, treat, covar) m.out.psid_plus.profile &lt;- matchit_profile(nsw_psid_plus, treat, covar) 4.3.2 Weighting 4.3.2.1 Inverse probability weights (IPW) # compute weights as inverse of estimated propensity scores w.out.cps_plus.ipw &lt;- weightit(model, data = nsw_cps_plus, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.ipw &lt;- weightit(model, data = nsw_psid_plus, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) nsw_cps_plus$ipw_weight &lt;- w.out.cps_plus.ipw$weights nsw_psid_plus$ipw_weight &lt;- w.out.psid_plus.ipw$weights 4.3.2.2 Standardized mortality ratio (SMR) treated weights # calculate weights for ATT by assigning weight = 1 to treated units and weights proportional to odds of treatment for control nsw_cps_plus$smr_weight &lt;- create_smr_weights(nsw_cps_plus, model, &quot;ATT&quot;) nsw_psid_plus$smr_weight &lt;- create_smr_weights(nsw_psid_plus, model, &quot;ATT&quot;) 4.3.2.3 Matching weights # derive optimal matching weights intending to minimize covariate imbalance while targeting ATT w.out.cps_plus.opt &lt;- weightit(model, data = nsw_cps_plus, method = &quot;optweight&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.opt &lt;- weightit(model, data = nsw_psid_plus, method = &quot;optweight&quot;, estimand = &quot;ATT&quot;) nsw_cps_plus$opt_weight &lt;- w.out.cps_plus.opt$weights nsw_psid_plus$opt_weight &lt;- w.out.psid_plus.opt$weights 4.3.2.4 Overlap weights # calculate overlap weights emphasizing units with propensity scores near 0.5 nsw_cps_plus$overlap_weight &lt;- create_overlap_weights(nsw_cps_plus, model) nsw_psid_plus$overlap_weight &lt;- create_overlap_weights(nsw_psid_plus, model) 4.3.2.5 Entropy weights # compute entropy balancing weights w.out.cps_plus.ebal &lt;- weightit(model, data = nsw_cps_plus, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;) w.out.psid_plus.ebal &lt;- weightit(model, data = nsw_psid_plus, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;) nsw_cps_plus$ebal_weight &lt;- w.out.cps_plus.ebal$weights nsw_psid_plus$ebal_weight &lt;- w.out.psid_plus.ebal$weights 4.4 Improving primarily overlap 4.4.1 Truncation # list of weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;smr_weight&quot;, &quot;opt_weight&quot;, &quot;overlap_weight&quot;, &quot;ebal_weight&quot;) 4.4.1.1 Fixed maximum value truncation # truncate weights by imposing a maximum threshold of 10 nsw_cps_plus.fixed &lt;- nsw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(nsw_cps_plus.fixed)) { nsw_cps_plus.fixed &lt;- truncate_weights_fixed(nsw_cps_plus.fixed, weight_col = wcol, max_weight = 10) } } nsw_psid_plus.fixed &lt;- nsw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(nsw_psid_plus.fixed)) { nsw_psid_plus.fixed &lt;- truncate_weights_fixed(nsw_psid_plus.fixed, weight_col = wcol, max_weight = 10) } } 4.4.1.2 At percentile truncation # truncate weights such that values above the 99th percentile are capped nsw_cps_plus.percent &lt;- nsw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(nsw_cps_plus.percent)) { nsw_cps_plus.percent &lt;- truncate_weights_percentile(nsw_cps_plus.percent, weight_col = wcol, percentile = 0.99) } } nsw_psid_plus.percent &lt;- nsw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(nsw_psid_plus.percent)) { nsw_psid_plus.percent &lt;- truncate_weights_percentile(nsw_psid_plus.percent, weight_col = wcol, percentile = 0.99) } } 4.4.1.3 Adaptive weight truncation # inspect variance of weights cps_results &lt;- list() psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(nsw_cps_plus)) { cps_results[[paste0(&quot;cps_&quot;, wcol)]] &lt;- check_weights(nsw_cps_plus, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in ldw_cps_plus&quot;)) } } for (wcol in weight_columns) { if (wcol %in% names(nsw_psid_plus)) { psid_results[[paste0(&quot;psid_&quot;, wcol)]] &lt;- check_weights(nsw_psid_plus, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in ldw_psid_plus&quot;)) } } var_cps_table &lt;- bind_rows(cps_results) var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_cps_table, caption = &quot;Variance of Weights (CPS)&quot;) Table 4.2: Variance of Weights (CPS) Weight_Column Variance ipw_weight 1.190795e-01 smr_weight 1.747924e+03 opt_weight 1.898746e+17 overlap_weight 2.027580e-02 ebal_weight 3.359692e+01 knitr::kable(var_psid_table, caption = &quot;Variance of Weights (PSID)&quot;) Table 4.2: Variance of Weights (PSID) Weight_Column Variance ipw_weight 3.5210003 smr_weight 486.5860900 opt_weight 22.9870965 overlap_weight 0.0416916 ebal_weight 32.9690097 Regarding these results we apply adaptive weight truncation to all considered weights. # truncate adaptively at mean + 3 standard deviations nsw_cps_plus.adapt &lt;- nsw_cps_plus for (wcol in weight_columns) { if (wcol %in% names(nsw_cps_plus.adapt)) { nsw_cps_plus.adapt &lt;- truncate_weights_adaptive(nsw_cps_plus.adapt, weight_col = wcol, c = 3) } } nsw_psid_plus.adapt &lt;- nsw_psid_plus for (wcol in weight_columns) { if (wcol %in% names(nsw_psid_plus.adapt)) { nsw_psid_plus.adapt &lt;- truncate_weights_adaptive(nsw_psid_plus.adapt, weight_col = wcol, c = 3) } } 4.4.2 Trimming 4.4.2.1 Propensity score threshold trimming (analogous to Imbens &amp; Xu (2024)) # apply trimming with thresholds 0.85 nsw_cps_trim &lt;- ps_trim(nsw_cps_plus.ps, threshold = 0.85) nsw_psid_trim &lt;- ps_trim(nsw_psid_plus.ps, threshold = 0.85) # exclude experimental controls, subset trimmed data appropriately nsw_cps.trim_match &lt;- subset(nsw_cps_trim, sample %in% c(0,3) &amp; ps_assoverlap) nsw_psid.trim_match &lt;- subset(nsw_psid_trim, sample %in% c(0,4) &amp; ps_assoverlap) # re-assign treat variable for controls in sample 3 or 4 (non-treated group) nsw_cps.trim_match$treat[nsw_cps.trim_match$sample == 0.5] &lt;- 0 nsw_psid.trim_match$treat[nsw_psid.trim_match$sample == 0.5] &lt;- 0 # re-estimate propensity scores on trimmed data and perform 1:1 matching nsw_cps.trim_match &lt;- psmatch(data = nsw_cps.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) nsw_psid.trim_match &lt;- psmatch(data = nsw_psid.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) 4.4.2.2 Common range trimming # trim observations outside the common support region of propensity scores nsw_cps_plus.common &lt;- common_range_trim(nsw_cps_plus.ps) nsw_psid_plus.common &lt;- common_range_trim(nsw_psid_plus.ps) 4.4.2.3 Propensity score trimming (Crump) # trim observations with propensity scores outside [0.1, 0.9] interval nsw_cps_plus.crump &lt;- crump_trim(nsw_cps_plus.ps, lower = 0.1, upper = 0.9) nsw_psid_plus.crump &lt;- crump_trim(nsw_psid_plus.ps, lower = 0.1, upper = 0.9) 4.4.2.4 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control nsw_cps_plus.stuermer &lt;- stuermer_trim(nsw_cps_plus.ps) nsw_psid_plus.stuermer &lt;- stuermer_trim(nsw_psid_plus.ps) 4.4.2.5 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations nsw_cps_plus.walker &lt;- walker_trim(nsw_cps_plus.ps) nsw_psid_plus.walker &lt;- walker_trim(nsw_psid_plus.ps) 4.4.3 Integrated methods # list trimming methods trim_names &lt;- c(&quot;ps_threshold&quot;, &quot;common_range&quot;, &quot;stuermer&quot;, &quot;walker&quot;, &quot;crump&quot;) trimmed_cps &lt;- list(ps_threshold = nsw_cps_trim, common_range = nsw_cps_plus.common, stuermer = nsw_cps_plus.stuermer, walker = nsw_cps_plus.walker, crump = nsw_cps_plus.crump) trimmed_psid &lt;- list(ps_threshold = nsw_psid_trim, common_range = nsw_psid_plus.common, stuermer = nsw_psid_plus.stuermer, walker = nsw_psid_plus.walker, crump = nsw_psid_plus.crump) 4.4.3.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], nsw_cps_plus, &quot;ipw_weight&quot;)), trim_names ) ipw_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], nsw_psid_plus, &quot;ipw_weight&quot;)), trim_names ) 4.4.3.2 SMR treated weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply standardized mortality ratio (SMR) weighting with trimming and attach SMR weights smr_treat_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], nsw_cps_plus, &quot;smr_weight&quot;)), trim_names ) smr_treat_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], nsw_psid_plus, &quot;smr_weight&quot;)), trim_names ) 4.4.3.3 Overlap weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply overlap weighting with trimming and attach overlap weights ov_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], nsw_cps_plus, &quot;overlap_weight&quot;)), trim_names ) ov_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], nsw_psid_plus, &quot;overlap_weight&quot;)), trim_names ) 4.4.3.4 Entropy weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights entropy_comb.cps_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_cps[[nm]], nsw_cps_plus, &quot;ebal_weight&quot;)), trim_names ) entropy_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], nsw_psid_plus, &quot;ebal_weight&quot;)), trim_names ) 4.5 Reassessing methods 4.5.1 Matching # list all matching methods methods.cps_plus &lt;- list( nn = m.out.cps_plus.nearest, k2 = m.out.cps_plus.k2, k3 = m.out.cps_plus.k3, caliper = m.out.cps_plus.caliper, cS = m.out.cps_plus.cs, mahvars = m.out.cps_plus.mahvars, optimal_pair = m.out.cps_plus.optimal_pair, optimal_full = m.out.cps_plus.optimal_full, gen_full = m.out.cps_plus.general_full, genetic = m.out.cps_plus.genetic, exact = m.out.cps_plus.exact, cem = m.out.cps_plus.cem, card = m.out.cps_plus.card, profile = m.out.cps_plus.profile, subcl = m.out.cps_plus.subcl ) methods.psid_plus &lt;- list( nn = m.out.psid_plus.nearest, k2 = m.out.psid_plus.k2, k3 = m.out.psid_plus.k3, caliper = m.out.psid_plus.caliper, cs = m.out.psid_plus.cs, mahvars = m.out.psid_plus.mahvars, optimal_pair = m.out.psid_plus.optimal_pair, optimal_full = m.out.psid_plus.optimal_full, gen_full = m.out.psid_plus.general_full, genetic = m.out.psid_plus.genetic, exact = m.out.psid_plus.exact, cem = m.out.psid_plus.cem, card = m.out.psid_plus.card, profile = m.out.psid_plus.profile, subcl = m.out.psid_plus.subcl ) 4.5.1.1 SMD # compute SMD smd_matchit.cps_plus &lt;- compute_abs_smd_matchit(methods.cps_plus) smd_matchit.psid_plus &lt;- compute_abs_smd_matchit(methods.psid_plus) 4.5.1.2 ESS # calculate balance statistics bal.cps_plus &lt;- cobalt::bal.tab(model, data = nsw_cps_plus, un = TRUE, weights = methods.cps_plus, s.d.denom = &quot;treated&quot;) bal.psid_plus &lt;- cobalt::bal.tab(model, data = nsw_psid_plus, un = TRUE, weights = methods.psid_plus, s.d.denom = &quot;treated&quot;) # compute ESS ess_matchit.cps_plus &lt;- compute_ess_matchit(bal.cps_plus) ess_matchit.psid_plus &lt;- compute_ess_matchit(bal.psid_plus) 4.5.1.3 Visuals # visualize covariate balance plot_matchit(methods.cps_plus, &quot;NSW-CPS1-PLUS&quot;) Figure 4.10: FIGURE C3. Figure 4.11: FIGURE C3. Figure 4.12: FIGURE C3. Figure 4.13: FIGURE C3. Figure 4.14: FIGURE C3. Figure 4.15: FIGURE C3. Figure 4.16: FIGURE C3. Figure 4.17: FIGURE C3. Figure 4.18: FIGURE C3. Figure 4.19: FIGURE C3. Figure 4.20: FIGURE C3. Figure 4.21: FIGURE C3. Figure 4.22: FIGURE C3. Figure 4.23: FIGURE C3. Figure 4.24: FIGURE C3. plot_matchit(methods.psid_plus, &quot;NSW-PSID1-PLUS&quot;) Figure 4.25: FIGURE C3. Figure 4.26: FIGURE C3. Figure 4.27: FIGURE C3. Figure 4.28: FIGURE C3. Figure 4.29: FIGURE C3. Figure 4.30: FIGURE C3. Figure 4.31: FIGURE C3. Figure 4.32: FIGURE C3. Figure 4.33: FIGURE C3. Figure 4.34: FIGURE C3. Figure 4.35: FIGURE C3. Figure 4.36: FIGURE C3. Figure 4.37: FIGURE C3. Figure 4.38: FIGURE C3. Figure 4.39: FIGURE C3. 4.5.2 Weighting # list all weights weight.cps_plus &lt;- list( ipw = nsw_cps_plus$ipw_weight, smr_tr = nsw_cps_plus$smr_weight, mw = nsw_cps_plus$opt_weight, ow = nsw_cps_plus$overlap_weight, ew = nsw_cps_plus$ebal_weight ) weight.psid_plus &lt;- list( ipw = nsw_psid_plus$ipw_weight, smr_tr = nsw_psid_plus$smr_weight, mw = nsw_psid_plus$opt_weight, ow = nsw_psid_plus$overlap_weight, ew = nsw_psid_plus$ebal_weight ) 4.5.2.1 SMD # compute SMD smd_weight.cps_plus &lt;- compute_abs_smd_weight(nsw_cps_plus, &quot;treat&quot;, covar, weight_columns) smd_weight.psid_plus &lt;- compute_abs_smd_weight(nsw_psid_plus, &quot;treat&quot;, covar, weight_columns) 4.5.2.2 ESS # compute ESS ess_weight.cps_plus &lt;- compute_ess_weight(nsw_cps_plus, &quot;treat&quot;, covar, weight_columns) ess_weight.psid_plus &lt;- compute_ess_weight(nsw_psid_plus, &quot;treat&quot;, covar, weight_columns) 4.5.2.3 Visuals # visualize covariate balance plot_weighting_methods(nsw_cps_plus, &quot;treat&quot;, covar, weight.cps_plus, &quot;NSWW-CPS1-PLUS&quot;) ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.40: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.41: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.42: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.43: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.44: FIGURE C4. plot_weighting_methods(nsw_psid_plus, &quot;treat&quot;, covar, weight.psid_plus, &quot;NSW-PSID1-PLUS&quot;) ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.45: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.46: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.47: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.48: FIGURE C4. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.49: FIGURE C4. 4.5.3 Truncation # list truncation methods trunc.cps_plus &lt;- list( fix_max_value_trunc.cps_plus = nsw_cps_plus.fixed, at_perc_trunc.cps_plus = nsw_cps_plus.percent, adap_weight_trunc.cps_plus = nsw_cps_plus.adapt ) trunc.psid_plus &lt;- list( fix_max_value_trunc.psid_plus = nsw_psid_plus.fixed, at_perc_trunc.psid_plus = nsw_psid_plus.percent, adap_weight_trunc.psid_plus = nsw_psid_plus.adapt ) 4.5.3.1 SMD # compute SMD smd_trunc.cps_plus &lt;- compute_abs_smd_trunc(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns) smd_trunc.psid_plus &lt;- compute_abs_smd_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 4.5.3.2 ESS # compute ESS ess_trunc.cps_plus &lt;- compute_ess_trunc(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns) ess_trunc.psid_plus &lt;- compute_ess_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 4.5.3.3 Visuals # visualize covariate balance plot_trunc_methods(trunc.cps_plus, &quot;treat&quot;, covar, weight_columns, &quot;NSW-CPS1-PLUS&quot;) ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.50: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.51: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.52: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.53: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.54: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.55: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.56: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.57: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.58: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.59: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.60: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.61: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.62: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.63: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.64: FIGURE C5. plot_trunc_methods(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns, &quot;NSW-PSID1-PLUS&quot;) ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.65: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.66: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.67: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.68: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.69: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.70: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.71: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.72: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.73: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.74: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.75: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.76: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.77: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.78: FIGURE C5. ## Warning: Standardized mean differences and raw mean differences are present in ## the same plot. Use the `stars` argument to distinguish between them and ## appropriately label the x-axis. See `?love.plot` for details. Figure 4.79: FIGURE C5. 4.5.4 Trimming # list trimming objects trim.cps_plus &lt;- list( original = nsw_cps_plus, ps_threshold = nsw_cps.trim_match, common_range = nsw_cps_plus.common, crump = nsw_cps_plus.crump, stuermer = nsw_cps_plus.stuermer, walker = nsw_cps_plus.walker ) trim.psid_plus &lt;- list( original = nsw_psid_plus, ps_threshold = nsw_psid.trim_match, common_range = nsw_psid_plus.common, crump = nsw_psid_plus.crump, stuermer = nsw_psid_plus.stuermer, walker = nsw_psid_plus.walker ) 4.5.4.1 SMD # compute SMD smd_trim.cps_plus &lt;- compute_abs_smd_trim(trim.cps_plus, &quot;treat&quot;, covar) smd_trim.psid_plus &lt;- compute_abs_smd_trim(trim.psid_plus, &quot;treat&quot;, covar) 4.5.4.2 ESS # compute ESS ess_trim.cps_plus &lt;- compute_ess_trim(trim.cps_plus, &quot;treat&quot;, covar) ess_trim.psid_plus &lt;- compute_ess_trim(trim.psid_plus, &quot;treat&quot;, covar) 4.5.4.3 Visuals # visualize overlap plot_trim(trim.cps_plus, treat, covar) ## -11.56837 2.929738 ## -0.6592159 0.7461659 ## -9.893722 3.430084 ## -3.280738 2.573095 ## -6.997391 -1.59283 ## -7.62003 -1.585741 Figure 4.80: FIGURE C6. plot_trim(trim.psid_plus, treat, covar) ## -9.367327 6.41566 ## -1.140174 1.012834 ## -7.64381 3.677856 ## -2.580346 2.434131 ## -2.389184 -0.3483448 ## -3.00048 -0.6997456 Figure 4.81: FIGURE C6. # visualize covariate balance love.plot(nsw_cps, nsw_cps.trim_match, treat, covar = covar, title = &quot;NSW-CPS1-PLUS - propensity threshold trimming&quot;) Figure 4.82: FIGURE C7. love.plot(nsw_cps_plus, nsw_cps_plus.common, treat, covar, title = &quot;NSW-CPS1-PLUS - common range trimming&quot;) Figure 4.83: FIGURE C7. love.plot(nsw_cps_plus, nsw_cps_plus.crump, treat, covar, title = &quot;NSW-CPS1-PLUS - crump trimming&quot;) Figure 4.84: FIGURE C7. love.plot(nsw_cps_plus, nsw_cps_plus.stuermer, treat, covar, title = &quot;NSW-CPS1-PLUS - stuermer trimming&quot;) Figure 4.85: FIGURE C7. love.plot(nsw_cps_plus, nsw_cps_plus.walker, treat, covar, title = &quot;NSW-CPS1-PLUS - walker trimming&quot;) Figure 4.86: FIGURE C7. love.plot(nsw_psid, nsw_psid.trim_match, treat, covar = covar, title = &quot;NSW-PSID1-PLUS - propensity threshold trimming&quot;) Figure 4.87: FIGURE C7. love.plot(nsw_psid_plus, nsw_psid_plus.common, treat, covar, title = &quot;NSW-PSID1-PLUS - common range trimming&quot;) Figure 4.88: FIGURE C7. love.plot(nsw_psid_plus, nsw_psid_plus.crump, treat, covar, title = &quot;NSW-PSID1-PLUS - crump trimming&quot;) Figure 4.89: FIGURE C7. love.plot(nsw_psid_plus, nsw_psid_plus.stuermer, treat, covar, title = &quot;NSW-PSID1-PLUS - stuermer trimming&quot;) Figure 4.90: FIGURE C7. love.plot(nsw_psid_plus, nsw_psid_plus.walker, treat, covar, title = &quot;NSW-PSID1-PLUS - walker trimming&quot;) Figure 4.91: FIGURE C7. 4.6 Integrated methods # list all combined method results comb_meth.cps_plus &lt;- list( ipw = ipw_comb.cps_plus, smr_treated = smr_treat_comb.cps_plus, overlap = ov_comb.cps_plus, entropy = entropy_comb.cps_plus ) comb_meth.psid_plus &lt;- list( ipw = ipw_comb.psid_plus, smr_treated = smr_treat_comb.psid_plus, overlap = ov_comb.psid_plus, entropy = entropy_comb.psid_plus ) 4.6.0.1 SMD # compute SMD smd_all_comb_meth.cps_plus &lt;- compute_smd_all_datasets(comb_meth.cps_plus, &quot;treat&quot;, covar) smd_all_comb_meth.psid_plus &lt;- compute_smd_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 4.6.0.2 ESS # compute ESS ess_all_comb_meth.cps_plus &lt;- compute_ess_all_datasets(comb_meth.cps_plus, &quot;treat&quot;, covar) ess_all_comb_meth.psid_plus &lt;- compute_ess_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 4.6.0.3 Visuals # visualize overlap plot_comb_overlap(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix_cps = &quot;NSW-CPS1&quot;, prefix_psid = &quot;NSW-PSID1&quot;) ## -11.66275 2.94699 ## -9.893722 3.430084 ## -6.997391 -1.59283 ## -7.62003 -1.585741 Figure 4.92: FIGURE C8. ## -3.280738 2.573095 ## -11.66275 2.94699 ## -9.893722 3.430084 ## -6.997391 -1.59283 Figure 4.93: FIGURE C8. ## -7.62003 -1.585741 ## -3.280738 2.573095 ## -11.66275 2.94699 ## -9.893722 3.430084 Figure 4.94: FIGURE C8. ## -6.997391 -1.59283 ## -7.62003 -1.585741 ## -3.280738 2.573095 ## -11.66275 2.94699 Figure 4.95: FIGURE C8. ## -9.893722 3.430084 ## -6.997391 -1.59283 ## -7.62003 -1.585741 ## -3.280738 2.573095 Figure 4.96: FIGURE C8. ## -9.032421 2.650827 ## -7.64381 3.677856 ## -2.389184 -0.3483448 ## -3.00048 -0.6997456 Figure 4.97: FIGURE C8. ## -2.580346 2.434131 ## -9.032421 2.650827 ## -7.64381 3.677856 ## -2.389184 -0.3483448 Figure 4.98: FIGURE C8. ## -3.00048 -0.6997456 ## -2.580346 2.434131 ## -9.032421 2.650827 ## -7.64381 3.677856 Figure 4.99: FIGURE C8. ## -2.389184 -0.3483448 ## -3.00048 -0.6997456 ## -2.580346 2.434131 ## -9.032421 2.650827 Figure 4.100: FIGURE C8. ## -7.64381 3.677856 ## -2.389184 -0.3483448 ## -3.00048 -0.6997456 ## -2.580346 2.434131 Figure 4.101: FIGURE C8. # visualize covariate balance plot_comb_love_plots(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix_cps = &quot;NSW-CPS1&quot;, prefix_psid = &quot;NSW-PSID1&quot;) Figure 4.102: FIGURE C9. Figure 4.103: FIGURE C9. Figure 4.104: FIGURE C9. Figure 4.105: FIGURE C9. Figure 4.106: FIGURE C9. Figure 4.107: FIGURE C9. Figure 4.108: FIGURE C9. Figure 4.109: FIGURE C9. Figure 4.110: FIGURE C9. Figure 4.111: FIGURE C9. Figure 4.112: FIGURE C9. Figure 4.113: FIGURE C9. Figure 4.114: FIGURE C9. Figure 4.115: FIGURE C9. Figure 4.116: FIGURE C9. Figure 4.117: FIGURE C9. Figure 4.118: FIGURE C9. Figure 4.119: FIGURE C9. Figure 4.120: FIGURE C9. Figure 4.121: FIGURE C9. Figure 4.122: FIGURE C9. Figure 4.123: FIGURE C9. Figure 4.124: FIGURE C9. Figure 4.125: FIGURE C9. Figure 4.126: FIGURE C9. Figure 4.127: FIGURE C9. Figure 4.128: FIGURE C9. Figure 4.129: FIGURE C9. Figure 4.130: FIGURE C9. Figure 4.131: FIGURE C9. Figure 4.132: FIGURE C9. Figure 4.133: FIGURE C9. Figure 4.134: FIGURE C9. Figure 4.135: FIGURE C9. Figure 4.136: FIGURE C9. Figure 4.137: FIGURE C9. Figure 4.138: FIGURE C9. Figure 4.139: FIGURE C9. Figure 4.140: FIGURE C9. Figure 4.141: FIGURE C9. # save results save_comb_hist(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix = &quot;nsw&quot;) save_comb_loveplots(comb_meth.cps_plus, comb_meth.psid_plus, &quot;treat&quot;, covar, prefix = &quot;nsw&quot;) 4.6.1 Top methods and datasets # combine all results all_cps_plus &lt;- combine_results(&quot;cps_plus&quot;) all_psid_plus &lt;- combine_results(&quot;psid_plus&quot;) # save results save_csv(all_cps_plus, &quot;CPS1_PLUS_all_results_nsw&quot;) save_csv(all_psid_plus, &quot;PSID1_PLUS_all_results_nsw&quot;) # get top 5 methods for each dataset ranked_cps_plus &lt;- assess_methods(all_cps_plus) ranked_psid_plus &lt;- assess_methods(all_psid_plus) top5_methods.cps_plus &lt;- get_top_methods(ranked_cps_plus, top_n = 5) top5_methods.psid_plus &lt;- get_top_methods(ranked_psid_plus, top_n = 5) # print results top5_methods_df.cps_plus &lt;- ranked_cps_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid_plus &lt;- ranked_psid_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps_plus, caption = &quot;Top 5 Methods for CPS1-PLUS&quot;, booktabs = TRUE) Table 4.3: Top 5 Methods for CPS1-PLUS Method Score mahvars 0.7354538 card 0.7343024 ps_threshold 0.7278238 overlap_crump 0.7254660 adap_weight_trunc_ipw_weight 0.6812703 knitr::kable(top5_methods_df.psid_plus, caption = &quot;Top 5 Methods for PSID1-PLUS&quot;, booktabs = TRUE) Table 4.3: Top 5 Methods for PSID1-PLUS Method Score card 0.7716809 fix_max_value_trunc_overlap_weight 0.7598889 overlap_weight 0.7598889 at_perc_trunc_overlap_weight 0.7592451 mahvars 0.7539451 # save results save_csv(top5_methods.cps_plus, &quot;CPS1_PLUS_top5_methods_nsw&quot;) save_csv(top5_methods.psid_plus, &quot;PSID1_PLUS_top5_methods_nsw&quot;) The table shows that CPS1 and PSID1 share the same top five methods, with the exception of one differing method and a variation in their ordering for PSID1. dataset_list_cps &lt;- list( &quot;All&quot; = nsw_cps_plus, &quot;original&quot; = nsw_cps_plus, &quot;nn&quot; = m.out.cps_plus.nearest, &quot;caliper&quot; = m.out.cps_plus.caliper, &quot;card&quot; = m.out.cps_plus.card, &quot;cem&quot; = m.out.cps_plus.cem, &quot;cS&quot; = m.out.cps_plus.cs, &quot;k2&quot; = m.out.cps_plus.k2, &quot;k3&quot; = m.out.cps_plus.k3, &quot;mahvars&quot; = m.out.cps_plus.mahvars, &quot;optimal_full&quot; = m.out.cps_plus.optimal_full, &quot;optimal_pair&quot; = m.out.cps_plus.optimal_pair, &quot;gen_full&quot; = m.out.cps_plus.general_full, &quot;genetic&quot; = m.out.cps_plus.genetic, &quot;exact&quot; = m.out.cps_plus.exact, &quot;subcl&quot; = m.out.cps_plus.subcl, &quot;profile&quot; = m.out.cps_plus.profile, &quot;ipw_weight&quot; = nsw_cps_plus$ipw_weight, &quot;smr_weight&quot; = nsw_cps_plus$smr_weight, &quot;opt_weight&quot; = nsw_cps_plus$opt_weight, &quot;overlap_weight&quot; = nsw_cps_plus$overlap_weight, &quot;ebal_weight&quot; = nsw_cps_plus$ebal_weight, &quot;fix_max_value_trunc_ebal_weight&quot; = nsw_cps_plus.fixed, &quot;fix_max_value_trunc_ipw_weight&quot; = nsw_cps_plus.fixed, &quot;fix_max_value_trunc_opt_weight&quot; = nsw_cps_plus.fixed, &quot;fix_max_value_trunc_overlap_weight&quot; = nsw_cps_plus.fixed, &quot;fix_max_value_trunc_smr_weight&quot; = nsw_cps_plus.fixed, &quot;at_perc_trunc_ebal_weight&quot; = nsw_cps_plus.percent, &quot;at_perc_trunc_ipw_weight&quot; = nsw_cps_plus.percent, &quot;at_perc_trunc_opt_weight&quot; = nsw_cps_plus.percent, &quot;at_perc_trunc_overlap_weight&quot; = nsw_cps_plus.percent, &quot;at_perc_trunc_smr_weight&quot; = nsw_cps_plus.percent, &quot;adap_weight_trunc_ebal_weight&quot; = nsw_cps_plus.adapt, &quot;adap_weight_trunc_ipw_weight&quot; = nsw_cps_plus.adapt, &quot;adap_weight_trunc_opt_weight&quot; = nsw_cps_plus.adapt, &quot;adap_weight_trunc_overlap_weight&quot; = nsw_cps_plus.adapt, &quot;adap_weight_trunc_smr_weight&quot; = nsw_cps_plus.adapt, &quot;ps_threshold&quot; = nsw_cps.trim_match, &quot;common_range&quot; = nsw_cps_plus.common, &quot;stuermer&quot; = nsw_cps_plus.stuermer, &quot;walker&quot; = nsw_cps_plus.walker, &quot;crump&quot; = nsw_cps_plus.crump, &quot;ipw_common_range&quot; = ipw_comb.cps_plus[[1]], &quot;ipw_crump&quot; = ipw_comb.cps_plus[[2]], &quot;ipw_ps_threshold&quot; = ipw_comb.cps_plus[[3]], &quot;ipw_stuermer&quot; = ipw_comb.cps_plus[[4]], &quot;ipw_walker&quot; = ipw_comb.cps_plus[[5]], &quot;smr_treated_common_range&quot; = smr_treat_comb.cps_plus[[1]], &quot;smr_treated_crump&quot; = smr_treat_comb.cps_plus[[2]], &quot;smr_treated_ps_threshold&quot; = smr_treat_comb.cps_plus[[3]], &quot;smr_treated_stuermer&quot; = smr_treat_comb.cps_plus[[4]], &quot;smr_treated_walker&quot; = smr_treat_comb.cps_plus[[5]], &quot;overlap_common_range&quot; = ov_comb.cps_plus[[1]], &quot;overlap_crump&quot; = ov_comb.cps_plus[[2]], &quot;overlap_ps_threshold&quot; = ov_comb.cps_plus[[3]], &quot;overlap_stuermer&quot; = ov_comb.cps_plus[[4]], &quot;overlap_walker&quot; = ov_comb.cps_plus[[5]], &quot;entropy_common_range&quot; = entropy_comb.cps_plus[[1]], &quot;entropy_crump&quot; = entropy_comb.cps_plus[[2]], &quot;entropy_ps_threshold&quot; = entropy_comb.cps_plus[[3]], &quot;entropy_stuermer&quot; = entropy_comb.cps_plus[[4]], &quot;entropy_walker&quot; = entropy_comb.cps_plus[[5]]) dataset_list_psid &lt;- list( &quot;All&quot; = nsw_psid_plus, &quot;original&quot; = nsw_psid_plus, &quot;nn&quot; = m.out.psid_plus.nearest, &quot;caliper&quot;= m.out.psid_plus.caliper, &quot;card&quot; = m.out.psid_plus.card, &quot;cem&quot; = m.out.psid_plus.cem, &quot;cS&quot; = m.out.psid_plus.cs, &quot;k2&quot; = m.out.psid_plus.k2, &quot;k3&quot; = m.out.psid_plus.k3, &quot;mahvars&quot; = m.out.psid_plus.mahvars, &quot;optimal_full&quot; = m.out.psid_plus.optimal_full, &quot;optimal_pair&quot; = m.out.psid_plus.optimal_pair, &quot;gen_full&quot; = m.out.psid_plus.general_full, &quot;genetic&quot; = m.out.psid_plus.genetic, &quot;exact&quot; = m.out.psid_plus.exact, &quot;subcl&quot; = m.out.psid_plus.subcl, &quot;profile&quot; = m.out.psid_plus.profile, &quot;ipw_weight&quot; = nsw_psid_plus$ipw_weight, &quot;smr_weight&quot; = nsw_psid_plus$smr_weight, &quot;opt_weight&quot; = nsw_psid_plus$opt_weight, &quot;overlap_weight&quot; = nsw_psid_plus$overlap_weight, &quot;ebal_weight&quot; = nsw_psid_plus$ebal_weight, &quot;fix_max_value_trunc_ebal_weight&quot; = nsw_psid_plus.fixed, &quot;fix_max_value_trunc_ipw_weight&quot; = nsw_psid_plus.fixed, &quot;fix_max_value_trunc_opt_weight&quot; = nsw_psid_plus.fixed, &quot;fix_max_value_trunc_overlap_weight&quot; = nsw_psid_plus.fixed, &quot;fix_max_value_trunc_smr_weight&quot; = nsw_psid_plus.fixed, &quot;at_perc_trunc_ebal_weight&quot; = nsw_psid_plus.percent, &quot;at_perc_trunc_ipw_weight&quot; = nsw_psid_plus.percent, &quot;at_perc_trunc_opt_weight&quot; = nsw_psid_plus.percent, &quot;at_perc_trunc_overlap_weight&quot; = nsw_psid_plus.percent, &quot;at_perc_trunc_smr_weight&quot; = nsw_psid_plus.percent, &quot;adap_weight_trunc_ebal_weight&quot; = nsw_psid_plus.adapt, &quot;adap_weight_trunc_ipw_weight&quot; = nsw_psid_plus.adapt, &quot;adap_weight_trunc_opt_weight&quot; = nsw_psid_plus.adapt, &quot;adap_weight_trunc_overlap_weight&quot; = nsw_psid_plus.adapt, &quot;adap_weight_trunc_smr_weight&quot; = nsw_psid_plus.adapt, &quot;ps_threshold&quot; = nsw_psid.trim_match, &quot;common_range&quot; = nsw_psid_plus.common, &quot;stuermer&quot; = nsw_psid_plus.stuermer, &quot;walker&quot; = nsw_psid_plus.walker, &quot;crump&quot; = nsw_psid_plus.crump, &quot;ipw_common_range&quot; = ipw_comb.psid_plus[[1]], &quot;ipw_crump&quot;= ipw_comb.psid_plus[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid_plus[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid_plus[[4]], &quot;ipw_walker&quot; = ipw_comb.psid_plus[[5]], &quot;smr_treated_common_range&quot; = smr_treat_comb.psid_plus[[1]], &quot;smr_treated_crump&quot;= smr_treat_comb.psid_plus[[2]], &quot;smr_treated_ps_threshold&quot; = smr_treat_comb.psid_plus[[3]], &quot;smr_treated_stuermer&quot; = smr_treat_comb.psid_plus[[4]], &quot;smr_treated_walker&quot; = smr_treat_comb.psid_plus[[5]], &quot;overlap_common_range&quot; = ov_comb.psid_plus[[1]], &quot;overlap_crump&quot; = ov_comb.psid_plus[[2]], &quot;overlap_ps_threshold&quot; = ov_comb.psid_plus[[3]], &quot;overlap_stuermer&quot; = ov_comb.psid_plus[[4]], &quot;overlap_walker&quot;= ov_comb.psid_plus[[5]], &quot;entropy_common_range&quot; = entropy_comb.psid_plus[[1]], &quot;entropy_crump&quot; = entropy_comb.psid_plus[[2]], &quot;entropy_ps_threshold&quot; = entropy_comb.psid_plus[[3]], &quot;entropy_stuermer&quot; = entropy_comb.psid_plus[[4]], &quot;entropy_walker&quot; = entropy_comb.psid_plus[[5]]) # create datasets corresponding to the top 5 methods for each dataset top5_datasets.cps_plus &lt;- create_top5_datasets(dataset_list_cps, top5_methods.cps_plus) top5_datasets.psid_plus &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid_plus) # save datasets into .RData files save_top5_individual_files(dataset_list_cps, top5_methods.cps_plus, prefix = &quot;nsw_cps&quot;) save_top5_individual_files(dataset_list_psid, top5_methods.psid_plus, prefix = &quot;nsw_psid&quot;) 4.7 Estimating 4.7.1 Average treatment effect on the treated (ATT) out1 &lt;- estimate_all(nsw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(nsw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(nsw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out4 &lt;- estimate_all(nsw_cps.trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) out5 &lt;- estimate_all(nsw_psid.trim_match, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out6 &lt;- out.cps_plus[[1]] out7 &lt;- out.cps_plus[[2]] out8 &lt;- out.cps_plus[[3]] out9 &lt;- out.cps_plus[[4]] out10 &lt;- out.cps_plus[[5]] out11 &lt;- out.psid_plus[[1]] out12 &lt;- out.psid_plus[[2]] out13 &lt;- out.psid_plus[[3]] out14 &lt;- out.psid_plus[[4]] out15 &lt;- out.psid_plus[[5]] # build plot titles base_titles &lt;- c(&quot;(A) NSW-Experimental&quot;, &quot;(B) NSW-CPS1&quot; , &quot;(C) NSW-PSID1&quot;, &quot;(D) Trimmed NSW-CPS1 &quot;, &quot;(E) Trimmed NSW-PSID1&quot;) top_start &lt;- 6 num_cps &lt;- length(top5_methods.cps_plus) num_psid &lt;- length(top5_methods.psid_plus) top_letters_cps &lt;- LETTERS[top_start:(top_start + num_cps - 1)] top_letters_psid &lt;- LETTERS[(top_start + num_cps):(top_start + num_cps + num_psid - 1)] top5_titles.cps_plus &lt;- paste0(&quot;(&quot;, top_letters_cps, &quot;) Top CPS1: &quot;, top5_methods.cps_plus) top5_titles.psid_plus &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid_plus) plot_titles &lt;- c(base_titles, top5_titles.cps_plus, top5_titles.psid_plus) # combine all results all_outs &lt;- c(list(out1, out2, out3, out4, out5), out.cps_plus, out.psid_plus) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 4.142: FIGURE C10. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.143: FIGURE C10. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.144: FIGURE C10. ATT Estimates Given Unconfoundedness using NSW Samples Figure 4.145: FIGURE C10. ATT Estimates Given Unconfoundedness using NSW Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;nsw&quot;) The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: NSW-Experimental, NSW-CPS1, NSW-PSID1, trimmed versions of the NSW-CPS1 and NSW-PSID1 samples (analogous to Imbens &amp; Xu (2024)) and a series of top-ranked subsamples of both NSW-CPS1 and NSW-PSID1 based on various matching, weighting, truncation and trimming criteria. Figure (A) presents the benchmark from the experimental sample (NSW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the observational samples, NSW-CPS1 and NSW-PSID1, while figures (D) and (E) present those for the trimmed versions, replicating the tutorial results of Imbens &amp; Xu (2024). Figures (F) through (J) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (K) through (O) summarize results for the corresponding PSID1-based subsamples under parallel rules. Across the NSW-CPS1 and its top-ranked subsamples, all estimators produce ATT estimates that closely align with the experimental benchmark, though all estimates are negative. Some larger deviations occur for the Diff-in-Means estimator within the overlap_crump and adapt_weight_trunc_ipw_weight subsamples. Nevertheless, these ATT estimates deviate more from the benchmark than those obtained under models A and B in previous sections using LDW data. In comparison, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors than NSW-CPS1 samples, consistent with previous observations from LDW data. All ATT estimates remain negatively aligned, reflecting heightened methodological uncertainty within these samples. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 4.4: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) NSW-Experimental 487.4523 511.2951 886.3037 375.0086 (B) NSW-CPS1 489.3734 -8870.3076 -290.3771 8579.9305 (C) NSW-PSID1 773.4068 -15577.5689 -691.8459 14885.7230 (D) Trimmed NSW-CPS1 554.9712 -1099.9504 -115.3250 984.6254 (E) Trimmed NSW-PSID1 1193.3602 -4728.2193 -3390.0776 1338.1417 (F) Top CPS1: mahvars 399.1508 -1537.7028 -1316.7205 220.9823 (G) Top CPS1: card 360.7632 -1519.8066 -302.0200 1217.7866 (H) Top CPS1: ps_threshold 554.9391 -1118.1455 -115.3250 1002.8205 (I) Top CPS1: overlap_crump 346.8995 -6683.5533 -764.9689 5918.5844 (J) Top CPS1: adap_weight_trunc_ipw_weight 346.1296 -9392.0238 -949.3620 8442.6618 (K) Top PSID1: card 730.7114 -4479.8846 -3118.2898 1361.5948 (L) Top PSID1: fix_max_value_trunc_overlap_weight 684.5118 -16099.2851 -896.8264 15202.4587 (M) Top PSID1: overlap_weight 639.4272 -16099.2851 -896.8264 15202.4587 (N) Top PSID1: at_perc_trunc_overlap_weight 684.3000 -16099.2851 -896.8264 15202.4587 (O) Top PSID1: mahvars 851.5132 -4976.8467 -3692.1595 1284.6872 # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) Table 4.5: ATT Estimates and SEs (A) NSW-Experimental (B) NSW-CPS1 (C) NSW-PSID1 (D) Trimmed NSW-CPS1 (E) Trimmed NSW-PSID1 (F) Top CPS1: mahvars (G) Top CPS1: card (H) Top CPS1: ps_threshold (I) Top CPS1: overlap_crump (J) Top CPS1: adap_weight_trunc_ipw_weight (K) Top PSID1: card (L) Top PSID1: fix_max_value_trunc_overlap_weight (M) Top PSID1: overlap_weight (N) Top PSID1: at_perc_trunc_overlap_weight (O) Top PSID1: mahvars Experimental Benchmark 886.30 (488.14) -8870.31 (408.30) -15577.57 (508.12) -519.65 (578.61) -3569.56 (1138.75) -1451.62 (416.60) -1519.81 (350.42) -519.65 (578.61) -6683.55 (249.72) -9392.02 (244.76) -3539.79 (680.90) -16099.29 (388.99) -16099.29 (388.99) -16099.29 (388.99) -4976.85 (841.41) diff 886.30 (488.14) -8870.31 (408.30) -15577.57 (508.12) -519.65 (578.61) -3569.56 (1138.75) -1451.62 (416.60) -1519.81 (350.42) -519.65 (578.61) -6683.55 (249.72) -9392.02 (244.76) -3539.79 (680.90) -16099.29 (388.99) -16099.29 (388.99) -16099.29 (388.99) -4976.85 (841.41) reg 812.52 (485.60) -792.15 (479.67) -1581.11 (718.80) -336.84 (552.46) -3579.07 (1270.85) -1441.89 (392.13) -1314.28 (338.42) -336.84 (552.46) -1436.18 (310.59) -1282.69 (303.78) -3409.65 (696.03) -2690.39 (593.28) -2690.39 (593.28) -2690.39 (593.28) -4409.79 (849.66) om.reg 854.16 (413.47) -726.42 (462.50) -1215.01 (481.08) -323.38 (461.86) -3476.55 (644.84) -1414.47 (322.48) -1121.88 (286.13) -323.38 (461.86) -1287.23 (276.96) -1175.13 (277.45) -3143.04 (460.21) -1689.47 (289.71) -1689.47 (289.71) -1689.47 (289.71) -3909.91 (535.12) om.grf 835.78 (408.33) -969.43 (451.72) -2823.28 (454.43) -244.74 (439.19) -3810.59 (548.81) -1316.72 (305.80) -615.47 (266.42) -223.71 (438.30) -1444.99 (269.05) -1509.01 (268.65) -3449.46 (397.52) -3221.38 (272.19) -3177.07 (272.34) -3177.07 (272.34) -4342.35 (489.49) matching 776.30 (553.82) -290.38 (585.14) -1122.98 (1210.25) -115.33 (637.40) -4531.07 (1382.58) -1415.62 (449.79) -929.42 (479.64) -115.33 (637.40) -924.76 (454.66) -980.76 (452.84) -4479.88 (1079.35) -1297.27 (1197.10) -1297.27 (1197.10) -1297.27 (1197.10) -4224.24 (970.34) psm 511.30 (525.03) -438.33 (548.33) -1851.62 (766.08) -1099.95 (592.33) -4728.22 (1292.72) -1537.70 (411.37) -302.02 (346.20) -1118.15 (592.84) -808.19 (338.84) -949.36 (341.05) -4123.34 (788.32) -2310.76 (466.73) -2287.16 (464.04) -2287.16 (464.04) -3692.16 (824.41) ipw 826.41 (498.62) -514.85 (486.08) -2084.41 (986.49) -377.35 (571.14) -4305.63 (1429.00) -1451.62 (416.60) -1519.81 (350.42) -377.35 (571.14) -973.18 (439.17) -1102.00 (416.66) -3539.79 (680.90) -2162.29 (1048.57) -3966.34 (682.20) -2162.29 (1048.57) -4976.85 (841.41) cbps 852.06 (495.44) -566.41 (476.37) -718.81 (888.13) -310.73 (578.63) -3403.78 (1336.51) -1451.62 (416.60) -1519.81 (350.42) -310.73 (578.63) -1053.88 (358.03) -1067.89 (357.05) -3539.79 (680.90) -1063.75 (854.31) -3966.34 (682.20) -1063.75 (854.31) -4976.85 (841.41) ebal 850.96 (495.52) -566.82 (476.39) -691.85 (889.21) -310.83 (578.64) -3390.08 (1355.57) -1414.38 (431.14) -1132.87 (356.06) -310.83 (578.64) -1048.48 (358.14) -1067.63 (357.12) -3118.29 (760.16) -896.83 (837.44) -896.83 (837.44) -896.83 (837.44) -3887.92 (951.58) dml 748.59 (482.57) -787.03 (479.32) -1673.83 (722.32) -482.94 (556.06) -3922.47 (1247.20) -1415.63 (391.98) -1315.63 (335.82) -482.94 (556.06) -1426.16 (310.30) -1265.05 (303.51) -3488.10 (699.54) -2758.46 (595.66) -2758.46 (595.66) -2758.46 (595.66) -4153.68 (851.41) aipw_grf 794.73 (500.39) -297.92 (514.54) -1962.22 (882.58) -252.04 (552.42) -4297.33 (1423.49) -1385.59 (416.93) -796.70 (473.79) -252.04 (552.42) -830.68 (423.77) -960.77 (435.75) -3786.54 (922.57) -2040.63 (933.50) -2040.63 (933.50) -2040.63 (933.50) -4504.62 (1138.75) aipw_ow 877.36 (502.50) -374.41 (504.11) -1691.75 (773.39) -247.39 (560.93) -3903.01 (1249.99) -1362.79 (418.38) -578.28 (395.41) -247.39 (560.93) -764.97 (373.55) -968.17 (394.92) -3888.80 (922.12) -1984.73 (736.66) -1984.73 (736.66) -1984.73 (736.66) -4421.74 (1083.18) The tabulated results confirm visual patterns: Column (A) reports the estimates for the NSW-Experimental sample, column (B) for the NSW-CPS1 sample, and column (C) for the NSW-PSID1 sample. Columns (D)-(O) summarize results for the trimmed and top-ranked samples for both NSW-CPS1 and NSW-PSID1. For all CPS1-based samples, ATT estimates remain negative, but are relatively close to the experimental benchmark. In contrast, the PSID1-based estimates exhibit larger negative magnitudes, and increased standard errors, underscoring the heightened difficulty of achieving covariate balance and overlap in this observational dataset. Overall, consistent with findings from models A and B, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain methods can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;NSW_att_estimates&quot;) 4.7.2 Conditional average treatment effect on the treated (CATT) catt.nsw &lt;- catt(nsw, Y, treat, covar) catt.cps &lt;- catt(nsw_cps, Y, treat, covar) catt.psid &lt;- catt(nsw_psid, Y, treat, covar) catt.cps.trim &lt;- catt(nsw_cps.trim_match, Y, treat, covar) catt.psid.trim &lt;- catt(nsw_psid.trim_match, Y, treat, covar) catt.top5_cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) catt(d, Y, treat, covar)) catt.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) catt(d, Y, treat, covar)) # combine all catt objects all_catt &lt;- c(list(catt.nsw, catt.cps, catt.psid, catt.cps.trim, catt.psid.trim), catt.top5_cps_plus, catt.top5_psid_plus) # plot results par(mfrow = c(2,2)) par(cex.main = 0.8) plot_catt_panels(all_catt, plot_titles) Figure 4.146: FIGURE C11. CATT Estimates using NSW Data Figure 4.147: FIGURE C11. CATT Estimates using NSW Data Figure 4.148: FIGURE C11. CATT Estimates using NSW Data Figure 4.149: FIGURE C11. CATT Estimates using NSW Data all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 4.6: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) NSW-Experimental -1179.028 3339.9595 812.1668 4518.987 (B) NSW-CPS1 -8652.642 6452.9655 -105.3929 15105.607 (C) NSW-PSID1 -8591.862 1170.5509 -2321.8692 9762.413 (D) Trimmed NSW-CPS1 -6700.928 5952.6255 -200.1068 12653.554 (E) Trimmed NSW-PSID1 -7477.050 -2200.6191 -4170.0879 5276.431 (F) Top CPS1: mahvars -7980.487 3597.1947 -1310.2401 11577.681 (G) Top CPS1: card -6844.664 3365.3751 -859.6157 10210.039 (H) Top CPS1: ps_threshold -6823.149 5912.2813 -215.4671 12735.431 (I) Top CPS1: overlap_crump -10037.858 4824.1747 -681.2193 14862.033 (J) Top CPS1: adap_weight_trunc_ipw_weight -10369.216 4832.0011 -719.8140 15201.217 (K) Top PSID1: card -7533.234 869.4020 -3655.0398 8402.636 (L) Top PSID1: fix_max_value_trunc_overlap_weight -11628.445 1646.8018 -2896.1540 13275.247 (M) Top PSID1: overlap_weight -11585.227 1804.8129 -3013.7087 13390.040 (N) Top PSID1: at_perc_trunc_overlap_weight -11960.848 1601.5888 -2964.8646 13562.437 (O) Top PSID1: mahvars -11380.388 206.8831 -4407.6457 11587.271 With NSW-CPS1, the CATT estimates range from $-8,652.64 to $6,452.97, contrasting with the benchmark where CATT estimates span from $-1,179.03 to $3,339.96, with a mean CATT estimate of $812.17. Alike in the previous sections, the NSW-PSID1 data exhibits a narrower CATT estimates range compared to NSW-CPS1, spanning from $-8,591.86 to $1,170.55. Yet its mean CATT estimate remains substantially negative, at approximately $-2,321.86, contrary to the positive mean CATT estimates observed in models A and B. Among the trimmed and top-ranked NSW-CPS1 subsamples, CATT estimates exhibit substantial variability. Subsamples such as overlap_crump or adap_weight_trunc_ipw_weight yield notably negative minimum CATT values alongside moderately negative mean CATT estimates. Similarly, card and mahvars subsamples produce consistently negative mean CATT estimates, although weaker alignment with the experimental benchmark. The ps_threshold subsample yields improved estimates with highest min CATT and mean CATTs estimates closest to the experimental benchmark, while still negative. The NSW-PSID1 trimmed and top-ranked subsamples deliver substantially decreased mean CATT estimates and wider extremes compared to their NSW-CPS1 counterparts, reflecting greater difficulties in producing reliable effect estimates. This variation in range and means across samples, as observed in previous sections, reflects substantial heterogeneity in treatment effect estimation but also indicates that while certain criteria improve alignment with the experimental benchmark, others introduce considerable discrepancies and spread in estimated heterogeneous effects. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;nsw&quot;) 4.7.3 Quantile treatment effect on the treated (QTET) qte.nsw &lt;- est_qte(Y, treat, covar, data = nsw, cores = 4) qte.nsw_cps &lt;- est_qte(Y, treat, covar, data = nsw_cps) qte.nsw_psid &lt;- est_qte(Y, treat, covar, data = nsw_psid) qte.nsw_cps.trim &lt;- est_qte(Y, treat, covar, data = nsw_cps.trim_match) qte.nsw_psid.trim &lt;- est_qte(Y, treat, covar, data = nsw_psid.trim_match) qte.top5_cps_plus &lt;- lapply(top5_datasets.cps_plus, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, covar, data = d)) qte.nsw0 &lt;- est_qte(Y, treat, NULL, data = nsw) qte.nsw.cps0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps) qte.nsw.psid0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid) qte.nsw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_cps.trim_match) qte.nsw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = nsw_psid.trim_match) qte.top5_cps_plus0 &lt;- lapply(top5_datasets.cps_plus, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid_plus0 &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, NULL, data = d)) par(mfrow = c(2,2)) par(cex.main = 0.8) # CPS plot_qte(qte.nsw_cps, qte.nsw.cps0, qte.nsw, main = &quot;(B) NSW-CPS&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID plot_qte(qte.nsw_psid, qte.nsw.psid0, qte.nsw, main = &quot;(C) NSW-PSID&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) ## CPS trimmed plot_qte(qte.nsw_cps.trim, qte.nsw_cps.trim0, qte.nsw_cps, main = &quot;(D) NSW-CPS (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID trimmed plot_qte(qte.nsw_psid.trim, qte.nsw_psid.trim0, qte.nsw_psid, main = &quot;(E) NSW-PSID (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 4.150: FIGURE C12. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental # CPS top methods plot_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.nsw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000)) Figure 4.151: FIGURE C12. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental # PSID top methods plot_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.nsw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000)) Figure 4.152: FIGURE C12. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental Figure 4.153: FIGURE C12. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the NSW experimental and various observational samples. The QTETs estimated from trimmed NSW-CPS1 sample (D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original NSW-CPS1, the original NSW-PSID1 and its trimmed subsample (B, C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked subsamples, CPS1-based QTETs (F–J) consistently track the true QTET closely. In contrast, PSID1-based QTETs (K–O) generally perform well, aligning closely with the true QTET, except for subsamples mahvars and card, which exhibit increased bias and noticeably wider confidence intervals, reflecting greater estimation uncertainty. # list results plots_nsw &lt;- list( list(mod = qte.nsw_cps, mod0 = qte.nsw.cps0, bm = qte.nsw, main = &quot;(A) NSW CPS&quot;), list(mod = qte.nsw_psid, mod0 = qte.nsw.psid0, bm = qte.nsw, main = &quot;(B) NSW PSID&quot;), list(mod = qte.nsw_cps.trim, mod0 = qte.nsw_cps.trim0, bm = qte.nsw_cps, main = &quot;(C) NSW CPS (Trimmed)&quot;), list(mod = qte.nsw_psid.trim, mod0 = qte.nsw_psid.trim0, bm = qte.nsw_psid, main = &quot;(D) NSW PSID (Trimmed)&quot;) ) # save results save_qtet(plots_nsw, prefix = &quot;nsw&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_cps_plus, qte.top5_cps_plus0, qte.nsw_cps, plot_titles, main_start = 6, ylim = c(-25000, 15000), prefix = &quot;nsw_top&quot;) save_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.nsw_psid, plot_titles, main_start = 11, ylim = c(-25000, 15000), prefix = &quot;nsw_top&quot;) 4.7.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c( list(nsw, nsw_cps, nsw_psid, nsw_cps.trim_match, nsw_psid.trim_match), top5_datasets.cps_plus, top5_datasets.psid_plus ) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 4.154: FIGURE C13. Outcome Weights using NSW Data Figure 4.155: FIGURE C13. Outcome Weights using NSW Data Figure 4.156: FIGURE C13. Outcome Weights using NSW Data Figure 4.157: FIGURE C13. Outcome Weights using NSW Data #evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat_var = treat, estimator = &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 4.7: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) NSW-Experimental 1 -1 (B) NSW-CPS1 1 -1 (C) NSW-PSID1 1 -1 (D) Trimmed NSW-CPS1 1 -1 (E) Trimmed NSW-PSID1 1 -1 (F) Top CPS1: mahvars 1 -1 (G) Top CPS1: card 1 -1 (H) Top CPS1: ps_threshold 1 -1 (I) Top CPS1: overlap_crump 1 -1 (J) Top CPS1: adap_weight_trunc_ipw_weight 1 -1 (K) Top PSID1: card 1 -1 (L) Top PSID1: fix_max_value_trunc_overlap_weight 1 -1 (M) Top PSID1: overlap_weight 1 -1 (N) Top PSID1: at_perc_trunc_overlap_weight 1 -1 (O) Top PSID1: mahvars 1 -1 #save results save_ow(ow_att, plot_titles, prefix = &quot;nsw&quot;) Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. A placebo test is not performed as the NSW data comes from a randomized controlled trial (RCT), which ensures internal validity and unbiased treatment effect estimates, without confounding. 4.8 Validation through sensitivity analyses # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets datasets_sens &lt;- c(list(nsw, nsw_cps, nsw_psid), top5_datasets.cps_plus, top5_datasets.psid_plus) filtered_datasets_sens &lt;- check_filter_datasets(datasets_sens, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx]) } Figure 4.158: FIGURE C14. Sensitivity Analyses NSW Figure 4.159: FIGURE C14. Sensitivity Analyses NSW Figure 4.160: FIGURE C14. Sensitivity Analyses NSW Figure 4.161: FIGURE C14. Sensitivity Analyses NSW # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;nsw&quot;) The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of re78. 4.9 Summary After reexamining the original LaLonde (NSW) dataset, the results confirm that the NSW-Experimental data shows nearly perfect overlap between treated and control groups, while the observational datasets (NSW-CPS1 and NSW-PSID1) display weak overlap, with many treated units outside the control range. Expanding these datasets with experimental controls improves overlap but does not consistently enhance covariate balance. These findings reinforce the lessons from previous LDW analyses: even with improved overlap and some gains in covariate balance, achieving consistent and reliable effect estimation remains difficult, especially with non-experimental data. The results highlight the persistent limitations of observational samples in replicating experimental benchmarks. "],["lalonde-calónico-smith-lcs-data.html", "Chapter 5 LaLonde-Calónico-Smith (LCS) Data 5.1 Set up 5.2 Improving primarily covariate balance 5.3 Improving primarily overlap 5.4 Reassessing methods 5.5 Integrated methods 5.6 Estimating 5.7 Validation through placebo analyses 5.8 Validation through sensitivity analyses 5.9 Summary", " Chapter 5 LaLonde-Calónico-Smith (LCS) Data This section (5) examines the LaLonde female samples reconstructed by Calónico and Smith (2017), referred to as the LaLonde-Calónico-Smith (LCS) sample (loaded as lcs below, similar to Imbens and Xu (2024)). For detailed explanations of the analysis steps and tips, please refer to section 2. Here, we only present and explain the LCS–specific results. 5.1 Set up 5.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lcs.RData&quot;) # set seed set.seed(42) 5.1.2 Load and preprocess data # expc = 0: experimental treated; # expc = 1: experimental control; # expc = 2: psid control; lcs_psid$expc &lt;- 0 lcs_psid[lcs_psid$treat==0, ]$expc &lt;- 2 lcs_tr &lt;- lcs[lcs$treat==1, ] lcs_co &lt;- lcs[lcs$treat==0, ] lcs_co$treat &lt;- 1 lcs_co$expc &lt;- 1 lcs_psid_plus &lt;- rbind.data.frame(lcs_psid, lcs_co) 5.1.3 Inspect data # collect datasets in a list data &lt;- list(lcs = lcs, lcs_psid = lcs_psid, lcs_psid_plus = lcs_psid_plus) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 5.1: Summary Statistics dataset num_obs num_vars name_vars lcs 1185 11 re79, treat, age, educ, nodegree, married, black, hisp, nchildren75, re75, u75 lcs_psid 1248 12 re79, treat, age, educ, nodegree, married, black, hisp, nchildren75, re75, u75, expc lcs_psid_plus 1833 12 re79, treat, age, educ, nodegree, married, black, hisp, nchildren75, re75, u75, expc # define variables Y &lt;- &quot;re79&quot; treat &lt;- &quot;treat&quot; # redefine covariates: removing &quot;nchildren75&quot; to be used as placebo outcome covar &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) In the following analysis, only PSID1 data is used as the original LaLonde study and its reconstruction by Calónico and Smith (2017) designate PSID1 as the appropriate nonexperimental control group for women, providing a comparable observational dataset that aligns with the experimental sample’s characteristics. 5.1.4 Assessing overlap and covariate balance 5.1.4.1 Overlap # assess overlap lcs.ps &lt;- assess_overlap(data = lcs, treat = treat, cov = covar, xlim = c(-1.5, 1.5), breaks = 40) Figure 5.1: FIGURE1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1. lcs_psid.ps &lt;- assess_overlap(data = lcs_psid, treat = treat, cov = covar, xlim = c(-11, 7), breaks = 40) Figure 5.2: FIGURE1. SubfigureA:LCS-Experimental. SubfigureB:LCS-PSID1. As anticipated, the LCS-Experimental data exhibit an almost perfect overlap. In contrast, the observational dataset LCS-PSID1 displays weak overlap. # assess overlap lcs_psid_plus.ps &lt;- assess_overlap(data = lcs_psid_plus, treat = treat, cov = covar, xlim = c(-15, 5)) Figure 5.3: FIGURE2. SubfigureC:LCS-PSID1-PLUS. With the expanded dataset LCS-PSID1, it is evident that the degree of overlap between treated and control groups has improved, as seen by a greater spread of log-odds densities across both samples. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 5.1.4.2 Covariate balance love.plot(lcs, lcs_psid, treat, covar = covar, title = &quot;LCS-PSID1&quot;) love.plot(lcs, lcs_psid_plus, treat, covar = covar, title = &quot;LCS-PSID1-PLUS&quot;) Due to computational constraints, we use a reduced set of matching methods, consistent with previous sections. 5.2 Improving primarily covariate balance 5.2.1 Matching 5.2.1.1 Distance Matching 5.2.1.1.1 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.psid_plus.optimal_pair &lt;- matchit(model, data = lcs_psid_plus, method = &quot;optimal&quot;, distance = &quot;logit&quot;) 5.2.1.1.2 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.psid_plus.optimal_full &lt;- matchit(model, data = lcs_psid_plus, method = &quot;full&quot;, distance = &quot;logit&quot;) 5.2.1.1.3 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.psid_plus.general_full &lt;- matchit(model, data = lcs_psid_plus, method = &quot;quick&quot;, distance = &quot;logit&quot;) 5.2.1.2 Stratum matching 5.2.1.2.1 Coarsened matching (cem) Strata = coarsened versions of covariates # match units exactly within coarse strata m.out.psid_plus.cem &lt;- matchit(model, data = lcs_psid_plus, method = &quot;cem&quot;) 5.2.1.2.2 Subclassification Strata = bins of the propensity score # partition sample into fixed number of bins based on propensity score m.out.psid_plus.subcl &lt;- matchit(model, data = lcs_psid_plus, method = &quot;subclass&quot;, subclass = 5) 5.2.1.3 Pure subset selection 5.2.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances m.out.psid_plus.card &lt;- matchit(model, data = lcs_psid_plus, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1) 5.2.1.3.2 Profile matching # matching by directly optimizing balance profile measures across covariates m.out.psid_plus.profile &lt;- matchit_profile(lcs_psid_plus, treat, covar) 5.2.2 Weighting 5.2.2.1 Inverse probability weights (IPW) # compute weights as inverse of estimated propensity scores w.out.psid_plus.ipw &lt;- weightit(model, data = lcs_psid_plus, method = &quot;ps&quot;, estimand = &quot;ATT&quot;) lcs_psid_plus$ipw_weight &lt;- w.out.psid_plus.ipw$weights 5.2.2.2 Standardized mortality ratio (SMR) treated weights # calculate weights for ATT by assigning weight = 1 to treated units and weights proportional to odds of treatment for control lcs_psid_plus$smr_weight &lt;- create_smr_weights(lcs_psid_plus, model, &quot;ATT&quot;) 5.2.2.3 Matching weights # derive optimal matching weights intending to minimize covariate imbalance while targeting ATT w.out.psid_plus.opt &lt;- weightit(model, data = lcs_psid_plus, method = &quot;optweight&quot;, estimand = &quot;ATT&quot;) lcs_psid_plus$opt_weight &lt;- w.out.psid_plus.opt$weights 5.2.2.4 Overlap weights # calculate overlap weights emphasizing units with propensity scores near 0.5 lcs_psid_plus$overlap_weight &lt;- create_overlap_weights(lcs_psid_plus, model) 5.2.2.5 Entropy weights # compute entropy balancing weights w.out.psid_plus.ebal &lt;- weightit(model, data = lcs_psid_plus, method = &quot;ebal&quot;, estimand = &quot;ATT&quot;) lcs_psid_plus$ebal_weight &lt;- w.out.psid_plus.ebal$weights 5.3 Improving primarily overlap 5.3.1 Truncation # list of weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;smr_weight&quot;, &quot;opt_weight&quot;, &quot;overlap_weight&quot;, &quot;ebal_weight&quot;) 5.3.1.1 Fixed maximum value truncation # truncate weights by imposing a maximum threshold of 10 lcs_psid_plus.fixed &lt;- lcs_psid_plus for (wcol in weight_columns) { if (wcol %in% names(lcs_psid_plus.fixed)) { lcs_psid_plus.fixed &lt;- truncate_weights_fixed(lcs_psid_plus.fixed, weight_col = wcol, max_weight = 10) } } 5.3.1.2 At percentile truncation # truncate weights such that values above the 99th percentile are capped lcs_psid_plus.percent &lt;- lcs_psid_plus for (wcol in weight_columns) { if (wcol %in% names(lcs_psid_plus.percent)) { lcs_psid_plus.percent &lt;- truncate_weights_percentile(lcs_psid_plus.percent, weight_col = wcol, percentile = 0.99) } } 5.3.1.3 Adaptive weight truncation psid_results &lt;- list() for (wcol in weight_columns) { if (wcol %in% names(lcs_psid_plus)) { psid_results[[wcol]] &lt;- check_weights(lcs_psid_plus, wcol) } else { warning(paste(&quot;Column&quot;, wcol, &quot;not found in lcs_psid_plus&quot;)) } } var_psid_table &lt;- bind_rows(psid_results) knitr::kable(var_psid_table, caption = &quot;Variance of Weights&quot;) Table 5.2: Variance of Weights Weight_Column Variance ipw_weight 4.8724784 smr_weight 5.7407460 opt_weight 0.8335116 overlap_weight 0.0620253 ebal_weight 1.0000674 Regarding these results we can apply adaptive weight truncation to all considered weights. # truncate adaptively at mean + 3 standard deviations lcs_psid_plus.adapt &lt;- lcs_psid_plus for (wcol in weight_columns) { if (wcol %in% names(lcs_psid_plus.adapt)) { lcs_psid_plus.adapt &lt;- truncate_weights_adaptive(lcs_psid_plus.adapt, weight_col = wcol, c = 3) } } 5.3.2 Trimming 5.3.2.1 Propensity score threshold trimming (Similar to tutorial of Imbens and Xu (2024)) # apply trimming with threshold 0.9 lcs_psid_trim &lt;- ps_trim(lcs_psid_plus.ps, threshold = 0.9) # exclude experimental controls, subset trimmed data appropriately lcs_psid.trim_match &lt;- subset(lcs_psid_trim, expc %in% c(0,2) &amp; ps_assoverlap) # re-estimate propensity scores on trimmed data and perform 1:1 matching lcs_psid.trim_match &lt;- psmatch(data = lcs_psid.trim_match, Y = &quot;re79&quot;, treat = &quot;treat&quot;, cov = covar) # trim experimental data and re-assign treat variable for controls in sample 3 or 4 (non-treated group) #lcs_trim_psid &lt;- subset(lcs_psid_trim, expc %in% c(0, 1)) #lcs_trim_psid$treat[lcs_trim_psid$expc == 1] &lt;- 0 5.3.2.2 Common range trimming # trim observations outside the common support region of propensity scores lcs_psid_plus.common &lt;- common_range_trim(lcs_psid_plus.ps) 5.3.2.3 Propensity score trimming (Crump) # trim observations with propensity scores outside [0.1, 0.9] interval lcs_psid_plus.crump &lt;- crump_trim(lcs_psid_plus.ps, lower = 0.1, upper = 0.9) 5.3.2.4 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control lcs_psid_plus.stuermer &lt;- stuermer_trim(lcs_psid_plus.ps) 5.3.2.5 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations lcs_psid_plus.walker &lt;- walker_trim(lcs_psid_plus.ps) 5.3.3 Combination of methods # list trimming methods trim_names &lt;- c(&quot;ps_threshold&quot;, &quot;common_range&quot;, &quot;stuermer&quot;, &quot;walker&quot;, &quot;crump&quot;) trimmed_psid &lt;- list(ps_threshold = lcs_psid_trim, common_range = lcs_psid_plus.common, stuermer = lcs_psid_plus.stuermer, walker = lcs_psid_plus.walker, crump = lcs_psid_plus.crump) 5.3.3.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, &quot;ipw_weight&quot;)), trim_names ) 5.3.3.2 SMR treated weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply standardized mortality ratio (SMR) weighting with trimming and attach SMR weights smr_treat_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, &quot;smr_weight&quot;)), trim_names ) 5.3.3.3 Overlap weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply overlap weighting with trimming and attach overlap weights ov_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, &quot;overlap_weight&quot;)), trim_names ) 5.3.3.4 Entropy weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights entropy_comb.psid_plus &lt;- setNames( lapply(trim_names, function(nm) trim_attach_weights(trimmed_psid[[nm]], lcs_psid_plus, &quot;ebal_weight&quot;)), trim_names ) 5.4 Reassessing methods 5.4.1 Matching # list all matching methods methods.psid_plus &lt;- list( optimal_pair = m.out.psid_plus.optimal_pair, optimal_full = m.out.psid_plus.optimal_full, gen_full = m.out.psid_plus.general_full, cem = m.out.psid_plus.cem, card = m.out.psid_plus.card, profile = m.out.psid_plus.profile, subcl = m.out.psid_plus.subcl ) 5.4.1.1 SMD # compute SMD smd_matchit.psid_plus &lt;- compute_abs_smd_matchit(methods.psid_plus) 5.4.1.2 ESS # calculate balance statistics bal.psid_plus &lt;- cobalt::bal.tab(model, data = lcs_psid_plus, un = TRUE, weights = methods.psid_plus, s.d.denom = &quot;treated&quot;) # compute effective sample sizes (ESS) ess_matchit.psid_plus &lt;- compute_ess_matchit(bal.psid_plus) 5.4.1.3 Visuals # visualize covariate balance plot_matchit(methods.psid_plus, &quot;LCS-PSID1-PLUS&quot;) Figure 5.4: FIGURE3. Figure 5.5: FIGURE3. Figure 5.6: FIGURE3. Figure 5.7: FIGURE3. Figure 5.8: FIGURE3. Figure 5.9: FIGURE3. Figure 5.10: FIGURE3. 5.4.2 Weighting # list all weights weight.psid_plus &lt;- list( ipw = lcs_psid_plus$ipw_weight, smr_tr = lcs_psid_plus$smr_weight, mw = lcs_psid_plus$opt_weight, ow = lcs_psid_plus$overlap_weight, ew = lcs_psid_plus$ebal_weight ) 5.4.2.1 SMD # compute SMD smd_weight.psid_plus &lt;- compute_abs_smd_weight(lcs_psid_plus, &quot;treat&quot;, covar, weight_columns) 5.4.2.2 ESS # compute ESS ess_weight.psid_plus &lt;- compute_ess_weight(lcs_psid_plus, &quot;treat&quot;, covar, weight_columns) 5.4.2.3 Visuals # visualize covariate balance plot_weighting_methods(lcs_psid_plus, &quot;treat&quot;, covar, weight.psid_plus, &quot;LCS-PSID1-PLUS&quot;) Figure 5.11: FIGURE4. Figure 5.12: FIGURE4. Figure 5.13: FIGURE4. Figure 5.14: FIGURE4. Figure 5.15: FIGURE4. 5.4.3 Truncation # list truncation methods trunc.psid_plus &lt;- list( fix_max_value_trunc.psid_plus = lcs_psid_plus.fixed, at_perc_trunc.psid_plus = lcs_psid_plus.percent, adap_weight_trunc.psid_plus = lcs_psid_plus.adapt ) 5.4.3.1 SMD # compute SMD smd_trunc.psid_plus &lt;- compute_abs_smd_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 5.4.3.2 ESS # compute ESS ess_trunc.psid_plus &lt;- compute_ess_trunc(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns) 5.4.3.3 Visuals # visualize covariate balance plot_trunc_methods(trunc.psid_plus, &quot;treat&quot;, covar, weight_columns, &quot;LCS-PSID-PLUS&quot;) Figure 5.16: FIGURE5. Figure 5.17: FIGURE5. Figure 5.18: FIGURE5. Figure 5.19: FIGURE5. Figure 5.20: FIGURE5. Figure 5.21: FIGURE5. Figure 5.22: FIGURE5. Figure 5.23: FIGURE5. Figure 5.24: FIGURE5. Figure 5.25: FIGURE5. Figure 5.26: FIGURE5. Figure 5.27: FIGURE5. Figure 5.28: FIGURE5. Figure 5.29: FIGURE5. Figure 5.30: FIGURE5. 5.4.4 Trimming # list trimming object trim.psid_plus &lt;- list( original = lcs_psid_plus, ps_threshold = lcs_psid.trim_match, common_range = lcs_psid_plus.common, crump = lcs_psid_plus.crump, stuermer = lcs_psid_plus.stuermer, walker = lcs_psid_plus.walker ) 5.4.4.1 SMD # compute SMD smd_trim.psid_plus &lt;- compute_abs_smd_trim(trim.psid_plus, &quot;treat&quot;, covar) 5.4.4.2 ESS # compute ESS ess_trim.psid_plus &lt;- compute_ess_trim(trim.psid_plus, &quot;treat&quot;, covar) 5.4.4.3 Visuals # visualize overlap plot_trim(trim.psid_plus, treat, covar) ## -6.793963 4.127747 ## -2.367007 2.208048 ## -1.765086 3.756502 ## -2.130258 3.494321 ## -0.4104685 3.304617 ## -0.6819315 3.071009 Figure 5.31: FIGURE6. # visualize covariate balance love.plot(lcs_psid, lcs_psid.trim_match, treat, covar = covar, title = &quot;LCS-PSID1-PLUS - propensity threshold trimming&quot;) Figure 5.32: FIGURE7. love.plot(lcs_psid, lcs_psid_plus.common, treat, covar, title = &quot;LCS-PSID1-PLUS - common range trimming&quot;) Figure 5.33: FIGURE7. love.plot(lcs_psid, lcs_psid_plus.crump, treat, covar, title = &quot;LCS-PSID1-PLUS - crump trimming&quot;) Figure 5.34: FIGURE7. love.plot(lcs_psid, lcs_psid_plus.stuermer, treat, covar, title = &quot;LCS-PSID1-PLUS - stuermer trimming&quot;) Figure 5.35: FIGURE7. love.plot(lcs_psid, lcs_psid_plus.walker, treat, covar, title = &quot;LCS-PSID1-PLUS - walker trimming&quot;) Figure 5.36: FIGURE7. 5.5 Integrated methods # list all combined method results comb_meth.psid_plus &lt;- list( ipw = ipw_comb.psid_plus, smr_treated = smr_treat_comb.psid_plus, overlap = ov_comb.psid_plus, entropy = entropy_comb.psid_plus ) 5.5.0.1 SMD # compute SMD smd_all_comb_meth.psid_plus &lt;- compute_smd_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 5.5.0.2 ESS # compute ESS ess_all_comb_meth.psid_plus &lt;- compute_ess_all_datasets(comb_meth.psid_plus, &quot;treat&quot;, covar) 5.5.0.3 Visuals # visualize overlap plot_comb_overlap(comb_meth_psid = comb_meth.psid_plus, treat = &quot;treat&quot;, covar = covar, prefix_psid = &quot;LCS-PSID1&quot;) ## -6.174843 3.35259 ## -1.773306 3.616391 ## -0.3876292 3.26982 ## -0.7134889 3.014494 Figure 5.37: FIGURE A8. ## -2.124707 3.514165 ## -6.174843 3.35259 ## -1.773306 3.616391 ## -0.3876292 3.26982 Figure 5.38: FIGURE A8. ## -0.7134889 3.014494 ## -2.124707 3.514165 ## -6.174843 3.35259 ## -1.773306 3.616391 Figure 5.39: FIGURE A8. ## -0.3876292 3.26982 ## -0.7134889 3.014494 ## -2.124707 3.514165 ## -6.174843 3.35259 Figure 5.40: FIGURE A8. ## -1.773306 3.616391 ## -0.3876292 3.26982 ## -0.7134889 3.014494 ## -2.124707 3.514165 Figure 5.41: FIGURE A8. # visualize covariate balance plot_comb_love_plots(comb_meth_psid = comb_meth.psid_plus, treat = &quot;treat&quot;, covar = covar, prefix_cps = &quot;LCS-PSID1&quot;) Figure 5.42: FIGURE A9. Figure 5.43: FIGURE A9. Figure 5.44: FIGURE A9. Figure 5.45: FIGURE A9. Figure 5.46: FIGURE A9. Figure 5.47: FIGURE A9. Figure 5.48: FIGURE A9. Figure 5.49: FIGURE A9. Figure 5.50: FIGURE A9. Figure 5.51: FIGURE A9. Figure 5.52: FIGURE A9. Figure 5.53: FIGURE A9. Figure 5.54: FIGURE A9. Figure 5.55: FIGURE A9. Figure 5.56: FIGURE A9. Figure 5.57: FIGURE A9. Figure 5.58: FIGURE A9. Figure 5.59: FIGURE A9. Figure 5.60: FIGURE A9. Figure 5.61: FIGURE A9. # save results save_comb_hist(comb_meth_psid = comb_meth.psid_plus, treat = &quot;treat&quot;, covar = covar, prefix = &quot;lcs&quot;, prefix_psid = &quot;LCS-PSID1&quot;) save_comb_loveplots(comb_meth_psid = comb_meth.psid_plus, treat = &quot;treat&quot;, covar = covar, prefix = &quot;lcs&quot;, prefix_cps = &quot;LCS-CPS1&quot;) 5.5.1 Top methods and datasets # combine all results all_psid_plus &lt;- combine_results(&quot;psid_plus&quot;) # save results save_csv(all_psid_plus, &quot;PSID1_PLUS_all_results_lcs&quot;) # get top 5 methods ranked_psid_plus &lt;- assess_methods(all_psid_plus) top5_methods.psid_plus &lt;- get_top_methods(ranked_psid_plus, top_n = 5) # print results top5_methods_df.psid_plus &lt;- ranked_psid_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.psid_plus, caption = &quot;Top 5 Methods&quot;, booktabs = TRUE) Table 5.3: Top 5 Methods Method Score card 0.7935529 adap_weight_trunc_overlap_weight 0.7382676 fix_max_value_trunc_overlap_weight 0.7382676 overlap_weight 0.7382676 at_perc_trunc_overlap_weight 0.7382002 # save results save_csv(top5_methods.psid_plus, &quot;PSID1_PLUS_top5_methods_lcs&quot;) The table shows that CPS1 and PSID1 share the same top five methods, with the exception of one differing method and a variation in their ordering for PSID1. dataset_list_psid &lt;- list( &quot;All&quot; = lcs_psid_plus, &quot;original&quot; = lcs_psid_plus, &quot;card&quot; = m.out.psid_plus.card, &quot;optimal_full&quot; = m.out.psid_plus.optimal_full, &quot;optimal_pair&quot; = m.out.psid_plus.optimal_pair, &quot;gen_full&quot; = m.out.psid_plus.general_full, &quot;subcl&quot; = m.out.psid_plus.subcl, &quot;profile&quot; = m.out.psid_plus.profile, &quot;ipw_weight&quot; = lcs_psid_plus$ipw_weight, &quot;smr_weight&quot; = lcs_psid_plus$smr_weight, &quot;opt_weight&quot; = lcs_psid_plus$opt_weight, &quot;overlap_weight&quot; = lcs_psid_plus$overlap_weight, &quot;ebal_weight&quot; = lcs_psid_plus$ebal_weight, &quot;fix_max_value_trunc_ebal_weight&quot; = lcs_psid_plus.fixed, &quot;fix_max_value_trunc_ipw_weight&quot; = lcs_psid_plus.fixed, &quot;fix_max_value_trunc_opt_weight&quot; = lcs_psid_plus.fixed, &quot;fix_max_value_trunc_overlap_weight&quot; = lcs_psid_plus.fixed, &quot;fix_max_value_trunc_smr_weight&quot; = lcs_psid_plus.fixed, &quot;at_perc_trunc_ebal_weight&quot; = lcs_psid_plus.percent, &quot;at_perc_trunc_ipw_weight&quot; = lcs_psid_plus.percent, &quot;at_perc_trunc_opt_weight&quot; = lcs_psid_plus.percent, &quot;at_perc_trunc_overlap_weight&quot; = lcs_psid_plus.percent, &quot;at_perc_trunc_smr_weight&quot; = lcs_psid_plus.percent, &quot;adap_weight_trunc_ebal_weight&quot; = lcs_psid_plus.adapt, &quot;adap_weight_trunc_ipw_weight&quot; = lcs_psid_plus.adapt, &quot;adap_weight_trunc_opt_weight&quot; = lcs_psid_plus.adapt, &quot;adap_weight_trunc_overlap_weight&quot; = lcs_psid_plus.adapt, &quot;adap_weight_trunc_smr_weight&quot; = lcs_psid_plus.adapt, &quot;ps_threshold&quot; = lcs_psid.trim_match, &quot;common_range&quot; = lcs_psid_plus.common, &quot;stuermer&quot; = lcs_psid_plus.stuermer, &quot;walker&quot; = lcs_psid_plus.walker, &quot;crump&quot; = lcs_psid_plus.crump, &quot;ipw_common_range&quot; = ipw_comb.psid_plus[[1]], &quot;ipw_crump&quot;= ipw_comb.psid_plus[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid_plus[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid_plus[[4]], &quot;ipw_walker&quot; = ipw_comb.psid_plus[[5]], &quot;smr_treated_common_range&quot; = smr_treat_comb.psid_plus[[1]], &quot;smr_treated_crump&quot;= smr_treat_comb.psid_plus[[2]], &quot;smr_treated_ps_threshold&quot; = smr_treat_comb.psid_plus[[3]], &quot;smr_treated_stuermer&quot; = smr_treat_comb.psid_plus[[4]], &quot;smr_treated_walker&quot; = smr_treat_comb.psid_plus[[5]], &quot;overlap_common_range&quot; = ov_comb.psid_plus[[1]], &quot;overlap_crump&quot; = ov_comb.psid_plus[[2]], &quot;overlap_ps_threshold&quot; = ov_comb.psid_plus[[3]], &quot;overlap_stuermer&quot; = ov_comb.psid_plus[[4]], &quot;overlap_walker&quot;= ov_comb.psid_plus[[5]], &quot;entropy_common_range&quot; = entropy_comb.psid_plus[[1]], &quot;entropy_crump&quot; = entropy_comb.psid_plus[[2]], &quot;entropy_ps_threshold&quot; = entropy_comb.psid_plus[[3]], &quot;entropy_stuermer&quot; = entropy_comb.psid_plus[[4]], &quot;entropy_walker&quot; = entropy_comb.psid_plus[[5]]) # create the datasets from combined lists for your top 5 methods: top5_datasets.psid_plus &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid_plus) # save them into .RData files save_top5_individual_files(dataset_list_psid, top5_methods.psid_plus, prefix = &quot;lcs_psid&quot;) 5.6 Estimating 5.6.1 Average treatment effect on the treated (ATT) # get estimates out1 &lt;- estimate_all(lcs, &quot;re79&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(lcs_psid, &quot;re79&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(lcs_psid.trim_match, &quot;re79&quot;, &quot;treat&quot;, covar) out.psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, &quot;re79&quot;, &quot;treat&quot;, covar)) out4 &lt;- out.psid_plus[[1]] out5 &lt;- out.psid_plus[[2]] out6 &lt;- out.psid_plus[[3]] out7 &lt;- out.psid_plus[[4]] out8 &lt;- out.psid_plus[[5]] # build plot titles base_titles &lt;- c(&quot;(A) LCS-Experimental&quot;, &quot;(B) LCS-PSID1&quot; , &quot;(C) Trimmed LCS-PSID1&quot;) top_start &lt;- 4 # D is 4th letter num_psid &lt;- length(top5_methods.psid_plus) top_letters_psid &lt;- LETTERS[top_start:(top_start + num_psid - 1)] top5_titles.psid_plus &lt;- paste0(&quot;(&quot;, top_letters_psid, &quot;) Top PSID1: &quot;, top5_methods.psid_plus) plot_titles &lt;- c(base_titles, top5_titles.psid_plus) # combine all results all_outs &lt;- c(list(out1, out2, out3), out.psid_plus) # plot results band &lt;- out1[1, 3:4] est &lt;- out1[1, 1] plot_att_panels(all_outs, plot_titles, band, est, ylim = c(-15500, 5500), textsize = 0.7) Figure 5.62: FIGURE 10. ATT Estimates Given Unconfoundedness using LCS Samples Figure 5.63: FIGURE 10. ATT Estimates Given Unconfoundedness using LCS Samples # save results save_att_panels(all_outs, plot_titles, band, est, &quot;lcs&quot;) The above figures show the ATT estimates and their 95% confidence intervals for eight samples: LCS-Experimental, LCS-PSID1, a trimmed version of the LCS-PSID1 sample (analogous to Imbens and Xu (2024)) and a series of top-ranked subsamples of LCS-PSID1 based on various matching, weighting, truncation and trimming criteria. Figure (A) presents the benchmark from the experimental sample (LCS-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) shows results for the observational sample LCS-PSID1 and figure (C) for its trimmed version, replicating the tutorial results of Imbens &amp; Xu (2024). Figures (D) through (H) display results for PSID1-based subsamples. Across the LCS-PSID1 dataset and its top-ranked subsamples, all estimators yield ATT estimates that largely cluster around the experimental benchmark except Diff-in-Means, which tends to produce estimates that deviate more noticeably from the benchmark. # prepare all results in the order shown in the plots all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- plot_titles knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) Table 5.4: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate (A) LCS-Experimental 296.2033 782.8049 1059.0663 276.2614 (B) LCS-PSID1 404.2344 -4172.1762 1228.6598 5400.8360 (C) Trimmed LCS-PSID1 415.5071 -848.9421 1126.9783 1975.9204 (D) Top PSID1: card 396.7480 -456.3466 -119.1435 337.2030 (E) Top PSID1: adap_weight_trunc_overlap_weight 367.6119 -4577.7195 986.9403 5564.6598 (F) Top PSID1: fix_max_value_trunc_overlap_weight 367.5901 -4577.7195 986.9403 5564.6598 (G) Top PSID1: overlap_weight 356.4673 -4577.7195 986.9403 5564.6598 (H) Top PSID1: at_perc_trunc_overlap_weight 367.5901 -4577.7195 986.9403 5564.6598 # get result matrix result_mat &lt;- create_matrix_results(all_outs, plot_titles) knitr::kable(result_mat, booktabs = TRUE, caption = &quot;ATT Estimates and SEs&quot;) Table 5.5: ATT Estimates and SEs (A) LCS-Experimental (B) LCS-PSID1 (C) Trimmed LCS-PSID1 (D) Top PSID1: card (E) Top PSID1: adap_weight_trunc_overlap_weight (F) Top PSID1: fix_max_value_trunc_overlap_weight (G) Top PSID1: overlap_weight (H) Top PSID1: at_perc_trunc_overlap_weight Experimental Benchmark 821.49 (307.89) -4172.18 (412.18) -848.94 (419.03) -313.44 (407.40) -4577.72 (377.25) -4577.72 (377.25) -4577.72 (377.25) -4577.72 (377.25) diff 821.49 (307.89) -4172.18 (412.18) -848.94 (419.03) -313.44 (407.40) -4577.72 (377.25) -4577.72 (377.25) -4577.72 (377.25) -4577.72 (377.25) reg 848.63 (303.41) 808.44 (389.48) 390.74 (415.74) -286.82 (387.76) 152.92 (342.69) 152.92 (342.69) 152.92 (342.69) 152.92 (342.69) om.reg 895.65 (230.21) 1128.29 (239.37) 655.41 (293.53) -245.12 (282.98) 739.76 (164.55) 739.76 (164.55) 739.76 (164.55) 739.76 (164.55) om.grf 869.18 (230.14) 937.89 (238.14) 470.63 (295.81) -384.52 (280.74) 463.70 (163.34) 484.83 (163.45) 484.83 (163.45) 484.83 (163.45) matching 1059.07 (320.55) 1036.86 (531.41) 540.05 (533.76) -456.35 (508.65) 681.42 (482.73) 681.42 (482.73) 681.42 (482.73) 681.42 (482.73) psm 782.80 (306.86) 728.12 (336.80) 1126.98 (378.48) -119.14 (401.91) 562.69 (233.34) 569.19 (232.97) 569.19 (232.97) 569.19 (232.97) ipw 914.46 (313.97) 978.91 (471.60) 570.32 (465.21) -313.44 (407.40) 919.66 (465.91) 919.66 (465.91) -87.61 (364.42) 919.66 (465.91) cbps 896.05 (304.69) 1216.52 (429.26) 730.25 (435.65) -313.44 (407.40) 849.28 (396.39) 849.28 (396.39) -87.61 (364.42) 849.28 (396.39) ebal 896.09 (304.69) 1228.66 (429.73) 732.89 (436.94) -224.33 (411.01) 850.40 (396.48) 850.40 (396.48) 850.40 (396.48) 850.40 (396.48) dml 787.78 (300.62) 813.84 (387.60) 406.80 (414.78) -292.46 (385.28) 155.06 (340.94) 155.06 (340.94) 155.06 (340.94) 155.06 (340.94) aipw_grf 935.73 (313.81) 1070.38 (498.86) 486.96 (461.06) -356.14 (468.80) 958.14 (505.34) 958.14 (505.34) 958.14 (505.34) 958.14 (505.34) aipw_ow 833.45 (317.61) 1127.15 (486.38) 521.14 (436.08) -254.22 (411.64) 986.94 (542.37) 986.94 (542.37) 986.94 (542.37) 986.94 (542.37) The tabulated results confirm visual patterns: Column (A) reports the estimates for the LCS-Experimental sample, column (B) for the LCS-PSID1 sample, and column (C) for its trimmed version. Columns (D)-(H) show results of the top-ranked subsample of LCS-PSID1. For all PSID1-based samples, the ATT estimates remain overly positive. However, the estimates obtained with the Diff-in-Means estimator are consistently negative. Likewise, for the sample constructed with the card method, the estimates remain negative across all estimators. # save results save_csv(result_mat, &quot;LCS_att_estimates&quot;) 5.6.2 Conditional average treatment effect on the treated (CATT) catt.lcs &lt;- catt(lcs, Y, treat, covar) catt.psid &lt;- catt(lcs_psid, Y, treat, covar) catt.psid.trim &lt;- catt(lcs_psid.trim_match, Y, treat, covar) catt.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) catt(d, Y, treat, covar)) # combine all catt objects all_catt &lt;- c(list(catt.lcs,catt.psid, catt.psid.trim), catt.top5_psid_plus) # plot results par(mfrow = c(2,2)) par(cex.main = 0.8) plot_catt_panels(all_catt, plot_titles) Figure 5.64: FIGURE 11. CATT Estimates using LCS Data Figure 5.65: FIGURE 11. CATT Estimates using LCS Data all_catt_eval &lt;- eval_catt(all_catt, plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) Table 5.6: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) LCS-Experimental -359.430 2719.135 863.5073 3078.565 (B) LCS-PSID1 -3357.477 2404.333 802.2476 5761.810 (C) Trimmed LCS-PSID1 -3180.260 2485.600 298.2523 5665.860 (D) Top PSID1: card -2868.709 2266.442 -415.7054 5135.151 (E) Top PSID1: adap_weight_trunc_overlap_weight -3768.323 2245.871 423.4495 6014.194 (F) Top PSID1: fix_max_value_trunc_overlap_weight -3933.587 2281.324 430.5526 6214.911 (G) Top PSID1: overlap_weight -3870.814 2250.947 415.5800 6121.760 (H) Top PSID1: at_perc_trunc_overlap_weight -3823.429 2244.234 391.2748 6067.663 With LCS-PSID1, CATT estimates span from $-3,357.48 to $2,404.33, contrasting with the CATT estimated from experimental data which ranges from $-359.43 to $2,719.14, with a mean CATT estimate of $863.51. In contract, across the LCS-PSID1-based subsamples, the ranges of CATT estimates are relatively similar. Importantly, the mean CATT estimates remain positive in all cases, except for card subsample, that produces a mean CATT estimate of $-415.71. # save results save_catt_panels(all_catt, plot_titles, prefix = &quot;lcs&quot;) 5.6.3 Quantile treatment effect on the treated (QTET) qte.lcs &lt;- est_qte(Y, treat, covar, data = lcs, cores = 4) qte.lcs_psid &lt;- est_qte(Y, treat, covar, data = lcs_psid) qte.lcs_psid.trim &lt;- est_qte(Y, treat, covar, data = lcs_psid.trim_match) qte.top5_psid_plus &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, covar, data = d)) qte.lcs0 &lt;- est_qte(Y, treat, NULL, data = lcs) qte.lcs_psid0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid) qte.lcs_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = lcs_psid.trim_match) qte.top5_psid_plus0 &lt;- lapply(top5_datasets.psid_plus, function(d) est_qte(Y, treat, NULL, data = d)) par(mfrow = c(2,2)) par(cex.main = 0.8) # PSID plot_qte(qte.lcs_psid, qte.lcs_psid0, qte.lcs, main = &quot;(B) LCS-PSID&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID trimmed plot_qte(qte.lcs_psid.trim, qte.lcs_psid.trim0, qte.lcs_psid, main = &quot;(C) LCS-PSID (Trimmed)&quot;, ylim = c(-25000, 15000)) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID top methods plot_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.lcs_psid, plot_titles, main_start = 2, ylim = c(-25000, 15000)) Figure 5.66: FIGURE C12. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental Figure 5.67: FIGURE C12. QTET Estimates Model A using NSW Data: Experimental vs. Nonexperimental These figures present QTET estimates obtained from LCS-Experimental sample and several observational samples. The QTETs estimated from both the original and trimmed LCS-PSID1 samples (B and C), as well as from the top-ranked subsamples (E through H), align comparatively close with the true QTET. However, the QTETs from subsample (F) exhibit a stronger bias, suggesting greater estimation uncertainty. plots_lcs &lt;- list( list(mod = qte.lcs_psid, mod0 = qte.lcs_psid0, bm = qte.lcs, main = &quot;(B) LCS PSID&quot;), list(mod = qte.lcs_psid.trim, mod0 = qte.lcs_psid.trim0, bm = qte.lcs_psid, main = &quot;(D) LCS PSID (Trimmed)&quot;) ) save_qtet(plots_lcs, prefix = &quot;lcs&quot;, ylim = c(-25000, 15000)) save_qte_top(qte.top5_psid_plus, qte.top5_psid_plus0, qte.lcs_psid, plot_titles, main_start = 4, ylim = c(-25000, 15000), prefix = &quot;lcs_top&quot;) 5.6.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c(list(lcs, lcs_psid, lcs_psid.trim_match), top5_datasets.psid_plus) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.8) # plot outcome weights distribution plot_ow(ow_att, plot_titles) Figure 5.68: FIGURE A14. Outcome Weights using LCS Data Figure 5.69: FIGURE A14. Outcome Weights using LCS Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, plot_titles, treat_var = treat, estimator = &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) Table 5.7: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated (A) LCS-Experimental 1 -1 (B) LCS-PSID1 1 -1 (C) Trimmed LCS-PSID1 1 -1 (D) Top PSID1: card 1 -1 (E) Top PSID1: adap_weight_trunc_overlap_weight 1 -1 (F) Top PSID1: fix_max_value_trunc_overlap_weight 1 -1 (G) Top PSID1: overlap_weight 1 -1 (H) Top PSID1: at_perc_trunc_overlap_weight 1 -1 Consistent with the preceding sections, the evaluation shows that, across each sample, the estimated outcome weights sum to one within the treated group and to minus one within the untreated group, yielding an overall total of zero. # save results save_ow(ow_att, plot_titles, prefix = &quot;lcs&quot;) 5.7 Validation through placebo analyses # define variables Y_pl &lt;- &quot;nchildren75&quot; treat &lt;- &quot;treat&quot; covar_pl &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) # estimate placebo ATT on original and observational datasets out1_pl &lt;- estimate_all(lcs, Y_pl, &quot;treat&quot;, covar_pl) out2_pl &lt;- estimate_all(lcs_psid, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on trimmed datasets (analogous to tutorial of @imbens2024) out3_pl &lt;- estimate_all(lcs_psid_trim, Y_pl, &quot;treat&quot;, covar_pl) # estimate placebo ATT on top ranked datasets out.psid_pl &lt;- lapply(top5_datasets.psid_plus, function(d) estimate_all(d, Y_pl, &quot;treat&quot;, covar_pl)) out4_pl &lt;- out.psid_pl[[1]] out5_pl &lt;- out.psid_pl[[2]] out6_pl &lt;- out.psid_pl[[3]] out7_pl &lt;- out.psid_pl[[4]] out8_pl &lt;- out.psid_pl[[5]] # collect all placebo results all_outs.pl &lt;- c(list(out1_pl, out2_pl, out3_pl), out.psid_pl) # plot placebo results band_pl &lt;- out1_pl[1, 3:4] est_pl &lt;- out1_pl[1, 1] ylim_pl = c(-1.5, 1) plot_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, ylim_pl, textsize = 0.7) Figure 5.70: FIGURE 13. Placebo Test LCS: Number of Children in 1975 as the Outcome Figure 5.71: FIGURE 13. Placebo Test LCS: Number of Children in 1975 as the Outcome # save results save_att_panels(all_outs.pl, plot_titles, band_pl, est_pl, &quot;lcs_placebo&quot;) result_mat_pl &lt;- create_matrix_results(all_outs.pl, plot_titles) knitr::kable(result_mat_pl, caption = &quot;Placebo ATT Estimates and SEs&quot;, booktabs = TRUE) Table 5.8: Placebo ATT Estimates and SEs (A) LCS-Experimental (B) LCS-PSID1 (C) Trimmed LCS-PSID1 (D) Top PSID1: card (E) Top PSID1: adap_weight_trunc_overlap_weight (F) Top PSID1: fix_max_value_trunc_overlap_weight (G) Top PSID1: overlap_weight (H) Top PSID1: at_perc_trunc_overlap_weight Experimental Benchmark -0.05 (0.08) 0.47 (0.09) 0.51 (0.08) 0.01 (0.11) 0.49 (0.08) 0.49 (0.08) 0.49 (0.08) 0.49 (0.08) diff -0.05 (0.08) 0.47 (0.09) 0.51 (0.08) 0.01 (0.11) 0.49 (0.08) 0.49 (0.08) 0.49 (0.08) 0.49 (0.08) reg -0.05 (0.08) -0.18 (0.11) 0.05 (0.10) -0.02 (0.11) -0.07 (0.10) -0.07 (0.10) -0.07 (0.10) -0.07 (0.10) om.reg -0.05 (0.05) -0.22 (0.06) -0.07 (0.05) -0.02 (0.07) -0.20 (0.04) -0.20 (0.04) -0.20 (0.04) -0.20 (0.04) om.grf -0.05 (0.06) -0.52 (0.06) -0.30 (0.05) -0.28 (0.07) -0.50 (0.04) -0.49 (0.04) -0.49 (0.04) -0.49 (0.04) matching -0.06 (0.07) -0.71 (0.14) -0.47 (0.13) -0.30 (0.15) -0.65 (0.14) -0.65 (0.14) -0.65 (0.14) -0.65 (0.14) psm -0.10 (0.07) -0.74 (0.09) -0.20 (0.08) -0.43 (0.11) -0.78 (0.07) -0.77 (0.07) -0.77 (0.07) -0.77 (0.07) ipw -0.05 (0.08) -0.67 (0.15) -0.34 (0.14) 0.01 (0.11) -0.76 (0.16) -0.76 (0.16) -0.07 (0.11) -0.76 (0.16) cbps -0.05 (0.08) -0.27 (0.14) -0.08 (0.12) 0.01 (0.11) -0.25 (0.13) -0.25 (0.13) -0.07 (0.11) -0.25 (0.13) ebal -0.05 (0.08) -0.27 (0.14) -0.08 (0.12) -0.03 (0.12) -0.25 (0.13) -0.25 (0.13) -0.25 (0.13) -0.25 (0.13) dml -0.04 (0.07) -0.18 (0.11) 0.06 (0.10) -0.00 (0.11) -0.08 (0.10) -0.08 (0.10) -0.08 (0.10) -0.08 (0.10) aipw_grf -0.05 (0.07) -0.76 (0.15) -0.44 (0.14) -0.44 (0.17) -0.81 (0.16) -0.81 (0.16) -0.81 (0.16) -0.81 (0.16) aipw_ow -0.06 (0.08) -0.67 (0.15) -0.43 (0.13) -0.33 (0.13) -0.77 (0.18) -0.77 (0.18) -0.77 (0.18) -0.77 (0.18) The placebo analysis shows that the experimental benchmark is close to zero and statistically insignificant, while all estimators applied to the observational datasets produce comparable results. # save results save_csv(result_mat_pl, &quot;LCS_att_estimates_pl&quot;) 5.8 Validation through sensitivity analyses # define variables Y &lt;- &quot;re79&quot; treat &lt;- &quot;treat&quot; # redefine covariates covar &lt;- c(&quot;age&quot;, &quot;educ&quot;, &quot;nodegree&quot;, &quot;married&quot;, &quot;black&quot;, &quot;hisp&quot;, &quot;re75&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets datasets_sens &lt;- c(list(lcs, lcs_psid), top5_datasets.psid_plus) filtered_datasets_sens &lt;- check_filter_datasets(datasets_sens, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(datasets_sens, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = plot_titles[idx]) } Figure 5.72: FIGURE 14. Sensitivity Analyses LCS Figure 5.73: FIGURE 14. Sensitivity Analyses LCS # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, plot_titles, &quot;lcs&quot;) The sensitivity analysis shows that treatment effect estimates in LCS-Experimental (A) are robust to unmeasured confounding, as expected. Observational samples instead show varying degrees of sensitivity, with the full observational sample (B) being more sensitive than the trimmed version (C). The top-ranked PSID1 subsamples (D-H) show that despite employing advanced criteria to improve balance and overlap, treatment effect estimates can exhibit increasing bias under plausible stronger confounding scenarios based on the reference confounder strength. 5.9 Summary After reexamining the LaLonde-Calónico-Smith (LCS) data, the results confirm that, as with the NSW and LDW datasets, overlap between treated and control groups is generally stronger in the experimental sample than in the observational (PSID-1) controls. Augmenting the sample with experimental controls improves overlap but does not consistently resolve covariate imbalance. The findings for the LCS sample closely mirror those from the LDW and NSW analyses: while certain methods can bring effect estimates closer to experimental benchmarks, substantial estimator-dependent variability and sensitivity to sample construction persist. Placebo and sensitivity analyses again show that unconfoundedness is difficult to verify, and that treatment effect estimates from observational data remain fragile. This underscores the ongoing challenge of obtaining reliable causal estimates for the LCS data. References Calónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” "],["references.html", "References", " References Calónico, Sebastian, and Jeffrey Smith. 2017. “The Women of the National Supported Work Demonstration.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
