[["index.html", "Application of the Outcome Weights Framework for Double Machine Learning to the Lalonde Study Preface", " Application of the Outcome Weights Framework for Double Machine Learning to the Lalonde Study Laura Kreisel 2025-11-06 Preface This book replicates the LaLonde study by Imbens and Xu (2024) and extends it by comparing a full with a reduced covariate model to mitigate potential confounding. It evaluates various methods to improve overlap and covariate balance for robust treatment effect estimation and applies the outcome weights framework by Knaus and Pfleiderer (2024) to assess another estimator and analyse the distributional properties of outcome weights. The analysis draws on the original LaLonde dataset as well as the LaLonde–Dehejia–Wahba (LDW) and LaLonde–Calónico–Smith (LCS) datasets. Section 1 introduces required packages and wrapper functions used throughout the analysis. Section 2 replicates and extends the full covariate model from Imbens and Xu (2024) using the LaLonde-Dehejia-Wahba (LDW) dataset. Section 3 applies a reduced covariate set to the same LDW dataset. Section 4 analyzes the original LaLonde dataset following similar methods and section 5 explores the LaLonde-Calónico-Smith (LCS) dataset, focusing on female samples. References Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” "],["lalonde-dehejia-wahba-ldw-data.html", "Chapter 1 LaLonde-Dehejia-Wahba (LDW) Data 1.1 Set up 1.2 Model A 1.3 Improving primarily covariate balance 1.4 Improving primarily overlap 1.5 Integrated methods 1.6 Reassessing methods 1.7 Integrated methods 1.8 Identifying best methods 1.9 Estimating 1.10 Validation through placebo analyses 1.11 Validation through sensitivity analyses 1.12 Inspection of re74 and re75 1.13 Summary", " Chapter 1 LaLonde-Dehejia-Wahba (LDW) Data LaLonde (1986) evaluated the effect of the National Supported Work Demonstration (NSW) program on both female and male participants. While the female participants were drawn from the Aid to Families with Dependent Children (AFDC) program, the male participants were drawn from three other groups: former drug addicts, ex-criminal offenders, and high-school dropouts. LaLonde relied on two main data sources: (1) CPS-SSA-1, based on Westat’s Matched Current Population Survey–Social Security Administration File for individuals under 55 matching specific criteria; (2) PSID-1, based on Panel Study of Income Dynamics for household heads under 55 from specific years who were not retired in 1975, adjusted for factors like employment status and poverty level, resulting in four additional comparison groups. Dehejia and Wahba (1999) constructed a subset of LaLonde’s original data, retaining 62% of observations and restricting the focus to male participants based on their 1974 earnings. As the dataset was formed entirely on pretreatment information like employment records or month of assignment, treatment allocation was effectively independent of all pre-treatment variables. Thus, they concluded that this subset, known as the LaLonde-Dehejia-Wahba (LDW) data, constitutes a valid experimental sample. The analysis in section 2 and 3 builds on the LDW data and considers in total three samples: (1) LDW-Experimental, consisting of 185 treated individuals and 280 controls from the experimental data; (2) LDW-CPS1, which pairs the same treated sample with 15,992 controls from CPS-SSA-1; (3) LDW-PSID1, featuring the same treated sample with 2,490 controls from PSID-1; In section 4, the analysis applies the same set of statistical tools to analyze a fourth sample as an additional demonstration: (4) LaLonde male samples (1986). In the last section, the analysis applies a reduced set of statistical tools to analyze a fifth sample again as an additional demonstration: (5) LaLonde female samples (2017). This section (2) covers model A, which includes the outcome variable 1978 earnings (re78) and adjusts for a set of covariates: age, education, race (black, hispanic), marital status, high school dropouts, 1974 and 1975 earnings (re74, re75), and unemployment status in 1974 and 1975 (u74, u75). The model is defined by a regression formula for treatment assignment using these covariates. To improve covariate balance and overlap between treated and control groups, various methods are applied and are structured into five parts (matching, weighting, truncation, trimming and integrated methods). From these methods, the five best methods are determined based on a score defined by absolute standardized mean differences (SMD) and the effective sample size (ESS). The corresponding datasets are used to estimate the average treatment effect on the treated (ATT). Notably, the estimation incorporates the recently introduced augmented inverse probability weighting (AIPW) estimator, implemented via the OutcomeWeights R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify potential patterns in the contribution of individual observations to the ATT. Placebo tests are then conducted using 1975 earnings (re75) as an outcome to assess potential biases and the validity of unconfoundedness assumptions. Finally, sensitivity analyses are performed to evaluate the robustness of treatment effect estimates to violations of these assumptions. 1.1 Set up 1.1.1 Source functions and load data # source functions source(&quot;https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE&quot;) source(&quot;tutorial/functions.R&quot;) # load data load(&quot;data/lalonde.RData&quot;) # set seed set.seed(42) 1.1.2 Inspect data We begin the analysis with an overview of each dataset, where the dataset name, number of observations (rows), number of treated and control units, number of variables (columns), and variable names are reviewed. # collect datasets in a list data &lt;- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid) # inspect key metrics of each dataset summary_stats &lt;- inspect_data(data) knitr::kable(summary_stats, caption = &quot;Summary Statistics&quot;) Table 1.1: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars lalonde 614 185 429 9 treat, age, educ, race, married, nodegree, re74, re75, re78 ldw_tr 185 185 0 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_co 260 0 260 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_cps 16177 185 15992 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid 2675 185 2490 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 1.1.3 Load and preprocess data Next, we augment the control groups in LDW-CPS1 and LDW-PSID1 by merging them with the experimental controls from LDW-Experimental. This approach follows the methodology laid out by Imbens and Xu (2024). These expanded datasets are used solely for comparative purposes, while all primary analyses rely on the original LDW‑CPS1 and LDW‑PSID1 data. # assigns 1 to the experimental controls ldw_co$treat &lt;- 1 # merge experimental data with CPS1 data ldw_cps_plus &lt;- rbind.data.frame( ldw_co, # experimental controls ldw_cps # CPS1 data ) # merge experimental data with PSID1 data ldw_psid_plus &lt;- rbind.data.frame( ldw_co, # experimental controls ldw_psid # PSID1 data ) datasets &lt;- list(ldw_cps_plus = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus) # inspect each dataset summary_stats_plus &lt;- inspect_data(datasets) knitr::kable(summary_stats_plus, caption = &quot;Summary Statistics&quot;) Table 1.2: Summary Statistics dataset num_obs num_treated num_controls num_vars name_vars ldw_cps_plus 16437 445 15992 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample ldw_psid_plus 2935 445 2490 14 data_id, treat, age, education, black, hispanic, married, nodegree, re74, re75, re78, u74, u75, sample 1.2 Model A Finally, we define Model A as the baseline specification underlying the analysis. # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) #re74 included 1.2.1 Assessing overlap and covariate balance 1.2.1.1 Overlap To identify the average causal effect under unconfoundedness (that asserts that the treatment assignment is independent of the potential outcomes), it must be ensured that one can estimate the average effect at every value for the covariates. Thus, overlaps between the treated and untreated units (meaning that for every combination of covariates, there are both treated and untreated units in the dataset) are required. To assess overlap in the propensity scores and visualize the results using histograms of their log-odds, we use the assess_overlap() function of Imbens and Xu (2024). In a properly balanced experimental design, the distributions of the treatment group (red) and the control group (gray) would show considerable coverage. ldw.ps &lt;- assess_overlap(data = ldw, treat = treat, cov = covar) ## -1.310867 0.7158619 Figure 1.1: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_cps.ps &lt;- assess_overlap(data = ldw_cps, treat = treat, cov = covar) ## -16.1181 1.787343 Figure 1.2: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. ldw_psid.ps &lt;- assess_overlap(data = ldw_psid, treat = treat, cov = covar) ## -16.1181 3.752723 Figure 1.3: FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. As anticipated, LDW-Experimental exhibits an almost perfect overlap. In contrast, the observational datasets LDW-CPS1 and LDW-PSID1 show weak overlap. Notably, many treated units have propensity scores outside the range of the controls, while a large share of control units have propensity scores concentrated at very low log-odds. Next, the overlap of the expanded observational datasets is examined. ldw_cps_plus.ps &lt;- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) ## -16.1181 3.63151 Figure 1.4: FIGUREA1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. ldw_psid_plus.ps &lt;- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar) ## -16.1181 7.271394 Figure 1.5: FIGUREA1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS. As expected, the datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS show an improved overlap compared to their non-plus states. For the following analysis, we set up a model formula. # set model formula model &lt;- as.formula(paste(treat, &quot;~&quot;, paste(covar, collapse = &quot; + &quot;))) 1.2.1.2 Covariate balance To make treatment and control groups more comparable, thus mimicking a randomized experiment, initial covariate balance is assessed to determine the degree to which treatment and control groups differ on observed characteristics. Therefore, we employ visual summaries using love.plot() by Imbens and Xu (2024), which depicts standardized mean differences across covariates before and after adjustment. # plot balance love.plot(ldw, ldw_cps, treat, covar = covar, title = &quot;LDW-CPS1&quot;) Figure 1.6: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid, treat, covar = covar, title = &quot;LDW-PSID1&quot;) Figure 1.7: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = &quot;LDW-CPS1-PLUS&quot;) Figure 1.8: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = &quot;LDW-PSID1-PLUS&quot;) Figure 1.9: FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS. Neither LDW-CPS1-PLUS nor LDW-PSID1-PLUS shows consistently improved covariate balance compared to their non-plus counterparts based on raw standardized mean differences. Although some specific covariates improve slightly, most show increased imbalance. For the subsequent analysis aimed at enhancing covariate balance and overlap, only the two datasets LDW-CPS1 and LDW-PSID1 are used. The LDW-Experimental dataset is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 1.3 Improving primarily covariate balance 1.3.1 Matching The purpose of matching is to create comparable treated and control groups by pairing units with similar covariate profiles, thereby reducing covariate imbalance and confounding bias. We apply several matching methods as outlined by Greifer (2025a) in the following. 1.3.1.1 Distance Matching 1.3.1.1.1 1:1 Nearest neighbor matching # perform nearest neighbor matching with k=1, logistic propensity score and replacement m.out.cps.nearest &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) m.out.psid.nearest &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE) 1.3.1.1.2 k:1 matching (k=2) k&lt;-2 # perform nearest neighbor matching with k=2, logistic propensity score and replacement m.out.cps.k2 &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k2 &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) 1.3.1.1.3 k:1 matching (k=3) k&lt;-3 # perform nearest neighbor matching with k=3, logistic propensity score and replacement m.out.cps.k3 &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) m.out.psid.k3 &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, ratio = k, replace = TRUE) 1.3.1.1.4 Caliper matching # perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score m.out.cps.caliper &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) m.out.psid.caliper &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, caliper = 0.1, replace = TRUE) 1.3.1.1.5 Common support restriction matching # perform nearest neighbor matching with exclusion of units outside common support m.out.cps.cs &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) m.out.psid.cs &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, discard = &quot;both&quot;, reestimate = TRUE, replace = TRUE) 1.3.1.1.6 Mahalanobis distance matching (mahvars) # perform nearest neighbor matching using mahalanobis distance m.out.cps.mahvars &lt;- matchit(model, data = ldw_cps, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) m.out.psid.mahvars &lt;- matchit(model, data = ldw_psid, method = &quot;nearest&quot;, distance = &quot;mahalanobis&quot;, replace = FALSE) 1.3.1.1.7 Optimal pair matching # perform optimal pair matching that minimizes total within-pair distance on propensity scores m.out.cps.optimal_pair &lt;- matchit(model, data = ldw_cps, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) m.out.psid.optimal_pair &lt;- matchit(model, data = ldw_psid, method = &quot;optimal&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) 1.3.1.1.8 Optimal full matching # perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion m.out.cps.optimal_full &lt;- matchit(model, data = ldw_cps, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) m.out.psid.optimal_full &lt;- matchit(model, data = ldw_psid, method = &quot;full&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) 1.3.1.1.9 Generalized full matching # perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios m.out.cps.general_full &lt;- matchit(model, data = ldw_cps, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) m.out.psid.general_full &lt;- matchit(model, data = ldw_psid, method = &quot;quick&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;) 1.3.1.1.10 Genetic matching # perform genetic matching m.out.cps.genetic &lt;- matchit(model, data = ldw_cps, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) m.out.psid.genetic &lt;- matchit(model, data = ldw_psid, method = &quot;genetic&quot;, distance = &quot;glm&quot;, link = &quot;logit&quot;, replace = TRUE, pop.size = 100) 1.3.1.2 Stratum matching 1.3.1.2.1 Exact matching (exact) Strata = unique covariate profiles (raw covariates) # match units exactly by raw covariate profiles m.out.cps.exact &lt;- matchit(model, data = ldw_cps, method = &quot;exact&quot;) m.out.psid.exact &lt;- matchit(model, data = ldw_psid, method = &quot;exact&quot;) 1.3.1.2.2 Coarsened matching (cem) Strata = coarsened versions of covariates # match units exactly within coarse strata m.out.cps.cem &lt;- matchit(model, data = ldw_cps, method = &quot;cem&quot;) m.out.psid.cem &lt;- matchit(model, data = ldw_psid, method = &quot;cem&quot;) 1.3.1.2.3 Subclassification Strata = bins of the propensity score # partition sample into fixed number of bins based on propensity score m.out.cps.subcl &lt;- matchit(model, data = ldw_cps, method = &quot;subclass&quot;, subclass = 5) m.out.psid.subcl &lt;- matchit(model, data = ldw_psid, method = &quot;subclass&quot;, subclass = 5) 1.3.1.3 Pure subset selection 1.3.1.3.1 Cardinality profile matching # select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units m.out.cps.card &lt;- matchit(model, data = ldw_cps, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) m.out.psid.card &lt;- matchit(model, data = ldw_psid, method = &quot;cardinality&quot;, tols = 0.1, ratio = 1, time = 1200) 1.3.1.3.2 Profile matching # select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact m.out.cps.profile &lt;- matchit(model, data = ldw_cps, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) m.out.psid.profile &lt;- matchit(model, data = ldw_psid, method = &quot;cardinality&quot;, estimand = &quot;ATT&quot;, tols = 0.1, ratio = NA, time = 1200) 1.3.2 Weighting The purpose of weighting is to reweight the units in order to create a synthetic population in which the distributions of observed characteristics is balanced between treatment and control groups. In the following, several weighting methods, as outlined by Greifer (2025b) and Stürmer et al. (2021) are applied. 1.3.2.1 Inverse probability weights (IPW) # estimates propensity scores (PS) with a parametric generalized linear model and converts them into weights w.out.cps.ipw &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) ldw_cps$ipw_weight &lt;- w.out.cps.ipw$weights w.out.psid.ipw &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;glm&quot;) ldw_psid$ipw_weight &lt;- w.out.psid.ipw$weights 1.3.2.2 Covariate balance propensity score weights # estimates PS using generalized method of moments and then converts them into weights w.out.cps.cbps &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) ldw_cps$cbps_weight &lt;- w.out.cps.cbps$weights w.out.psid.cbps &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;cbps&quot;) ldw_psid$cbps_weight &lt;- w.out.psid.cbps$weights 1.3.2.3 Stable balancing weights # estimates weights by minimizing the variance of the weights w.out.cps.opt &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;optweight&quot;) w.out.psid.opt &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;optweight&quot;) ldw_cps$opt_weight &lt;- w.out.cps.opt$weights ldw_psid$opt_weight &lt;- w.out.psid.opt$weights 1.3.2.4 Entropy balancing weights # estimates weights by minimizing the negative entropy of the weights subject to exact moment balancing constraints w.out.cps.ebal &lt;- WeightIt::weightit(model, data = ldw_cps, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) ldw_cps$ebal_weight &lt;- w.out.cps.ebal$weights w.out.psid.ebal &lt;- WeightIt::weightit(model, data = ldw_psid, estimand = &quot;ATT&quot;, method = &quot;ebal&quot;) ldw_psid$ebal_weight &lt;- w.out.psid.ebal$weights 1.4 Improving primarily overlap Truncation aims at limiting the influence of extreme weights by capping them at a specified threshold. This helps to reduce variance and improve the stability of causal effect estimates. In the following, several truncation methods are applied, following similar approaches outlined by Matsouaka and Zhou (2023) and Ju, Schwab, and Laan (2013). 1.4.1 Truncation 1.4.1.1 Fixed value truncation # truncate weights by imposing a minimum and maximum ldw_cps.ps_fixed &lt;- truncate_ps_fixed(ldw_cps.ps, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, lower = 0.05, upper = 0.95) ldw_psid.ps_fixed &lt;- truncate_ps_fixed(ldw_psid.ps, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, lower = 0.05, upper = 0.95) 1.4.1.2 At percentile truncation # truncate weights such that values below the 5th percentile and above the 95th percentile are capped ldw_cps.ps_percent &lt;- truncate_ps_percentile(ldw_cps.ps, ps = &quot;ps_assoverlap&quot;, lower_percentile = 5, upper_percentile = 95) ldw_psid.ps_percent &lt;- truncate_ps_percentile(ldw_psid.ps, ps = &quot;ps_assoverlap&quot;, lower_percentile = 5, upper_percentile = 95) 1.4.1.3 Adaptive weight truncation # truncate weights using data-driven quantile selection ldw_cps.ps_adapt &lt;- truncate_ps_adaptive(ldw_cps.ps, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, folds = 5, lower_grid = seq(0.01, 0.10, by = 0.01), upper_grid = seq(0.90, 0.99, by = 0.01)) ldw_psid.ps_adapt &lt;- truncate_ps_adaptive(ldw_psid.ps, treat = &quot;treat&quot;, ps = &quot;ps_assoverlap&quot;, folds = 5, lower_grid = seq(0.01, 0.10, by = 0.01), upper_grid = seq(0.90, 0.99, by = 0.01)) 1.4.2 Trimming The purpose of trimming is to remove units whose propensity scores are too dissimilar from the opposite group, thereby improving covariate balance between treated and control groups. Below, we employ several trimming methods in line with the approaches proposed by Stürmer et al. (2021) and Imbens and Xu (2024). 1.4.2.1 Propensity score threshold trimming # apply trimming with threshold 0.9 ldw_cps.trim &lt;- ps_trim(ldw_cps.ps, threshold = 0.9) ldw_psid.trim &lt;- ps_trim(ldw_psid.ps, threshold = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.trim &lt;- assess_overlap(data = ldw_cps.trim, treat = treat, cov = covar) ## -16.1181 1.787343 ldw_psid.trim &lt;- assess_overlap(data = ldw_psid.trim, treat = treat, cov = covar) ## -16.1181 2.365266 1.4.2.2 Common range trimming # trim observations outside the common support region of propensity scores ldw_cps.common &lt;- common_range_trim(ldw_cps.ps) ldw_psid.common &lt;- common_range_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.common &lt;- assess_overlap(data = ldw_cps.common, treat = treat, cov = covar) ## -16.1181 1.787343 ldw_psid.common &lt;- assess_overlap(data = ldw_psid.common, treat = treat, cov = covar) ## -7.117438 2.571188 1.4.2.3 Crump trimming # trim observations with propensity scores outside [0.1, 0.9] interval ldw_cps.crump &lt;- crump_trim(ldw_cps.ps, lower = 0.1, upper = 0.9) ldw_psid.crump &lt;- crump_trim(ldw_psid.ps, lower = 0.1, upper = 0.9) # re-estimate propensity scores on trimmed data ldw_cps.crump &lt;- assess_overlap(data = ldw_cps.crump, treat = treat, cov = covar) ## -2.050139 1.563952 ldw_psid.crump &lt;- assess_overlap(data = ldw_psid.crump, treat = treat, cov = covar) ## -1.969023 2.449887 1.4.2.4 Stuermer trimming # trim observations based on propensity score quantiles separately for treated and control ldw_cps.stuermer &lt;- stuermer_trim(ldw_cps.ps) ldw_psid.stuermer &lt;- stuermer_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.stuermer &lt;- assess_overlap(data = ldw_cps.stuermer, treat = treat, cov = covar) ## -16.1181 -1.500729 ldw_psid.stuermer &lt;- assess_overlap(data = ldw_psid.stuermer, treat = treat, cov = covar) ## -8.326673 -2.127801 1.4.2.5 Walker trimming # trim observations based on preference scores that adjust for treatment prevalence using logit transformations ldw_cps.walker &lt;- walker_trim(ldw_cps.ps) ldw_psid.walker &lt;- walker_trim(ldw_psid.ps) # re-estimate propensity scores on trimmed data ldw_cps.walker &lt;- assess_overlap(data = ldw_cps.walker, treat = treat, cov = covar) ## -16.1181 -1.547533 ldw_psid.walker &lt;- assess_overlap(data = ldw_psid.walker, treat = treat, cov = covar) ## -8.405169 -1.926528 1.5 Integrated methods 1.5.1 Trimming and matching In line with the tutorial by Imbens and Xu (2024), combinations of trimming and matching methods are applied only to the plus datasets used for comparison. However, it is strongly recommended to extend this analysis to the non-plus datasets as well, in order to evaluate whether integrating trimming and matching improves final scores and effect estimates. (Similar to tutorial by Imbens and Xu (2024)) ldw_cps_trim &lt;- ps_trim(ldw_cps_plus.ps, threshold = 0.9) ldw_psid_trim &lt;- ps_trim(ldw_psid_plus.ps, threshold = 0.8) # excluding the experimental controls ldw_cps.trim_match &lt;- subset(ldw_cps_trim, sample %in% c(1,3) &amp; ps_assoverlap) ldw_psid.trim_match &lt;- subset(ldw_psid_trim, sample %in% c(1,4) &amp; ps_assoverlap) # re-estimate propensity scores and employ 1:1 matching ldw_cps.trim_match &lt;- psmatch(data = ldw_cps.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) ldw_psid.trim_match &lt;- psmatch(data = ldw_psid.trim_match, Y = &quot;re78&quot;, treat = &quot;treat&quot;, cov = covar) # further subset data and re-assign treat variable ldw_trim_cps &lt;- subset(ldw_cps_trim, sample %in% c(1,2) &amp; ps_assoverlap &lt;= 0.9) ldw_trim_cps$treat[which(ldw_trim_cps$sample == 2)] &lt;- 0 ldw_trim_psid &lt;- subset(ldw_psid_trim, sample %in% c(1,2) &amp; ps_assoverlap &lt;= 0.8) ldw_trim_psid$treat[which(ldw_trim_psid$sample == 2)] &lt;- 0 1.5.2 Trimming and weighting The purpose of combining trimming and weighting methods is to leverage the strengths of both approaches for causal effect estimation. Trimming enhances overlap and reduces the influence of outliers by excluding units with extreme or non-comparable propensity scores, while weighting further adjusts for remaining covariate imbalance among the retained units. A similar approach to that presented by Stürmer et al. (2021) is employed, but weighting methods of Greifer (2025b) are used. all_trim.cps &lt;- list(ps_threshold = ldw_cps.trim, common_range = ldw_cps.common, stuermer = ldw_cps.stuermer, walker = ldw_cps.walker, crump = ldw_cps.crump) all_trim.psid &lt;- list(ps_threshold = ldw_psid.trim, common_range = ldw_psid.common, stuermer = ldw_psid.stuermer, walker = ldw_psid.walker, crump = ldw_psid.crump) 1.5.2.1 IPW with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply inverse probability weighting (IPW) with trimming and attach IPW weights ipw_comb.cps &lt;- attach_weights(all_trim.cps, model, &quot;ipw_weight&quot;) ipw_comb.psid &lt;- attach_weights(all_trim.psid, model, &quot;ipw_weight&quot;) 1.5.2.2 Stable balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply stable balancing with trimming and attach stable balance weights opt_comb.cps &lt;- attach_weights(all_trim.cps, model, &quot;opt_weight&quot;) opt_comb.psid &lt;- attach_weights(all_trim.psid, model, &quot;opt_weight&quot;) 1.5.2.3 Propensity score weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply propensity score weighting with trimming and attach propensity score weights cbps_comb.cps &lt;- attach_weights(all_trim.cps, model, &quot;cbps_weight&quot;) cbps_comb.psid &lt;- attach_weights(all_trim.psid, model, &quot;cbps_weight&quot;) 1.5.2.4 Entropy balancing weights with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump # apply entropy balancing weights with trimming and attach entropy weights ebal_comb.cps &lt;- attach_weights(all_trim.cps, model, &quot;ebal_weight&quot;) ebal_comb.psid &lt;- attach_weights(all_trim.psid, model, &quot;ebal_weight&quot;) 1.5.3 Truncation and weighting # list weight columns to apply truncation weight_columns &lt;- c(&quot;ipw_weight&quot;, &quot;opt_weight&quot;, &quot;cbps_weight&quot;, &quot;ebal_weight&quot;) 1.5.3.1 IPW, stable balancing, propensity score and entropy weights with 1) fixed maximum value truncation # truncate weights by imposing a minimum and maximum threshold fixed_comb.cps &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(fixed_comb.cps)) { fixed_comb.cps &lt;- truncate_weights_fixed(fixed_comb.cps, weight_col = wcol, lower = 0.025, upper = 0.975) } } fixed_comb.psid &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(fixed_comb.psid)) { fixed_comb.psid &lt;- truncate_weights_fixed(fixed_comb.psid, weight_col = wcol, lower = 0.025, upper = 0.975) } } 1.5.3.2 IPW, stable balancing, propensity score and entropy weights with 2) at percentile truncation # truncate weights such that values below the 5th percentile and above the 95th percentile are capped percent_comb.cps &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(percent_comb.cps)) { percent_comb.cps &lt;- truncate_weights_percentile(percent_comb.cps, weight_col = wcol, lower = 0.05, upper = 0.95) } } percent_comb.psid &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(percent_comb.psid)) { percent_comb.psid &lt;- truncate_weights_percentile(percent_comb.psid, weight_col = wcol, lower = 0.05, upper = 0.95) } } 1.5.3.3 IPW, stable balancing, propensity score and entropy weights with 3) adaptive weight truncation # truncate weights using data-driven quantile selection adapt_comb.cps &lt;- ldw_cps for (wcol in weight_columns) { if (wcol %in% names(adapt_comb.cps)) { adapt_comb.cps &lt;- truncate_weights_adaptive(adapt_comb.cps, weight_col = wcol) } } adapt_comb.psid &lt;- ldw_psid for (wcol in weight_columns) { if (wcol %in% names(adapt_comb.psid)) { adapt_comb.psid &lt;- truncate_weights_adaptive(adapt_comb.psid, weight_col = wcol) } } 1.6 Reassessing methods We now systematically reassess all methods described above by evaluating covariate balance and effective sample size. Specifically, we examine the SMD and ESS for each approach and use visual diagnostics to assess covariate balance and overlap between treated and control groups. 1.6.1 Matching # list all matching objects all_match.cps &lt;- list( nn = m.out.cps.nearest, k2 = m.out.cps.k2, k3 = m.out.cps.k3, caliper = m.out.cps.caliper, cS = m.out.cps.cs, mahvars = m.out.cps.mahvars, optimal_pair = m.out.cps.optimal_pair, optimal_full = m.out.cps.optimal_full, gen_full = m.out.cps.general_full, genetic = m.out.cps.genetic, exact = m.out.cps.exact, cem = m.out.cps.cem, card = m.out.cps.card, profile = m.out.cps.profile, subcl = m.out.cps.subcl ) all_match.psid &lt;- list( nn = m.out.psid.nearest, k2 = m.out.psid.k2, k3 = m.out.psid.k3, caliper = m.out.psid.caliper, cs = m.out.psid.cs, mahvars = m.out.psid.mahvars, optimal_pair = m.out.psid.optimal_pair, optimal_full = m.out.psid.optimal_full, gen_full = m.out.psid.general_full, genetic = m.out.psid.genetic, exact = m.out.psid.exact, cem = m.out.psid.cem, card = m.out.psid.card, profile = m.out.psid.profile, subcl = m.out.psid.subcl ) 1.6.1.1 SMD # compute absolute SMD smd_matchit.cps &lt;- compute_abs_smd_matchit(all_match.cps) smd_matchit.psid &lt;- compute_abs_smd_matchit(all_match.psid) smd_matchit.cps ## Method Mean_Abs_SMD Max_Abs_SMD ## 1 nn 3.364487e-02 1.134447e-01 ## 2 k2 3.980415e-02 1.196332e-01 ## 3 k3 4.698305e-02 1.254580e-01 ## 4 caliper 3.453507e-02 1.159518e-01 ## 5 cS 5.770059e-02 2.285129e-01 ## 6 mahvars 8.200879e-02 1.671024e-01 ## 7 optimal_pair 4.046118e-02 1.518496e-01 ## 8 optimal_full 2.848035e-02 1.251411e-01 ## 9 gen_full 3.083566e-02 1.388281e-01 ## 10 genetic 6.426426e-03 3.226064e-02 ## 11 exact 1.776357e-16 1.776357e-15 ## 12 cem 5.555001e-03 2.422462e-02 ## 13 card 5.151441e-02 9.993396e-02 ## 14 profile 5.451142e-02 9.956021e-02 ## 15 subcl 1.503371e-01 5.509951e-01 1.6.1.2 ESS # calculate balance statistics bal.cps &lt;- cobalt::bal.tab(model, data = ldw_cps, un = TRUE, weights = all_match.cps, s.d.denom = &quot;treated&quot;) bal.psid &lt;- cobalt::bal.tab(model, data = ldw_psid, un = TRUE, weights = all_match.psid, s.d.denom = &quot;treated&quot;) # compute ESS ess_matchit.cps &lt;- compute_ess_matchit(bal.cps) ess_matchit.psid &lt;- compute_ess_matchit(bal.psid) 1.6.1.3 Visuals # visualize covariate balance plot_matching_balance(all_match.cps, title = &quot;LDW-CPS1&quot;) ## $nn Figure 1.10: FIGUREA3. ## ## $k2 Figure 1.11: FIGUREA3. ## ## $k3 Figure 1.12: FIGUREA3. ## ## $caliper Figure 1.13: FIGUREA3. ## ## $cS Figure 1.14: FIGUREA3. ## ## $mahvars Figure 1.15: FIGUREA3. ## ## $optimal_pair Figure 1.16: FIGUREA3. ## ## $optimal_full Figure 1.17: FIGUREA3. ## ## $gen_full Figure 1.18: FIGUREA3. ## ## $genetic Figure 1.19: FIGUREA3. ## ## $exact Figure 1.20: FIGUREA3. ## ## $cem Figure 1.21: FIGUREA3. ## ## $card Figure 1.22: FIGUREA3. ## ## $profile Figure 1.23: FIGUREA3. ## ## $subcl Figure 1.24: FIGUREA3. plot_matching_balance(all_match.psid, title = &quot;LDW-PSID1&quot;) ## $nn Figure 1.25: FIGUREA3. ## ## $k2 Figure 1.26: FIGUREA3. ## ## $k3 Figure 1.27: FIGUREA3. ## ## $caliper Figure 1.28: FIGUREA3. ## ## $cs Figure 1.29: FIGUREA3. ## ## $mahvars Figure 1.30: FIGUREA3. ## ## $optimal_pair Figure 1.31: FIGUREA3. ## ## $optimal_full Figure 1.32: FIGUREA3. ## ## $gen_full Figure 1.33: FIGUREA3. ## ## $genetic Figure 1.34: FIGUREA3. ## ## $exact Figure 1.35: FIGUREA3. ## ## $cem Figure 1.36: FIGUREA3. ## ## $card Figure 1.37: FIGUREA3. ## ## $profile Figure 1.38: FIGUREA3. ## ## $subcl Figure 1.39: FIGUREA3. 1.6.2 Weighting # list all weights all_weight.cps &lt;- list( ipw_weight = ldw_cps$ipw_weight, opt_weight = ldw_cps$opt_weight, cbps_weight = ldw_cps$cbps_weight, ebal_weight = ldw_cps$ebal_weight ) all_weight.psid &lt;- list( ipw_weight = ldw_psid$ipw_weight, opt_weight = ldw_psid$opt_weight, cbps_weight = ldw_psid$cbps_weight, ebal_weight = ldw_psid$ebal_weight ) 1.6.2.1 SMD # compute absolute SMD smd_weight.cps &lt;- compute_abs_smd_weight(ldw_cps, treat, covar, all_weight.cps) smd_weight.psid &lt;- compute_abs_smd_weight(ldw_psid, treat, covar, all_weight.psid) 1.6.2.2 ESS # compute ESS ess_weight.cps &lt;- compute_ess_weight(ldw_cps, treat, covar, all_weight.cps) ess_weight.psid &lt;- compute_ess_weight(ldw_psid, treat, covar, all_weight.psid) 1.6.2.3 Visuals # visualize covariate balance plot_weighting_balance(ldw_cps, treat, covar, all_weight.cps, &quot;LDW-CPS1&quot;) ## $ipw_weight Figure 1.40: FIGUREA4. ## ## $opt_weight Figure 1.41: FIGUREA4. ## ## $cbps_weight Figure 1.42: FIGUREA4. ## ## $ebal_weight Figure 1.43: FIGUREA4. plot_weighting_balance(ldw_psid, treat, covar, all_weight.psid, &quot;LDW-PSID1&quot;) ## $ipw_weight Figure 1.44: FIGUREA4. ## ## $opt_weight Figure 1.45: FIGUREA4. ## ## $cbps_weight Figure 1.46: FIGUREA4. ## ## $ebal_weight Figure 1.47: FIGUREA4. 1.6.3 Truncation # list truncation methods all_trunc.cps &lt;- list( fix_value = ldw_cps.ps_fixed, at_perc = ldw_cps.ps_percent, adapt = ldw_cps.ps_adapt ) all_trunc.psid &lt;- list( fix_value = ldw_psid.ps_fixed, at_perc = ldw_psid.ps_percent, adapt = ldw_psid.ps_adapt ) 1.6.3.1 SMD # compute absolute SMD smd_trunc.cps &lt;- compute_abs_smd_trunc(all_trunc.cps, treat = &quot;treat&quot;, covar, &quot;ps_assoverlap&quot;) smd_trunc.psid &lt;- compute_abs_smd_trunc(all_trunc.psid, treat = &quot;treat&quot;, covar, &quot;ps_assoverlap&quot;) 1.6.3.2 ESS # compute ESS ess_trunc.cps &lt;- compute_ess_trunc(all_trunc.cps, treat = &quot;treat&quot;, covar, &quot;ps_assoverlap&quot;) ess_trunc.psid &lt;- compute_ess_trunc(all_trunc.psid, treat = &quot;treat&quot;, covar, &quot;ps_assoverlap&quot;) 1.6.3.3 Visuals # visualize covariate balance plot_trunc_balance(all_trunc.cps, treat = &quot;treat&quot;, covar, &quot;ps_assoverlap&quot;, &quot;LDW-CPS1&quot;) ## $fix_value Figure 1.48: FIGUREA5. ## ## $at_perc Figure 1.49: FIGUREA5. ## ## $adapt Figure 1.50: FIGUREA5. plot_trunc_balance(all_trunc.psid, treat = &quot;treat&quot;, covar, &quot;ps_assoverlap&quot;, &quot;LDW-PSID1&quot;) ## $fix_value Figure 1.51: FIGUREA5. ## ## $at_perc Figure 1.52: FIGUREA5. ## ## $adapt Figure 1.53: FIGUREA5. 1.6.4 Trimming # list trimming objects plus original all_trim.cps &lt;- list( original = ldw_cps, ps_threshold = ldw_cps.trim, common_range = ldw_cps.common, crump = ldw_cps.crump, stuermer = ldw_cps.stuermer, walker = ldw_cps.walker ) all_trim.psid &lt;- list( original = ldw_psid, ps_threshold = ldw_psid.trim, common_range = ldw_psid.common, crump = ldw_psid.crump, stuermer = ldw_psid.stuermer, walker = ldw_psid.walker ) 1.6.4.1 SMD # compute absolute SMD smd_trim.cps &lt;- compute_abs_smd_trim(all_trim.cps, &quot;treat&quot;, covar) smd_trim.psid &lt;- compute_abs_smd_trim(all_trim.psid, &quot;treat&quot;, covar) 1.6.4.2 ESS # compute ESS ess_trim.cps &lt;- compute_ess_trim(all_trim.cps, &quot;treat&quot;, covar) ess_trim.psid &lt;- compute_ess_trim(all_trim.psid, &quot;treat&quot;, covar) 1.6.4.3 Visuals # visualize overlap plot_trim_overlap(all_trim.cps, treat, covar, prefix = &quot;LDW-CPS1&quot;) Figure 1.54: FIGUREA6. plot_trim_overlap(all_trim.psid, treat, covar, prefix = &quot;LDW-PSID1&quot;) Figure 1.55: FIGUREA6. 1.7 Integrated methods 1.7.1 Trimming and matching (Similar to tutorial by Imbens and Xu (2024)) # list all trimmed and matched samples trim_match_comb.cps &lt;- list( ps_threshold_match = ldw_cps.trim_match ) trim_match_comb.psid &lt;- list( ps_threshold_match = ldw_psid.trim_match ) 1.7.1.1 SMD # compute absolute SMD smd_trim_match_comb.cps &lt;- compute_abs_smd_trim(trim_match_comb.cps, &quot;treat&quot;, covar) smd_trim_match_comb.psid &lt;- compute_abs_smd_trim(trim_match_comb.psid, &quot;treat&quot;, covar) 1.7.1.2 ESS # compute ESS ess_trim_match_comb.cps &lt;- compute_ess_trim(trim_match_comb.cps, &quot;treat&quot;, covar) ess_trim_match_comb.psid &lt;- compute_ess_trim(trim_match_comb.psid, &quot;treat&quot;, covar) 1.7.1.3 Visuals # visualize overlap par(mfrow = c(1, 3)) plot_trim_overlap(trim_match_comb.cps, treat, covar, prefix = &quot;LDW-CPS1-PLUS&quot;) plot_trim_overlap(trim_match_comb.psid, treat, covar, prefix = &quot;LDW-PSID1-PLUS&quot;) Figure 1.56: FIGUREA7. Figure 1.57: FIGUREA7. 1.7.2 Trimming and weighting # list all combined results trim_weight_comb.cps &lt;- list( ipw = ipw_comb.cps, opt = opt_comb.cps, cbps = cbps_comb.cps, ebal = ebal_comb.cps ) trim_weight_comb.psid &lt;- list( ipw = ipw_comb.psid, opt = opt_comb.psid, cbps = cbps_comb.psid, ebal = ebal_comb.psid ) 1.7.2.1 SMD # compute absolute SMD smd_trim_weight_comb.cps &lt;- compute_abs_smd_trim_weight(trim_weight_comb.cps, &quot;treat&quot;, covar) smd_trim_weight_comb.psid &lt;- compute_abs_smd_trim_weight(trim_weight_comb.psid, &quot;treat&quot;, covar) 1.7.2.2 ESS # compute ESS ess_trim_weight_comb.cps &lt;- compute_ess_trim_weight(trim_weight_comb.cps, &quot;treat&quot;, covar) ess_trim_weight_comb.psid &lt;- compute_ess_trim_weight(trim_weight_comb.psid, &quot;treat&quot;, covar) 1.7.2.3 Visuals # visualize overlap plot_comb_overlap(comb_meth_cps = trim_weight_comb.cps, comb_meth_psid = trim_weight_comb.psid, treat = &quot;treat&quot;, covar = covar, prefix_cps = &quot;LDW-CPS1&quot;, prefix_psid = &quot;LDW-PSID1&quot;) Figure 1.58: FIGUREA8. Figure 1.59: FIGUREA8. Figure 1.60: FIGUREA8. Figure 1.61: FIGUREA8. Figure 1.62: FIGUREA8. Figure 1.63: FIGUREA8. Figure 1.64: FIGUREA8. Figure 1.65: FIGUREA8. # save results save_comb_hist(comb_meth_cps = trim_weight_comb.cps, comb_meth_psid = trim_weight_comb.psid, treat = &quot;treat&quot;, covar = covar, prefix = &quot;model_a&quot;, prefix_cps = &quot;ldw_cps1&quot;, prefix_psid = &quot;ldw_psid1&quot;) 1.7.3 Truncation and weighting # list all combined results trunc_weight_comb.cps &lt;- list( fix_value = fixed_comb.cps, at_perc = percent_comb.cps, adapt = adapt_comb.cps ) trunc_weight_comb.psid &lt;- list( fix_value = fixed_comb.psid, at_perc = percent_comb.psid, adapt = adapt_comb.psid ) 1.7.3.1 SMD # compute absolute SMD smd_trunc_weight_comb.cps &lt;- compute_abs_smd_trunc_weight(trunc_weight_comb.cps, &quot;treat&quot;, covar, weight_columns) smd_trunc_weight_comb.psid &lt;- compute_abs_smd_trunc_weight(trunc_weight_comb.psid, &quot;treat&quot;, covar, weight_columns) 1.7.3.2 ESS # compute ESS ess_trunc_weight_comb.cps &lt;- compute_ess_trunc_weight(trunc_weight_comb.cps, &quot;treat&quot;, covar, weight_columns) ess_trunc_weight_comb.psid &lt;- compute_ess_trunc_weight(trunc_weight_comb.psid, &quot;treat&quot;, covar, weight_columns) 1.7.3.3 Visuals # visualize covariate balance plot_trunc_weight_balance(trunc_weight_comb.cps, &quot;treat&quot;, covar, weight_columns, &quot;LDW-CPS1&quot;) ## $fix_value_ipw_weight Figure 1.66: FIGUREA5. ## ## $fix_value_opt_weight Figure 1.67: FIGUREA5. ## ## $fix_value_cbps_weight Figure 1.68: FIGUREA5. ## ## $fix_value_ebal_weight Figure 1.69: FIGUREA5. ## ## $at_perc_ipw_weight Figure 1.70: FIGUREA5. ## ## $at_perc_opt_weight Figure 1.71: FIGUREA5. ## ## $at_perc_cbps_weight Figure 1.72: FIGUREA5. ## ## $at_perc_ebal_weight Figure 1.73: FIGUREA5. ## ## $adapt_ipw_weight Figure 1.74: FIGUREA5. ## ## $adapt_opt_weight Figure 1.75: FIGUREA5. ## ## $adapt_cbps_weight Figure 1.76: FIGUREA5. ## ## $adapt_ebal_weight Figure 1.77: FIGUREA5. plot_trunc_weight_balance(trunc_weight_comb.psid, &quot;treat&quot;, covar, weight_columns, &quot;LDW-PSID1&quot;) ## $fix_value_ipw_weight Figure 1.78: FIGUREA5. ## ## $fix_value_opt_weight Figure 1.79: FIGUREA5. ## ## $fix_value_cbps_weight Figure 1.80: FIGUREA5. ## ## $fix_value_ebal_weight Figure 1.81: FIGUREA5. ## ## $at_perc_ipw_weight Figure 1.82: FIGUREA5. ## ## $at_perc_opt_weight Figure 1.83: FIGUREA5. ## ## $at_perc_cbps_weight Figure 1.84: FIGUREA5. ## ## $at_perc_ebal_weight Figure 1.85: FIGUREA5. ## ## $adapt_ipw_weight Figure 1.86: FIGUREA5. ## ## $adapt_opt_weight Figure 1.87: FIGUREA5. ## ## $adapt_cbps_weight Figure 1.88: FIGUREA5. ## ## $adapt_ebal_weight Figure 1.89: FIGUREA5. 1.8 Identifying best methods To identify the top five methods for each observational dataset, we first combine for each dataset all results of the absolute SMD and ESS into a single data frame. This allows for a comprehensive comparison across all methods. Only results based on the non-plus datasets are included in the identification of the best methods, as the objective is to identify the overall best-performing methods for the original observational samples. # combine all results all_cps &lt;- combine_results(&quot;cps&quot;) all_psid &lt;- combine_results(&quot;psid&quot;) # save results save_csv(all_cps, &quot;ldw_model_a_cps1_all_results&quot;) save_csv(all_psid, &quot;ldw_model_a_psid1_all_results&quot;) Next, we evaluate each method by constructing a composite score that is build on two separate scores equally weighted: - smd_score rescales the absolute SMD to a 0-1 range, where a lower value leads to a higher score - ess_score measures the effective sample size of treated and control groups and normalizes it to a 0-1 range. # rank comparatively ranked_cps &lt;- assess_methods(all_cps) ranked_psid &lt;- assess_methods(all_psid) Based on the composite scores, we rank all methods and select the top five for each dataset. # get top 5 methods top5_methods.cps &lt;- get_top_methods(ranked_cps, top_n = 5) top5_methods.psid &lt;- get_top_methods(ranked_psid, top_n = 5) # print results top5_methods_df.cps &lt;- ranked_cps %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid &lt;- ranked_psid %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps, caption = &quot;Top 5 Methods for CPS1&quot;, booktabs = TRUE) Table 1.3: Top 5 Methods for CPS1 Method Score optimal_pair 0.7372593 card 0.7324357 mahvars 0.7191283 exact 0.7058145 ebal_weight 0.6773941 knitr::kable(top5_methods_df.psid, caption = &quot;Top 5 Methods for PSID1&quot;, booktabs = TRUE) Table 1.3: Top 5 Methods for PSID1 Method Score card 0.7511588 adapt_ebal_weight 0.6911758 optimal_pair 0.6805432 at_perc_cbps_weight 0.6786002 cem 0.6590564 # save results save_csv(top5_methods.cps, &quot;ldw_model_a_cps1_top5_methods&quot;) save_csv(top5_methods.psid, &quot;ldw_model_a_psid1_top5_methods&quot;) As a point of reference, we also examine the score for the trimmed and matched plus‑datasets. The plus‑datasets are included only to evaluate how incorporating experimental controls and the integrated trimming and matching approach affects method performance. Their results are not directly comparable to the main scoring and are not used in subsequent analyses. # combine results all_cps_plus &lt;- combine_results_plus(&quot;cps&quot;) all_psid_plus &lt;- combine_results_plus(&quot;psid&quot;) # save results save_csv(all_cps, &quot;ldw_model_a_cps1_plus_all_results&quot;) save_csv(all_psid, &quot;ldw_model_a_psid1_plus_all_results&quot;) # assess composite scores ranked_cps_plus &lt;- assess_methods(all_cps_plus) ranked_psid_plus &lt;- assess_methods(all_psid_plus) # get top 5 methods top5_methods.cps_plus &lt;- get_top_methods(ranked_cps_plus, top_n = 5) top5_methods.psid_plus &lt;- get_top_methods(ranked_psid_plus, top_n = 5) # print results top5_methods_df.cps_plus &lt;- ranked_cps_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) top5_methods_df.psid_plus &lt;- ranked_psid_plus %&gt;% arrange(desc(Score)) %&gt;% head(5) knitr::kable(top5_methods_df.cps_plus, caption = &quot;Top 5 Methods for CPS1 incl. CPS1-PLUS&quot;, booktabs = TRUE) Table 1.4: Top 5 Methods for CPS1 incl. CPS1-PLUS Method Score optimal_pair 0.7372593 card 0.7324357 mahvars 0.7191283 ps_threshold_match 0.7060254 exact 0.7058145 knitr::kable(top5_methods_df.psid_plus, caption = &quot;Top 5 Methods for PSID1 incl. PSID1-PLUS&quot;, booktabs = TRUE) Table 1.4: Top 5 Methods for PSID1 incl. PSID1-PLUS Method Score card 0.7511588 ps_threshold_match 0.7313409 adapt_ebal_weight 0.6911758 optimal_pair 0.6805432 at_perc_cbps_weight 0.6786002 # save results save_csv(top5_methods.cps, &quot;ldw_model_a_cps1_plus_top5_methods&quot;) save_csv(top5_methods.psid, &quot;ldw_model_a_psid1_plus_top5_methods&quot;) These results indicate that the top‑ranked methods for both CPS1 and PSID1 change once the trimmed and matched plus‑datasets are included, suggesting that either the integration of additional experimental control units or the combined trimming and matching approach enhances performance. Consequently, it is advisable to repeat the full analysis using only the plus‑datasets while systematically applying integrated trimming and matching methods. For dataset construction of the top‑ranked methods required in the subsequent estimation, we match all method names back to their corresponding datasets, objects or vectors and construct corresponding datasets. dataset_list_cps &lt;- list( &quot;All&quot; = ldw_cps, &quot;original&quot; = ldw_cps, # matching &quot;nn&quot; = m.out.cps.nearest, &quot;caliper&quot; = m.out.cps.caliper, &quot;card&quot; = m.out.cps.card, &quot;cem&quot; = m.out.cps.cem, &quot;cS&quot; = m.out.cps.cs, &quot;k2&quot; = m.out.cps.k2, &quot;k3&quot; = m.out.cps.k3, &quot;mahvars&quot; = m.out.cps.mahvars, &quot;optimal_full&quot; = m.out.cps.optimal_full, &quot;optimal_pair&quot; = m.out.cps.optimal_pair, &quot;gen_full&quot; = m.out.cps.general_full, &quot;genetic&quot; = m.out.cps.genetic, &quot;exact&quot; = m.out.cps.exact, &quot;subcl&quot; = m.out.cps.subcl, &quot;profile&quot; = m.out.cps.profile, # weighting &quot;ipw_weight&quot; = ldw_cps$ipw_weight, &quot;opt_weight&quot; = ldw_cps$opt_weight, &quot;cbps_weight&quot; = ldw_cps$cbps_weight, &quot;ebal_weight&quot; = ldw_cps$ebal_weight, # trimming &quot;ps_threshold&quot; = ldw_cps.trim, &quot;common_range&quot; = ldw_cps.common, &quot;stuermer&quot; = ldw_cps.stuermer, &quot;walker&quot; = ldw_cps.walker, &quot;crump&quot; = ldw_cps.crump, # truncation &quot;adapt&quot; = ldw_cps.ps_fixed, &quot;at_perc&quot; = ldw_cps.ps_percent, &quot;fix_value&quot; = ldw_cps.ps_adapt, # truncation and weighting &quot;fix_value_ipw_weight&quot; = fixed_comb.cps$ipw_weight, &quot;fix_value_opt_weight&quot; = fixed_comb.cps$opt_weight, &quot;fix_value_cbps_weight&quot; = fixed_comb.cps$cbps_weight, &quot;fix_value_ebal_weight&quot; = fixed_comb.cps$ebal_weight, &quot;at_perc_ipw_weight&quot; = percent_comb.cps$ipw_weight, &quot;at_perc_opt_weight&quot; = percent_comb.cps$opt_weight, &quot;at_perc_cbps_weight&quot; = percent_comb.cps$cbps_weight, &quot;at_perc_ebal_weight&quot; = percent_comb.cps$ebal_weight, &quot;adapt_ipw_weight&quot; = adapt_comb.cps$ipw_weight, &quot;adapt_opt_weight&quot; = adapt_comb.cps$opt_weight, &quot;adapt_cbps_weight&quot; = adapt_comb.cps$cbps_weight, &quot;adapt_ebal_weight&quot; = adapt_comb.cps$ebal_weight, # trimming and weighting &quot;ipw_common_range&quot; = ipw_comb.cps[[1]], &quot;ipw_crump&quot;= ipw_comb.cps[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.cps[[3]], &quot;ipw_stuermer&quot;= ipw_comb.cps[[4]], &quot;ipw_walker&quot; = ipw_comb.cps[[5]], &quot;opt_common_range&quot; = opt_comb.cps[[1]], &quot;opt_crump&quot; = opt_comb.cps[[2]], &quot;opt_ps_threshold&quot; = opt_comb.cps[[3]], &quot;opt_stuermer&quot; = opt_comb.cps[[4]], &quot;opt_walker&quot; = opt_comb.cps[[5]], &quot;cbps_common_range&quot; = cbps_comb.cps[[1]], &quot;cbps_crump&quot; = cbps_comb.cps[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.cps[[3]], &quot;cbps_stuermer&quot; = cbps_comb.cps[[4]], &quot;cbps_walker&quot;= cbps_comb.cps[[5]], &quot;ebal_common_range&quot; = ebal_comb.cps[[1]], &quot;ebal_crump&quot; = ebal_comb.cps[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.cps[[3]], &quot;ebal_stuermer&quot; = ebal_comb.cps[[4]], &quot;ebal_walker&quot; = ebal_comb.cps[[5]]) dataset_list_psid &lt;- list( &quot;All&quot; = ldw_psid, # matching &quot;original&quot; = ldw_psid, &quot;nn&quot; = m.out.psid.nearest, &quot;caliper&quot; = m.out.psid.caliper, &quot;card&quot; = m.out.psid.card, &quot;cem&quot; = m.out.psid.cem, &quot;cS&quot; = m.out.psid.cs, &quot;k2&quot; = m.out.psid.k2, &quot;k3&quot; = m.out.psid.k3, &quot;mahvars&quot; = m.out.psid.mahvars, &quot;optimal_full&quot; = m.out.psid.optimal_full, &quot;optimal_pair&quot; = m.out.psid.optimal_pair, &quot;gen_full&quot; = m.out.psid.general_full, &quot;genetic&quot; = m.out.psid.genetic, &quot;exact&quot; = m.out.psid.exact, &quot;subcl&quot; = m.out.psid.subcl, &quot;profile&quot; = m.out.psid.profile, # weighting &quot;ipw_weight&quot; = ldw_psid$ipw_weight, &quot;opt_weight&quot; = ldw_psid$opt_weight, &quot;cbps_weight&quot; = ldw_psid$cbps_weight, &quot;ebal_weight&quot; = ldw_psid$ebal_weight, # trimming &quot;ps_threshold&quot; = ldw_psid.trim, &quot;common_range&quot; = ldw_psid.common, &quot;stuermer&quot; = ldw_psid.stuermer, &quot;walker&quot; = ldw_psid.walker, &quot;crump&quot; = ldw_psid.crump, # truncation &quot;adapt&quot; = ldw_psid.ps_fixed, &quot;at_perc&quot; = ldw_psid.ps_percent, &quot;fix_value&quot; = ldw_psid.ps_adapt, # truncation and weighting &quot;fix_value_ipw_weight&quot; = fixed_comb.psid$ipw_weight, &quot;fix_value_opt_weight&quot; = fixed_comb.psid$opt_weight, &quot;fix_value_cbps_weight&quot; = fixed_comb.psid$cbps_weight, &quot;fix_value_ebal_weight&quot; = fixed_comb.psid$ebal_weight, &quot;at_perc_ipw_weight&quot; = percent_comb.psid$ipw_weight, &quot;at_perc_opt_weight&quot; = percent_comb.psid$opt_weight, &quot;at_perc_cbps_weight&quot; = percent_comb.psid$cbps_weight, &quot;at_perc_ebal_weight&quot; = percent_comb.psid$ebal_weight, &quot;adapt_ipw_weight&quot; = adapt_comb.psid$ipw_weight, &quot;adapt_opt_weight&quot; = adapt_comb.psid$opt_weight, &quot;adapt_cbps_weight&quot; = adapt_comb.psid$cbps_weight, &quot;adapt_ebal_weight&quot; = adapt_comb.psid$ebal_weight, # trimming and weighting &quot;ipw_common_range&quot; = ipw_comb.psid[[1]], &quot;ipw_crump&quot;= ipw_comb.psid[[2]], &quot;ipw_ps_threshold&quot;= ipw_comb.psid[[3]], &quot;ipw_stuermer&quot;= ipw_comb.psid[[4]], &quot;ipw_walker&quot; = ipw_comb.psid[[5]], &quot;opt_common_range&quot; = opt_comb.psid[[1]], &quot;opt_crump&quot; = opt_comb.psid[[2]], &quot;opt_ps_threshold&quot; = opt_comb.psid[[3]], &quot;opt_stuermer&quot; = opt_comb.psid[[4]], &quot;opt_walker&quot; = opt_comb.psid[[5]], &quot;cbps_common_range&quot; = cbps_comb.psid[[1]], &quot;cbps_crump&quot; = cbps_comb.psid[[2]], &quot;cbps_ps_threshold&quot; = cbps_comb.psid[[3]], &quot;cbps_stuermer&quot; = cbps_comb.psid[[4]], &quot;cbps_walker&quot;= cbps_comb.psid[[5]], &quot;ebal_common_range&quot; = ebal_comb.psid[[1]], &quot;ebal_crump&quot; = ebal_comb.psid[[2]], &quot;ebal_ps_threshold&quot; = ebal_comb.psid[[3]], &quot;ebal_stuermer&quot; = ebal_comb.psid[[4]], &quot;ebal_walker&quot; = ebal_comb.psid[[5]]) # create datasets corresponding to the top 5 methods for each dataset top5_datasets.cps &lt;- create_top5_datasets(dataset_list_cps, top5_methods.cps) top5_datasets.psid &lt;- create_top5_datasets(dataset_list_psid, top5_methods.psid) # save datasets into .RData files save_top5_datasets(dataset_list_cps, top5_methods.cps, prefix = &quot;ldw_model_a_cps1&quot;) save_top5_datasets(dataset_list_psid, top5_methods.psid, prefix = &quot;ldw_model_a_psid1&quot;) 1.9 Estimating 1.9.1 Average treatment effect on the treated (ATT) Next, we estimate the average treatment effect on the treated (ATT) using the LDW-Experimental sample, the top‑ranked observational samples (LDW‑CPS1 and LDW‑PSID1), and, for comparison, the trimmed and matched plus‑datasets. We employ a broad set of estimators, including difference-in-means, regression, the Oaxaca-Blinder estimator, generalized random forests (GRF) as an outcome model, 1:5 nearest neighbor matching with bias correction, inverse probability weighting (IPW) with GRF-based propensity scores, covariate balancing propensity score (CBPS), entropy balancing, double/debiased machine learning using elastic net, and augmented inverse probability weighting (AIPW) via GRF. We also incorporate the recently introduced estimand-specific AIPW estimator implemented through an expansion of the OutcomeWeights R package by Knaus and Pfleiderer (2024). We utilize the estimate_all() and plot_coef() functions as defined by Imbens and Xu (2024). # estimate ATT out1 &lt;- estimate_all(ldw, &quot;re78&quot;, &quot;treat&quot;, covar) out2 &lt;- estimate_all(ldw_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out3 &lt;- estimate_all(ldw_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out.cps &lt;- lapply(top5_datasets.cps, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out.psid &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, &quot;re78&quot;, &quot;treat&quot;, covar)) out4 &lt;- out.cps[[1]] out5 &lt;- out.cps[[2]] out6 &lt;- out.cps[[3]] out7 &lt;- out.cps[[4]] out8 &lt;- out.cps[[5]] out9 &lt;- out.psid[[1]] out10 &lt;- out.psid[[2]] out11 &lt;- out.psid[[3]] out12 &lt;- out.psid[[4]] out13 &lt;- out.psid[[5]] # estimate ATT load(&quot;data/trimmed.RData&quot;) out14 &lt;- estimate_all(ldw_trim_cps, &quot;re78&quot;, &quot;treat&quot;, covar) out15 &lt;- estimate_all(ldw_trim_psid, &quot;re78&quot;, &quot;treat&quot;, covar) out16 &lt;- estimate_all(ldw_cps_trim, &quot;re78&quot;, &quot;treat&quot;, covar) out17 &lt;- estimate_all(ldw_psid_trim, &quot;re78&quot;, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 1)) # experimental benchmarks band.exp &lt;- out1[1, 3:4] est.exp &lt;- out1[1, 1] # plot results plot_coef(out1, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(A) LDW-Experimental&quot;) plot_coef(out2, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(B) LDW-CPS1&quot;) plot_coef(out3, band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = &quot;(C) LDW-PSID1&quot;) for (i in seq_along(out.cps)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+3], &quot;) Top CPS1: &quot;, top5_methods.cps[i]) plot_coef(out.cps[[i]], band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = this_title) } Figure 1.90: FIGUREA10. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples Figure 1.91: FIGUREA10. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples for (i in seq_along(out.psid)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+7], &quot;) Top PSID1: &quot;, top5_methods.psid[i]) plot_coef(out.psid[[i]], band = band.exp, line = est.exp, ylim = c(-15500, 5500), main = this_title) } Figure 1.92: FIGUREA10. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples # nonexperimtenal benchmarks band.cps_plus &lt;- out14[1, 3:4] est.cps_plus &lt;- out14[1, 1] band.psid_plus &lt;- out15[1, 3:4] est.psid_plus &lt;- out15[1, 1] # plot results plot_coef(out16, band = band.cps_plus, line = est.cps_plus, ylim = c(-15500, 5500), main = &quot;(N) Trimmed LDW-CPS1-PLUS&quot;) plot_coef(out17, band = band.psid_plus, line = est.psid_plus, ylim = c(-15500, 5500), main = &quot;(O) Trimmed LDW-PSID1-PLUS&quot;) Figure 1.93: FIGUREA10. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. ATT Estimates Model A Given Unconfoundedness using LDW Samples # save results save_att_panels( out_list = list(out1, out2, out3), plot_titles = c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS1&quot;, &quot;(C) LDW-PSID1&quot;), band_list = list(band.exp, band.exp, band.exp), est_list = list(est.exp, est.exp, est.exp), prefix = &quot;ldw_model_a_est_exp&quot; ) save_att_panels( out_list = out.cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS1: &quot;, top5_methods.cps), band_list = replicate(length(out.cps), band.exp, simplify = FALSE), est_list = replicate(length(out.cps), est.exp, simplify = FALSE), prefix = &quot;ldw_model_a_est_top_cps&quot; ) save_att_panels( out_list = out.psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID1: &quot;, top5_methods.psid), band_list = replicate(length(out.psid), band.exp, simplify = FALSE), est_list = replicate(length(out.psid), est.exp, simplify = FALSE), prefix = &quot;ldw_model_a_est_top_psid&quot; ) save_att_panels( out_list = list(out16, out17), plot_titles = c(&quot;(N) Trimmed LDW-CPS1-PLUS&quot;, &quot;(O) Trimmed LDW-PSID1-PLUS&quot;), band_list = list(band.cps_plus, band.psid_plus), est_list = list(est.cps_plus, est.psid_plus), prefix = &quot;ldw_model_a_est_plus&quot; ) The above figures show the ATT estimates and their 95% confidence intervals for fifteen samples: LDW-Experimental, LDW-CPS1, LDW-PSID1, a series of top-ranked subsamples of both LDW-CPS1 and LDW-PSID1 based on various matching, weighting, truncation and trimming criteria and trimmed and matched versions of the LDW-CPS1 and LDW-PSID1 samples (similar to Imbens and Xu (2024)). Figure (A) presents the benchmark from the experimental sample (LDW-Experimental), serving as a reference for bias and variance assessment of observational samples. Figures (B) and (C) show results for the original observational samples, LDW-CPS1 and LDW-PSID1, while figures (D) through (H) display results for CPS1-based subsamples constructed with the top-ranked methods. Analogously, figures (I) through (M) summarize results for the corresponding PSID1-based subsamples under parallel rules. Figures (N) and (O) present results for the trimmed and matched versions, replicating the tutorial results of Imbens &amp; Xu (2024). Across the LDW-CPS1 dataset and its top-ranked subsamples, all estimators generally produce ATT estimates that closely cluster around the experimental benchmark. However, the ebal_weight sample exhibit somewhat larger deviations. While most estimates are positive, the ebal_weight subsample results include one negative ATT estimates. In contrast, PSID1-based subsamples frequently exhibit greater dispersion and substantially higher standard errors compared to LDW-CPS1 samples. While most ATT estimates are positive, all methods exhibit some negative ATT estimators across various estimators. # get all outputs all_outs &lt;- c(list(out1, out2, out3), out.cps, out.psid, list(out16, out17)) # get plot titles all_plot_titles &lt;- c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS1&quot;, &quot;(C) LDW-PSID1&quot;, paste0(&quot;(&quot;, LETTERS[6:10], &quot;) Top CPS1: &quot;, top5_methods.cps), paste0(&quot;(&quot;, LETTERS[11:15], &quot;) Top PSID1: &quot;, top5_methods.psid), &quot;(N) Trimmed LDW-CPS1-PLUS&quot;, &quot;(O) Trimmed LDW-PSID1-PLUS&quot;) # evaluate results all_summaries &lt;- lapply(all_outs, eval_att) att_summary &lt;- do.call(rbind, all_summaries) rownames(att_summary) &lt;- all_plot_titles # print results knitr::kable(att_summary, caption = &quot;ATT Summary Statistics&quot;, booktabs = TRUE) %&gt;% kable_styling(full_width = TRUE) Table 1.5: Table 1.6: ATT Summary Statistics Mean_SE Min_Estimate Max_Estimate Diff_Estimate LDW-Experimental 675.9799 1670.7088 1960.989 290.2805 LDW-CPS1 670.2431 -8497.5161 1729.118 10226.6344 LDW-PSID1 829.1860 -15204.7774 3093.015 18297.7928 Top CPS1: optimal_pair 713.9302 1798.3715 2460.050 661.6786 Top CPS1: card 743.9572 1120.3711 2037.508 917.1369 Top CPS1: mahvars 726.4418 1342.9255 2005.042 662.1162 Top CPS1: exact 1543.5646 1850.0940 3406.319 1556.2253 Top CPS1: ebal_weight 667.7695 -8497.5161 1729.118 10226.6344 Top PSID1: card 941.1423 -862.3562 1732.681 2595.0374 Top PSID1: adapt_ebal_weight 818.6949 -15204.7774 3082.077 18286.8544 Top PSID1: optimal_pair 890.2079 -799.8420 2580.055 3379.8966 Top PSID1: at_perc_cbps_weight 820.3766 -15204.7774 3098.974 18303.7516 Top PSID1: cem 1294.7466 -3958.6855 -1293.486 2665.1994 Trimmed LDW-CPS1-PLUS 806.9749 878.3362 2137.900 1259.5640 Trimmed LDW-PSID1-PLUS 1184.3732 -2430.1464 -1456.009 974.1373 The ATT results are presented in the table below: # create result matrix result_mat &lt;- create_matrix_results(all_outs, all_plot_titles) # render formatted table output datatable(result_mat, caption = &quot;ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The first value in each cell represents the point estimate from the respective estimator and sample. The number in brackets directly following it is the robust standard error (SE) associated with that estimate, indicating the uncertainty or variability around the point estimate. The tabulated results confirm visual patterns: Column (A) reports the estimates for the LDW-Experimental sample, column (B) for the LDW-CPS1 sample, and column (C) for the LDW-PSID1 sample. Columns (D)-(O) summarize the trimmed and top-ranked sample results for both LDW-CPS1 and LDW-PSID1. For most LDW-CPS1-based samples, estimates remain not only positive but also comparatively close to the experimental benchmark, with modest variance inflation. In contrast, the LDW-PSID1-based estimates exhibit greater variability, more frequently negative values, and larger standard errors, reflecting an increased challenge of achieving balance and overlap in this observational dataset. Overall, figures and table jointly demonstrate that ATT estimates from observational samples tend to have larger standard errors compared to the experimental sample, reflecting greater statistical uncertainty in non-experimental causal effect estimation, and that certain criteria can bring observational estimates closer to the experimental benchmark. Nevertheless, significant estimator-dependent variability and sensitivity to sample construction persist. # save results save_csv(result_mat, &quot;ldw_att_est_model_a&quot;) Improved overlap and covariate balance generally leads to estimates closer to the experimental benchmark, but often at the cost of increased standard errors. This trade-off highlights the need to carefully balance bias reduction against precision when selecting methods for robust causal inference. Next, we explore alternative estimands such as heterogeneous treatment effects and quantile treatment effects, which may provide deeper insights into the validity of the unconfoundedness assumption. 1.9.2 Conditional average treatment effect on the treated (CATT) CATT enables analysis of treatment effect heterogeneity across covariate-defined subpopulations. We estimate the CATT for the same samples previously considered in the ATT estimation by applying the Augmented Inverse Probability Weighting Generalized Random Forest (AIPW-GRF) method via the catt() function from Imbens and Xu (2024). # estimate CATT catt.ldw &lt;- catt(ldw, Y, treat, covar) catt.cps &lt;- catt(ldw_cps, Y, treat, covar) catt.psid &lt;- catt(ldw_psid, Y, treat, covar) catt.top5_cps &lt;- lapply(top5_datasets.cps, function(d) catt(d, Y, treat, covar)) catt.top5_psid &lt;- lapply(top5_datasets.psid, function(d) catt(d, Y, treat, covar)) # similar to Imbens &amp; Xu (2024) catt.trim_cps &lt;- catt(ldw_trim_cps, Y, treat, covar) catt.trim_psid &lt;- catt(ldw_trim_psid, Y, treat, covar) catt.cps_trim &lt;- catt(ldw_cps_trim, Y, treat, covar) catt.psid_trim &lt;- catt(ldw_psid_trim, Y, treat, covar) Then, we employ a modified version of the function plot_catt() from Imbens and Xu (2024) to visualize the results by plotting the estimated CATTs for all samples at the covariate values of each treated unit against their corresponding experimental benchmarks. Gray dots represent pairs of CATT estimates at covariate values of treated units, while the red crosses indicate pairs of estimated ATTs. # plot results par(mfrow = c(2,2)) par(cex.main = 0.9) plot_catt( catt1 = catt.ldw$catt, catt2 = catt.cps$catt, att1 = catt.ldw$att[1], att2 = catt.cps$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS1)&quot;, main = &quot;(B) LDW-CPS1&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 = catt.ldw$catt, catt2 = catt.psid$catt, att1 = catt.ldw$att[1], att2 = catt.psid$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID1)&quot;, main = &quot;(C) LDW-PSID1&quot;, axes.range = c(-8000, 8000) ) Figure 1.94: FIGUREA11. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental par(mfrow = c(2,2)) par(cex.main = 0.9) plot_catt_panels( exp_catt = catt.ldw, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS1: &quot;, top5_methods.cps) ) Figure 1.95: FIGUREA11. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental plot_catt_panels( exp_catt = catt.ldw, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID1: &quot;, top5_methods.psid) ) Figure 1.96: FIGUREA11. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 1.97: FIGUREA11. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 1.98: FIGUREA11. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental # plot results par(mfrow = c(2,2)) par(cex.main = 0.9) plot_catt( catt1 &lt;- catt.trim_cps$catt, catt2 &lt;- catt.cps_trim$catt, att1 &lt;- catt.trim_cps$att[1], att2 &lt;- catt.cps_trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (CPS1-PLUS-Trimmed)&quot;, main = &quot;(N) Trimmed LDW-CPS1-PLUS&quot;, axes.range = c(-8000, 8000) ) plot_catt( catt1 &lt;- catt.trim_psid$catt, catt2 &lt;- catt.psid_trim$catt, att1 &lt;- catt.trim_psid$att[1], att2 &lt;- catt.psid_trim$att[1], xlab = &quot;CATT (Experimental)&quot;, ylab = &quot;CATT (PSID1-PLUS-Trimmed)&quot;, main = &quot;(O) Trimmed LDW-PSID1-PLUS&quot;, axes.range = c(-8000, 8000) ) Figure 1.99: FIGUREA11. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. CATT Estimates Model A using LDW Data: Experimental vs. Nonexperimental # combine all catt objects all_catt &lt;- c(list(catt.ldw, catt.cps, catt.psid), catt.top5_cps, catt.top5_psid, list(catt.cps_trim, catt.psid_trim)) all_catt_eval &lt;- eval_catt(all_catt, all_plot_titles) knitr::kable(all_catt_eval, caption = &quot;CATT Summary Statistics&quot;, booktabs = TRUE) ## Warning in attr(x, &quot;align&quot;): &#39;xfun::attr()&#39; ist veraltet. ## Benutzen Sie stattdessen &#39;xfun::attr2()&#39; ## Siehe help(&quot;Deprecated&quot;) ## Warning in attr(x, &quot;format&quot;): &#39;xfun::attr()&#39; ist veraltet. ## Benutzen Sie stattdessen &#39;xfun::attr2()&#39; ## Siehe help(&quot;Deprecated&quot;) Table 1.7: CATT Summary Statistics Method Min_Catt Max_Catt Mean_Catt Diff_Catt (A) LDW-Experimental -106.7322 4009.538 1748.6183 4116.270 (B) LDW-CPS1 -5334.0441 6947.078 2063.0321 12281.122 (C) LDW-PSID1 -8552.2574 4635.637 766.4958 13187.894 (F) Top CPS1: optimal_pair -1173.6438 6096.667 2198.5938 7270.310 (G) Top CPS1: card -858.2185 4699.197 1546.8888 5557.416 (H) Top CPS1: mahvars -2477.1589 5329.045 1614.0057 7806.203 (I) Top CPS1: exact 1893.1853 2902.437 2596.3965 1009.251 (J) Top CPS1: ebal_weight -5495.0380 7029.987 1973.2698 12525.025 (K) Top PSID1: card -3057.6048 3882.944 990.2618 6940.549 (L) Top PSID1: adapt_ebal_weight -7823.6843 4668.130 789.3497 12491.814 (M) Top PSID1: optimal_pair -5566.2220 2902.654 332.1093 8468.876 (N) Top PSID1: at_perc_cbps_weight -8254.0491 4511.911 709.2994 12765.961 (O) Top PSID1: cem -4658.3140 1300.720 -1159.9362 5959.034 (N) Trimmed LDW-CPS1-PLUS -2499.2542 5745.244 1318.4281 8244.498 (O) Trimmed LDW-PSID1-PLUS -7394.3318 1706.341 -1872.7306 9100.673 Specifically, with LDW-CPS1, CATT estimates span from $-4,979.99 to $7,201.81, contrasting with the CATT estimated from experimental data which ranges from $-189.40 to $3,835.95, with a mean CATT estimate of $1,713.26. The LDW-PSID1 data shows an even broader CATT estimate range, spanning from $-8,643.02 to $4,903.22, and a notably lower mean of approximately $820.77. Among the trimmed and top-ranked LDW-CPS1 subsamples, CATT ranges vary substantially. Specific samples such as card or overlap_crump subsamples produce minimum CATTs that are considerably negative, but produce positive mean estimates. Subsamples like ps_threshold, and optimal_pair also deliver positive mean CATT estimates, though with smaller negative minimums, while mahvars is the only method among these to produce a negative mean CATT. Importantly, across all methods, the mean CATT estimates are far away from experimental mean estimate. The CATT estimates for the LDW-PSID1 trimmed and top-ranked subsamples reveal substantially decreased mean values and wider extremes compared to their CPS1 counterparts, reflecting greater difficulties in producing reliable treatment effect estimates. This variation in range and means across methods and samples reflects substantial heterogeneity in treatment effect estimation, indicating that while some criteria improve alignment with experimental benchmarks, others introduce considerable discrepancies and variability in estimated heterogeneous effects. # save results save_main_catt_panels( catt_refs = list(catt.ldw), catt_comps = list(catt.cps, catt.psid), ylabels = c(&quot;CATT (CPS1)&quot;, &quot;CATT (PSID1)&quot;), prefix = &quot;ldw_model_a_catt_main_panels&quot;, main_titles = c(&quot;(B) LDW-CPS1&quot;, &quot;(C) LDW-PSID1&quot;) ) save_catt_panels( exp_catt = catt.ldw, catt_list = catt.top5_cps, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS1: &quot;, top5_methods.cps), prefix = &quot;ldw_model_a_catt_top5_cps&quot; ) save_catt_panels( exp_catt = catt.ldw, catt_list = catt.top5_psid, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID1: &quot;, top5_methods.psid), prefix = &quot;ldw_model_a_catt_top5_psid&quot; ) save_plus_catt_panels( catt1_list = list(catt.trim_cps, catt.trim_psid), catt2_list = list(catt.cps_trim, catt.psid_trim), ylabels = c(&quot;CATT (CPS1-PLUS-Trimmed)&quot;, &quot;CATT (PSID1-PLUS-Trimmed)&quot;), prefix = &quot;ldw_model_a_catt_plus_panels&quot;, main_titles = c(&quot;(N) LDW-CPS1-PLUS&quot;, &quot;(O) LDW-PSID1-PLUS&quot;) ) Although the AIPW estimator can produce ATT estimates closely aligned with the experimental benchmark using LDW data, its performance for revealing the true CATT is considerably worse. 1.9.3 Quantile treatment effect on the treated (QTET) QTET provides a robust way to analyze treatment effect heterogeneity while being less impacted by outliers compared to average treatment effect measures. The QTET estimates are obtained using the propensity score re-weighting method introduced by Firpo (2007). Implementation leverages the qte() function from Imbens and Xu (2024), while visualization employs a modified version of their plot_qte() function. qte.ldw &lt;- est_qte(Y, treat, covar, data = ldw, cores = 4) qte.ldw_cps &lt;- est_qte(Y, treat, covar, data = ldw_cps) qte.ldw_psid &lt;- est_qte(Y, treat, covar, data = ldw_psid) qte.top5_cps &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, covar, data = d)) qte.top5_psid &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, covar, data = d)) qte.trim.ldw_cps &lt;- est_qte(Y, treat, NULL, data = ldw_trim_cps) qte.trim.ldw_psid &lt;- est_qte(Y, treat, NULL, data = ldw_trim_psid) qte.ldw_cps.trim &lt;- est_qte(Y, treat, covar, data = ldw_cps_trim) qte.ldw_psid.trim &lt;- est_qte(Y, treat, covar, data = ldw_psid_trim) qte.ldw0 &lt;- est_qte(Y, treat, NULL, data = ldw) qte.ldw_cps0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps) qte.ldw_psid0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid) qte.top5_cps0 &lt;- lapply(top5_datasets.cps, function(d) est_qte(Y, treat, NULL, data = d)) qte.top5_psid0 &lt;- lapply(top5_datasets.psid, function(d) est_qte(Y, treat, NULL, data = d)) qte.ldw_cps.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_cps_trim) qte.ldw_psid.trim0 &lt;- est_qte(Y, treat, NULL, data = ldw_psid_trim) Each plot displays three distinct series for every dataset analyzed: (1) The blue line with diamond-shaped points represents QTET estimates derived from the experimental sample, serving as the benchmark. (2) The red line with triangles shows QTET estimates from the observational data before any adjustment. (3) The black line with circles presents QTET estimates for the observational data after applying covariate adjustment. par(mfrow = c(2,2)) par(cex.main = 0.9) ylim = c(-25000, 15000) # CPS1 plot_qte(qte.ldw_cps, qte.ldw_cps0, qte.ldw, main = &quot;(B) LDW-CPS1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1 plot_qte(qte.ldw_psid, qte.ldw_psid0, qte.ldw, main = &quot;(C) LDW-PSID1&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # CPS1 top methods plot_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw, all_plot_titles, main_start = 4) Figure 1.100: FIGUREA13. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental # PSID1 top methods plot_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw, all_plot_titles, main_start = 9) Figure 1.101: FIGUREA13. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental Figure 1.102: FIGUREA13. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental # CPS1-PLUS trimmed plot_qte(qte.ldw_cps.trim, qte.ldw_cps.trim0, qte.trim.ldw_cps, main = &quot;(N) LDW-CPS1-PLUS (Trimmed)&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) # PSID1-PLUS trimmed plot_qte(qte.ldw_psid.trim, qte.ldw_psid.trim0, qte.trim.ldw_psid, main = &quot;(O) LDW-PSID1-PLUS (Trimmed)&quot;, ylim) legend(&quot;bottomleft&quot;, legend = c(&quot;Experimental&quot;, &quot;Unadjusted&quot;, &quot;Adjusted&quot;), lty = 1, pch = c(16, 17, 16), col = c(4, 2, 1), bty = &quot;n&quot;) Figure 1.103: FIGUREA13. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. QTET Estimates Model A using LDW Data: Experimental vs. Nonexperimental These figures display QTET estimates derived from both the experimental and various observational samples. The QTETs estimated from the original and trimmed LDW-CPS1 sample (B and D) corresponds well with the true QTET, although the estimates are often underpowered. The QTET estimates from the original and trimmed LDW-PSID1 subsample (C and E) show clear biases when compared to the experimental benchmark, which clusters near zero. Among the top-ranked LDW-CPS1-based subsamples, QTETs (F - J) continue to track the true experimental effect well, whereas LDW-PSID1-based subsamples produce QTETs (K - O) that exhibit increased bias and noticeably wider confidence bands, indicating greater estimation uncertainty. # list results plots_ldw &lt;- list( list(mod = qte.ldw_cps, mod0 = qte.ldw_cps0, bm = qte.ldw, main = &quot;(B) LDW-CPS1&quot;), list(mod = qte.ldw_psid, mod0 = qte.ldw_psid0, bm = qte.ldw, main = &quot;(C) LDW-PSID1&quot;), list(mod = qte.ldw_cps.trim, mod0 = qte.ldw_cps.trim0, bm = qte.trim.ldw_cps, main = &quot;(N) LDW-CPS1-PLUS (Trimmed)&quot;), list(mod = qte.ldw_psid.trim, mod0 = qte.ldw_psid.trim0, bm = qte.trim.ldw_psid, main = &quot;(O) LDW-PSID1-PLUS (Trimmed)&quot;) ) # save results save_qtet(plots_ldw, prefix = &quot;ldw_model_a&quot;) save_qte_top(qte.top5_cps, qte.top5_cps0, qte.ldw, all_plot_titles, main_start = 8, prefix = &quot;ldw_model_a_top&quot;) save_qte_top(qte.top5_psid, qte.top5_psid0, qte.ldw, all_plot_titles, main_start = 13, prefix = &quot;ldw_model_a_top&quot;) 1.9.4 Assessing outcome weights (OW) # list all datasets all_datasets &lt;- c(list(ldw, ldw_cps, ldw_psid), top5_datasets.cps, top5_datasets.psid, list(ldw_trim_cps, ldw_trim_psid)) # estimate ATT res_att &lt;- get_res_att(all_datasets, Y, treat, covar) # extract outcome weights ow_att &lt;- derive_ow(res_att) par(mfrow = c(2,2)) par(cex.main = 0.9) # plot outcome weights distribution plot_ow(ow_att, all_plot_titles) Figure 1.104: FIGUREA14. Outcome Weights Model A using LDW Data Figure 1.105: FIGUREA14. Outcome Weights Model A using LDW Data Figure 1.106: FIGUREA14. Outcome Weights Model A using LDW Data Figure 1.107: FIGUREA14. Outcome Weights Model A using LDW Data # evaluate results res_ow &lt;- eval_ow(ow_att, all_datasets, all_plot_titles, treat, &quot;AIPW-ATT&quot;) knitr::kable(res_ow, caption = &quot;Outcome Weights for Treated and Untreated&quot;, booktabs = TRUE) %&gt;% kable_styling(full_width = TRUE) Table 1.8: Table 1.9: Outcome Weights for Treated and Untreated Method Sum_Treated Sum_Untreated LDW-Experimental 1 -1 LDW-CPS1 1 -1 LDW-PSID1 1 -1 Top CPS1: optimal_pair 1 -1 Top CPS1: card 1 -1 Top CPS1: mahvars 1 -1 Top CPS1: exact 1 -1 Top CPS1: ebal_weight 1 -1 Top PSID1: card 1 -1 Top PSID1: adapt_ebal_weight 1 -1 Top PSID1: optimal_pair 1 -1 Top PSID1: at_perc_cbps_weight 1 -1 Top PSID1: cem 1 -1 Trimmed LDW-CPS1-PLUS 1 -1 Trimmed LDW-PSID1-PLUS 1 -1 The outcome weights are not obtained directly from the ATT point estimates due to computational design of other methods. Instead, the ATT is separately estimated for each dataset following the approach developed by Knaus and Pfleiderer (2024). The evaluation reveals that across each sample the estimated outcome weights sum to one within the treated group and minus one within the untreated group, resulting in an overall sum of zero. #save results save_ow(ow_att, all_plot_titles, prefix = &quot;model_a&quot;) 1.10 Validation through placebo analyses To further evaluate the credibility of the unconfoundedness assumption, a placebo analysis is performed by designating 1975 earnings (re75) as the outcome variable and omitting both re75 and u75 from the list of covariates. The analysis utilizes all previously considered samples and recomputes the ATT via the function estimate_all, conditioning only on the remaining set of covariates. # define variables Y &lt;- &quot;re75&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re74&quot;, &quot;u74&quot;) # estimate placebo ATT on original and observational datasets out1_pl &lt;- estimate_all(ldw, Y, &quot;treat&quot;, covar) out2_pl &lt;- estimate_all(ldw_cps, Y, &quot;treat&quot;, covar) out3_pl &lt;- estimate_all(ldw_psid, Y, &quot;treat&quot;, covar) # estimate placebo ATT on top ranked datasets out.cps_pl &lt;- lapply(top5_datasets.cps, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out.psid_pl &lt;- lapply(top5_datasets.psid, function(d) estimate_all(d, Y, &quot;treat&quot;, covar)) out4_pl &lt;- out.cps_pl[[1]] out5_pl &lt;- out.cps_pl[[2]] out6_pl &lt;- out.cps_pl[[3]] out7_pl &lt;- out.cps_pl[[4]] out8_pl &lt;- out.cps_pl[[5]] out9_pl &lt;- out.psid_pl[[1]] out10_pl &lt;- out.psid_pl[[2]] out11_pl &lt;- out.psid_pl[[3]] out12_pl &lt;- out.psid_pl[[4]] out13_pl &lt;- out.psid_pl[[5]] # estimate placebo ATT on plus datasets load(&quot;data/trimmed.RData&quot;) out14_pl &lt;- estimate_all(ldw_trim_cps_pl, Y, &quot;treat&quot;, covar) out15_pl &lt;- estimate_all(ldw_trim_psid_pl, Y, &quot;treat&quot;, covar) out16_pl &lt;- estimate_all(ldw_cps_trim_pl, Y, &quot;treat&quot;, covar) out17_pl &lt;- estimate_all(ldw_psid_trim_pl, Y, &quot;treat&quot;, covar) par(mfrow = c(4, 1), mar = c(4, 4, 2, 1)) # experimental benchmarks band.exp_pl &lt;- out1_pl[1, 3:4] est.exp_pl &lt;- out1_pl[1, 1] # plot placebo results plot_coef(out1_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(A) LDW-Experimental&quot;) plot_coef(out2_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(B) LDW-CPS1&quot;) plot_coef(out3_pl, band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = &quot;(C) LDW-PSID1&quot;) for (i in seq_along(out.cps_pl)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+2], &quot;) Top CPS1: &quot;, top5_methods.cps[i]) plot_coef(out.cps_pl[[i]], band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = this_title) } Figure 1.108: FIGUREA15. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. Placebo Test Model A: ’75 Earnings as the Outcome Figure 1.109: FIGUREA15. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. Placebo Test Model A: ’75 Earnings as the Outcome for (i in seq_along(out.psid_pl)) { this_title &lt;- paste0(&quot;(&quot;, LETTERS[i+7], &quot;) Top PSID1: &quot;, top5_methods.psid[i]) plot_coef(out.psid_pl[[i]], band = band.exp_pl, line = est.exp_pl, ylim = c(-15500, 5500), main = this_title) } Figure 1.110: FIGUREA15. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. Placebo Test Model A: ’75 Earnings as the Outcome Figure 1.111: FIGUREA15. SubfigureA:LDW-Experimental. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1. SubfigureD-H:Top-LDW-CPS1. SubfigureI-M:Top-LDW-PSID1. Placebo Test Model A: ’75 Earnings as the Outcome par(mfrow = c(4, 1)) # nonexperimtenal benchmarks band.cps_plus_pl &lt;- out14_pl[1, 3:4] est.cps_plus_pl &lt;- out14_pl[1, 1] band.psid_plus_pl &lt;- out15_pl[1, 3:4] est.psid_plus_pl &lt;- out15_pl[1, 1] # plot results plot_coef(out16_pl, band = band.cps_plus_pl, line = est.cps_plus_pl, ylim = c(-12000, 2000), main = &quot;(N) Trimmed LDW-CPS1-PLUS&quot;) plot_coef(out17_pl, band = band.psid_plus_pl, line = est.psid_plus_pl, ylim = c(-12000, 2000), main = &quot;(O) Trimmed LDW-PSID1-PLUS&quot;) Figure 1.112: FIGUREA15. SubfigureN:LDW-CPS1-PLUS. SubfigureO:LDW-PSID1-PLUS. Placebo Test Model A: ’75 Earnings as the Outcome # save results save_att_panels( out_list = list(out1_pl, out2_pl, out3_pl), plot_titles = c(&quot;(A) LDW-Experimental&quot;, &quot;(B) LDW-CPS1&quot;, &quot;(C) LDW-PSID1&quot;), band_list = list(band.exp_pl, band.exp_pl, band.exp_pl), est_list = list(est.exp_pl, est.exp_pl, est.exp_pl), prefix = &quot;ldw_model_a_pl_est_exp&quot; ) save_att_panels( out_list = out.cps_pl, plot_titles = paste0(&quot;(&quot;, LETTERS[4:8], &quot;) Top CPS1: &quot;, top5_methods.cps), band_list = replicate(length(out.cps_pl), band.exp_pl, simplify = FALSE), est_list = replicate(length(out.cps_pl), est.exp_pl, simplify = FALSE), prefix = &quot;ldw_model_a_pl_est_top_cps&quot; ) save_att_panels( out_list = out.psid_pl, plot_titles = paste0(&quot;(&quot;, LETTERS[9:13], &quot;) Top PSID1: &quot;, top5_methods.psid), band_list = replicate(length(out.psid_pl), band.exp_pl, simplify = FALSE), est_list = replicate(length(out.psid_pl), est.exp_pl, simplify = FALSE), prefix = &quot;ldw_model_a_pl_est_top_psid&quot; ) save_att_panels( out_list = list(out16_pl, out17_pl), plot_titles = c(&quot;(P) Trimmed LDW-CPS1-PLUS&quot;, &quot;(Q) Trimmed LDW-PSID1-PLUS&quot;), band_list = list(band.cps_plus_pl, band.psid_plus_pl), est_list = list(est.cps_plus_pl, est.psid_plus_pl), prefix = &quot;ldw_model_a_pl_est_plus&quot;, ylim = c(-12000, 2000) ) The placebo ATT results are presented in the table below: # print placebo results all_outs.pl &lt;- c(list(out1_pl, out2_pl, out3_pl), out.cps_pl, out.psid_pl, list(out16_pl, out17_pl)) result_mat_pl &lt;- create_matrix_results(all_outs.pl, all_plot_titles) datatable(result_mat_pl, caption = &quot;Placebo ATT Estimates and SEs&quot;, options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE)) The placebo analysis reveals that the experimental benchmarks are positive, near zero and statistically insignificant, while all estimators applied to the observational datasets, LDW-CPS1 and LDW-PSID1, yield by majority large, negative ATT estimates. For LDW-CPS1, most ATT estimates are negative. The overlap_crump subsample shows a modest improvement toward the experimental benchmark compared to LDW-CPS1 (B) results, but also produces notably poorer estimates for certain estimators. The trimmed subsamples (D) and (I), which use similar approaches, further improve upon the LDW-CPS1 (B) results. The optimal_pair and card subsamples provide even greater improvement. The mahvars (G) subsample delivers ATT estimates closest to the experimental benchmark and is the only case to yield positive ATT estimates across the LDW-CPS1 samples. For LDW-PSID1, the subsample (O) applying the overlap_common_range method shows no improvement compared to the LDW-PSID1 sample (C) except for the Diff-in-Means estimator. The overlap_crump subsample generally delivers ATT estimates closer to the experimental benchmark, while the card and mahvars subsamples producing estimates even closer to the experimental benchmark. The trimmed subsamples (E) and (N), which use similar approaches, achieve the closest alignment with the benchmark. Across most estimators and observational top-ranked subsamples (F–O) the placebo analysis reveals substantial bias and deviation from the true effect, highlighting the persistent challenges in adjusting for confounding using observational data. This underlines the limitations of these methods in recovering unbiased ATT estimates outside of randomized experimental settings. # save results save_csv(result_mat_pl, &quot;ldw_att_estimates_pl_model_a&quot;) 1.11 Validation through sensitivity analyses Finally, a sensitivity analyses using the LDW data is conducted and results are depicted in contour plots using the function sens_ana of Imbens &amp; Xu (2024). # define variables Y &lt;- &quot;re78&quot; treat &lt;- &quot;treat&quot; covar &lt;- c(&quot;age&quot;, &quot;education&quot;, &quot;black&quot;, &quot;hispanic&quot;, &quot;married&quot;, &quot;nodegree&quot;, &quot;re75&quot;, &quot;u74&quot;, &quot;u75&quot;) bm &lt;- c(&quot;re75&quot;) # check for valid datasets filtered_datasets_sens &lt;- check_filter_datasets(all_datasets, Y, treat, covar, bm) par(mfrow = c(2,2)) par(cex.main = 0.8) # loop over valid datasets and assign index for (i in seq_along(filtered_datasets_sens)) { idx &lt;- which(sapply(all_datasets, identical, filtered_datasets_sens[[i]])) sens_ana(filtered_datasets_sens[[i]], Y, treat, covar, bm, kd = 1:3) title(main = all_plot_titles[idx]) } Figure 1.113: FIGUREA16. Sensitivity Analyses Model A Figure 1.114: FIGUREA16. Sensitivity Analyses Model A Figure 1.115: FIGUREA16. Sensitivity Analyses Model A Figure 1.116: FIGUREA16. Sensitivity Analyses Model A # save results save_sensitivity_plots(filtered_datasets_sens, Y, treat, covar, bm, all_plot_titles, &quot;ldw_model_a&quot;) The sensitivity analysis shows that for most samples, the estimated treatment effects are fairly robust to increasing confounder strength, as indicated by relatively stable values despite up to triple the correlation levels of re75. Notably, some samples such as LDW-PSID1 exhibit a greater sensitivity with more pronounced swings including negative estimates at higher confounder strengths, contrasting with consistent positive effects in LDW-CPS1 variants. This highlights sample-specific differences in robustness against potential unobserved confounding. The analyses suggest that some samples maintain stable treatment effect estimates despite increasing confounder strength, while others show greater sensitivity. This highlights the importance of assessing robustness across different samples (respectively methods used to derive specific samples) to account for potential unobserved bias. 1.12 Inspection of re74 and re75 1.12.1 Correlation # correlation re74 and re75 cor_results &lt;- sapply(all_datasets, function(d) cor(d$re74, d$re75, use = &quot;complete.obs&quot;)) cor_table &lt;- data.frame(Method = all_plot_titles, Correlation = cor_results) knitr::kable(cor_table, caption = &quot;Correlation between re74 and re75 across datasets&quot;, booktabs = TRUE) %&gt;% kable_styling(full_width = TRUE) Table 1.10: Table 1.11: Correlation between re74 and re75 across datasets Method Correlation LDW-Experimental 0.6552006 LDW-CPS1 0.8719266 LDW-PSID1 0.8558592 Top CPS1: optimal_pair 0.7010616 Top CPS1: card 0.5249007 Top CPS1: mahvars 0.7102523 Top CPS1: exact NA Top CPS1: ebal_weight 0.8719266 Top PSID1: card 0.5125231 Top PSID1: adapt_ebal_weight 0.8558592 Top PSID1: optimal_pair 0.5686556 Top PSID1: at_perc_cbps_weight 0.8558592 Top PSID1: cem 0.6521532 Trimmed LDW-CPS1-PLUS 0.6460145 Trimmed LDW-PSID1-PLUS 0.5451712 1.13 Summary After reexamining model A, that is based on the LaLonde-Dehejia-Wahba (LDW) data and its augmented versions with control groups from CPS-1 and PSID-1, several insights into causal inference challenges emerge. First, we confirm that ensuring overlap between treated and control groups remains crucial for credible causal estimation. The LDW-Experimental data exhibit excellent overlap, while the observational datasets (LDW-CPS1 and LDW-PSID1) show weaker overlap, with many treated units outside the control range. Augmenting these datasets with experimental controls improves overlap but does not consistently improve covariate balance. Second, controlling for covariates such as age, education, race, and prior earnings, and using various methods including matching, weighting, truncation, trimming, and combined approaches, largely yields consistent effects. The propensity score plays an important role in assessing overlap and balancing covariates across groups. Third, the LDW dataset is somewhat unique in that most methods approximate the experimental benchmark well for average treatment effects on the treated (ATT), an achievement not fully replicated in the original LaLonde samples. However, placebo tests using pre-treatment earnings and sensitivity analyses reveal lingering concerns about the unconfoundedness assumption and robustness of some estimators. Overall, this chapter highlights the importance of overlap and covariate balance, the utility of propensity scores, and the need for rigorous validation of treatment assignment assumptions to produce credible causal estimates. Despite improvements in data and methods, tests of unconfoundedness via placebo outcomes suggest caution in interpreting causal effects. References Greifer, Noah. 2025a. “Matching Methods.” ———. 2025b. “Using WeightIt to Estimate Balancing Weights.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Ju, Cheng, Joshua Schwab, and Mark J. van der Laan. 2013. “On Adaptive Propensity Score Truncation in Causal Inference.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” Matsouaka, Roland A., and Yunji Zhou. 2023. “Causal Inference in the Absence of Positivity: The Role of Overlap Weights.” Biometrical Journal. Stürmer, Til, Michael Webster-Clark, Jennifer L. Lund, Richard Wyss, Alan R. Ellis, Mark Lunt, Kenneth J. Rothman, and Robert J. Glynn. 2021. “Propensity Score Weighting and Trimming Strategies for Reducing Variance and Bias of Treatment Effect Estimates: A Simulation Study.” American Journal of Epidemiology. "],["references.html", "References", " References Greifer, Noah. 2025a. “Matching Methods.” ———. 2025b. “Using WeightIt to Estimate Balancing Weights.” Imbens, Guido W., and Yiqing Xu. 2024. “LaLonde (1986) After Nearly Four Decades: Lessons Learned.” Ju, Cheng, Joshua Schwab, and Mark J. van der Laan. 2013. “On Adaptive Propensity Score Truncation in Causal Inference.” Knaus, Michael C., and Henri Pfleiderer. 2024. “Outcome Weights.” Matsouaka, Roland A., and Yunji Zhou. 2023. “Causal Inference in the Absence of Positivity: The Role of Overlap Weights.” Biometrical Journal. Stürmer, Til, Michael Webster-Clark, Jennifer L. Lund, Richard Wyss, Alan R. Ellis, Mark Lunt, Kenneth J. Rothman, and Robert J. Glynn. 2021. “Propensity Score Weighting and Trimming Strategies for Reducing Variance and Bias of Treatment Effect Estimates: A Simulation Study.” American Journal of Epidemiology. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
