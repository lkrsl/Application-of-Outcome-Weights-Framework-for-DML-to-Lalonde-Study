--- 
title: "Application of the Outcome Weights Framework for Double Machine Learning to the Lalonde Study"
author: "Laura Kreisel"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
documentclass: book
bibliography: [tutorial/book.bib, tutorial/packages.bib]
description: |
  This book replicates the LaLonde study by Imbens & Xu (2024) and extends it by comparing a
  full with a reduced covariate model to mitigate potential confounding. 
  It evaluates various methods to improve overlap and covariate balance for robust 
  treatment effect estimation and applies the outcome weights framework by Knaus & Pfleiderer (2024) 
  to assess another estimator and analyse the distributional properties of outcome weights.
  The analysis draws on the original LaLonde dataset as well as the LaLonde–Dehejia–Wahba (LDW) and LaLonde–Calónico–Smith (LCS) datasets.
link-citations: yes
github-repo: lkrsl/Application-of-Outcome-Weights-Framework-for-DML-to-Lalonde-Study
---

# Preface {-}

This book replicates the LaLonde study by @imbens2024 and extends it by comparing a
full with a reduced covariate model to mitigate potential confounding. 
It evaluates various methods to improve overlap and covariate balance for robust treatment effect estimation and 
applies the outcome weights framework by @OW_Package to assess another estimator and analyse the distributional properties of outcome weights. 
The analysis draws on the original LaLonde dataset as well as the LaLonde–Dehejia–Wahba (LDW) and LaLonde–Calónico–Smith (LCS) datasets.

```{r, echo=FALSE, out.width="80%", fig.align="center"}
knitr::include_graphics("tutorial/Outcome-Weights_files/figure-html/image3.jpg")
```

Section 1 introduces required packages and wrapper functions used throughout the analysis. 
Section 2 replicates and extends the full covariate model from @imbens2024 using the LaLonde-Dehejia-Wahba (LDW) dataset. 
Section 3 applies a reduced covariate set to the same LDW dataset. 
Section 4 analyzes the original LaLonde dataset following similar methods and 
section 5 explores the LaLonde-Calónico-Smith (LCS) dataset, focusing on female samples.

<!--chapter:end:index.Rmd-->

# LaLonde-Dehejia-Wahba (LDW) Data
LaLonde (1986) evaluated the effect of the National Supported Work Demonstration (NSW) program on both female and male participants. While the female participants were drawn from the Aid to Families with Dependent Children (AFDC) program, the male participants were drawn from three other groups: former drug addicts, ex-criminal offenders, and high-school dropouts. LaLonde relied on two main data sources:
(1) CPS-SSA-1, based on Westat’s Matched Current Population Survey–Social Security Administration File for individuals under 55 matching specific criteria;
(2) PSID-1, based on Panel Study of Income Dynamics for household heads under 55 from specific years who were not retired in 1975, adjusted for factors like employment status and poverty level, resulting in four additional comparison groups.

Dehejia and Wahba (1999) constructed a subset of LaLonde's original data, retaining 62% of observations and restricting the focus to male participants based on their 1974 earnings. As the dataset was formed entirely on pretreatment information like employment records or month of assignment, treatment allocation was effectively independent of all pre-treatment variables. Thus, they concluded that this subset, known as the LaLonde-Dehejia-Wahba (LDW) data, constitutes a valid experimental sample.

The analysis in section 2 and 3 builds on the LDW data and considers in total three samples: 
(1) LDW-Experimental, consisting of 185 treated individuals and 280 controls from the experimental data;
(2) LDW-CPS1, which pairs the same treated sample with 15,992 controls from CPS-SSA-1;
(3) LDW-PSID1, featuring the same treated sample with 2,490 controls from PSID-1; 
In section 4, the analysis applies the same set of statistical tools to analyze a fourth sample as an additional demonstration:
(4) LaLonde male samples (1986).
In the last section, the analysis applies a reduced set of statistical tools to analyze a fifth sample again as an additional demonstration:
(5) LaLonde female samples (2017).

This section (2) covers model A, which includes the outcome variable 1978 earnings (`re78`) and adjusts for a set of covariates: age, education, race (`black`, `hispanic`), marital status, high school dropouts, 1974 and 1975 earnings (`re74`, `re75`), and unemployment status in 1974 and 1975 (`u74`, `u75`). The model is defined by a regression formula for treatment assignment using these covariates. To improve covariate balance and overlap between treated and control groups, various methods are applied and are structured into five parts (matching, weighting, truncation, trimming and integrated methods). From these methods, the five best methods are determined based on a score defined by absolute standardized mean differences (SMD) and the effective sample size (ESS). The corresponding datasets are used to estimate the average treatment effect on the treated (ATT). Notably, the estimation incorporates the recently introduced augmented inverse probability weighting (AIPW) estimator, implemented via the `OutcomeWeights` R package. Subsequently, alternative estimands are considered, including the conditional average treatment effect for the treated (CATT) and the quantile treatment effect on the treated (QTET). After estimating these effects, outcome weights are analyzed to identify potential patterns in the contribution of individual observations to the ATT.  Placebo tests are then conducted using 1975 earnings (`re75`) as an outcome to assess potential biases and the validity of unconfoundedness assumptions. Finally, sensitivity analyses are performed to evaluate the robustness of treatment effect estimates to violations of these assumptions. 

## Set up
### Source functions and load data
```{r, message=FALSE, warning=FALSE}
source("https://github.com/xuyiqing/lalonde/blob/main/tutorial/functions.R?raw=TRUE")
source("tutorial/functions.R")
#source("C:/Users/lkreisel/workspace/uni-projects/Application-of-Outcome-Weights-Framework-for-DML-to-Lalonde-Study/tutorial/functions.R")
# source functions (skip remote copy when offline)
# remote_url <- "https://raw.githubusercontent.com/xuyiqing/lalonde/main/tutorial/functions.R"
# tryCatch(
#         source(remote_url, local = FALSE),
#         error = function(e) message("Skipping remote helper script: ", conditionMessage(e))
# )
# source("tutorial/functions.R")
```

```{r, message=FALSE, warning=FALSE}
# load data
load("data/lalonde.RData")
```

```{r, message=FALSE, warning=FALSE}
# set seed
set.seed(42)
```

### Inspect data

We begin the analysis with an overview of each dataset, where the dataset name, number of observations (rows), number of treated and control units, number of variables (columns), and variable names are reviewed.
```{r, message=FALSE, warning=FALSE}
# collect datasets in a list
data <- list(lalonde = lalonde, ldw_tr = ldw_tr, ldw_co = ldw_co, ldw_cps = ldw_cps, ldw_psid = ldw_psid)

# inspect key metrics of each dataset
summary_stats <- inspect_data(data)
datatable(summary_stats, caption = "Summary Statistics",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

### Load and preprocess data

Next, we augment the control groups in LDW-CPS1 and LDW-PSID1 by merging them with the experimental controls from LDW-Experimental. This approach follows the methodology laid out by @imbens2024. These expanded datasets are used solely for comparative purposes, while all primary analyses rely on the original LDW‑CPS1 and LDW‑PSID1 data.
```{r, message=FALSE, warning=FALSE}
# assigns 1 to the experimental controls
ldw_co$treat <- 1

# merge experimental data with CPS1 data
ldw_cps_plus <- rbind.data.frame(
  ldw_co,    # experimental controls 
  ldw_cps    # CPS1 data 
)

# merge experimental data with PSID1 data
ldw_psid_plus <- rbind.data.frame(
  ldw_co,    # experimental controls 
  ldw_psid   # PSID1 data 
)

datasets <- list(ldw_cps_plus  = ldw_cps_plus, ldw_psid_plus = ldw_psid_plus)

# inspect each dataset
summary_stats_plus <- inspect_data(datasets)
datatable(summary_stats_plus, caption = "Summary Statistics",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```

## Model A

Finally, we define Model A as the baseline specification underlying the analysis.
```{r, message=FALSE, warning=FALSE}
# define variables
Y <- "re78" 
treat <- "treat" 
covar <- c("age", "education", "black", "hispanic", "married", 
           "nodegree", "re74", "re75", "u74", "u75") #re74 included
```

## Assessing overlap and covariate balance
### Overlap
To identify the average causal effect under unconfoundedness (that asserts that the treatment assignment is independent of the potential outcomes), it must be ensured that one can estimate the average effect at every value for the covariates. Thus, overlaps between the treated and untreated units (meaning that for every combination of covariates, there are both treated and untreated units in the dataset) are required. To assess overlap in the propensity scores and visualize the results using histograms of their log-odds, we use the `assess_overlap()` function of @imbens2024.

<div class="callout-note">
In a properly balanced experimental design, the distributions of the treatment group (red) and the control group (gray) would show considerable coverage.
</div>
```{r, fig.cap='FIGUREA1. SubfigureA:LDW. SubfigureB:LDW-CPS1. SubfigureC:LDW-PSID1.',out.width='100%', fig.asp=0.5}
ldw.ps <- assess_overlap(data = ldw, treat = treat, cov = covar)
ldw_cps.ps <- assess_overlap(data = ldw_cps, treat = treat, cov = covar) 
ldw_psid.ps <- assess_overlap(data = ldw_psid, treat = treat, cov = covar) 
```

As anticipated, LDW-Experimental exhibits an almost perfect overlap. In contrast, the observational datasets LDW-CPS1 and LDW-PSID1 show weak overlap. Notably, many treated units have propensity scores outside the range of the controls, while a large share of control units have propensity scores concentrated at very low log-odds.

Next, the overlap of the expanded observational datasets is examined.
```{r, fig.cap='FIGUREA1. SubfigureD:LDW-CPS1-PLUS. SubfigureE:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
ldw_cps_plus.ps <- assess_overlap(data = ldw_cps_plus, treat = treat, cov = covar) 
ldw_psid_plus.ps <- assess_overlap(data = ldw_psid_plus, treat = treat, cov = covar)
```

As expected, the datasets LDW-CPS1-PLUS and LDW-PSID1-PLUS show an improved overlap compared to their non-plus states.

For the following analysis, we set up a model formula.
```{r, message=FALSE, warning=FALSE}
# set model formula
model <- as.formula(paste(treat, "~", paste(covar, collapse = " + ")))
```

### Covariate balance

To make treatment and control groups more comparable, thus mimicking a randomized experiment, initial covariate balance is assessed to determine the degree to which treatment and control groups differ on observed characteristics. Therefore, we employ visual summaries using `love.plot()` by @imbens2024, which depicts standardized mean differences across covariates before and after adjustment.
```{r, warning=FALSE, message=FALSE, fig.cap='FIGUREA2. SubfigureA:LDW-CPS1. SubfigureB:LDW-CPS1-PLUS. SubfigureC:LDW-PSID1. SubfigureD:LDW-PSID1-PLUS.', out.width='80%', fig.asp=1, fig.align='center'}
# plot balance
love.plot(ldw, ldw_cps, treat, covar = covar, title = "LDW-CPS1")
love.plot(ldw, ldw_psid, treat, covar = covar, title = "LDW-PSID1")
love.plot(ldw, ldw_cps_plus, treat, covar = covar, title = "LDW-CPS1-PLUS")
love.plot(ldw, ldw_psid_plus, treat, covar = covar, title = "LDW-PSID1-PLUS")
```

Neither LDW-CPS1-PLUS nor LDW-PSID1-PLUS shows consistently improved covariate balance compared to their non-plus counterparts based on raw standardized mean differences. Although some specific covariates improve slightly, most show increased imbalance.

<div class="callout-note">
For the subsequent analysis aimed at enhancing covariate balance and overlap, only the two datasets LDW-CPS1 and LDW-PSID1 are used. The LDW-Experimental dataset is excluded from these steps, as randomization already ensures adequate covariate balance and overlap. 
</div>

## Improving overlap
### Single methods
#### Trimming 

The purpose of trimming is to remove units whose propensity scores are too dissimilar from the opposite group, thereby improving covariate balance between treated and control groups. Below, we employ several trimming methods in line with the approaches proposed by @Stuermer_2021 and @imbens2024.

1) Propensity score threshold trimming 
```{r, message=FALSE, warning=FALSE}
# apply trimming with threshold 0.9
ldw_cps.ps_trim <- ps_trim(ldw_cps.ps, threshold = 0.9)
ldw_psid.ps_trim <- ps_trim(ldw_psid.ps, threshold = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_trim <- ps_estimate(data = ldw_cps.ps_trim, treat = treat, cov = covar)
ldw_psid.ps_trim <- ps_estimate(data = ldw_psid.ps_trim, treat = treat, cov = covar)
```

2) Common range trimming
```{r, message=FALSE, warning=FALSE}
# trim observations outside the common support region of propensity scores
ldw_cps.ps_common   <- common_range_trim(ldw_cps.ps)
ldw_psid.ps_common  <- common_range_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_common <- ps_estimate(data = ldw_cps.ps_common, treat = treat, cov = covar)
ldw_psid.ps_common <- ps_estimate(data = ldw_psid.ps_common, treat = treat, cov = covar)
```

3) Crump trimming 
```{r, message=FALSE, warning=FALSE}
# trim observations with propensity scores outside [0.1, 0.9] interval
ldw_cps.ps_crump  <- crump_trim(ldw_cps.ps, lower = 0.1, upper = 0.9)
ldw_psid.ps_crump <- crump_trim(ldw_psid.ps, lower = 0.1, upper = 0.9)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_crump <- ps_estimate(data = ldw_cps.ps_crump, treat = treat, cov = covar)
ldw_psid.ps_crump <- ps_estimate(data = ldw_psid.ps_crump, treat = treat, cov = covar)
```

4) Stuermer trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on propensity score quantiles separately for treated and control
ldw_cps.ps_stuermer  <- stuermer_trim(ldw_cps.ps)
ldw_psid.ps_stuermer <- stuermer_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_stuermer <- ps_estimate(data = ldw_cps.ps_stuermer, treat = treat, cov = covar)
ldw_psid.ps_stuermer <- ps_estimate(data = ldw_psid.ps_stuermer, treat = treat, cov = covar)
```

5) Walker trimming
```{r, message=FALSE, warning=FALSE}
# trim observations based on preference scores that adjust for treatment prevalence using logit transformations
ldw_cps.ps_walker  <- walker_trim(ldw_cps.ps)
ldw_psid.ps_walker <- walker_trim(ldw_psid.ps)

# re-estimate propensity scores on trimmed data 
ldw_cps.ps_walker <- ps_estimate(data = ldw_cps.ps_walker, treat = treat, cov = covar)
ldw_psid.ps_walker <- ps_estimate(data = ldw_psid.ps_walker, treat = treat, cov = covar)
```

### Integrated methods
#### Trimming and matching 

The purpose of matching is to create comparable treated and control groups by pairing units with similar covariate profiles, thereby reducing covariate imbalance and confounding bias. We apply several matching methods as outlined by @Greifer_3_2025 in the following. 

<div class="callout-note">
For comparison, combinations of trimming and matching methods are applied in line with the tutorial by @imbens2024, before being applied to the initial datasets.
</div>

##### Extended datasets (similar to tutorial by @imbens2024)
```{r, message=FALSE, warning=FALSE}
ldw_cps_trim <- ps_trim(ldw_cps_plus.ps, threshold = 0.9)
ldw_psid_trim <- ps_trim(ldw_psid_plus.ps, threshold = 0.8)

# excluding the experimental controls
ldw_cps.trim_match <- subset(ldw_cps_trim, sample %in% c(1,3) & ps_assoverlap)
ldw_psid.trim_match <- subset(ldw_psid_trim, sample %in% c(1,4) & ps_assoverlap)

# re-estimate propensity scores and employ 1:1 matching
ldw_cps.trim_match <- psmatch(data = ldw_cps.trim_match, Y = "re78", treat = "treat", cov = covar)
ldw_psid.trim_match <- psmatch(data = ldw_psid.trim_match, Y = "re78", treat = "treat", cov = covar)

# further subset data and re-assign treat variable 
ldw_trim_cps <- subset(ldw_cps_trim, sample %in% c(1,2) & ps_assoverlap <= 0.9)
ldw_trim_cps$treat[which(ldw_trim_cps$sample == 2)] <- 0

ldw_trim_psid <- subset(ldw_psid_trim, sample %in% c(1,2) & ps_assoverlap <= 0.8)
ldw_trim_psid$treat[which(ldw_trim_psid$sample == 2)] <- 0
```

```{r, message=FALSE, warning=FALSE}
all_trim.cps  <- list(
  ps_threshold = ldw_cps.ps_trim, 
  common_range = ldw_cps.ps_common, 
  stuermer = ldw_cps.ps_stuermer, 
  walker = ldw_cps.ps_walker, 
  crump = ldw_cps.ps_crump)

all_trim.psid  <- list(
  ps_threshold = ldw_psid.ps_trim, 
  common_range = ldw_psid.ps_common, 
  stuermer = ldw_psid.ps_stuermer, 
  walker = ldw_psid.ps_walker, 
  crump = ldw_psid.ps_crump)
```

##### Initial datasets

###### Distance matching
1) 1:1 Nearest neighbor matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with k=1, logistic propensity score and replacement
nn_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "nearest", distance = "glm", link = "logit", replace = TRUE)
nn_trim_comb.psid <- attach_matchit(model, data_list = all_trim.psid, method = "nearest", distance = "glm", link = "logit", replace = TRUE)

names(match.data(nn_trim_comb.cps[[1]]))
names(match.data(nn_trim_comb.psid[[1]]))

bal<- bal.tab(nn_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")
bal$Balance$Diff.Adj

bal<- bal.tab(nn_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

2) k:1 matching (k=2) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with k=2, logistic propensity score and replacement
k<-2
k2_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "nearest", distance = "glm", link = "logit", ratio = k, replace = TRUE)
k2_trim_comb.psid <- attach_matchit(model, data_list = all_trim.psid, method = "nearest", distance = "glm", link = "logit", ratio = k, replace = TRUE)

names(match.data(k2_trim_comb.cps[[1]]))
names(match.data(k2_trim_comb.psid[[1]]))

bal<-bal.tab(k2_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(k2_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

3) k:1 matching (k=3) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with k=3, logistic propensity score and replacement
k<-3
k3_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "nearest", distance = "glm", link = "logit", ratio = k, replace = TRUE)
k3_trim_comb.psid <- attach_matchit(model, data_list = all_trim.psid, method = "nearest", distance = "glm", link = "logit", ratio = k, replace = TRUE)

names(match.data(k3_trim_comb.cps[[1]]))
names(match.data(k3_trim_comb.psid[[1]]))

bal<-bal.tab(k3_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")
bal$Balance$Diff.Adj

bal<-bal.tab(k3_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

4) Caliper matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with a caliper of 0.1 on the logistic propensity score 
caliper_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "nearest", distance = "glm", link = "logit", caliper = 0.1, replace = TRUE)
caliper_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "nearest", distance = "glm", link = "logit", caliper = 0.1, replace = TRUE)

names(match.data(caliper_trim_comb.cps[[1]]))
names(match.data(caliper_trim_comb.psid[[1]]))

bal<-bal.tab(caliper_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")
bal$Balance$Diff.Adj

bal<-bal.tab(caliper_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

5) Common support restriction matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching with exclusion of units outside common support
cs_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "nearest", distance = "glm", link = "logit", discard = "both", reestimate = TRUE, replace = TRUE)
cs_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "nearest", distance = "glm", link = "logit", discard = "both", reestimate = TRUE, replace = TRUE)

names(match.data(cs_trim_comb.cps[[1]], data = all_trim.cps[[1]]))
names(match.data(cs_trim_comb.psid[[1]], data = all_trim.psid[[1]]))

bal<-bal.tab(cs_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(cs_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

6) Mahalanobis distance matching (mahvars) with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform nearest neighbor matching using mahalanobis distance
mahvars_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "nearest", distance = "mahalanobis", replace = FALSE)
mahvars_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "nearest", distance = "mahalanobis", replace = FALSE)

names(match.data(mahvars_trim_comb.cps[[1]], data = all_trim.cps[[1]]))
names(match.data(mahvars_trim_comb.psid[[1]], data = all_trim.psid[[1]]))

bal<-bal.tab(mahvars_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(mahvars_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

7) Optimal pair matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform optimal pair matching that minimizes total within-pair distance on propensity scores
optimal_pair_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "optimal", distance = "glm", link = "logit")
optimal_pair_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "optimal", distance = "glm", link = "logit")

names(match.data(optimal_pair_trim_comb.cps[[1]]))
names(match.data(optimal_pair_trim_comb.psid[[1]]))

bal<-bal.tab(optimal_pair_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(optimal_pair_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

8) Optimal full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform optimal full matching allowing sets with varying ratios of treated to controls and minimizing a global distance criterion
optimal_full_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "full", distance = "glm", link = "logit")
optimal_full_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "full", distance = "glm", link = "logit")

names(match.data(optimal_full_trim_comb.cps[[1]]))
names(match.data(optimal_full_trim_comb.psid[[1]]))

bal<-bal.tab(optimal_full_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(optimal_full_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

9) Generalized full matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform generalized full matching using fast approximation and producing matched sets with flexible treated/control ratios 
general_full_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "quick", distance = "glm", link = "logit")
general_full_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "quick", distance = "glm", link = "logit")

names(match.data(general_full_trim_comb.cps[[1]]))
names(match.data(general_full_trim_comb.psid[[1]]))

bal<-bal.tab(general_full_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(general_full_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

10) Genetic matching with 1) propensity threshold 2) common range 3) stuermer 4) walker 5) crump trimming
```{r, message=FALSE, warning=FALSE}
# perform genetic matching 
genetic_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "genetic", distance = "glm", link = "logit", replace = TRUE, pop.size = 100)
genetic_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "genetic", distance = "glm", link = "logit", replace = TRUE, pop.size = 100)

names(match.data(genetic_trim_comb.cps[[1]]))
names(match.data(genetic_trim_comb.psid[[1]]))

bal<-bal.tab(genetic_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(genetic_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

###### Stratum matching
11) Exact matching (exact)
```{r, message=FALSE, warning=FALSE}
# match units exactly by raw covariate profiles 
exact_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "exact")
exact_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "exact")

names(match.data(exact_trim_comb.cps[[1]], data = all_trim.cps[[1]]))
names(match.data(exact_trim_comb.psid[[1]], data = all_trim.psid[[1]]))

bal<-bal.tab(exact_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(exact_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

12) Coarsened matching (cem)
```{r, message=FALSE, warning=FALSE}
# match units exactly within coarse strata 
cem_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "cem")
cem_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "cem")

names(match.data(cem_trim_comb.cps[[1]], data = all_trim.cps[[1]]))
names(match.data(cem_trim_comb.psid[[1]], data = all_trim.psid[[1]]))

bal<-bal.tab(cem_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(cem_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

13) Subclassification 
```{r, message=FALSE, warning=FALSE}
# partition sample into fixed number of bins based on propensity score 
subcl_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "subclass", subclass = 5)
subcl_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "subclass", subclass = 5)

names(match.data(subcl_trim_comb.cps[[1]]))
names((subcl_trim_comb.psid[[1]]))

bal<-bal.tab(subcl_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(subcl_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

###### Pure subset selection
14) Cardinality profile matching
```{r, message=FALSE, warning=FALSE}
# select largest balanced subsample meeting covariate balance tolerances and a fixed ratio of controls to treated units
card_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)
card_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "cardinality", tols = 0.1, ratio = 1, time = 1200)

names(match.data(card_trim_comb.cps[[1]], data = all_trim.cps[[1]]))
names(match.data(card_trim_comb.psid[[1]], data = all_trim.psid[[1]]))

bal<-bal.tab(card_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(card_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

15) Profile matching
```{r, message=FALSE, warning=FALSE}
# select the largest control group subset balanced to the treated group (for ATT), leaving the treated group intact
profile_trim_comb.cps <- attach_matchit(model, data_list = all_trim.cps, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, time = 1200)
profile_trim_comb.psid <- attach_matchit(model,data_list = all_trim.psid, method = "cardinality", estimand = "ATT", tols = 0.1, ratio = NA, time = 1200)

names(match.data(profile_trim_comb.cps[[1]], data = all_trim.cps[[1]]))
names(match.data(profile_trim_comb.psid[[1]], data = all_trim.psid[[1]]))

bal<-bal.tab(profile_trim_comb.cps[[1]], 
        data = all_trim.cps[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj

bal<-bal.tab(profile_trim_comb.psid[[1]], 
        data = all_trim.psid[[1]], 
        stats = "mean.diffs", 
        un = TRUE, 
        s.d.denom = "treated")

bal$Balance$Diff.Adj
```

## Assessing methods

We now systematically reassess all methods described above by evaluating the overlap coefficient (OVL) and the absolute standardized mean differences (ASMD). Specifically, we compute the ASMD and OVL for each approach and compute a composite score to determine the best performing methods.

### Single methods
#### Trimming
##### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trim.cps <- compute_abs_smd_trim(all_trim.cps, "treat", covar)
smd_trim.psid <- compute_abs_smd_trim(all_trim.psid, "treat", covar)
```

##### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trim.cps <- compute_ovl_trim(all_trim.cps, "ps_assoverlap", "treat")
ovl_trim.psid <- compute_ovl_trim(all_trim.psid, "ps_assoverlap", "treat")
```

### Integrated methods
#### Trimming and matching
##### Extended datasets
(Similar to tutorial by @imbens2024)
```{r, message=FALSE, warning=FALSE}
# list all trimmed and matched samples
trim_match_comb.cps_plus <- list(ps_threshold_match = ldw_cps.trim_match)
trim_match_comb.psid_plus <- list(ps_threshold_match = ldw_psid.trim_match)
```

###### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trim_match_comb.cps_plus <- compute_abs_smd_trim(trim_match_comb.cps_plus, "treat", covar)
smd_trim_match_comb.psid_plus <- compute_abs_smd_trim(trim_match_comb.psid_plus, "treat", covar)
```

###### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trim_match_comb.cps_plus <- compute_ovl_trim(trim_match_comb.cps_plus, "ps_assoverlap", "treat")
ovl_trim_match_comb.psid_plus <- compute_ovl_trim(trim_match_comb.psid_plus, "ps_assoverlap", "treat")
```

##### Initial datasets
```{r, message=FALSE, warning=FALSE}
# list all trimmed and matched samples
trim_match_comb.cps <- list(
  nn = nn_trim_comb.cps, 
  k2 = k2_trim_comb.cps,
  k3 = k3_trim_comb.cps, 
  caliper = caliper_trim_comb.cps,
  cs = cs_trim_comb.cps, 
  mahvars = mahvars_trim_comb.cps,
  optimal_pair = optimal_pair_trim_comb.cps,
  optimal_full = optimal_full_trim_comb.cps, 
  genetic = genetic_trim_comb.cps, 
  exact = exact_trim_comb.cps,
  cem = cem_trim_comb.cps,
  subcl = subcl_trim_comb.cps 
)

trim_match_comb.psid <- list(
  nn = nn_trim_comb.psid,
  k2 = k2_trim_comb.psid, 
  k3 = k3_trim_comb.psid, 
  caliper = caliper_trim_comb.psid, 
  cs = cs_trim_comb.psid,
  mahvars = mahvars_trim_comb.psid,
  optimal_pair = optimal_pair_trim_comb.psid, 
  optimal_full = optimal_full_trim_comb.psid, 
  genetic = genetic_trim_comb.psid,
  exact = exact_trim_comb.psid,
  cem = cem_trim_comb.psid,
  subcl = subcl_trim_comb.psid 
)
```

###### SMD
```{r, message=FALSE, warning=FALSE}
# compute absolute SMD
smd_trim_match_comb.cps <- compute_abs_smd_matchit(trim_match_comb.cps, all_trim.cps) 
smd_trim_match_comb.psid <- compute_abs_smd_matchit(trim_match_comb.psid, all_trim.psid)

smd_trim_match_comb.cps
smd_trim_match_comb.psid
```

###### OVL
```{r, message=FALSE, warning=FALSE}
# compute overlap coefficients
ovl_trim_match_comb.cps <- compute_ovl_matchit(trim_match_comb.cps, all_trim.cps, ps = "ps_assoverlap", treat = "treat", covar = covar)
ovl_trim_match_comb.psid <- compute_ovl_matchit(trim_match_comb.psid, all_trim.psid, ps = "ps_assoverlap", treat = "treat", covar = covar)

ovl_trim_match_comb.cps
```



## Identifying best methods

### Ranking
To identify the top five methods for each observational dataset, we first combine for each dataset all results of the absolute SMD and OVL into a single data frame. This allows for a comprehensive comparison across all methods.

<div class="callout-note">
Only results based on the non-plus datasets are included in the identification of the best methods, as the objective is to identify the overall best-performing methods for the original observational samples. 
</div>
```{r, message=FALSE, warning=FALSE}
# combine all results
all_cps <- combine_results("cps")
all_psid <- combine_results("psid") 

all_cps
```

```{r, message=FALSE, warning=FALSE}
# save results 
save_csv(all_cps, "ldw_model_a_cps1_all_results")
save_csv(all_psid, "ldw_model_a_psid1_all_results")
```

Next, each method is evaluated according to its OVL value. The top five methods are then selected based on the highest OVL values, with higher OVL values indicating better overlap between treated and control groups.
```{r, message=FALSE, warning=FALSE}
# rank comparatively
ranked_cps  <- assess_methods(all_cps)
ranked_psid <- assess_methods(all_psid)

# get top 5 methods 
top5_methods.cps <- get_top_methods(ranked_cps, top_n = 5)
top5_methods.psid <- get_top_methods(ranked_psid, top_n = 5)

# rerank top 5 methods 
```

```{r, message=FALSE, warning=FALSE}
# print results
top5_methods_df.cps <- ranked_cps %>% arrange(desc(OVL)) %>% head(5)
top5_methods_df.psid <- ranked_psid %>% arrange(desc(OVL)) %>% head(5)

datatable(top5_methods_df.cps, caption = "Top 5 Methods for CPS1",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
datatable(top5_methods_df.psid, caption = "Top 5 Methods for PSID1",
          options = list(scrollX = TRUE, paging = FALSE, pageLength = -1, searching = FALSE))
```


### Dataset construction
For the subsequent estimation, we need to construct datasets of the top‑ranked methods. Therefore, we match all method names back to their corresponding datasets, objects or vectors and construct corresponding datasets. 
```{r, message=FALSE, warning=FALSE}
trim_only_cps <- list(
        ps_threshold = ldw_cps.ps_trim,
        common_range = ldw_cps.ps_common,
        stuermer = ldw_cps.ps_stuermer,
        walker = ldw_cps.ps_walker,
        crump = ldw_cps.ps_crump
)

match_lookup_cps <- c(
        wrap_match_entries(nn_trim_comb.cps, all_trim.cps, "nn"),
        wrap_match_entries(k2_trim_comb.cps, all_trim.cps, "k2"),
        wrap_match_entries(k3_trim_comb.cps, all_trim.cps, "k3"),
        wrap_match_entries(caliper_trim_comb.cps, all_trim.cps, "caliper"),
        wrap_match_entries(cs_trim_comb.cps, all_trim.cps, "cs"),
        wrap_match_entries(mahvars_trim_comb.cps, all_trim.cps, "mahvars"),
        wrap_match_entries(optimal_pair_trim_comb.cps, all_trim.cps, "optimal_pair"),
        wrap_match_entries(optimal_full_trim_comb.cps, all_trim.cps, "optimal_full"),
        wrap_match_entries(genetic_trim_comb.cps, all_trim.cps, "genetic"),
        wrap_match_entries(exact_trim_comb.cps, all_trim.cps, "exact"),
        wrap_match_entries(cem_trim_comb.cps, all_trim.cps, "cem"),
        wrap_match_entries(subcl_trim_comb.cps, all_trim.cps, "subcl")
)

trim_only_psid <- list(
        ps_threshold = ldw_psid.ps_trim,
        common_range = ldw_psid.ps_common,
        stuermer = ldw_psid.ps_stuermer,
        walker = ldw_psid.ps_walker,
        crump = ldw_psid.ps_crump
)

match_lookup_psid <- c(
        wrap_match_entries(nn_trim_comb.psid, all_trim.psid, "nn"),
        wrap_match_entries(k2_trim_comb.psid, all_trim.psid, "k2"),
        wrap_match_entries(k3_trim_comb.psid, all_trim.psid, "k3"),
        wrap_match_entries(caliper_trim_comb.psid, all_trim.psid, "caliper"),
        wrap_match_entries(cs_trim_comb.psid, all_trim.psid, "cs"),
        wrap_match_entries(mahvars_trim_comb.psid, all_trim.psid, "mahvars"),
        wrap_match_entries(optimal_pair_trim_comb.psid, all_trim.psid, "optimal_pair"),
        wrap_match_entries(optimal_full_trim_comb.psid, all_trim.psid, "optimal_full"),
        wrap_match_entries(genetic_trim_comb.psid, all_trim.psid, "genetic"),
        wrap_match_entries(exact_trim_comb.psid, all_trim.psid, "exact"),
        wrap_match_entries(cem_trim_comb.psid, all_trim.psid, "cem"),
        wrap_match_entries(subcl_trim_comb.psid, all_trim.psid, "subcl")
)

list_cps <- c(trim_only_cps, match_lookup_cps)
list_psid <- c(trim_only_psid, match_lookup_psid)
```

```{r, message=FALSE, warning=FALSE}
# create datasets corresponding to the top 5 methods for each dataset
top5_datasets.cps <- create_top5_datasets(list_cps, top5_methods.cps)
top5_datasets.psid <- create_top5_datasets(list_psid, top5_methods.psid)
```

```{r, message=FALSE, warning=FALSE}
# save datasets into .RData files
save_top5_datasets(list_cps, top5_methods.cps, prefix = "ldw_model_a_cps1")
save_top5_datasets(list_psid, top5_methods.psid, prefix = "ldw_model_a_psid1")
```


## Estimating
### Average treatment effect on the treated (ATT)

Next, we estimate the average treatment effect on the treated (ATT) using the LDW-Experimental sample, the top‑ranked observational samples (LDW‑CPS1 and LDW‑PSID1), and, for comparison, the trimmed and matched plus‑datasets. We employ a broad set of estimators, including difference-in-means, regression, the Oaxaca-Blinder estimator, generalized random forests (GRF) as an outcome model, 1:5 nearest neighbor matching with bias correction, inverse probability weighting (IPW) with GRF-based propensity scores, covariate balancing propensity score (CBPS), entropy balancing, double/debiased machine learning using elastic net, and augmented inverse probability weighting (AIPW) via GRF. We also incorporate the recently introduced estimand-specific AIPW estimator implemented through an expansion of the `OutcomeWeights` R package by @OW_Package.

We utilize the `estimate_all()` and `plot_coef()` functions as defined by @imbens2024.
```{r, message=FALSE, warning=FALSE}
# estimate ATT
out1 <- estimate_all(ldw, "re78", "treat", covar)
out2 <- estimate_all(ldw_cps, "re78", "treat", covar)
out3 <- estimate_all(ldw_psid, "re78", "treat", covar)

out.cps <- lapply(top5_datasets.cps, function(d) estimate_all(d, "re78", "treat", covar))
out.psid <- lapply(top5_datasets.psid, function(d) estimate_all(d, "re78", "treat", covar))

out4 <- out.cps[[1]]
out5 <- out.cps[[2]]
out6 <- out.cps[[3]]
out7 <- out.cps[[4]]
out8 <- out.cps[[5]]

out9 <- out.psid[[1]]
out10 <- out.psid[[2]]
out11 <- out.psid[[3]]
out12 <- out.psid[[4]]
out13 <- out.psid[[5]]
print("Estimation completed.")
```

<!--chapter:end:tutorial/02-LDW-Model-A.Rmd-->

